<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="2b185d63fe43e391e79f2722fa9c01f4" category="summary">Leia blogs de IA/ML que destacam tendências do setor, inovações e impacto no mundo real, bem como recursos para desenvolvedores, insights da comunidade e ferramentas práticas para trabalhar com soluções de IA da NetApp .</block>
  <block id="7a206e7f1f7bd7df4f649256e750768b" category="doc">Leia blogs sobre soluções de IA de especialistas da NetApp</block>
  <block id="683be49e9105a56d06431bcdc1630cb6" category="paragraph">Leia os blogs de IA/ML que destacam tendências do setor, inovações e impacto no mundo real, além de recursos para desenvolvedores, insights da comunidade e ferramentas práticas para trabalhar com soluções de IA da NetApp .</block>
  <block id="5bbe94ba0a14c52be3cc9534b43f4713" category="paragraph-title">Tendências de IA e insights do setor</block>
  <block id="78463a384a5aa4fad5fa73e2f506ecfc" category="inline-link-macro">Inglês</block>
  <block id="69501f595c5bd3cdb17ea63c90291622" category="paragraph">Explore tendências do setor, inovações e impacto real da IA em vários setores. <block ref="3b277c3e8740f32e48fe9dd888ed34aa" category="inline-link-macro-rx"></block> &amp;f:@facet_soultion_mktg=[IA,Análise,inteligência-artificial]++[Leia blogs sobre IA no NetApp.com^]</block>
  <block id="d5769d364696d52f17c7b56bd51573f8" category="paragraph-title">Recursos e comunidade para desenvolvedores</block>
  <block id="bb765a119d53333b43f301b6a00a388a" category="inline-link-macro">Leia blogs de IA no Pub</block>
  <block id="43c273574ee7233878bcc9fc0bd893c9" category="paragraph">Insights técnicos, ferramentas práticas e conteúdo voltado para a comunidade para profissionais de IA/ML.<block ref="f89e2ffa35ae5933259a8ae6e49a69ad" category="inline-link-macro-rx"></block></block>
  <block id="e7ee239a021c71c67431ac1c23b9cf1e" category="summary">O artigo fornece um guia para criar um pipeline de MLOps com serviços da AWS, com foco em retreinamento automatizado de modelos, implantação e otimização de custos.</block>
  <block id="b77650c231f63812b48a3802736172ae" category="doc">Parte 3 - Construindo um Pipeline MLOps Simplificado (CI/CT/CD)</block>
  <block id="3fc6ea95b9f9aac82c7a39c3743664ba" category="paragraph">Este artigo fornece um guia para criar um pipeline de MLOps com serviços da AWS, com foco em retreinamento automatizado de modelos, implantação e otimização de custos.</block>
  <block id="0b79795d3efc95b9976c7c5b933afce2" category="section-title">Introdução</block>
  <block id="4c04d3884cafb85369c7a0a6b81d10b0" category="paragraph">Neste tutorial, você aprenderá como aproveitar vários serviços da AWS para construir um pipeline de MLOps simples que abrange integração contínua (CI), treinamento contínuo (CT) e implantação contínua (CD).  Ao contrário dos pipelines tradicionais de DevOps, o MLOps requer considerações adicionais para concluir o ciclo operacional.  Ao seguir este tutorial, você obterá insights sobre como incorporar CT no loop MLOps, permitindo o treinamento contínuo de seus modelos e implantação perfeita para inferência.  O tutorial guiará você pelo processo de utilização dos serviços da AWS para estabelecer esse pipeline de MLOps de ponta a ponta.</block>
  <block id="76c3e002d3c052bd6a909366a8dc3845" category="section-title">Manifesto</block>
  <block id="e7e0038bb30579a3120d266861982881" category="cell">Funcionalidade</block>
  <block id="49ee3087348e8d44e1feda1917443987" category="cell">Nome</block>
  <block id="0be8406951cdfda82f00f79328cf4efc" category="cell">Comentário</block>
  <block id="dc21b082b0947a93d387b8c7e8f89ee5" category="cell">Armazenamento de dados</block>
  <block id="f3eec26de1c09022af7c97255f0dfee6" category="cell">AWS FSx ONTAP</block>
  <block id="ae8cde6d64ec0b4ed71f7e4d5a28d65f" category="inline-link-macro">Parte 1 - Integrando o Amazon FSx for NetApp ONTAP (FSx ONTAP) como um bucket S3 privado no AWS SageMaker</block>
  <block id="273b64842c06632a1f361f1a341b8c24" category="cell">Consulte <block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block> .</block>
  <block id="4c5f43ed06df4b05c18ca410c7016249" category="cell">IDE de ciência de dados</block>
  <block id="5a1439989b12745b5a4ed4b944539247" category="cell">AWS SageMaker</block>
  <block id="4c99a9cb175cf27f5edb2b2a9e21f32c" category="inline-link-macro">Parte 2 - Aproveitando o Amazon FSx for NetApp ONTAP (FSx ONTAP) como uma fonte de dados para treinamento de modelos no SageMaker</block>
  <block id="077914145dbaab3cc9a1f25998b4b703" category="cell">Este tutorial é baseado no notebook Jupyter apresentado em<block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block> .</block>
  <block id="e1d9ae96a3cc2d87549ec614a5eea75b" category="cell">Função para disparar o pipeline MLOps</block>
  <block id="10740b99bf79c58d32e1a8e73062d05c" category="cell">Função AWS Lambda</block>
  <block id="336d5ebc5436534e61d16e63ddfca327" category="cell">-</block>
  <block id="0fc1223c31c6d7d5d233235c0a8f3ee0" category="cell">Gatilho de tarefa cron</block>
  <block id="0abaf4e46241f987a0b4e6a434e596cd" category="cell">AWS EventBridge</block>
  <block id="e015867873eac103879d29f569610c66" category="cell">Estrutura de aprendizagem profunda</block>
  <block id="95b88f180e9eb5678e0f9ebac2cbe643" category="cell">PyTorch</block>
  <block id="6af8c08e3948b664c72a8cc3c2709254" category="cell">SDK do AWS Python</block>
  <block id="6686853da3491a56c98917cc5c4ddea2" category="cell">boto3</block>
  <block id="4f465e36f699fcf0570d854d9f692508" category="cell">Linguagem de programação</block>
  <block id="a7f5f35426b927411fc9231b56382173" category="cell">Pitão</block>
  <block id="cd9ec78e2cad962acfcab027dd62d904" category="cell">v3.10</block>
  <block id="925335f81021de4d22fde55ae7f0e86a" category="section-title">Pré-requisito</block>
  <block id="368743a79699dd2e9a1db93cb728196a" category="list-text">Um sistema de arquivos FSx ONTAP pré-configurado.  Este tutorial utiliza dados armazenados no FSx ONTAP para o processo de treinamento.</block>
  <block id="73d970f5582fe283900cc4b125f71ab0" category="list-text">Uma *instância do SageMaker Notebook* configurada para compartilhar a mesma VPC que o sistema de arquivos FSx ONTAP mencionado acima.</block>
  <block id="cd201faac7e3cf792faa46c93195c65b" category="list-text">Antes de acionar a *função AWS Lambda*, certifique-se de que a *instância do SageMaker Notebook* esteja no status *interrompido*.</block>
  <block id="238f736fdf6bcdcd7f397969fe6eb36e" category="list-text">O tipo de instância *ml.g4dn.xlarge* é necessário para aproveitar a aceleração da GPU necessária para os cálculos de redes neurais profundas.</block>
  <block id="2d242bb36ec91b32005f9296ff03a912" category="section-title">Arquitetura</block>
  <block id="2c03bdafce7f1816c8faa5db2e5d1258" category="paragraph"><block ref="2c03bdafce7f1816c8faa5db2e5d1258" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e320ad9e531a78d8b06272138f0f29b7" category="paragraph">Este pipeline MLOps é uma implementação prática que utiliza uma tarefa cron para acionar uma função sem servidor, que por sua vez executa um serviço da AWS registrado com uma função de retorno de chamada do ciclo de vida.  O *AWS EventBridge* atua como uma tarefa cron.  Ele invoca periodicamente uma *função AWS Lambda* responsável por retreinar e reimplantar o modelo.  Este processo envolve a criação da instância do *AWS SageMaker Notebook* para executar as tarefas necessárias.</block>
  <block id="2f53ab942978849d906d82a87554a1e2" category="section-title">Configuração passo a passo</block>
  <block id="ecce3b4394f7f06232bad571a96a0391" category="section-title">Configurações do ciclo de vida</block>
  <block id="8482e23b03456ee8ac2760d540c11442" category="paragraph">Para configurar a função de retorno de chamada do ciclo de vida para a instância do AWS SageMaker Notebook, você utilizaria *Configurações do ciclo de vida*.  Este serviço permite que você defina as ações necessárias a serem executadas durante a inicialização da instância do notebook.  Especificamente, um script de shell pode ser implementado dentro das *Configurações do ciclo de vida* para desligar automaticamente a instância do notebook assim que os processos de treinamento e implantação forem concluídos.  Esta é uma configuração necessária, pois o custo é uma das principais considerações em MLOps.</block>
  <block id="79d14d6493dc1a7a7d33bf031166f9a9" category="paragraph">É importante observar que a configuração para *Configurações do ciclo de vida* precisa ser definida com antecedência.  Portanto, é recomendável priorizar a configuração desse aspecto antes de prosseguir com a configuração de outros pipelines do MLOps.</block>
  <block id="29beb103651093d4e75530e25a50f4bd" category="list-text">Para definir as configurações do ciclo de vida, abra o painel *Sagemaker* e navegue até *Configurações do ciclo de vida* na seção *Configurações do administrador*.</block>
  <block id="e40d22b369f011035946ad31f47b655a" category="inline-image-macro">Painel SageMaker</block>
  <block id="808aecfbb727487113195461863f7b8f" category="paragraph"><block ref="808aecfbb727487113195461863f7b8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="706c89d427897aa8c9093c9ea4ddf1cb" category="list-text">Selecione a aba *Instância do Notebook* e clique no botão *Criar configuração*</block>
  <block id="6d548bb5536b7ca36996b9a2bf7f3fc9" category="inline-image-macro">Página de boas-vindas da configuração do ciclo de vida</block>
  <block id="533585f6e9e5ce51a2cd2322d75dfd10" category="paragraph"><block ref="533585f6e9e5ce51a2cd2322d75dfd10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4bfce2cb9f46fa7b22c7f04d6aa38b9e" category="list-text">Cole o código abaixo na área de entrada.</block>
  <block id="a3c7be0a54a45c8a39d852df0ffe5795" category="list-text">Este script executa o Jupyter Notebook, que lida com o retreinamento e a reimplantação do modelo para inferência.  Após a conclusão da execução, o notebook será desligado automaticamente em 5 minutos.  Para saber mais sobre a declaração do problema e a implementação do código, consulte<block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block> .</block>
  <block id="f8d2f79250f54a742eec560a47022213" category="inline-image-macro">Criar configuração de ciclo de vida</block>
  <block id="32868d8eaf16b0e5d6cc389594591fa8" category="paragraph"><block ref="32868d8eaf16b0e5d6cc389594591fa8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a835fb020d342258f64fe6be9b11cc29" category="list-text">Após a criação, navegue até Instâncias do Notebook, selecione a instância de destino e clique em *Atualizar configurações* no menu suspenso Ações.</block>
  <block id="386c8dd530ade6b4cdc15f9f6ebad5c4" category="inline-image-macro">Menu suspenso de configurações de atualização</block>
  <block id="c2ba792fac24b100bacf8cb5998dfc1e" category="paragraph"><block ref="c2ba792fac24b100bacf8cb5998dfc1e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2f80499d713c8d9fe19313ec1dc9bd45" category="list-text">Selecione a *Configuração do ciclo de vida* criada e clique em *Atualizar instância do notebook*.</block>
  <block id="929b843b11b6f17c62198cd38020bfe6" category="inline-image-macro">Atualizar a configuração do ciclo de vida do notebook</block>
  <block id="e0dc07a964d60792b3ec801e8395ef77" category="paragraph"><block ref="e0dc07a964d60792b3ec801e8395ef77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a0f9cbbefa9b9603cf2241f33621e37" category="section-title">Função sem servidor do AWS Lambda</block>
  <block id="4a799fa8d490fae92d630fe6cc65b928" category="paragraph">Como mencionado anteriormente, a *função AWS Lambda* é responsável por iniciar a *instância do AWS SageMaker Notebook*.</block>
  <block id="be107f93440a41fcae408e1abec6403e" category="list-text">Para criar uma *função AWS Lambda*, navegue até o painel respectivo, alterne para a guia *Funções* e clique em *Criar função*.</block>
  <block id="d28550fe1b16be91a51602ddd8c1d60f" category="inline-image-macro">Página inicial da função lambda da AWS</block>
  <block id="627b95a2fda6260f5df8d487a291ceea" category="paragraph"><block ref="627b95a2fda6260f5df8d487a291ceea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a60f634c6f68222d8abaaa29bd057217" category="list-text">Preencha todas as entradas necessárias na página e lembre-se de mudar o tempo de execução para *Python 3.10*.</block>
  <block id="267b7733eb14e4bbd98146ea3f8501b1" category="inline-image-macro">Crie uma função lambda da AWS</block>
  <block id="cce551decdf09efb16caf7432d6c7eba" category="paragraph"><block ref="cce551decdf09efb16caf7432d6c7eba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bee22bc8ca787cbf1475d27ae7429d6" category="list-text">Verifique se a função designada tem a permissão necessária *AmazonSageMakerFullAccess* e clique no botão *Criar função*.</block>
  <block id="3f6a1b36a855303ea55de235a44c52b0" category="inline-image-macro">Selecione a função de execução</block>
  <block id="fa8e9001a3295e1f7a1f8d3ef3e92572" category="paragraph"><block ref="fa8e9001a3295e1f7a1f8d3ef3e92572" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fcc43af2494337ee641b41a13f71fc46" category="list-text">Selecione a função Lambda criada.  Na aba de código, copie e cole o seguinte código na área de texto.  Este código inicia a instância do notebook chamada *fsxn-ontap*.</block>
  <block id="c2edd2bdf75433b7f31062be9571f528" category="list-text">Clique no botão *Implantar* para aplicar esta alteração de código.</block>
  <block id="ea355214fd4bc7c57f471bd92918879b" category="inline-image-macro">Implantação</block>
  <block id="64446fff99d978434b172f7c745ece52" category="paragraph"><block ref="64446fff99d978434b172f7c745ece52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b9bb44167ffa5f5dc2d30616b32fe21b" category="list-text">Para especificar como acionar esta função do AWS Lambda, clique no botão Adicionar acionador.</block>
  <block id="c8d04adc09d32f5c953177228f96826b" category="inline-image-macro">Adicionar gatilho de função AWS</block>
  <block id="6297ab474f745fe7abc72cd5f148311b" category="paragraph"><block ref="6297ab474f745fe7abc72cd5f148311b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ba138d79283b1a8aad0ef0cc35ce105" category="list-text">Selecione EventBridge no menu suspenso e clique no botão de opção Criar uma nova regra.  No campo de expressão do cronograma, insira<block ref="5bb28b828095c4a920fb3d34b89c2b84" prefix=" " category="inline-code"></block> e clique no botão Adicionar para criar e aplicar esta nova regra de tarefa cron à função do AWS Lambda.</block>
  <block id="4ab295fce5805d57b17ce3316bf007fa" category="inline-image-macro">Finalizar gatilho</block>
  <block id="46f9833b45661170323abab7808e6219" category="paragraph"><block ref="46f9833b45661170323abab7808e6219" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3643e50ab12ef03d2731f0654366409d" category="paragraph">Após concluir a configuração em duas etapas, diariamente, a *função AWS Lambda* iniciará o *SageMaker Notebook*, executará o retreinamento do modelo usando os dados do repositório *FSx ONTAP*, reimplantará o modelo atualizado no ambiente de produção e desligará automaticamente a *instância do SageMaker Notebook* para otimizar custos.  Isso garante que o modelo permaneça atualizado.</block>
  <block id="0be5bfaeb8f14cd39a235e5050cecbc9" category="paragraph">Isso conclui o tutorial para desenvolver um pipeline de MLOps.</block>
  <block id="fbf39511561166f560c51e6bdf601a0e" category="summary">Esta é a página introdutória da seção FSx ONTAP MLOps.</block>
  <block id="28cd7fd0e401ee73677b7f7441149a51" category="doc">Amazon FSx for NetApp ONTAP (FSx ONTAP) para MLOps</block>
  <block id="fba7ee1ae1e1979f64e6e11317d235ff" category="paragraph">Esta seção se aprofunda na aplicação prática do desenvolvimento de infraestrutura de IA, fornecendo um passo a passo completo da construção de um pipeline MLOps usando o FSx ONTAP.  Composto por três exemplos abrangentes, ele orienta você a atender às suas necessidades de MLOps por meio desta poderosa plataforma de gerenciamento de dados.</block>
  <block id="e2e58416305212ecee9fc44a8a57e389" category="paragraph">Esses artigos se concentram em:</block>
  <block id="a4f6db8ee799d71c8436c5d66421c857" category="list-text"><block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block></block>
  <block id="3f7fd29e3ed2add54c00cc8c8501cde7" category="list-text"><block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block></block>
  <block id="71b4f7c054c855f2e85df08fc5e39095" category="list-text"><block ref="71b4f7c054c855f2e85df08fc5e39095" category="inline-link-macro-rx"></block></block>
  <block id="8b34d4c412144b306293274a1964c465" category="paragraph">Ao final desta seção, você terá adquirido uma sólida compreensão de como usar o FSx ONTAP para otimizar os processos de MLOps.</block>
  <block id="f3be583adfbfc01a44597d4c6f7e4ef5" category="summary">Esta postagem fornece um guia sobre como configurar o FSx ONTAP como um bucket S3 privado usando o AWS SageMaker.</block>
  <block id="405642837c20faf5ee6d81b4d039206f" category="paragraph">Esta seção fornece um guia sobre como configurar o FSx ONTAP como um bucket S3 privado usando o AWS SageMaker.</block>
  <block id="8c52c9bdd7d9ef6a6f82004af97fae7b" category="paragraph">Usando o SageMaker como exemplo, esta página fornece orientação sobre como configurar o FSx ONTAP como um bucket S3 privado.</block>
  <block id="69620f6919f430e72c0f67207535605b" category="inline-link-macro">Link do vídeo</block>
  <block id="2b6442845e4dd1bf2e9140ac796e1a93" category="paragraph">Para mais informações sobre o FSx ONTAP, consulte esta apresentação (<block ref="f781ab67717d91cabffd32c6ef2dd731" category="inline-link-macro-rx"></block> )</block>
  <block id="7a97419a6312bf2f5dcdb87d844f3d07" category="section-title">Guia do usuário</block>
  <block id="2f5513954af7462427835c65fbeeac6d" category="section-title">Criação de servidor</block>
  <block id="aa5fe14483191172e4fb6ae032e063db" category="section-title">Criar uma instância do SageMaker Notebook</block>
  <block id="22a9741b15ba6b8515c1bcf1eb1e2424" category="list-text">Abra o console da AWS.  No painel de pesquisa, pesquise SageMaker e clique no serviço *Amazon SageMaker*.</block>
  <block id="f81ad91c4e9a7e4840e3c7a28ad316cb" category="inline-image-macro">Abra o console da AWS</block>
  <block id="91ff4fb5f0a57e0f0b2c24cdefb4f12b" category="paragraph"><block ref="91ff4fb5f0a57e0f0b2c24cdefb4f12b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7b8d9a34ee98c3b1e7231bdb38a022c7" category="list-text">Abra as *Instâncias do Notebook* na aba Notebook, clique no botão laranja *Criar instância do notebook*.</block>
  <block id="519925d609277093d7d2ace0457f720a" category="inline-image-macro">Console da instância do AWS SageMaker Notebook</block>
  <block id="d8d17e525889b2a89d32645cb06938f6" category="paragraph"><block ref="d8d17e525889b2a89d32645cb06938f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b070f651df156f54539ea886d6fdb252" category="list-text">Na página de criação, insira o *Nome da instância do Notebook*. Expanda o painel *Rede*. Deixe as outras entradas padrão e selecione uma *VPC*, *Sub-rede* e *Grupo(s) de segurança*.  (Esta *VPC* e *Sub-rede* serão usadas para criar o sistema de arquivos FSx ONTAP posteriormente) Clique no botão laranja *Criar instância de notebook* no canto inferior direito.</block>
  <block id="02ca97619a6b22b9a2f189b3ebb82b57" category="inline-image-macro">Criar instância do notebook</block>
  <block id="39578328ea9c3b8e5a35ce1c48b45447" category="paragraph"><block ref="39578328ea9c3b8e5a35ce1c48b45447" category="inline-image-macro-rx" type="image"></block></block>
  <block id="08bf44c8870f044a9c29ec0decd4506f" category="section-title">Crie um sistema de arquivos FSx ONTAP</block>
  <block id="a0de53cada8c076391cb766a21d191f7" category="list-text">Abra o console da AWS.  No painel de pesquisa, pesquise Fsx e clique no serviço *FSx*.</block>
  <block id="f815343e909cc0c69784c51630a10b2d" category="inline-image-macro">Painel FSx</block>
  <block id="eb780b87d03905721f4484288ab2cde0" category="paragraph"><block ref="eb780b87d03905721f4484288ab2cde0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55ecf05d044f8d3b179ea6daf134664f" category="list-text">Clique em *Criar sistema de arquivos*.</block>
  <block id="77d148bb10790640cfe7639dbc11e075" category="inline-image-macro">Criar sistema de arquivos</block>
  <block id="af10909a9067ddaba9079a1b5b37ca6d" category="paragraph"><block ref="af10909a9067ddaba9079a1b5b37ca6d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="83c8e65862a92cd7eadb9812c8c5f780" category="list-text">Selecione o primeiro cartão *FSx ONTAP* e clique em *Avançar*.</block>
  <block id="6277f28f413aee819a82e3e0058bc5ee" category="inline-image-macro">Selecione o tipo de sistema de arquivo</block>
  <block id="03ad22f430d1bae0e9c295ff4191eac1" category="paragraph"><block ref="03ad22f430d1bae0e9c295ff4191eac1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9b05d3465523c46c6ece6e36ff05bba" category="list-text">Na página de configuração de detalhes.</block>
  <block id="720e4d0907f5f98d25c99b23a410c93c" category="list-text">Selecione a opção *Criação padrão*.</block>
  <block id="fb23d0162f70b1382f3c50cb5b513f4d" category="inline-image-macro">Criar painel do sistema de arquivos</block>
  <block id="69ff48a0fa8eb8c1e7999c1ff581fe73" category="paragraph"><block ref="69ff48a0fa8eb8c1e7999c1ff581fe73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bea7f738749e0c476b2d1c016021ec5b" category="list-text">Digite o *Nome do sistema de arquivos* e a *Capacidade de armazenamento do SSD*.</block>
  <block id="aad9529851b728c0fb560a0f7d9b8a5b" category="inline-image-macro">Especificar detalhes do sistema de arquivos</block>
  <block id="1c15f13ef7a0d9e6720f0178a39c5dde" category="paragraph"><block ref="1c15f13ef7a0d9e6720f0178a39c5dde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5db4aeb81b94a1ba5cdcc12c96b36cb1" category="list-text">Certifique-se de usar a *VPC* e a *sub-rede* da mesma forma que a instância do *SageMaker Notebook*.</block>
  <block id="84e88a3298035d04334f19541c31a16a" category="inline-image-macro">Configuração de rede e segurança</block>
  <block id="3788a93ec701a347dfa0def01330fa09" category="paragraph"><block ref="1832dc909b2a82e8c4b70afb493963cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb695bdcb362931108f41ff0ec65293" category="list-text">Digite o nome da *máquina virtual de armazenamento* e *especifique uma senha* para sua SVM (máquina virtual de armazenamento).</block>
  <block id="691a3c3a3ffee99887addcf66bcceeec" category="inline-image-macro">Configuração padrão da máquina virtual de armazenamento</block>
  <block id="68cc70fed3a17a1a1caec811e0d01f03" category="paragraph"><block ref="68cc70fed3a17a1a1caec811e0d01f03" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4c7ba1524cf2b18e8592e9ceb83df71" category="list-text">Deixe as outras entradas como padrão e clique no botão laranja *Avançar* no canto inferior direito.</block>
  <block id="38f46900c7e5018a4d712fad6dde98ea" category="inline-image-macro">Confirmar configuração</block>
  <block id="c715f26fb866d18303643cfaf886a63c" category="paragraph"><block ref="c715f26fb866d18303643cfaf886a63c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6d5ce0306761971a734da357efdf9e6f" category="list-text">Clique no botão laranja *Criar sistema de arquivos* no canto inferior direito da página de revisão.</block>
  <block id="c0e0aca15b43c5f4360b8e6c8f2451d9" category="inline-image-macro">Revise a configuração e confirme a criação</block>
  <block id="29fe6a20d375efc9f6e4ae1a07258da3" category="paragraph"><block ref="29fe6a20d375efc9f6e4ae1a07258da3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c12346192a59739b1315d8d07143db6e" category="list-text">Pode levar cerca de *20-40 minutos* para iniciar o sistema de arquivos FSx.</block>
  <block id="391b09977b768e724f35dad726f1f3ef" category="inline-image-macro">Inspecione o console FSx</block>
  <block id="37f274b71add0d0952db64f7c20abd4f" category="paragraph"><block ref="37f274b71add0d0952db64f7c20abd4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01ecbbb2b353cf4d915bbe1c1cd5505c" category="section-title">Configuração do servidor</block>
  <block id="d36647d06b353fcd6fedc60898e43187" category="section-title">Configuração ONTAP</block>
  <block id="07afa2af969623c48103624cdb58551c" category="list-text">Abra o sistema de arquivos FSx criado.  Certifique-se de que o status é *Disponível*.</block>
  <block id="69d4f895c19503f5e9f518c3b74993bb" category="inline-image-macro">Aguarde a criação do backend</block>
  <block id="a29e057394c30462c97d0a046428ccc6" category="paragraph"><block ref="a29e057394c30462c97d0a046428ccc6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6cbcfc771dc80f5ee77c4deba078b135" category="list-text">Selecione a aba *Administração* e mantenha o *Ponto de extremidade de gerenciamento - Endereço IP* e o *Nome de usuário do administrador do ONTAP *.</block>
  <block id="a63e6273ab6f9d27c79b63c3e31a3f35" category="inline-image-macro">Console de detalhes do sistema de arquivos</block>
  <block id="3a0eb32361b0c7bfba5fc5c8da00fec5" category="paragraph"><block ref="3a0eb32361b0c7bfba5fc5c8da00fec5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0164aebedfb5a99b6386ba01ffbc963" category="list-text">Abra a *instância do SageMaker Notebook* criada e clique em *Abrir JupyterLab*.</block>
  <block id="5f42fc26006705fa3b9ffe25fe3d881d" category="inline-image-macro">Console da instância do AWS SageMaker Notebook</block>
  <block id="85c4a421924bf2d8fbb4d65b5fcd0317" category="paragraph"><block ref="85c4a421924bf2d8fbb4d65b5fcd0317" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12dbc394c66b065a1aef771f11914dad" category="list-text">Na página do Jupyter Lab, abra um novo *Terminal*.</block>
  <block id="f3970717b786c14ff186b01681be062f" category="inline-image-macro">Página inicial do Jupyter Lab</block>
  <block id="6774664dc7058399d3db96209da79e83" category="paragraph"><block ref="6774664dc7058399d3db96209da79e83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ad2ec02537c0b93a2b5a7937ea89048" category="list-text">Digite o comando ssh ssh &lt;nome de usuário administrador&gt;@&lt; IP do servidor ONTAP &gt; para efetuar login no sistema de arquivos FSx ONTAP .  (O nome de usuário e o endereço IP são recuperados na etapa 2) Use a senha usada ao criar a *Máquina virtual de armazenamento*.</block>
  <block id="7d71a86e3b4885ad307f3e18ba62c9cb" category="inline-image-macro">Terminal do Jupyter Lab</block>
  <block id="3907af7edeccc904e748efdec97a698b" category="paragraph"><block ref="3907af7edeccc904e748efdec97a698b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7fe5b2fa5a8ec0c7d2b2e65bce4c302" category="list-text">Execute os comandos na seguinte ordem.  Usamos *fsxn-ontap* como nome para o *nome do bucket S3 privado do FSx ONTAP *.  Use o *nome da máquina virtual de armazenamento* para o argumento *-vserver*.</block>
  <block id="9166665a24ce86a4cdc78ee5dc10b99e" category="inline-image-macro">Saída do terminal do Jupyter Lab</block>
  <block id="f953d25a23501b488d1729dde1bcbfec" category="paragraph"><block ref="f953d25a23501b488d1729dde1bcbfec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09b48d43c330baa7527d4d5b785ddc78" category="list-text">Execute os comandos abaixo para recuperar o IP do endpoint e as credenciais do FSx ONTAP private S3.</block>
  <block id="1025c82e986534d7a6a941036fce2afd" category="list-text">Guarde o IP do endpoint e a credencial para uso futuro.</block>
  <block id="8d5111b0ef521165f30cc6043e79b8b4" category="paragraph"><block ref="8d5111b0ef521165f30cc6043e79b8b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb11dcb3b0575af26386e753c028e37d" category="section-title">Configuração do cliente</block>
  <block id="d885926aec2cdf1253c078102968eb8d" category="list-text">Na instância do SageMaker Notebook, crie um novo notebook Jupyter.</block>
  <block id="6aa1a9a77e640f5f5edc06a932b6ed8a" category="inline-image-macro">Abra um novo notebook Jupyter</block>
  <block id="28f138d5d6604c9e1a6788b166239c3f" category="paragraph"><block ref="28f138d5d6604c9e1a6788b166239c3f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e248de3aba6cefa5adacaaee03aaa6e8" category="inline-link-macro">fsxn_demo.ipynb</block>
  <block id="3161057d478204432fe5225e86346e57" category="list-text">Use o código abaixo como uma solução alternativa para carregar arquivos no bucket S3 privado do FSx ONTAP .  Para um exemplo de código abrangente, consulte este notebook.<block ref="5926c62f2c3d59c789081e1f0aff3f08" category="inline-link-macro-rx"></block></block>
  <block id="9c715084d36062c3ee5a47d1e528cd94" category="paragraph">Isso conclui a integração entre o FSx ONTAP e a instância do SageMaker.</block>
  <block id="6d8aee76fb8c09877162ad6d9e5fdac9" category="section-title">Lista de verificação de depuração útil</block>
  <block id="c00ea068fc81a9c0fcad0e38fbc7bb94" category="list-text">Certifique-se de que a instância do SageMaker Notebook e o sistema de arquivos FSx ONTAP estejam na mesma VPC.</block>
  <block id="2ec57b268e910c39ad70e1b259d09e1a" category="list-text">Lembre-se de executar o comando *set dev* no ONTAP para definir o nível de privilégio como *dev*.</block>
  <block id="5a7d7d5f81481db284cc081576a810b0" category="section-title">Perguntas frequentes (em 27 de setembro de 2023)</block>
  <block id="de9370dee0783c12eee2dcba49377c0c" category="paragraph">P: Por que estou recebendo o erro "*Ocorreu um erro (NotImplemented) ao chamar a operação CreateMultipartUpload: O comando s3 que você solicitou não foi implementado*" ao carregar arquivos no FSx ONTAP?</block>
  <block id="b17f3ba7d3e19cd555784a4d2fd9e51b" category="paragraph">R: Como um bucket S3 privado, o FSx ONTAP suporta o upload de arquivos de até 100 MB.  Ao usar o protocolo S3, arquivos maiores que 100 MB são divididos em pedaços de 100 MB, e a função 'CreateMultipartUpload' é chamada.  Entretanto, a implementação atual do FSx ONTAP private S3 não suporta esta função.</block>
  <block id="89551e14b23206a9d9d14f16530fc28d" category="paragraph">P: Por que estou recebendo o erro "*Ocorreu um erro (AccessDenied) ao chamar as operações PutObject: Acesso negado*" ao carregar arquivos no FSx ONTAP?</block>
  <block id="21ba2b927703c559d6b74e6dbc961ebb" category="paragraph">R: Para acessar o bucket S3 privado do FSx ONTAP a partir de uma instância do SageMaker Notebook, troque as credenciais da AWS para as credenciais do FSx ONTAP .  No entanto, conceder permissão de gravação à instância requer uma solução alternativa que envolve montar o bucket e executar o comando shell 'chmod' para alterar as permissões.</block>
  <block id="a713cfa91c4b5642352b00e081eca0ce" category="paragraph">P: Como posso integrar o bucket S3 privado do FSx ONTAP com outros serviços do SageMaker ML?</block>
  <block id="eae99a039ae09d5e28c061d7218d0efb" category="paragraph">R: Infelizmente, o SDK de serviços do SageMaker não fornece uma maneira de especificar o ponto de extremidade para o bucket privado do S3.  Como resultado, o FSx ONTAP S3 não é compatível com serviços do SageMaker, como Sagemaker Data Wrangler, Sagemaker Clarify, Sagemaker Glue, Sagemaker Athena, Sagemaker AutoML e outros.</block>
  <block id="7892d93cdad4bcd1c3e8157592ed858e" category="summary">O artigo é um tutorial sobre como usar o Amazon FSx for NetApp ONTAP (FSx ONTAP) para treinar modelos PyTorch no SageMaker, especificamente para um projeto de classificação de qualidade de pneus.</block>
  <block id="ecccb638c3da2e33f2ce538fc895233a" category="doc">Parte 2 - Aproveitando o AWS Amazon FSx for NetApp ONTAP (FSx ONTAP) como uma fonte de dados para treinamento de modelos no SageMaker</block>
  <block id="ca3ef01192dfa69eac50d8be997f6b51" category="paragraph">Este artigo é um tutorial sobre como usar o Amazon FSx for NetApp ONTAP (FSx ONTAP) para treinar modelos PyTorch no SageMaker, especificamente para um projeto de classificação de qualidade de pneus.</block>
  <block id="23851f05df4c2ebe4433cd559cf23e55" category="paragraph">Este tutorial oferece um exemplo prático de um projeto de classificação de visão computacional, proporcionando experiência prática na construção de modelos de ML que utilizam o FSx ONTAP como fonte de dados no ambiente SageMaker.  O projeto se concentra no uso do PyTorch, uma estrutura de aprendizado profundo, para classificar a qualidade dos pneus com base em imagens de pneus.  Ele enfatiza o desenvolvimento de modelos de aprendizado de máquina usando o FSx ONTAP como fonte de dados no Amazon SageMaker.</block>
  <block id="516bec227f44816f7ecc2d58aae01bb2" category="section-title">O que é FSx ONTAP</block>
  <block id="e586360cf616ba9b2800383d7e36b444" category="paragraph">O Amazon FSx ONTAP é de fato uma solução de armazenamento totalmente gerenciada oferecida pela AWS.  Ele aproveita o sistema de arquivos ONTAP da NetApp para fornecer armazenamento confiável e de alto desempenho.  Com suporte para protocolos como NFS, SMB e iSCSI, ele permite acesso direto de diferentes instâncias de computação e contêineres.  O serviço foi projetado para oferecer desempenho excepcional, garantindo operações de dados rápidas e eficientes.  Ele também oferece alta disponibilidade e durabilidade, garantindo que seus dados permaneçam acessíveis e protegidos.  Além disso, a capacidade de armazenamento do Amazon FSx ONTAP é escalável, permitindo que você a ajuste facilmente de acordo com suas necessidades.</block>
  <block id="05ec336213c5aa3c3a49c743c5fbad19" category="section-title">Ambiente de rede</block>
  <block id="9e7ee35cf251304984a47d590762e1d2" category="inline-image-macro">Ambiente de rede</block>
  <block id="8ebf7b35e6a40f5a75092ae4b590f9d1" category="paragraph"><block ref="8ebf7b35e6a40f5a75092ae4b590f9d1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a431daf3a478d96ed5ffc10a4056228" category="paragraph">FSx ONTAP (Amazon FSx ONTAP) é um serviço de armazenamento da AWS.  Ele inclui um sistema de arquivos em execução no sistema NetApp ONTAP e uma máquina virtual do sistema gerenciada pela AWS (SVM) que se conecta a ele.  No diagrama fornecido, o servidor NetApp ONTAP gerenciado pela AWS está localizado fora da VPC.  O SVM atua como intermediário entre o SageMaker e o sistema NetApp ONTAP , recebendo solicitações de operação do SageMaker e encaminhando-as para o armazenamento subjacente.  Para acessar o FSx ONTAP, o SageMaker deve ser colocado na mesma VPC que a implantação do FSx ONTAP .  Esta configuração garante a comunicação e o acesso aos dados entre o SageMaker e o FSx ONTAP.</block>
  <block id="f8aacfa5c683858912c498f517c9b457" category="section-title">Acesso a dados</block>
  <block id="70385d02db6379c01d4b7b17101f2004" category="paragraph">Em cenários do mundo real, os cientistas de dados normalmente utilizam os dados existentes armazenados no FSx ONTAP para construir seus modelos de aprendizado de máquina.  No entanto, para fins de demonstração, como o sistema de arquivos FSx ONTAP fica inicialmente vazio após a criação, é necessário carregar manualmente os dados de treinamento.  Isso pode ser feito montando o FSx ONTAP como um volume no SageMaker.  Depois que o sistema de arquivos for montado com sucesso, você poderá carregar seu conjunto de dados no local montado, tornando-o acessível para treinar seus modelos no ambiente SageMaker.  Essa abordagem permite que você aproveite a capacidade de armazenamento e os recursos do FSx ONTAP enquanto trabalha com o SageMaker para desenvolvimento e treinamento de modelos.</block>
  <block id="23ea498668d1fa717fb7cfb600bf3238" category="inline-link-macro">Parte 1 - Integrando o Amazon FSx for NetApp ONTAP (FSx ONTAP) como um bucket S3 privado no AWS SageMaker</block>
  <block id="95d89db7f4a106e280e1c30cde658610" category="paragraph">O processo de leitura de dados envolve a configuração do FSx ONTAP como um bucket S3 privado.  Para aprender as instruções detalhadas de configuração, consulte<block ref="8e7379c67a0724b1a49308a7ae6ac3d5" category="inline-link-macro-rx"></block></block>
  <block id="30eaeebc8f9611f55e018d1dd51789ba" category="section-title">Visão geral da integração</block>
  <block id="7ffc912d31a398685c5667622bb5ed7f" category="inline-image-macro">Fluxo de trabalho de treinamento</block>
  <block id="29e5f040e75c8e4e628e90efc594e3ef" category="paragraph"><block ref="29e5f040e75c8e4e628e90efc594e3ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da4169484addf29c5d1d35a28a5073fd" category="paragraph">O fluxo de trabalho de uso de dados de treinamento no FSx ONTAP para criar um modelo de aprendizado profundo no SageMaker pode ser resumido em três etapas principais: definição do carregador de dados, treinamento do modelo e implantação.  Em um nível alto, essas etapas formam a base de um pipeline de MLOps.  No entanto, cada etapa envolve várias subetapas detalhadas para uma implementação abrangente.  Essas subetapas abrangem várias tarefas, como pré-processamento de dados, divisão de conjuntos de dados, configuração de modelo, ajuste de hiperparâmetros, avaliação de modelo e implantação de modelo.  Essas etapas garantem um processo completo e eficaz para criar e implantar modelos de aprendizado profundo usando dados de treinamento do FSx ONTAP no ambiente SageMaker.</block>
  <block id="2870e83ec05413b09bc7de07f60f54fa" category="section-title">Integração passo a passo</block>
  <block id="e3364bc8e125077137411ae17c13b771" category="section-title">Loader de dados</block>
  <block id="220b880a3d218e80d8fde5901827649a" category="paragraph">Para treinar uma rede de aprendizado profundo PyTorch com dados, um carregador de dados é criado para facilitar a alimentação de dados.  O carregador de dados não apenas define o tamanho do lote, mas também determina o procedimento de leitura e pré-processamento de cada registro dentro do lote.  Ao configurar o carregador de dados, podemos lidar com o processamento de dados em lotes, permitindo o treinamento da rede de aprendizado profundo.</block>
  <block id="cc0322e5278f21d6001e3995e46e2810" category="paragraph">O carregador de dados consiste em 3 partes.</block>
  <block id="0cee527e2a952dcfca00fb6de192e2a1" category="section-title">Função de pré-processamento</block>
  <block id="50a46eb952358276ed306b6d88aadc7d" category="paragraph">O trecho de código acima demonstra a definição de transformações de pré-processamento de imagem usando o módulo *torchvision.transforms*.  Neste tutorial, o objeto de pré-processo é criado para aplicar uma série de transformações.  Primeiro, a transformação *ToTensor()* converte a imagem em uma representação tensorial.  Posteriormente, a transformação *Resize((224,224))* redimensiona a imagem para um tamanho fixo de 224x224 pixels.  Por fim, a transformação *Normalize()* normaliza os valores do tensor subtraindo a média e dividindo pelo desvio padrão ao longo de cada canal.  Os valores de média e desvio padrão usados para normalização são comumente empregados em modelos de redes neurais pré-treinados.  No geral, esse código prepara os dados da imagem para processamento posterior ou entrada em um modelo pré-treinado, convertendo-os em um tensor, redimensionando-os e normalizando os valores de pixels.</block>
  <block id="578a55cb1cfe6e1363a1c73fec7d9c6f" category="section-title">A classe de conjunto de dados PyTorch</block>
  <block id="7895a195c178ff4c5e59638a3c762dd2" category="paragraph">Esta classe fornece funcionalidade para obter o número total de registros no conjunto de dados e define o método de leitura de dados para cada registro.  Dentro da função *__getitem__*, o código utiliza o objeto de bucket boto3 S3 para recuperar os dados binários do FSx ONTAP.  O estilo de código para acessar dados do FSx ONTAP é semelhante à leitura de dados do Amazon S3.  A explicação a seguir se aprofunda no processo de criação do objeto privado S3 *bucket*.</block>
  <block id="76d805ebfad939474c22611b1a64ec91" category="section-title">FSx ONTAP como um repositório S3 privado</block>
  <block id="3d67de2c700f42063d686e92a37a82aa" category="paragraph">Para ler dados do FSx ONTAP no SageMaker, é criado um manipulador que aponta para o armazenamento do FSx ONTAP usando o protocolo S3.  Isso permite que o FSx ONTAP seja tratado como um bucket S3 privado.  A configuração do manipulador inclui a especificação do endereço IP do FSx ONTAP SVM, o nome do bucket e as credenciais necessárias.  Para uma explicação abrangente sobre como obter esses itens de configuração, consulte o documento em<block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block> .</block>
  <block id="ac5d6406e8dadcbc23e9cf65fe528510" category="paragraph">No exemplo mencionado acima, o objeto bucket é usado para instanciar o objeto do conjunto de dados PyTorch.  O objeto dataset será explicado com mais detalhes na seção subsequente.</block>
  <block id="e03717a5c1692689919250506bf382a0" category="section-title">O Loader de dados PyTorch</block>
  <block id="0c919f2bf87f2c6df41e7bbc52c68d04" category="paragraph">No exemplo fornecido, um tamanho de lote de 64 é especificado, indicando que cada lote conterá 64 registros.  Combinando a classe *Dataset* do PyTorch, a função de pré-processamento e o tamanho do lote de treinamento, obtemos o carregador de dados para treinamento.  Este carregador de dados facilita o processo de iteração pelo conjunto de dados em lotes durante a fase de treinamento.</block>
  <block id="74415cec8ae4d65c228c7fa8da8eae8a" category="section-title">Treinamento de modelo</block>
  <block id="74492eb8210f5168d9ee3eff7524ecde" category="paragraph">Este código implementa um processo de treinamento padrão do PyTorch.  Ele define um modelo de rede neural chamado *TyreQualityClassifier* usando camadas convolucionais e uma camada linear para classificar a qualidade dos pneus.  O loop de treinamento itera sobre lotes de dados, calcula a perda e atualiza os parâmetros do modelo usando retropropagação e otimização.  Além disso, ele imprime a hora atual, época, lote e perda para fins de monitoramento.</block>
  <block id="4d2e185dfba9f3df542300054ad07998" category="section-title">Implantação do modelo</block>
  <block id="6116a0f9a85671aec95cc56a205cf186" category="paragraph">O código salva o modelo PyTorch no *Amazon S3* porque o SageMaker exige que o modelo seja armazenado no S3 para implantação.  Ao carregar o modelo no *Amazon S3*, ele se torna acessível ao SageMaker, permitindo a implantação e a inferência no modelo implantado.</block>
  <block id="075e4fb3d67ee1fb4bc39dbc5d72b129" category="paragraph">Este código facilita a implantação de um modelo PyTorch no SageMaker.  Ele define um serializador personalizado, *TyreQualitySerializer*, que pré-processa e serializa dados de entrada como um tensor PyTorch.  A classe *TyreQualityPredictor* é um preditor personalizado que utiliza o serializador definido e um *JSONDeserializer*.  O código também cria um objeto *PyTorchModel* para especificar o local S3 do modelo, a função do IAM, a versão do framework e o ponto de entrada para inferência.  O código gera um registro de data e hora e constrói um nome de ponto de extremidade com base no modelo e no registro de data e hora.  Por fim, o modelo é implantado usando o método deploy, especificando a contagem de instâncias, o tipo de instância e o nome do endpoint gerado.  Isso permite que o modelo PyTorch seja implantado e fique acessível para inferência no SageMaker.</block>
  <block id="bfc7647fbfe6e589911d2da73377b475" category="section-title">Inferência</block>
  <block id="99e1766840e675b2dbd8230be049188f" category="paragraph">Este é o exemplo de uso do ponto de extremidade implantado para fazer a inferência.</block>
  <block id="727c63651b565bca2eb7d8a48e0fefd9" category="summary">Esta seção resume este documento sobre as soluções de armazenamento da NetApp para o Apache Spark.</block>
  <block id="6f8b794f3246b0c1e1780bb4d4d5dc53" category="doc">Conclusão</block>
  <block id="900200cfc3f2577215c327d16f34840a" category="paragraph">Neste documento, discutimos a arquitetura do Apache Spark, casos de uso do cliente e o portfólio de armazenamento da NetApp em relação a big data, análise moderna e IA, ML e DL.  Em nossos testes de validação de desempenho baseados em ferramentas de benchmarking padrão do setor e na demanda do cliente, as soluções NetApp Spark demonstraram desempenho superior em relação aos sistemas Hadoop nativos.  Uma combinação dos casos de uso do cliente e dos resultados de desempenho apresentados neste relatório pode ajudar você a escolher uma solução Spark apropriada para sua implantação.</block>
  <block id="ca052b24845534e817869836d49d519a" category="summary">Este documento se concentra na arquitetura do Apache Spark, nos casos de uso do cliente e no portfólio de armazenamento da NetApp relacionado à análise de big data e inteligência artificial.  Ele também apresenta vários resultados de testes usando ferramentas de IA, aprendizado de máquina e aprendizado profundo padrão do setor em relação a um sistema Hadoop típico, para que você possa escolher a solução Spark apropriada.</block>
  <block id="58b2293adcda372fb415412d23f01a8e" category="doc">TR-4570: Soluções de armazenamento NetApp para Apache Spark: Arquitetura, casos de uso e resultados de desempenho</block>
  <block id="057e5f9ddc5d049ab86855dceffd6d14" category="paragraph">Rick Huang, Karthikeyan Nagalingam, NetApp</block>
  <block id="550fd771b94cb8eb3739d16af31243f3" category="paragraph">Este documento se concentra na arquitetura do Apache Spark, nos casos de uso do cliente e no portfólio de armazenamento da NetApp relacionado à análise de big data e inteligência artificial (IA).  Ele também apresenta vários resultados de testes usando ferramentas de IA, aprendizado de máquina (ML) e aprendizado profundo (DL) padrão do setor em relação a um sistema Hadoop típico para que você possa escolher a solução Spark apropriada.  Para começar, você precisa de uma arquitetura Spark, componentes apropriados e dois modos de implantação (cluster e cliente).</block>
  <block id="9e19cfda234e917201ce19469f25275b" category="paragraph">Este documento também fornece casos de uso do cliente para resolver problemas de configuração e discute uma visão geral do portfólio de armazenamento da NetApp relevante para análise de big data e IA, ML e DL com Spark.  Em seguida, finalizamos com os resultados dos testes derivados de casos de uso específicos do Spark e do portfólio de soluções NetApp Spark.</block>
  <block id="d4612e7dc1347f1ccbfd5e470dda2295" category="section-title">Desafios do cliente</block>
  <block id="ce663ffc6a85b2c97e60368b5a9c76e3" category="paragraph">Esta seção se concentra nos desafios dos clientes com análise de big data e IA/ML/DL em setores de crescimento de dados, como varejo, marketing digital, bancos, manufatura discreta, manufatura por processos, governo e serviços profissionais.</block>
  <block id="8a5bab0d8f4c0d1b73de5ada6b1c91e6" category="section-title">Desempenho imprevisível</block>
  <block id="9790dc49aa09b4759e4c6ebc65fb4c42" category="paragraph">Implantações tradicionais do Hadoop normalmente usam hardware comum.  Para melhorar o desempenho, você deve ajustar a rede, o sistema operacional, o cluster Hadoop, os componentes do ecossistema, como o Spark, e o hardware.  Mesmo se você ajustar cada camada, pode ser difícil atingir os níveis de desempenho desejados porque o Hadoop é executado em hardware comum que não foi projetado para alto desempenho em seu ambiente.</block>
  <block id="b496a0269649d7b570c2052646fd23b6" category="section-title">Falhas de mídia e nó</block>
  <block id="21af95409591262fb36555acb96262d8" category="paragraph">Mesmo em condições normais, o hardware comum está sujeito a falhas.  Se um disco em um nó de dados falhar, o mestre do Hadoop, por padrão, considera esse nó como não íntegro.  Em seguida, ele copia dados específicos desse nó pela rede, de réplicas para um nó íntegro.  Esse processo torna os pacotes de rede mais lentos para qualquer tarefa do Hadoop.  O cluster deve então copiar os dados novamente e remover os dados replicados em excesso quando o nó com problemas retornar a um estado saudável.</block>
  <block id="03d4836e0d1deb07679d400b8c88a880" category="section-title">Bloqueio de fornecedor do Hadoop</block>
  <block id="bb33286c56b053ae85ab21a377bd4347" category="paragraph">Os distribuidores do Hadoop têm sua própria distribuição do Hadoop com seu próprio controle de versão, o que prende o cliente a essas distribuições.  No entanto, muitos clientes exigem suporte para análises na memória que não vinculem o cliente a distribuições específicas do Hadoop.  Eles precisam da liberdade de mudar as distribuições e ainda levar suas análises com eles.</block>
  <block id="a940c960f38c44b75bf1da78215690c2" category="section-title">Falta de suporte para mais de um idioma</block>
  <block id="65a27ee7da3f8c68004d31f60ab65e55" category="paragraph">Os clientes geralmente precisam de suporte para vários idiomas, além dos programas MapReduce Java, para executar seus trabalhos.  Opções como SQL e scripts oferecem mais flexibilidade para obter respostas, mais opções para organizar e recuperar dados e maneiras mais rápidas de mover dados para uma estrutura de análise.</block>
  <block id="f3e2f69098f73bd8bb3cf61330433955" category="section-title">Dificuldade de uso</block>
  <block id="e2bdfb6bb3e956b38b6aacde957996df" category="paragraph">Já faz algum tempo que as pessoas reclamam que o Hadoop é difícil de usar.  Embora o Hadoop tenha se tornado mais simples e poderoso a cada nova versão, essa crítica persiste.  O Hadoop exige que você entenda os padrões de programação Java e MapReduce, um desafio para administradores de banco de dados e pessoas com conjuntos de habilidades tradicionais de script.</block>
  <block id="5f5f8f99cf4c6ebc0b81445be5328bf6" category="section-title">Estruturas e ferramentas complicadas</block>
  <block id="74faacaf156cd022099bed5469595b3e" category="paragraph">As equipes de IA corporativas enfrentam vários desafios.  Mesmo com conhecimento especializado em ciência de dados, ferramentas e estruturas para diferentes ecossistemas e aplicativos de implantação podem não ser facilmente transferidas de um para outro.  Uma plataforma de ciência de dados deve integrar-se perfeitamente com plataformas de big data correspondentes criadas no Spark, com facilidade de movimentação de dados, modelos reutilizáveis, código pronto para uso e ferramentas que oferecem suporte às melhores práticas para prototipagem, validação, controle de versão, compartilhamento, reutilização e implantação rápida de modelos na produção.</block>
  <block id="067be0651f3de8fd60ec45827a4078ed" category="section-title">Por que escolher a NetApp?</block>
  <block id="8ff43bcedde084850831da9cdcc5a43a" category="paragraph">A NetApp pode melhorar sua experiência com o Spark das seguintes maneiras:</block>
  <block id="dc5106ccf618944587be46565f5585cd" category="list-text">O acesso direto do NetApp NFS (mostrado na figura abaixo) permite que os clientes executem trabalhos de análise de big data em seus dados NFSv3 ou NFSv4 existentes ou novos sem mover ou copiar os dados.  Ele evita múltiplas cópias de dados e elimina a necessidade de sincronizar os dados com uma fonte.</block>
  <block id="38bc62edaebd471500fa64a4758f7f04" category="list-text">Armazenamento mais eficiente e menos replicação de servidor.  Por exemplo, a solução NetApp E-Series Hadoop requer duas, em vez de três réplicas dos dados, e a solução FAS Hadoop requer uma fonte de dados, mas nenhuma replicação ou cópias de dados.  As soluções de armazenamento da NetApp também produzem menos tráfego de servidor para servidor.</block>
  <block id="2fc945668748ad0173e63b5db34773e7" category="list-text">Melhor comportamento do cluster e do trabalho do Hadoop durante falhas de unidade e nó.</block>
  <block id="343500ea6d724fe727d127f6409b86c2" category="list-text">Melhor desempenho de ingestão de dados.</block>
  <block id="109f256618c8d9037bb2cd6cc28f5959" category="inline-image-macro">Configurações alternativas do Apache Spark.</block>
  <block id="0c0038bcea5bace3c716607bdf5ea55f" category="paragraph"><block ref="0c0038bcea5bace3c716607bdf5ea55f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40771867b1bf0db74b9505757197a17a" category="paragraph">Por exemplo, no setor financeiro e de saúde, a movimentação de dados de um lugar para outro deve atender a obrigações legais, o que não é uma tarefa fácil.  Nesse cenário, o acesso direto do NetApp NFS analisa os dados financeiros e de saúde de seu local original.  Outro benefício importante é que o uso do acesso direto do NetApp NFS simplifica a proteção de dados do Hadoop usando comandos nativos do Hadoop e permitindo fluxos de trabalho de proteção de dados com o rico portfólio de gerenciamento de dados da NetApp.</block>
  <block id="a9e81b3240a7c1ae64fc23e96c84f4ea" category="paragraph">O acesso direto do NetApp NFS oferece dois tipos de opções de implantação para clusters Hadoop/Spark:</block>
  <block id="4e8fe573a9fe74b6429508c87337b99b" category="list-text">Por padrão, os clusters Hadoop ou Spark usam o Hadoop Distributed File System (HDFS) para armazenamento de dados e o sistema de arquivos padrão.  O acesso direto do NetApp NFS pode substituir o HDFS padrão pelo armazenamento NFS como o sistema de arquivos padrão, permitindo análises diretas em dados NFS.</block>
  <block id="071998ed00d39b3ff27f5410b196f9cc" category="list-text">Em outra opção de implantação, o acesso direto do NetApp NFS oferece suporte à configuração do NFS como armazenamento adicional junto com o HDFS em um único cluster Hadoop ou Spark.  Nesse caso, o cliente pode compartilhar dados por meio de exportações NFS e acessá-los do mesmo cluster junto com os dados HDFS.</block>
  <block id="c1923befca33cfe6cc9ace80af8580b6" category="paragraph">Os principais benefícios de usar o acesso direto do NetApp NFS incluem o seguinte:</block>
  <block id="91221d408b0c171556751f29fb9d8071" category="list-text">Analisar os dados de seu local atual, o que evita a tarefa demorada e de alto desempenho de mover dados analíticos para uma infraestrutura Hadoop, como o HDFS.</block>
  <block id="1675635f440b61b7219bf7ed2bb2ed27" category="list-text">Reduzindo o número de réplicas de três para uma.</block>
  <block id="16f81b84f137a7a52da9ba8d798af622" category="list-text">Permitindo que os usuários dissociem a computação e o armazenamento para dimensioná-los de forma independente.</block>
  <block id="71946d3c421aea3a8238a481bebe1919" category="list-text">Fornecendo proteção de dados empresariais aproveitando os recursos avançados de gerenciamento de dados do ONTAP.</block>
  <block id="abebb9b977d736f599ab76c517961b24" category="list-text">Certificação com a plataforma de dados Hortonworks.</block>
  <block id="3c41c2d3511fa95c83687fae6fb57754" category="list-text">Habilitando implantações de análise de dados híbrida.</block>
  <block id="05550a44691e53e07f81616af5d58e20" category="list-text">Reduzindo o tempo de backup aproveitando a capacidade multithread dinâmica.</block>
  <block id="6a604a825549ac87ecf8a00412ee6365" category="inline-link-macro">TR-4657: Soluções de dados em nuvem híbrida da NetApp - Spark e Hadoop com base em casos de uso do cliente</block>
  <block id="c5153856e4d13c48696624c702620995" category="paragraph">Ver<block ref="46ae0631eaa2b1a19769e051f280e3cf" category="inline-link-macro-rx"></block> para fazer backup de dados do Hadoop, backup e recuperação de desastres da nuvem para o local, habilitar DevTest em dados do Hadoop existentes, proteção de dados e conectividade multicloud e acelerar cargas de trabalho de análise.</block>
  <block id="3100ca44a05fa97ed5f07875f442084e" category="paragraph">As seções a seguir descrevem recursos de armazenamento que são importantes para clientes do Spark.</block>
  <block id="da2518ef48c60077e2b2c0be7fed7193" category="section-title">Camadas de armazenamento</block>
  <block id="d9a83ca3a623dce37a2f84027f1495ce" category="paragraph">Com o armazenamento em camadas do Hadoop, você pode armazenar arquivos com diferentes tipos de armazenamento de acordo com uma política de armazenamento.  Os tipos de armazenamento incluem<block ref="27369b3bf4483e8dcfd85ba9a39a947f" prefix=" " category="inline-code"></block> ,<block ref="75e52a0ecfafeda17a34fc60111c1f0b" prefix=" " category="inline-code"></block> ,<block ref="a957a3153eb7126b1c5f8b6aac35de53" prefix=" " category="inline-code"></block> ,<block ref="714f8e54e71566bd1c2e29328288a62c" prefix=" " category="inline-code"></block> ,<block ref="7fc1aa11178f33b4f796d69c73f7f0b4" prefix=" " category="inline-code"></block> , e<block ref="fa4fdcc80e19a0848c6360538fdd86ef" prefix=" " category="inline-code"></block> .</block>
  <block id="c2398745386edbb0221cc4ee496ff79f" category="paragraph">Realizamos a validação da divisão em camadas de armazenamento do Hadoop em um controlador de armazenamento NetApp AFF e um controlador de armazenamento da série E com unidades SSD e SAS com diferentes políticas de armazenamento.  O cluster Spark com AFF-A800 tem quatro nós de trabalho de computação, enquanto o cluster com E-Series tem oito.  O objetivo principal é comparar o desempenho de unidades de estado sólido (SSDs) com o de discos rígidos (HDDs).</block>
  <block id="36edc8f5974bdf6ad51a220254b99dfb" category="paragraph">A figura a seguir mostra o desempenho das soluções NetApp para um SSD Hadoop.</block>
  <block id="d09520ed9b4a17ada38e70314907675f" category="inline-image-macro">Hora de classificar 1 TB de dados.</block>
  <block id="12b6622989087d668bc9d1da31e9fb70" category="paragraph"><block ref="12b6622989087d668bc9d1da31e9fb70" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2f530d95c6332b106d86a53b41e4a36" category="inline-link">Solução NetApp E-Series TR-3969 para Hadoop</block>
  <block id="bd9ad8221382748a4f008c3af02731bd" category="list-text">A configuração básica do NL-SAS usava oito nós de computação e 96 unidades NL-SAS.  Esta configuração gerou 1 TB de dados em 4 minutos e 38 segundos.  Ver<block ref="264d8d379e3a34fdac32f9057509bf65" category="inline-link-rx"></block> para obter detalhes sobre a configuração do cluster e do armazenamento.</block>
  <block id="f895fa75cdc40f4e672bba6f7a873e25" category="list-text">Usando o TeraGen, a configuração SSD gerou 1 TB de dados 15,66x mais rápido que a configuração NL-SAS.  Além disso, a configuração SSD usou metade do número de nós de computação e metade do número de unidades de disco (24 unidades SSD no total).  Com base no tempo de conclusão do trabalho, ele foi quase duas vezes mais rápido que a configuração NL-SAS.</block>
  <block id="459f180fc71a8f8bb773d3c879314e39" category="list-text">Usando o TeraSort, a configuração SSD classificou 1 TB de dados 1138,36 vezes mais rápido que a configuração NL-SAS.  Além disso, a configuração SSD usou metade do número de nós de computação e metade do número de unidades de disco (24 unidades SSD no total).  Portanto, por unidade, era aproximadamente três vezes mais rápido que a configuração NL-SAS.</block>
  <block id="52be2edb04819f386804af38bd53a55d" category="list-text">A conclusão é que a transição de discos giratórios para all-flash melhora o desempenho.  O número de nós de computação não era o gargalo.  Com o armazenamento all-flash da NetApp, o desempenho do tempo de execução é bem dimensionado.</block>
  <block id="8cc25131075ed11b8263304fceebc5c6" category="list-text">Com o NFS, os dados eram funcionalmente equivalentes a serem agrupados, o que pode reduzir o número de nós de computação dependendo da sua carga de trabalho.  Os usuários do cluster Apache Spark não precisam rebalancear manualmente os dados ao alterar o número de nós de computação.</block>
  <block id="c13c2e056adb51078f3067ba570d2780" category="section-title">Escalonamento de desempenho - Escala horizontal</block>
  <block id="beb08cca1e99e0bdbf11c74ebb62d5ea" category="paragraph">Quando você precisa de mais poder de computação de um cluster Hadoop em uma solução AFF , você pode adicionar nós de dados com um número apropriado de controladores de armazenamento.  A NetApp recomenda começar com quatro nós de dados por matriz de controlador de armazenamento e aumentar o número para oito nós de dados por controlador de armazenamento, dependendo das características da carga de trabalho.</block>
  <block id="431bd1a68814e184bc49ff7231450049" category="paragraph">AFF e FAS são perfeitos para análises no local.  Com base nos requisitos de computação, você pode adicionar gerenciadores de nós, e operações não disruptivas permitem adicionar um controlador de armazenamento sob demanda, sem tempo de inatividade.  Oferecemos recursos avançados com AFF e FAS, como suporte de mídia NVME, eficiência garantida, redução de dados, QOS, análise preditiva, camadas de nuvem, replicação, implantação de nuvem e segurança.  Para ajudar os clientes a atender às suas necessidades, a NetApp oferece recursos como análise de sistema de arquivos, cotas e balanceamento de carga on-box, sem custos adicionais de licença.  A NetApp tem melhor desempenho no número de trabalhos simultâneos, menor latência, operações mais simples e maior taxa de transferência de gigabytes por segundo do que nossos concorrentes.  Além disso, o NetApp Cloud Volumes ONTAP é executado em todos os três principais provedores de nuvem.</block>
  <block id="ccfed4ad520d8db8b13dc91438d30680" category="section-title">Escalonamento de desempenho - Escalonamento vertical</block>
  <block id="9341bdabe891be81d2be3440a4c413b5" category="paragraph">Os recursos de expansão permitem que você adicione unidades de disco aos sistemas AFF, FAS e E-Series quando precisar de capacidade de armazenamento adicional.  Com o Cloud Volumes ONTAP, dimensionar o armazenamento para o nível PB é uma combinação de dois fatores: hierarquizar dados usados com pouca frequência para armazenamento de objetos a partir do armazenamento em bloco e empilhar licenças do Cloud Volumes ONTAP sem computação adicional.</block>
  <block id="1a4f71bef2c7cfcc6846e82e9e0e0331" category="section-title">Vários protocolos</block>
  <block id="11d6ae97757031ae53e1437c9c9b61bd" category="paragraph">Os sistemas NetApp oferecem suporte à maioria dos protocolos para implantações do Hadoop, incluindo SAS, iSCSI, FCP, InfiniBand e NFS.</block>
  <block id="98ed4f29e9a08c43fe10dda6782e567e" category="section-title">Soluções operacionais e suportadas</block>
  <block id="464e596f1568de8e5f19e16e09beaaa8" category="inline-link">Hortonworks</block>
  <block id="f1fd1913c968a1c383c88631e335a7ca" category="inline-link">certificação</block>
  <block id="7454739e907f5595ae61d84b8547f574" category="inline-link">parceiro</block>
  <block id="24cd9f53ddcc21c3360cfbf1ab787373" category="paragraph">As soluções Hadoop descritas neste documento são suportadas pela NetApp.  Essas soluções também são certificadas pelos principais distribuidores do Hadoop.  Para obter informações, consulte o<block ref="030fa12946d3d4653223853ac09b7183" category="inline-link-rx"></block> site e o Cloudera<block ref="110185abc20d52e7eb83135b84742416" category="inline-link-rx"></block> e<block ref="a573734769be98dedf1aa2242c0eb40c" category="inline-link-rx"></block> sites.</block>
  <block id="7e838102a13e780977b21c90f648a5d0" category="summary">Esta seção descreve a natureza e os componentes do Apache Spark e como eles contribuem para esta solução.</block>
  <block id="8f4c7939e8a42e023939df947aba54f6" category="doc">Tecnologia de soluções</block>
  <block id="f4387c90411f7b92618497bc53b16256" category="paragraph">Apache Spark é uma estrutura de programação popular para escrever aplicativos Hadoop que funciona diretamente com o Hadoop Distributed File System (HDFS).  O Spark está pronto para produção, suporta processamento de dados de streaming e é mais rápido que o MapReduce.  O Spark tem cache de dados na memória configurável para iteração eficiente, e o shell do Spark é interativo para aprendizado e exploração de dados.  Com o Spark, você pode criar aplicativos em Python, Scala ou Java.  Os aplicativos Spark consistem em um ou mais trabalhos que têm uma ou mais tarefas.</block>
  <block id="6a696023a577a0d26763ef9c382b4b1f" category="paragraph">Cada aplicativo Spark tem um driver Spark.  No modo YARN-Client, o driver é executado no cliente localmente.  No modo YARN-Cluster, o driver é executado no cluster no mestre do aplicativo.  No modo de cluster, o aplicativo continua em execução mesmo se o cliente se desconectar.</block>
  <block id="5e8f0f670e38fbdf628b0883f946934f" category="inline-image-macro">Figura mostrando diálogo de entrada/saída ou representando conteúdo escrito</block>
  <block id="bb21b729c47dce20f94160002efec039" category="paragraph"><block ref="bb21b729c47dce20f94160002efec039" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6feb0bd2b4db4693572a9fc2e517e888" category="paragraph">Existem três gerenciadores de cluster:</block>
  <block id="4c79d7007667a60b712836e2f93d6bfc" category="list-text">*Autônomo.*  Este gerenciador faz parte do Spark, o que facilita a configuração de um cluster.</block>
  <block id="c0a5bce529ff277ee2735538a7b43913" category="list-text">*Apache Mesos.*  Este é um gerenciador de cluster geral que também executa o MapReduce e outros aplicativos.</block>
  <block id="24683e4dfc33dc5b20a0d9a75c0ff150" category="list-text">*Hadoop YARN.*  Este é um gerenciador de recursos no Hadoop 3.</block>
  <block id="569531fd384ec251943946598eb00dcb" category="paragraph">O conjunto de dados distribuídos resilientes (RDD) é o principal componente do Spark.  O RDD recria os dados perdidos e ausentes a partir dos dados armazenados na memória do cluster e armazena os dados iniciais que vêm de um arquivo ou são criados programaticamente.  RDDs são criados a partir de arquivos, dados na memória ou outro RDD.  A programação Spark realiza duas operações: transformação e ações.  A transformação cria um novo RDD com base em um existente.  Ações retornam um valor de um RDD.</block>
  <block id="1af693ed22a2df92eb5adff8c506d0ef" category="paragraph">Transformações e ações também se aplicam a conjuntos de dados e quadros de dados do Spark.  Um conjunto de dados é uma coleção distribuída de dados que fornece os benefícios de RDDs (tipagem forte, uso de funções lambda) com os benefícios do mecanismo de execução otimizado do Spark SQL.  Um conjunto de dados pode ser construído a partir de objetos JVM e então manipulado usando transformações funcionais (mapa, flatMap, filtro e assim por diante).  Um DataFrame é um conjunto de dados organizado em colunas nomeadas.  É conceitualmente equivalente a uma tabela em um banco de dados relacional ou a um quadro de dados em R/Python.  Os DataFrames podem ser construídos a partir de uma ampla gama de fontes, como arquivos de dados estruturados, tabelas no Hive/HBase, bancos de dados externos no local ou na nuvem, ou RDDs existentes.</block>
  <block id="89d836212e4c5086ebcd9e5fbd6a4b37" category="paragraph">Os aplicativos Spark incluem um ou mais trabalhos Spark.  Os trabalhos executam tarefas em executores, e os executores são executados em contêineres YARN.  Cada executor é executado em um único contêiner, e os executores existem durante toda a vida de um aplicativo.  Um executor é corrigido depois que o aplicativo é iniciado, e o YARN não redimensiona o contêiner já alocado.  Um executor pode executar tarefas simultaneamente em dados na memória.</block>
  <block id="bd8f37587e7778e9d19d350dd4bd6d3a" category="summary">Esta seção descreve quem pode estar interessado no conteúdo desta solução.</block>
  <block id="bf8dd94f74c5878ba969abeeef0286d1" category="doc">Público-alvo</block>
  <block id="49997701037fef2c24b57a2e7186d0ab" category="paragraph">O mundo da análise e da ciência de dados abrange diversas disciplinas em TI e negócios:</block>
  <block id="cddde51824956f407b4c02c1e4bc8004" category="list-text">O cientista de dados precisa de flexibilidade para usar as ferramentas e bibliotecas de sua escolha.</block>
  <block id="310a768ecb4689bcaf80072231d73e83" category="list-text">O engenheiro de dados precisa saber como os dados fluem e onde eles residem.</block>
  <block id="529ac4605b034914d0e8b489a81e45e0" category="list-text">Um engenheiro de DevOps precisa de ferramentas para integrar novos aplicativos de IA e ML em seus pipelines de CI e CD.</block>
  <block id="090e55ccd8633a454f9d471ca3ed004d" category="list-text">Administradores e arquitetos de nuvem devem ser capazes de configurar e gerenciar recursos de nuvem híbrida.</block>
  <block id="3cb782c6019ddcbb4e7f6bf8ae154d40" category="list-text">Usuários empresariais querem ter acesso a aplicativos de análise, IA, ML e DL.</block>
  <block id="3dfd24951a51ec1661b0294f59bea86e" category="paragraph">Neste relatório técnico, descrevemos como NetApp AFF, E-Series, StorageGRID, NFS direct access, Apache Spark, Horovod e Keras ajudam cada uma dessas funções a agregar valor aos negócios.</block>
  <block id="49c9a66d1f76b5f264fea5d54130b82a" category="summary">Usamos os scripts TeraSort e TeraValidate na ferramenta de benchmarking TeraGen para medir a validação de desempenho do Spark com as configurações E5760, E5724 e AFF-A800.  Além disso, três casos de uso principais foram testados: pipelines Spark NLP e treinamento distribuído TensorFlow, treinamento distribuído Horovod e aprendizado profundo multi-trabalhador usando Keras para previsão de CTR com DeepFM.</block>
  <block id="41be8de44faa8ba43210d7494ee095d2" category="doc">Resultados dos testes</block>
  <block id="60637296d8b6dcd84aaff3afc778241d" category="paragraph">Usamos os scripts TeraSort e TeraValidate na ferramenta de benchmarking TeraGen para medir a validação de desempenho do Spark com as configurações E5760, E5724 e AFF-A800.  Além disso, três casos de uso principais foram testados: pipelines Spark NLP e treinamento distribuído TensorFlow, treinamento distribuído Horovod e aprendizado profundo de vários trabalhadores usando Keras para previsão de CTR com DeepFM.</block>
  <block id="653a9ba51c0af0c11aab6af3ecfdc8c6" category="paragraph">Para validação do E-Series e do StorageGRID , usamos o fator de replicação 2 do Hadoop.  Para validação do AFF , usamos apenas uma fonte de dados.</block>
  <block id="6cdf0c4c6177a49f44f3688dd2a5b9ad" category="paragraph">A tabela a seguir lista a configuração de hardware para a validação de desempenho do Spark.</block>
  <block id="a1fa27779242b4902f7ae3bdd5c6d508" category="cell">Tipo</block>
  <block id="00e536f9715964bf964b4961d7287f95" category="cell">Nós de trabalho do Hadoop</block>
  <block id="ce1dc110e77caccbe12e51dce2d1c9b7" category="cell">Tipo de unidade</block>
  <block id="c8fafade5cff4119459018fc205beed1" category="cell">Unidades por nó</block>
  <block id="bb43878952414106e66a5d3e8902dd46" category="cell">Controlador de armazenamento</block>
  <block id="c69ff1785c16ab7db216e04b62e5ef4f" category="cell">SG6060</block>
  <block id="a87ff679a2f3e71d9181a67b7542122c" category="cell">4</block>
  <block id="2db46c628cfb3bd1545d3b5a14b4a9c5" category="cell">SAS</block>
  <block id="c20ad4d76fe97759aa27a0c99bff6710" category="cell">12</block>
  <block id="d748fcab9e84c60a5a7b1e5ed2d052c8" category="cell">Par único de alta disponibilidade (HA)</block>
  <block id="fb5e436e0878dfd2227011932c4eb93c" category="cell">E5760</block>
  <block id="072b030ba126b2f4b2374f342be9ed44" category="cell">60</block>
  <block id="6303aa59a000812ac121a6f5238d6c2c" category="cell">Par único de HA</block>
  <block id="83ac07c2ad3d90f5c6608cfaa2eec573" category="cell">E5724</block>
  <block id="1ff1de774005f8da13f42943881c655f" category="cell">24</block>
  <block id="26b9fff68b23131979be5c2d9a456454" category="cell">AFF800</block>
  <block id="34df20bab5e85dc75bfc94ef569cced9" category="cell">SSD</block>
  <block id="1679091c5a880faf6fb5e6087eb1b2dc" category="cell">6</block>
  <block id="bddda15d92b567df6d8aa197c281ddc4" category="paragraph">A tabela a seguir lista os requisitos de software.</block>
  <block id="719d067b229178f03bcfa1da4ac4dede" category="cell">Software</block>
  <block id="34b6cd75171affba6957e308dcbd92be" category="cell">Versão</block>
  <block id="8b6f93f33bce541c7f50f8aff637e2e1" category="cell">RHEL</block>
  <block id="299e5505ce975112afaefec130cc83e0" category="cell">7,9</block>
  <block id="bedb19167c4cde670f36a4985efbadd2" category="cell">Ambiente de execução OpenJDK</block>
  <block id="4fda350b2148254bcd9e67bbdbecdc93" category="cell">1.8.0</block>
  <block id="b185818332a596af6cda9cae4dc594f6" category="cell">VM do servidor OpenJDK de 64 bits</block>
  <block id="681eea6b2a996d12035edc50dc4cb4c2" category="cell">25,302</block>
  <block id="0bcc70105ad279503e31fe7b3f47b665" category="cell">Git</block>
  <block id="30a2ec41610037af662087fe85d19a4d" category="cell">2.24.1</block>
  <block id="87f16b82c65c9274a67305d08b5dfecb" category="cell">GCC/G++</block>
  <block id="b87ed8b82b1cf2cb4e4ddaa75ec9e0e4" category="cell">11.2.1</block>
  <block id="8cde774d6f7333752ed72cacddb05126" category="cell">Fagulha</block>
  <block id="f2f87b58be0d57ecf71ada8df361a2d9" category="cell">3.2.1</block>
  <block id="17e918efeeeb8f100c695e284d5c0a08" category="cell">PySpark</block>
  <block id="1f4e00506ff9fb5fe179f2ba1c60ff61" category="cell">3.1.2</block>
  <block id="401534b4a193f467279a370076ccb955" category="cell">SparkNLP</block>
  <block id="de8a4e99bb5f22ded6d686cfd948274b" category="cell">3.4.2</block>
  <block id="074dd699710da0ec1eb45f13b31788e3" category="cell">TensorFlow</block>
  <block id="0d6f7e6ce6f1553544acb14682c8eb07" category="cell">2.9.0</block>
  <block id="7fee7bb66f4294c3e32783efa7d9bafc" category="cell">Keras</block>
  <block id="f5f1c35a78d5584cdb787d4e3b6b10b6" category="cell">Horovod</block>
  <block id="35a0c5fdc22109515a67a96e5e7fb914" category="cell">0.24.3</block>
  <block id="14bdb1335d2386afb42f726416a2a83b" category="section-title">Análise de sentimento financeiro</block>
  <block id="494027a6b5e9fc8bb84443d03b97a9b7" category="inline-link-macro">TR-4910: Análise de sentimentos das comunicações com o cliente com a NetApp AI</block>
  <block id="74bef786b12cb9d03a6c04df1f605181" category="inline-link">Kit de ferramentas NetApp DataOps</block>
  <block id="559cf37b505e9001d46e6d6bd73e746c" category="inline-link">NVIDIA Riva SDK</block>
  <block id="e65b49198d65919095402991b0cf5624" category="inline-link">Estrutura do Tao</block>
  <block id="460926218a6b1ab3e124f410ee69f408" category="paragraph">Nós publicamos<block ref="d791c48f7898bbaecde983abed6ac7c1" category="inline-link-macro-rx"></block> , no qual um pipeline de IA de conversação de ponta a ponta foi construído usando o<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block> , armazenamento AFF e sistema NVIDIA DGX.  O pipeline executa processamento de sinal de áudio em lote, reconhecimento automático de fala (ASR), aprendizagem de transferência e análise de sentimentos, aproveitando o DataOps Toolkit,<block ref="8702bd0254f484bdfe9f1ec1c2a853b1" category="inline-link-rx"></block> , e o<block ref="bba656873bd8ccd45c0c4fc908390474" category="inline-link-rx"></block> .  Expandindo o caso de uso da análise de sentimentos para o setor de serviços financeiros, criamos um fluxo de trabalho SparkNLP, carregamos três modelos BERT para várias tarefas de PNL, como reconhecimento de entidade nomeada, e obtivemos sentimentos em nível de frase para as teleconferências de resultados trimestrais das 10 maiores empresas da NASDAQ.</block>
  <block id="ffeb7ccd27ad1e7d783757733dadec57" category="paragraph">O seguinte script<block ref="e313c2865ad76497c3eaf980ccfa3d03" prefix=" " category="inline-code"></block> usa o modelo FinBERT para processar transcrições no HDFS e produzir contagens de sentimentos positivos, neutros e negativos, conforme mostrado na tabela a seguir:</block>
  <block id="077259b584adffb379f7f2638be91edc" category="paragraph">A tabela a seguir lista a análise de sentimento em nível de frase e teleconferência de resultados para as 10 maiores empresas da NASDAQ de 2016 a 2020.</block>
  <block id="30702e828192097c5634358e6047d0cf" category="cell">Contagens de sentimentos e porcentagem</block>
  <block id="7838fb6ed7918fca8c7797b3b68952d2" category="cell">Todas as 10 empresas</block>
  <block id="8b10e4ae9eeb5684921a9ab27e4d87aa" category="cell">AAPL</block>
  <block id="48af4341f745163f945fa838eeabb062" category="cell">AMD</block>
  <block id="261fd26b0151a81370d097e4ed4c6505" category="cell">AMZN</block>
  <block id="85fd1bb0e226da6a33e9b5dc1a4952f1" category="cell">CSCO</block>
  <block id="e15ce71ff533c9125f11a46c09e2412b" category="cell">GOOGL</block>
  <block id="fc39dab34bbe435680d30933db783ba0" category="cell">INTC</block>
  <block id="b004b3ecde24c85e32c1923f10d3fb62" category="cell">MSFT</block>
  <block id="7f5f6a07b14840f4d8a22caa3df2aed0" category="cell">NVDA</block>
  <block id="4f65a47dc5d0d8a27379f2b1b4d9281b" category="cell">Contagens positivas</block>
  <block id="9e6adb1432c4a75a33d48693328e4159" category="cell">7447</block>
  <block id="18d10dc6e666eab6de9215ae5b3d54df" category="cell">1567</block>
  <block id="5c572eca050594c7bc3c36e7e8ab9550" category="cell">743</block>
  <block id="f90f2aca5c640289d0a29417bcb63a37" category="cell">290</block>
  <block id="08d98638c6fcd194a4b1e6992063e944" category="cell">682</block>
  <block id="795c7a7a5ec6b460ec00c5841019b9e9" category="cell">826</block>
  <block id="677e09724f0e2df9b6c000b75b5da10d" category="cell">824</block>
  <block id="f47d0ad31c4c49061b9e505593e3db98" category="cell">904</block>
  <block id="41ae36ecb9b3eee609d05b90c14222fb" category="cell">417</block>
  <block id="be201b8b1b0b81005e46d49fd301124c" category="cell">Contagens neutras</block>
  <block id="1ab0418ab8dc5325176cd1e26660234f" category="cell">64067</block>
  <block id="34ad9bc83e3c72c62281cb2c744ac966" category="cell">6856</block>
  <block id="1796a48fa1968edd5c5d10d42c7b1813" category="cell">7596</block>
  <block id="71e63ef5b7249cfc60852f0e0f5bf4c8" category="cell">5086</block>
  <block id="126c2da128e5b044dc53405c25b4d8de" category="cell">6650</block>
  <block id="dd5bfdeb57f7c75d400de61e99d78e2e" category="cell">5914</block>
  <block id="80c0e8c4457441901351e4abbcf8c75c" category="cell">6099</block>
  <block id="6e4243f5511fd6ef0f03e9f386d54403" category="cell">5715</block>
  <block id="67ba02d73c54f0b83c05507b7fb7267f" category="cell">6189</block>
  <block id="e65849536f4b2170d6b42c8309222fac" category="cell">Contagens negativas</block>
  <block id="d860bd12ce9c026814bbdfc1c573f0f5" category="cell">1787</block>
  <block id="c24cd76e1ce41366a4bbe8a49b02a028" category="cell">253</block>
  <block id="979d472a84804b9f647bc185a877a8b5" category="cell">213</block>
  <block id="68d30a9594728bc39aa24be94b319d21" category="cell">84</block>
  <block id="a2557a7b2e94197ff767970b67041697" category="cell">189</block>
  <block id="e2ef524fbf3d9fe611d5a8e90fefdc9c" category="cell">97</block>
  <block id="6a9aeddfc689c1d0e3b9ccc3ab651bc5" category="cell">282</block>
  <block id="854d6fae5ee42911677c739ee1734486" category="cell">202</block>
  <block id="7647966b7343c29048673252e490f736" category="cell">89</block>
  <block id="691ec36991472d115c60f32cd84bfc5b" category="cell">Contagens não categorizadas</block>
  <block id="084b6fbb10729ed4da8c3d3f5a3ae7c9" category="cell">196</block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="fbd7939d674997cdb4692d34de8633c4" category="cell">76</block>
  <block id="c4ca4238a0b923820dcc509a6f75849b" category="cell">1</block>
  <block id="2706e1e04688749582425d394866306e" category="cell">(contagens totais)</block>
  <block id="b72e37e992d9e460ce2a491a974d13b5" category="cell">73497</block>
  <block id="9f6f2381bc56ef668e94f6d1fb4f6309" category="cell">8676</block>
  <block id="a563b6d5abbf137175059d6bb14672cc" category="cell">8552</block>
  <block id="1134ac57b5b1d38b7d70c1b6feaa28cf" category="cell">5536</block>
  <block id="e1e1f667ce4596e5644be6fab627c226" category="cell">7521</block>
  <block id="176bf6219855a6eb1f3a30903e34b6fb" category="cell">6837</block>
  <block id="75da5036f659fe64b53f3d9b39412967" category="cell">7205</block>
  <block id="e6be4c22a5963ab00dfe8f3b695b5332" category="cell">6822</block>
  <block id="2ea1202aed1e0ce30d41be4919b0cc99" category="cell">6695</block>
  <block id="14d1ed13bbef7783a73cfb9346480ce2" category="paragraph">Em termos de porcentagem, a maioria das frases ditas pelos CEOs e CFOs são factuais e, portanto, carregam sentimentos neutros.  Durante uma teleconferência de resultados, os analistas fazem perguntas que podem transmitir sentimentos positivos ou negativos.  Vale a pena investigar mais quantitativamente como o sentimento negativo ou positivo afeta os preços das ações no mesmo dia ou no dia seguinte de negociação.</block>
  <block id="3957e5ecad1215aa086504cf2c9ba9cc" category="paragraph">A tabela a seguir lista a análise de sentimento em nível de frase para as 10 maiores empresas do NASDAQ, expressa em porcentagem.</block>
  <block id="e8a6f3527192d64ba338192ce83f6283" category="cell">Porcentagem de sentimento</block>
  <block id="3289297424e01eda5b788c083bbf3147" category="cell">Positivo</block>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="doc"></block>
  <block id="3e263985564016f5774bfb75e31efb0d" category="paragraph">10,13%</block>
  <block id="d983b23f5dc08dfb28a31a898b6fbb6a" category="cell">18,06%</block>
  <block id="ed5f9ec0b398f0f53408828898412855" category="cell">8,69%</block>
  <block id="4d8e8cc0a97724584c1cd94c9485d555" category="cell">5,24%</block>
  <block id="d43cdfa633a84f9ca5043f4eb9363a38" category="cell">9,07%</block>
  <block id="a134c476ebd0c219b3cc879185d436ce" category="cell">12,08%</block>
  <block id="27cd80a0bdc79a724fdc31fa8841e19b" category="cell">11,44%</block>
  <block id="e954976d9376dfe5860acd553772a6df" category="cell">13,25%</block>
  <block id="d30929e6786318e19a22c88447dcc97c" category="cell">6,23%</block>
  <block id="e9bb5320b3890b6747c91b5a71ae5a01" category="cell">Neutro</block>
  <block id="6c3d5ec0fc8197d1a8f8366e142e37aa" category="cell">87,17%</block>
  <block id="578429551436bef848f19eccdd93fb73" category="cell">79,02%</block>
  <block id="bd443bde0360eb444a5906bea9d081b0" category="cell">88,82%</block>
  <block id="97840fcb1a1f07bef3a12ef2d7975f09" category="cell">91,87%</block>
  <block id="32edca53c1f1f00d865543b435d4ce3a" category="cell">88,42%</block>
  <block id="407967ec786c26ce4ee7608c076fa6d7" category="cell">86,50%</block>
  <block id="9784395b081e78ec535161a5ba0ffd1e" category="cell">84,65%</block>
  <block id="5d4b03024bcea7385ffc5808dd9c3b74" category="cell">83,77%</block>
  <block id="b73c3663139621b36cfdafbeab44fae9" category="cell">92,44%</block>
  <block id="ffb9356ff2b7da85c75c92fa7ea03b8b" category="cell">Negativo</block>
  <block id="672484e7c4fb5894b2ec75fd7e277fe4" category="cell">2,43%</block>
  <block id="c1fbc8ff600d3f571e0c440833db1a10" category="cell">2,92%</block>
  <block id="161a790eac04cd27fc3e4ffd23ba452d" category="cell">2,49%</block>
  <block id="5fd44dd7fb1198b1903141531424bb54" category="cell">1,52%</block>
  <block id="6916237a9f5c4ed45ddfff6fe37f45e7" category="cell">2,51%</block>
  <block id="43045dfce9b4c190cfa4dad2e4bf9457" category="cell">1,42%</block>
  <block id="248199b9ac50bd355476016ad093ac09" category="cell">3,91%</block>
  <block id="1cdf97682ca1bcd645e8dbcebb105529" category="cell">2,96%</block>
  <block id="8098f29a2cea86e839d8ca03f50d52ce" category="cell">1,33%</block>
  <block id="0d015d96f63a8c12d96b8399482b593f" category="cell">Sem categoria</block>
  <block id="1291f0b93a9f9d5a7e7391a09b5ec0cc" category="cell">0,27%</block>
  <block id="9f1ef07877f9d85a82bd500f408b4814" category="cell">0%</block>
  <block id="6a040d1ee7200a1dc349a598a163cc38" category="cell">1,37%</block>
  <block id="d9fd62085e1ade721df051f8bc4c320d" category="cell">0,01%</block>
  <block id="28bf86a8e29245437d4ad59ea6e80962" category="paragraph">Em termos de tempo de execução do fluxo de trabalho, vimos uma melhoria significativa de 4,78x<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block> modo para um ambiente distribuído no HDFS e uma melhoria adicional de 0,14% ao aproveitar o NFS.</block>
  <block id="87509d62c8804cdab48bea9e54013be4" category="paragraph">Como mostra a figura a seguir, o paralelismo de dados e modelos melhorou o processamento de dados e a velocidade de inferência do modelo distribuído do TensorFlow.  A localização dos dados no NFS produziu um tempo de execução um pouco melhor porque o gargalo do fluxo de trabalho é o download de modelos pré-treinados.  Se aumentarmos o tamanho do conjunto de dados de transcrições, a vantagem do NFS fica mais óbvia.</block>
  <block id="493d0790c882abcf160f461d269c7ec5" category="inline-image-macro">Tempo de execução do fluxo de trabalho de análise de sentimentos do Spark NLP.</block>
  <block id="44ec3b18d4516fc85f1a9789d47bd91c" category="paragraph"><block ref="44ec3b18d4516fc85f1a9789d47bd91c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3484d035679c83a95496eb633ffde0d3" category="section-title">Treinamento distribuído com desempenho Horovod</block>
  <block id="43fc68a998702bc80e46c46de6c28621" category="inline-link-macro">Scripts Python para cada caso de uso principal</block>
  <block id="1bdfd0f4247bc70668e65a97471adcb5" category="paragraph">O comando a seguir produziu informações de tempo de execução e um arquivo de log em nosso cluster Spark usando um único<block ref="eb0a191797624dd3a48fa681d3061212" prefix=" " category="inline-code"></block> nó com 160 executores, cada um com um núcleo.  A memória do executor foi limitada a 5 GB para evitar erros de falta de memória.  Veja a seção<block ref="bda46a99ea3f7d5775466396b660e993" category="inline-link-macro-rx"></block> para mais detalhes sobre o processamento de dados, treinamento do modelo e cálculo de precisão do modelo em<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block> .</block>
  <block id="6281f693bbc375a45312622b626d3bcd" category="paragraph">O tempo de execução resultante com dez épocas de treinamento foi o seguinte:</block>
  <block id="842bc4f8403cd2df9f22939e3df59aee" category="paragraph">Foram necessários mais de 43 minutos para processar dados de entrada, treinar um modelo DNN, calcular a precisão e produzir pontos de verificação do TensorFlow e um arquivo CSV para resultados de previsão.  Limitamos o número de períodos de treinamento a 10, que na prática geralmente é definido como 100 para garantir precisão satisfatória do modelo.  O tempo de treinamento normalmente é escalonado linearmente com o número de épocas.</block>
  <block id="1e580bbdb11118035631867d15ad9f25" category="paragraph">Em seguida, usamos os quatro nós de trabalho disponíveis no cluster e executamos o mesmo script em<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> modo com dados em HDFS:</block>
  <block id="3661bcf870f3d2b11b0489ed7f0585a7" category="paragraph">O tempo de execução resultante foi melhorado da seguinte forma:</block>
  <block id="68b0154732e3239041317d0c7d4ac636" category="paragraph">Com o modelo de Horovod e o paralelismo de dados no Spark, vimos uma aceleração de tempo de execução de 5,29x<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> contra<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block> modo com dez épocas de treinamento.  Isso é mostrado na figura a seguir com as legendas<block ref="99c35850ff7cf7e436b03acedd4c59b3" prefix=" " category="inline-code"></block> e<block ref="509820290d57f333403f490dde7316f4" prefix=" " category="inline-code"></block> .  O treinamento do modelo DNN subjacente do TensorFlow pode ser ainda mais acelerado com GPUs, se disponíveis.  Planejamos realizar esses testes e publicar os resultados em um futuro relatório técnico.</block>
  <block id="216851565edc166c4409515484cac08b" category="paragraph">Nosso próximo teste comparou os tempos de execução com dados de entrada residindo em NFS versus HDFS.  O volume NFS no AFF A800 foi montado em<block ref="e5f5dfd1cb98e0a4c27a3ce6df3ca358" prefix=" " category="inline-code"></block> nos cinco nós (um mestre, quatro trabalhadores) em nosso cluster Spark.  Executamos um comando semelhante aos testes anteriores, com o<block ref="97a9c2c856bc676ba715d3eecc314be6" prefix=" " category="inline-code"></block> parâmetro agora apontando para a montagem NFS:</block>
  <block id="3ba4d622f15813cc383c433722b46d27" category="paragraph">O tempo de execução resultante com NFS foi o seguinte:</block>
  <block id="7e1d2a49ae0a0e06a39a62e2c7c74877" category="paragraph">Houve uma aceleração adicional de 1,43x, conforme mostrado na figura a seguir.  Portanto, com um armazenamento all-flash da NetApp conectado ao seu cluster, os clientes aproveitam os benefícios da rápida transferência e distribuição de dados para fluxos de trabalho do Horovod Spark, alcançando uma aceleração de 7,55x em comparação à execução em um único nó.</block>
  <block id="88caa92ecc3ebb345f81205aa696e3ac" category="inline-image-macro">Tempo de execução do fluxo de trabalho do Horovod Spark.</block>
  <block id="aab5160a7c41d499723acfc13e430eef" category="paragraph"><block ref="aab5160a7c41d499723acfc13e430eef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b32c8309a0c0ca3edc35cb1597b9182c" category="section-title">Modelos de aprendizado profundo para desempenho de previsão de CTR</block>
  <block id="6ff877f80b732c197c0a432029ad1920" category="paragraph">Para sistemas de recomendação projetados para maximizar o CTR, você deve aprender interações de recursos sofisticados por trás dos comportamentos do usuário que podem ser calculados matematicamente da ordem mais baixa para a mais alta.  Tanto as interações de recursos de baixa quanto de alta ordem devem ser igualmente importantes para um bom modelo de aprendizado profundo, sem distorção em relação a uma ou outra.  Deep Factorization Machine (DeepFM), uma rede neural baseada em máquina de fatoração, combina máquinas de fatoração para recomendação e aprendizado profundo para aprendizado de recursos em uma nova arquitetura de rede neural.</block>
  <block id="a22645195470eca2abbe24e7d40cde8e" category="inline-link">Modelos largos e profundos</block>
  <block id="8a7e0c5a65151889fa193b20e6ea6484" category="paragraph">Embora as máquinas de fatoração convencionais modelem interações de recursos em pares como um produto interno de vetores latentes entre recursos e possam, teoricamente, capturar informações de alta ordem, na prática, os profissionais de aprendizado de máquina geralmente usam apenas interações de recursos de segunda ordem devido à alta complexidade de computação e armazenamento.  Variantes de redes neurais profundas como as do Google<block ref="6c51a2ff49c9929908a73e863a1421f0" category="inline-link-rx"></block> por outro lado, aprende interações de recursos sofisticados em uma estrutura de rede híbrida combinando um modelo linear amplo e um modelo profundo.</block>
  <block id="a22f6dcc8bc499f7332ab04cdb36fcf9" category="paragraph">Há duas entradas para este Modelo Amplo e Profundo, uma para o modelo amplo subjacente e outra para o profundo, sendo que esta última parte ainda requer engenharia de recursos especializada e, portanto, torna a técnica menos generalizável para outros domínios.  Diferentemente do modelo amplo e profundo, o DeepFM pode ser treinado eficientemente com recursos brutos sem qualquer engenharia de recursos, porque sua parte ampla e parte profunda compartilham a mesma entrada e o mesmo vetor de incorporação.</block>
  <block id="fa3406903536d0cf09bf8e66ae33aebf" category="inline-link-macro">Scripts Python para cada caso de uso principal.</block>
  <block id="e78769fdc1aff8f5383517c0dc3ec750" category="paragraph">Primeiro processamos o Criteo<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block> (11 GB) em um arquivo CSV chamado<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> armazenado em uma montagem NFS<block ref="17d831727f14e5379e2f4773837ccfa4" prefix=" " category="inline-code"></block> usando<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block> da seção<block ref="b6cb6fe53e443d0379ed59c804a7a30d" category="inline-link-macro-rx"></block> Dentro deste script, a função<block ref="000f75d2ea65c8a3d82d62e405ce82ee" prefix=" " category="inline-code"></block> executa vários métodos de string para remover tabulações e inserir<block ref="433beb9a090abf694184e96d76b3046d" prefix=" " category="inline-code"></block> como delimitador e<block ref="11b282e345a74511901532f5c84b59ee" prefix=" " category="inline-code"></block> como nova linha.  Observe que você só precisa processar o original<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block> uma vez, para que o bloco de código seja mostrado como comentários.</block>
  <block id="02aeed17192e292b1708094a50785b65" category="paragraph">Para os testes seguintes de diferentes modelos DL, usamos<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> como arquivo de entrada.  Em execuções de testes subsequentes, o arquivo CSV de entrada foi lido em um Spark DataFrame com esquema contendo um campo de<block ref="182ea3b4ea8b947ba1626831aa9debbe" prefix=" " category="inline-code"></block> , recursos densos inteiros<block ref="2c94c76f60323031573497e25961744a" prefix=" " category="inline-code"></block> , e recursos esparsos<block ref="57fae172685844997d173fa4248d66f8" prefix=" " category="inline-code"></block> .  A seguir<block ref="78d07f07ead3482e696c0c224c2a7ed5" prefix=" " category="inline-code"></block> O comando recebe um CSV de entrada, treina modelos DeepFM com divisão de 20% para validação cruzada e escolhe o melhor modelo após dez períodos de treinamento para calcular a precisão da previsão no conjunto de teste:</block>
  <block id="52703dd8fd8c710b0aed616d19ddc0fb" category="paragraph">Observe que, como o arquivo de dados<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> for maior que 11 GB, você deve definir um espaço suficiente<block ref="af770896b1954b7c355d9becfe487e40" prefix=" " category="inline-code"></block> maior que o tamanho do conjunto de dados para evitar erros.</block>
  <block id="650f108a9978f10b1e3b0a8cbdcd6ac1" category="inline-link">Flecha Apache</block>
  <block id="caa01fc7f9a1a61f1bc803760af8e97f" category="paragraph">No acima<block ref="0ce62b6d4610e91242b63139adeb9432" prefix=" " category="inline-code"></block> configuração também habilitamos<block ref="d19d750623d06d371730c4055a0fbbbf" category="inline-link-rx"></block> , que converte um Spark DataFrame em um Pandas DataFrame com o<block ref="5d77cff4a1fdffb38c875e9a11a310fb" prefix=" " category="inline-code"></block> método.</block>
  <block id="e20380d4fed48eae6cd24a0df1477ba7" category="paragraph">Após a divisão aleatória, há mais de 36 milhões de linhas no conjunto de dados de treinamento e 9 milhões de amostras no conjunto de teste:</block>
  <block id="a390a463e93dd87edffb2c8b23242507" category="paragraph">Como este relatório técnico se concentra em testes de CPU sem usar GPUs, é fundamental que você crie o TensorFlow com sinalizadores de compilador apropriados.  Esta etapa evita invocar quaisquer bibliotecas aceleradas por GPU e aproveita ao máximo as instruções Advanced Vector Extensions (AVX) e AVX2 do TensorFlow.  Esses recursos são projetados para cálculos algébricos lineares, como adição vetorizada, multiplicação de matrizes dentro de um treinamento DNN de propagação direta ou retropropagação.  A instrução Fused Multiply Add (FMA) disponível com AVX2 usando registradores de ponto flutuante (FP) de 256 bits é ideal para códigos inteiros e tipos de dados, resultando em um aumento de velocidade de até 2x.  Para códigos FP e tipos de dados, o AVX2 atinge 8% de aceleração em relação ao AVX.</block>
  <block id="6c396013ff0ebff6a2a96cdc20a4ba4c" category="inline-link">Bazel</block>
  <block id="97139e366bae36e316c93ce5b5e7e10b" category="paragraph">Para construir o TensorFlow a partir do código-fonte, a NetApp recomenda usar<block ref="0bf1f7ee55f693a3c117cb75493ba615" category="inline-link-rx"></block> .  Para nosso ambiente, executamos os seguintes comandos no prompt do shell para instalar<block ref="ffd93b30364fb8893d5bbb6fdb312666" prefix=" " category="inline-code"></block> ,<block ref="1208feb4bf9c4dd21156d8231d098ba1" prefix=" " category="inline-code"></block> , e Bazel.</block>
  <block id="29fe549665f940a68b9303eae3e3a61e" category="paragraph">Você deve habilitar o GCC 5 ou mais recente para usar os recursos do C++17 durante o processo de compilação, que é fornecido pelo RHEL com a Software Collections Library (SCL).  Os seguintes comandos instalam<block ref="188b06575e77785e6b73e5e85b8e6ada" prefix=" " category="inline-code"></block> e GCC 11.2.1 em nosso cluster RHEL 7.9:</block>
  <block id="92a2b5cb9c6906035c2864fa225e1940" category="inline-link">artigo</block>
  <block id="d4b82f54dfee1e5c527d0d5f8cb0d7aa" category="paragraph">Observe que os dois últimos comandos habilitam<block ref="1dde0514b51c7c8f49cc63e4b54b8b37" prefix=" " category="inline-code"></block> , que usa<block ref="03fec70ce2bd12477f18ac0667e43d67" prefix=" " category="inline-code"></block> (GCC 11.2.1).  Além disso, certifique-se de que seu<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block> a versão é maior que 1.8.3 (vem com o RHEL 7.9).  Consulte isto<block ref="7d93914bddb4046675adee0145ba45bd" category="inline-link-rx"></block> para atualização<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block> para 2.24.1.</block>
  <block id="ba89c701879ec1f07e28185e3446d252" category="inline-link-macro">Scripts Python para cada caso de uso principal,</block>
  <block id="a33b7755e5f9b504d2d038eaca4ff28d" category="inline-link">CUDA</block>
  <block id="e63cc75a56452201d199b8b0694ad9c1" category="paragraph">Presumimos que você já clonou o repositório mestre mais recente do TensorFlow.  Em seguida, crie um<block ref="1629dee48cc4e53161f9b2be8614e062" prefix=" " category="inline-code"></block> diretório com um<block ref="09498dbadf45966909850dc8a47ebb13" prefix=" " category="inline-code"></block> arquivo para compilar o TensorFlow a partir do código-fonte com AVX, AVX2 e FMA.  Execute o<block ref="e2d5a00791bce9a01f99bc6fd613a39d" prefix=" " category="inline-code"></block> arquivo e especifique o local binário correto do Python.<block ref="be1c72ed18fb5f637a2d34d959decb73" category="inline-link-rx"></block> está desabilitado para nossos testes porque não usamos uma GPU.  UM<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block> o arquivo é gerado de acordo com suas configurações.  Além disso, editamos o arquivo e configuramos<block ref="4e1b2fd49a68e112bae6de1bc453f18c" prefix=" " category="inline-code"></block> para habilitar o suporte HDFS.  Consulte<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block> na seção<block ref="f76831928c99e33a4e51e1e38bb9ab3c" category="inline-link-macro-rx"></block> para uma lista completa de configurações e sinalizadores.</block>
  <block id="8329b0f29ec7368fd026b86d981f9dc7" category="paragraph">Depois de criar o TensorFlow com os sinalizadores corretos, execute o script a seguir para processar o conjunto de dados Criteo Display Ads, treinar um modelo DeepFM e calcular a Área sob a Curva Característica Operacional do Receptor (ROC AUC) a partir das pontuações de previsão.</block>
  <block id="d5a94c8db568912353007fdff822667e" category="paragraph">Após dez períodos de treinamento, obtivemos a pontuação AUC no conjunto de dados de teste:</block>
  <block id="e3c9ed451390735cd8c4f8e5eb0e31f5" category="paragraph">De maneira semelhante aos casos de uso anteriores, comparamos o tempo de execução do fluxo de trabalho do Spark com dados residentes em locais diferentes.  A figura a seguir mostra uma comparação da previsão de CTR de aprendizado profundo para um tempo de execução de fluxos de trabalho do Spark.</block>
  <block id="3737826be0460f743becdc4c64050946" category="inline-image-macro">Comparação da previsão de CTR de aprendizado profundo para um tempo de execução de fluxos de trabalho do Spark.</block>
  <block id="f68ffbfae290c4d8a7f8381ad0cad4ff" category="paragraph"><block ref="f68ffbfae290c4d8a7f8381ad0cad4ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="edeeafbd44ff39ea2ff14f5de4488b69" category="summary">Esta página descreve as diferentes áreas nas quais esta solução pode ser usada.</block>
  <block id="bf9bdab57c82171f2cc9bcebdc37b2c2" category="doc">Resumo do caso de uso</block>
  <block id="badfbf9255d6b555592b41ab34e4efc6" category="section-title">Dados de streaming</block>
  <block id="4cc7dbb8e0e56a0e190e0ad588a8ba78" category="paragraph">O Apache Spark pode processar dados de streaming, que são usados para processos de extração, transformação e carregamento (ETL) de streaming; enriquecimento de dados; disparo de detecção de eventos; e análise de sessão complexa:</block>
  <block id="35658693f34a1c5dc8b752f79caeb198" category="list-text">*Streaming ETL.*  Os dados são continuamente limpos e agregados antes de serem enviados aos armazenamentos de dados.  A Netflix usa o streaming Kafka e Spark para criar uma solução de recomendação de filmes e monitoramento de dados online em tempo real que pode processar bilhões de eventos por dia de diferentes fontes de dados.  No entanto, o ETL tradicional para processamento em lote é tratado de forma diferente.  Esses dados são lidos primeiro e depois convertidos em um formato de banco de dados antes de serem gravados nele.</block>
  <block id="1e8d9d663f583499f32f92ca2486e7df" category="list-text">*Enriquecimento de dados.*  O Spark Streaming enriquece os dados ao vivo com dados estáticos para permitir uma análise de dados mais em tempo real.  Por exemplo, os anunciantes on-line podem fornecer anúncios personalizados e segmentados, direcionados com base em informações sobre o comportamento do cliente.</block>
  <block id="c8fc01958b8b24afef85387342bc2aef" category="list-text">*Detecção de evento de gatilho.*  O Spark Streaming permite que você detecte e responda rapidamente a comportamentos incomuns que podem indicar problemas potencialmente sérios.  Por exemplo, instituições financeiras usam gatilhos para detectar e interromper transações fraudulentas, e hospitais usam gatilhos para detectar alterações perigosas de saúde detectadas nos sinais vitais de um paciente.</block>
  <block id="af8f12b6a4cff696802c46442e36e264" category="list-text">*Análise complexa de sessão.*  O Spark Streaming coleta eventos como atividade do usuário após login em um site ou aplicativo, que são então agrupados e analisados.  Por exemplo, a Netflix usa essa funcionalidade para fornecer recomendações de filmes em tempo real.</block>
  <block id="22f51db51c9641d5358726fa5e03f67b" category="inline-link-macro">TR-4912: Diretrizes de práticas recomendadas para armazenamento em camadas do Confluent Kafka com NetApp</block>
  <block id="519be207be9b1131f1e8524db61cf335" category="paragraph">Para obter mais configurações de dados de streaming, verificação do Confluent Kafka e testes de desempenho, consulte<block ref="474863345040f8931cecadcc38733702" category="inline-link-macro-rx"></block> .</block>
  <block id="2a80513f40f0c2a9c11009fa83049bd9" category="section-title">Aprendizado de máquina</block>
  <block id="c2e9a1abebd45c1d446eb49fb690afd7" category="paragraph">A estrutura integrada do Spark ajuda você a executar consultas repetidas em conjuntos de dados usando a biblioteca de aprendizado de máquina (MLlib).  O MLlib é usado em áreas como agrupamento, classificação e redução de dimensionalidade para algumas funções comuns de big data, como inteligência preditiva, segmentação de clientes para fins de marketing e análise de sentimentos.  O MLlib é usado em segurança de rede para conduzir inspeções em tempo real de pacotes de dados em busca de indícios de atividade maliciosa.  Ele ajuda os provedores de segurança a aprender sobre novas ameaças e a ficar à frente dos hackers, ao mesmo tempo em que protegem seus clientes em tempo real.</block>
  <block id="03d3e10f072ae25d491b55767b4fc37e" category="section-title">Aprendizado profundo</block>
  <block id="b45690b6bb62bd55da7e1911ed880ec6" category="paragraph">TensorFlow é uma estrutura de aprendizado profundo popular usada em todo o setor.  O TensorFlow suporta treinamento distribuído em um cluster de CPU ou GPU.  Este treinamento distribuído permite que os usuários o executem em uma grande quantidade de dados com muitas camadas profundas.</block>
  <block id="9981faa66d13ca7ba415a6c70dc52893" category="paragraph">Até bem pouco tempo, se quiséssemos usar o TensorFlow com o Apache Spark, precisávamos executar todo o ETL necessário para o TensorFlow no PySpark e então gravar os dados no armazenamento intermediário.  Esses dados seriam então carregados no cluster TensorFlow para o processo de treinamento real.  Esse fluxo de trabalho exigia que o usuário mantivesse dois clusters diferentes, um para ETL e outro para treinamento distribuído do TensorFlow.  Executar e manter vários clusters costumava ser tedioso e demorado.</block>
  <block id="082ad29f115c5cd4ab167c596b90688c" category="paragraph">DataFrames e RDD em versões anteriores do Spark não eram adequados para aprendizado profundo porque o acesso aleatório era limitado.  No Spark 3.0 com projeto hidrogênio, o suporte nativo para as estruturas de aprendizado profundo é adicionado.  Essa abordagem permite o agendamento não baseado em MapReduce no cluster Spark.</block>
  <block id="44cd5d1ec9ffc51f82d838faf685ef6e" category="section-title">Análise interativa</block>
  <block id="9650da7c8eb40c14055202b3dd7f4443" category="paragraph">O Apache Spark é rápido o suficiente para executar consultas exploratórias sem amostragem com linguagens de desenvolvimento diferentes do Spark, incluindo SQL, R e Python.  O Spark usa ferramentas de visualização para processar dados complexos e visualizá-los interativamente.  O Spark com streaming estruturado executa consultas interativas em dados ao vivo em análises da web, o que permite que você execute consultas interativas na sessão atual de um visitante da web.</block>
  <block id="d89f01bf7c0ceacaf30849bab08e0939" category="section-title">Sistema de recomendação</block>
  <block id="38c79706797b854a06f30876828ee766" category="paragraph">Ao longo dos anos, os sistemas de recomendação trouxeram mudanças tremendas para nossas vidas, à medida que empresas e consumidores responderam a mudanças drásticas nas compras on-line, no entretenimento on-line e em muitos outros setores.  De fato, esses sistemas estão entre as histórias de sucesso mais evidentes da IA na produção.  Em muitos casos de uso prático, sistemas de recomendação são combinados com IA conversacional ou chatbots interligados a um backend de PNL para obter informações relevantes e produzir inferências úteis.</block>
  <block id="6346d11f3fda24eb2d12fa4ac478fe3b" category="paragraph">Hoje em dia, muitos varejistas estão adotando novos modelos de negócios, como comprar on-line e retirar na loja, retirada na calçada, autoatendimento, escanear e levar, e muito mais.  Esses modelos se tornaram populares durante a pandemia da COVID-19, tornando as compras mais seguras e convenientes para os consumidores.  A IA é crucial para essas crescentes tendências digitais, que são influenciadas pelo comportamento do consumidor e vice-versa.  Para atender às crescentes demandas dos consumidores, aprimorar a experiência do cliente, melhorar a eficiência operacional e aumentar a receita, a NetApp ajuda seus clientes e empresas empresariais a usar algoritmos de aprendizado de máquina e aprendizado profundo para projetar sistemas de recomendação mais rápidos e precisos.</block>
  <block id="b32f1d719ba1fea2cad3538a4795c552" category="paragraph">Existem várias técnicas populares usadas para fornecer recomendações, incluindo filtragem colaborativa, sistemas baseados em conteúdo, modelo de recomendação de aprendizado profundo (DLRM) e técnicas híbridas.  Anteriormente, os clientes utilizavam o PySpark para implementar filtragem colaborativa para criar sistemas de recomendação.  O Spark MLlib implementa mínimos quadrados alternados (ALS) para filtragem colaborativa, um algoritmo muito popular entre empresas antes do surgimento do DLRM.</block>
  <block id="9389b39b238fbd5ad61de2fea371853d" category="section-title">Processamento de linguagem natural</block>
  <block id="18bfab6309a4addeb7e1dae07d2a4b89" category="inline-link">Gartner</block>
  <block id="47fa981bf7641c90f0ce83a88c21234e" category="paragraph">A IA conversacional, possibilitada pelo processamento de linguagem natural (PLN), é o ramo da IA que ajuda os computadores a se comunicarem com os humanos.  A PNL é predominante em todos os setores e em muitos casos de uso, desde assistentes inteligentes e chatbots até pesquisa do Google e texto preditivo.  De acordo com um<block ref="be3a50ddc5683c6936ee69409b86e212" category="inline-link-rx"></block> previsão é que até 2022, 70% das pessoas estarão interagindo com plataformas de IA conversacional diariamente.  Para uma conversa de alta qualidade entre um humano e uma máquina, as respostas devem ser rápidas, inteligentes e naturais.</block>
  <block id="9cac4209da8ee0481a45fa299b66e587" category="paragraph">Os clientes precisam de uma grande quantidade de dados para processar e treinar seus modelos de PNL e reconhecimento automático de fala (ASR).  Eles também precisam mover dados pela borda, núcleo e nuvem, e precisam do poder de realizar inferências em milissegundos para estabelecer comunicação natural com humanos.  O NetApp AI e o Apache Spark são uma combinação ideal para computação, armazenamento, processamento de dados, treinamento de modelos, ajuste fino e implantação.</block>
  <block id="6ecf226f4b849e3111584c1eebd25f3c" category="paragraph">Análise de sentimentos é um campo de estudo dentro da PNL em que sentimentos positivos, negativos ou neutros são extraídos do texto.  A análise de sentimentos tem uma variedade de casos de uso, desde determinar o desempenho dos funcionários do centro de suporte em conversas com os chamadores até fornecer respostas automatizadas e apropriadas do chatbot.  Ele também tem sido usado para prever o preço das ações de uma empresa com base nas interações entre representantes da empresa e o público em teleconferências de resultados trimestrais.  Além disso, a análise de sentimentos pode ser usada para determinar a opinião do cliente sobre os produtos, serviços ou suporte fornecido pela marca.</block>
  <block id="635dbe8a61ae76776533cf731db5ca3d" category="inline-link">Spark NLP</block>
  <block id="511405f2428e9a6a71530b7f2cdcbc21" category="inline-link">Laboratórios John Snow</block>
  <block id="351594930581e8fa82cf694de7562fd2" category="inline-link">sentimento de notícias financeiras</block>
  <block id="8f1fadc17d848b3be53c2009f5f9070a" category="inline-link">FinBERT</block>
  <block id="c1856f13b6ce4dd1f710cf08138e0c51" category="paragraph">Nós usamos o<block ref="0f17ea1334fb20ed83c3ab03268616d7" category="inline-link-rx"></block> biblioteca de<block ref="22825786ea861b373c2a5fdda9f62d81" category="inline-link-rx"></block> para carregar pipelines pré-treinados e modelos de Representações de Codificadores Bidirecionais de Transformadores (BERT), incluindo<block ref="1a3a0057856cc0bfa7cb2c9343eb2415" category="inline-link-rx"></block> e<block ref="ac723dc3fc44f63057a74e935ae9db52" category="inline-link-rx"></block> , realizando tokenização, reconhecimento de entidades nomeadas, treinamento de modelos, ajuste e análise de sentimentos em escala.  Spark NLP é a única biblioteca NLP de código aberto em produção que oferece transformadores de última geração, como BERT, ALBERT, ELECTRA, XLNet, DistilBERT, RoBERTa, DeBERTa, XLM-RoBERTa, Longformer, ELMO, Universal Sentence Encoder, Google T5, MarianMT e GPT2.  A biblioteca funciona não apenas em Python e R, mas também no ecossistema JVM (Java, Scala e Kotlin) em escala, estendendo o Apache Spark nativamente.</block>
  <block id="e353dbe42c8654f33588d4da0b517469" category="doc">Resumo</block>
  <block id="c9da861bd07fd9446a0e4f9108517532" category="paragraph">Este documento descreve como mover dados de análises de big data e sistemas de computação de alto desempenho (HPC) para que possam ser usados em fluxos de trabalho de inteligência artificial (IA).  A IA normalmente processa dados NFS por meio de exportações NFS.  No entanto, você pode ter seus dados de IA em uma plataforma de análise de big data e computação de alto desempenho (HPC).  Pode ser o Hadoop Distributed File System (HDFS), um objeto binário grande (Blob), armazenamento S3 ou o General Parallel File System (GPFS) da IBM.  Neste documento, descrevemos como mover dados de uma plataforma de análise de big data e GPFS para NFS usando comandos nativos do Hadoop, o NetApp In-Place Analytics Module (NIPAM) e o NetApp XCP.  Este documento também discute os benefícios comerciais de mover dados de big data e HPC para IA.</block>
  <block id="4bb047f8c530785002e490ef17fa725e" category="doc">Onde encontrar informações adicionais</block>
  <block id="7d5b957cd473f6eaf5ad335a9c63c4ff" category="paragraph">Para saber mais sobre as informações descritas neste documento, revise os seguintes documentos e/ou sites:</block>
  <block id="f5ac1e3c252855373c7f660dbd89699d" category="list-text">Guia de práticas recomendadas e implementação do NetApp FlexGroup Volume</block>
  <block id="7d72333a4556beea0bd57e4b8a007b47" category="paragraph"><block ref="7d72333a4556beea0bd57e4b8a007b47" category="inline-link-rx"></block></block>
  <block id="bc4fe2352063642d68529f2aa0ca7ca3" category="list-text">Documentação do produto NetApp</block>
  <block id="c9617ae303d0bce89d13bebecca2ea1b" category="paragraph"><block ref="c9617ae303d0bce89d13bebecca2ea1b" category="inline-link-rx"></block></block>
  <block id="e0a1057b7f63b9621d22a28a118e4a79" category="summary">Esta seção descreve os benefícios comerciais desta solução.</block>
  <block id="7f0cbc7391fd4e971628295e6bff035a" category="doc">Benefícios para os negócios</block>
  <block id="239f77225835899839f2d1318d1cc1c4" category="paragraph">Mover dados da análise de big data para a IA oferece os seguintes benefícios:</block>
  <block id="c07548816e2d37db2db301172209009e" category="list-text">A capacidade de extrair dados de diferentes sistemas de arquivos Hadoop e GPFS em um sistema de armazenamento NFS unificado</block>
  <block id="17480f22ec6a36806354b84f9824ff80" category="list-text">Uma maneira automatizada e integrada ao Hadoop de transferir dados</block>
  <block id="626dfcaeea53c1bdef78276b0f594dbf" category="list-text">Uma redução no custo de desenvolvimento de bibliotecas para movimentação de dados de sistemas de arquivos Hadoop</block>
  <block id="8576c8e67d6540e2f677340d38ec60e9" category="list-text">Desempenho máximo por meio de taxa de transferência agregada de múltiplas interfaces de rede a partir de uma única fonte de dados usando NIPAM</block>
  <block id="28338c61f9a9de656b504b14a75bb824" category="list-text">Métodos programados e sob demanda para transferência de dados</block>
  <block id="3c70d03dd35337605475e972b74654c8" category="list-text">Eficiência de armazenamento e capacidade de gerenciamento empresarial para dados NFS unificados usando o software de gerenciamento de dados ONTAP</block>
  <block id="2b602714583b0c6daac65349c0e00e16" category="list-text">Custo zero para movimentação de dados com o método Hadoop para transferência de dados</block>
  <block id="eea7b9fa88f883b7983320cb8dd802ac" category="summary">Esta página discute os desafios que um cliente pode enfrentar ao tentar acessar dados de análises de big data para operações de IA.</block>
  <block id="b794cc731a2a9499d064b08a32552e78" category="paragraph">Os clientes podem enfrentar os seguintes desafios ao tentar acessar dados de análises de big data para operações de IA:</block>
  <block id="593806557377bd8506b6705484962785" category="list-text">Os dados do cliente estão em um repositório de data lake.  O data lake pode conter diferentes tipos de dados, como dados estruturados, não estruturados, semiestruturados, logs e dados de máquina para máquina.  Todos esses tipos de dados devem ser processados em sistemas de IA.</block>
  <block id="43d7d5ce8487763157eabcf01d1cf6ef" category="list-text">O AI não é compatível com sistemas de arquivos Hadoop.  Uma arquitetura de IA típica não é capaz de acessar diretamente dados HDFS e HCFS, que devem ser movidos para um sistema de arquivos compreensível por IA (NFS).</block>
  <block id="e032c722c87677b6dfba13af108c61b8" category="list-text">Mover dados do data lake para IA normalmente requer processos especializados.  A quantidade de dados no data lake pode ser muito grande.  Um cliente precisa ter uma maneira eficiente, de alto rendimento e econômica de mover dados para sistemas de IA.</block>
  <block id="30bd7dc66c05e60d2ea66d09e568cb06" category="list-text">Sincronizando dados.  Se um cliente quiser sincronizar dados entre a plataforma de big data e a IA, às vezes os dados processados pela IA podem ser usados com big data para processamento analítico.</block>
  <block id="c877e65bbe37324c3309ace4aa7745d1" category="summary">Em um cluster de big data, os dados são armazenados em HDFS ou HCFS, como MapR-FS, Windows Azure Storage Blob, S3 ou o sistema de arquivos do Google.  Realizamos testes com HDFS, MapR-FS e S3 como fonte para copiar dados para exportação NetApp ONTAP NFS com a ajuda do NIPAM usando o comando hadoop distcp da fonte.</block>
  <block id="d73e7d11401e9256a0dea0d1e174e1de" category="doc">Solução de movimentação de dados</block>
  <block id="013c5604f73da0e909c46aa5d3a670f3" category="paragraph">Em um cluster de big data, os dados são armazenados em HDFS ou HCFS, como MapR-FS, Windows Azure Storage Blob, S3 ou o sistema de arquivos do Google.  Realizamos testes com HDFS, MapR-FS e S3 como fonte para copiar dados para exportação NetApp ONTAP NFS com a ajuda do NIPAM usando o<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> comando da fonte.</block>
  <block id="9fabfa5fcba2e539b6d2c5eff5bb2116" category="paragraph">O diagrama a seguir ilustra a movimentação típica de dados de um cluster Spark em execução com armazenamento HDFS para um volume NetApp ONTAP NFS para que a NVIDIA possa processar operações de IA.</block>
  <block id="67ed14506d4065a668f7cb0136039d8b" category="paragraph"><block ref="67ed14506d4065a668f7cb0136039d8b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da6616575a7b32d3eb2fa505007a9a4a" category="paragraph">O<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> O comando usa o programa MapReduce para copiar os dados.  O NIPAM trabalha com o MapReduce para atuar como um driver para o cluster Hadoop ao copiar dados.  O NIPAM pode distribuir uma carga entre várias interfaces de rede para uma única exportação.  Esse processo maximiza a taxa de transferência da rede distribuindo os dados entre várias interfaces de rede quando você copia os dados do HDFS ou HCFS para o NFS.</block>
  <block id="c2cad9f038dfeecd75697cb4bebe4c68" category="admonition">O NIPAM não é compatível nem certificado com o MapR.</block>
  <block id="20220b4c576eeca673151438f5ee1da9" category="summary">A solução de movimentação de dados para IA é baseada nas necessidades dos clientes de processar dados do Hadoop de operações de IA.  O NetApp move dados do HDFS para o NFS usando o NIPAM.  Em um caso de uso, o cliente precisava mover dados para o NFS local e outro cliente precisava mover dados do Windows Azure Storage Blob para o Google Cloud NetApp Volumes para processar os dados das instâncias de nuvem da GPU na nuvem.</block>
  <block id="7f10e017358079527e7045a68782eb14" category="doc">Solução de movimentação de dados para IA</block>
  <block id="b6392eaf0ddf0463d633e69aaeeef3ce" category="paragraph">O diagrama a seguir ilustra os detalhes da solução de movimentação de dados.</block>
  <block id="44c3f61c0684bc5b43b5e243a139152c" category="paragraph"><block ref="44c3f61c0684bc5b43b5e243a139152c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e01b73324e59213b14e79f9d912546bc" category="paragraph">As seguintes etapas são necessárias para criar a solução de movimentação de dados:</block>
  <block id="03337d241355e58cdaa3df5a4bb980ef" category="list-text">O ONTAP SAN fornece HDFS, e o NAS fornece o volume NFS por meio do NIPAM para o cluster de data lake de produção.</block>
  <block id="625dd6cfdf4a097dff4340366eec8942" category="list-text">Os dados do cliente estão em HDFS e NFS.  Os dados do NFS podem ser dados de produção de outros aplicativos usados para análises de big data e operações de IA.</block>
  <block id="32477fa182341c04b6e8076232250f76" category="list-text">A tecnologia NetApp FlexClone cria um clone do volume NFS de produção e o provisiona para o cluster de IA local.</block>
  <block id="4e7e9a946510d25d1b28cc93a3723e69" category="list-text">Os dados de um HDFS SAN LUN são copiados para um volume NFS com NIPAM e o<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> comando.  O NIPAM usa a largura de banda de várias interfaces de rede para transferir dados.  Esse processo reduz o tempo de cópia de dados para que mais dados possam ser transferidos.</block>
  <block id="b0dd56fceeaba1e1db258d1b06d2572d" category="list-text">Ambos os volumes NFS são provisionados no cluster de IA para operações de IA.</block>
  <block id="344c1652d7730f66d822b6ed5d07ff77" category="list-text">Para processar dados NFS locais com GPUs na nuvem, os volumes NFS são espelhados no NetApp Private Storage (NPS) com tecnologia NetApp SnapMirror e montados em provedores de serviços de nuvem para GPUs.</block>
  <block id="98105737f8ac55863a4e0763f588cab5" category="list-text">O cliente deseja processar dados em serviços EC2/EMR, HDInsight ou DataProc em GPUs de provedores de serviços de nuvem.  O movedor de dados Hadoop move os dados dos serviços Hadoop para o Google Cloud NetApp Volumes com NIPAM e o<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> comando.</block>
  <block id="f490cd633c8e7648911d95daf043af8f" category="list-text">Os dados do Google Cloud NetApp Volumes são provisionados para a IA por meio do protocolo NFS. Os dados processados pela IA podem ser enviados para um local para análise de big data, além do cluster NVIDIA por meio de NIPAM, SnapMirror e NPS.</block>
  <block id="f13f02e9fbfc272070bb10c4ae60e707" category="paragraph">Neste cenário, o cliente tem um grande número de dados de arquivos no sistema NAS em um local remoto, necessários para o processamento de IA no controlador de armazenamento NetApp local.  Nesse cenário, é melhor usar a Ferramenta de Migração XCP para migrar os dados em uma velocidade maior.</block>
  <block id="74c03e6f525ff7a5f56d15dd77d9d7ee" category="paragraph">O cliente do caso de uso híbrido pode usar o BlueXP Copy and Sync para migrar dados locais de dados NFS, CIFS e S3 para a nuvem e vice-versa para processamento de IA usando GPUs como as de um cluster NVIDIA .  Tanto o BlueXP Copy and Sync quanto o XCP Migration Tool são usados para a migração de dados NFS para o NetApp ONTAP NFS.</block>
  <block id="ae1992b408fce873deb0f11eb017ea19" category="summary">Nesta validação, usamos quatro servidores como servidores de disco compartilhado de rede (NSD) para fornecer discos físicos para GPFS.  O GPFS é criado sobre os discos NSD para exportá-los como exportações NFS para que os clientes NFS possam acessá-los, conforme mostrado na figura abaixo.  Usamos o XCP para copiar os dados do NFS exportados pelo GPFS para um volume NetApp NFS.</block>
  <block id="bc64aad447f072e96947f5d02f7e8134" category="doc">GPFS para NetApp ONTAP NFS</block>
  <block id="f0987b9b1ed71523f2b4be4961e35e12" category="paragraph"><block ref="f0987b9b1ed71523f2b4be4961e35e12" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86339fb1bc11f77d6e48efc42d910f0f" category="section-title">Noções básicas do GPFS</block>
  <block id="d859f99e3b66fbd7305cfd50ba2d4566" category="paragraph">Os seguintes tipos de nós são usados no GPFS:</block>
  <block id="4ac5c1b5474a4920e2433b8f1610729f" category="list-text">*Nó de administração.*  Especifica um campo opcional contendo um nome de nó usado pelos comandos de administração para comunicação entre nós.  Por exemplo, o nó de administração<block ref="f2fde43b571e78e29f67743af45165cb" prefix=" " category="inline-code"></block> poderia passar uma verificação de rede para todos os outros nós no cluster.</block>
  <block id="6659be8d3c5ae97ae05588383a9efb5a" category="list-text">*Nó de quorum.*  Determina se um nó está incluído no conjunto de nós do qual o quorum é derivado.  Você precisa de pelo menos um nó como nó de quorum.</block>
  <block id="504f43a7f6382dae9e638f1c396a1779" category="list-text">*Nó do Gerenciador.*  Indica se um nó faz parte do pool de nós do qual os gerenciadores de sistema de arquivos e gerenciadores de tokens podem ser selecionados.  É uma boa ideia definir mais de um nó como um nó gerenciador.  A quantidade de nós que você designa como gerenciador depende da carga de trabalho e do número de licenças de servidor GPFS que você tem.  Se você estiver executando grandes tarefas paralelas, poderá precisar de mais nós de gerenciador do que em um cluster de quatro nós que dá suporte a um aplicativo web.</block>
  <block id="48b637b1e31141b7e6faae1b7c6d8be2" category="list-text">*Servidor NSD.*  O servidor que prepara cada disco físico para uso com GPFS.</block>
  <block id="8cd64755dc629d6061cef8f3bdddfe8f" category="list-text">*Nó de protocolo.*  O nó que compartilha dados GPFS diretamente por meio de qualquer protocolo Secure Shell (SSH) com o NFS.  Este nó requer uma licença de servidor GPFS.</block>
  <block id="d1a65ffa2a3768b3a494baba34855023" category="section-title">Lista de operações para GPFS, NFS e XCP</block>
  <block id="089009e49dc3cafdc4329d07f11c5250" category="paragraph">Esta seção fornece a lista de operações que criam GPFS, exportam GPFS como uma exportação NFS e transferem os dados usando o XCP.</block>
  <block id="1d9da206467eb5273c4b522820cfddb2" category="section-title">Criar GPFS</block>
  <block id="454f38a55393f7773c6e59f13eb6fef5" category="paragraph">Para criar o GPFS, conclua as seguintes etapas:</block>
  <block id="a69093440b15d387cf13aadb026e36a9" category="list-text">Baixe e instale o acesso a dados em escala de espectro para a versão Linux em um dos servidores.</block>
  <block id="8a3d13c75e4dd8c8cffdf92d8e9dd956" category="list-text">Instale o pacote de pré-requisitos (chef, por exemplo) em todos os nós e desabilite o Security-Enhanced Linux (SELinux) em todos os nós.</block>
  <block id="9356dbe859ed4334d7e27c641d7dd594" category="list-text">Configure o nó de instalação e adicione o nó de administração e o nó GPFS ao arquivo de definição do cluster.</block>
  <block id="1bdc86658a65033989c8064812818633" category="list-text">Adicione o nó do gerenciador, o nó do quorum, os servidores NSD e o nó GPFS.</block>
  <block id="d55b679ec8a82b729ae03c882f27b80e" category="list-text">Adicione os nós GUI, admin e GPFS e adicione um servidor GUI adicional, se necessário.</block>
  <block id="f4e47c4647a3dafebf21a5f40cfa7f9c" category="list-text">Adicione outro nó GPFS e verifique a lista de todos os nós.</block>
  <block id="303364b5437159140dc70a76a77e8aa8" category="list-text">Especifique um nome de cluster, perfil, binário de shell remoto, binário de cópia de arquivo remoto e intervalo de portas a serem definidos em todos os nós GPFS no arquivo de definição de cluster.</block>
  <block id="30d14bbe638530772662c104a30d53d3" category="list-text">Visualize as configurações do GPFS e adicione um nó de administrador adicional.</block>
  <block id="d6daa755d449b0cec4c1c23153b9a0be" category="list-text">Desative a coleta de dados e carregue o pacote de dados para o IBM Support Center.</block>
  <block id="765ad728fb1bb9eb3c981693321a01ef" category="list-text">Habilite o NTP e pré-verifique as configurações antes da instalação.</block>
  <block id="1deb66562b5d0f8ce755a102f2731d8d" category="list-text">Configure, crie e verifique os discos NSD.</block>
  <block id="f54668a02541c80dd54234689ef58ad4" category="list-text">Crie o GPFS.</block>
  <block id="048c1f8a018373ca436ef1a91fe6be57" category="list-text">Monte o GPFS.</block>
  <block id="18a8260437fd56c8bdc1f994d860e490" category="list-text">Verifique e forneça as permissões necessárias ao GPFS.</block>
  <block id="a150a1930bbf429fc0204993b66d46cb" category="list-text">Verifique a leitura e gravação do GPFS executando o<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> comando.</block>
  <block id="83cd36fb568894200fe5f9cf7f7e1193" category="section-title">Exportar GPFS para NFS</block>
  <block id="e2fc86fc4827b925f5cccecdcd51d6b1" category="paragraph">Para exportar o GPFS para o NFS, conclua as seguintes etapas:</block>
  <block id="af125b713cb0d82420980798e0276ea7" category="list-text">Exportar GPFS como NFS através do<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block> arquivo.</block>
  <block id="c953ca93794388b6266ed8529319d420" category="list-text">Instale os pacotes do servidor NFS necessários.</block>
  <block id="c0d11d4c7c65daa849ff313e229d632c" category="list-text">Inicie o serviço NFS.</block>
  <block id="873ad6aeda101f4e6c3a2cb8a46e84ad" category="list-text">Liste os arquivos no GPFS para validar o cliente NFS.</block>
  <block id="f9b2649730ae4997f650bc4a2f8c1773" category="section-title">Configurar cliente NFS</block>
  <block id="25be8238edbbbd8936c0385098957520" category="paragraph">Para configurar o cliente NFS, conclua as seguintes etapas:</block>
  <block id="d11e3a3b633c68e9cc37f13adcdfd95a" category="list-text">Exporte o GPFS como NFS através do<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block> arquivo.</block>
  <block id="64aef4f16c4a9f913379e9668323ed4f" category="list-text">Inicie os serviços do cliente NFS.</block>
  <block id="b7eb10685995437ddaa0df5b09b22fb8" category="list-text">Monte o GPFS por meio do protocolo NFS no cliente NFS.</block>
  <block id="bb8a91cbc28d52ebb4edab31956c7f58" category="list-text">Valide a lista de arquivos GPFS na pasta NFS montada.</block>
  <block id="690b19ed08f992a8a2d6e3e872641b2e" category="list-text">Mova os dados do NFS exportado do GPFS para o NetApp NFS usando o XCP.</block>
  <block id="f919d4d761d618912a13cac0895236af" category="list-text">Valide os arquivos GPFS no cliente NFS.</block>
  <block id="0e0fdc9fc616f1d8648561d150679a8c" category="summary">Esta seção fornece as etapas detalhadas necessárias para configurar o GPFS e mover dados para o NFS usando o NetApp XCP.</block>
  <block id="2cf43976b964350d85af88e8c7c56bfc" category="doc">GPFS para NFS - Etapas detalhadas</block>
  <block id="7f1260d8686ace0468fd1c74b243b7a1" category="section-title">Configurar GPFS</block>
  <block id="de00400b12b028274700d1385b53c26d" category="list-text">Baixe e instale o Spectrum Scale Data Access para Linux em um dos servidores.</block>
  <block id="61a030f51cd790deb6f1374ae7e4d88f" category="list-text">Instale o pacote de pré-requisitos (incluindo o chef e os cabeçalhos do kernel) em todos os nós.</block>
  <block id="cea532f5e6d51ac7b08d9f6d71886efe" category="list-text">Desabilite o SELinux em todos os nós.</block>
  <block id="e116db66dcd3a8a38d53716cdd97c179" category="list-text">Configure o nó de instalação.</block>
  <block id="6021211d885ba9ec28a1dfcdb72b0542" category="list-text">Adicione o nó de administração e o nó GPFS ao arquivo de definição de cluster.</block>
  <block id="8b361b52f2d7d8ddca7c364e1826015d" category="list-text">Adicione o nó do gerenciador e o nó GPFS.</block>
  <block id="d98e392ead2711bea231821e3cafe06e" category="list-text">Adicione o nó de quorum e o nó GPFS.</block>
  <block id="549101fb45a9a42ca05a3b680ea6dcdc" category="list-text">Adicione os servidores NSD e o nó GPFS.</block>
  <block id="0150b7ec1d76a294c8fce802481a2e2d" category="list-text">Adicione os nós GUI, admin e GPFS.</block>
  <block id="5076e582b15cea2e7319261b9eb2dc4e" category="list-text">Adicione outro servidor GUI.</block>
  <block id="65d8f0643532859908a7e9616439572a" category="list-text">Adicione outro nó GPFS.</block>
  <block id="8c6e090e52befa2e95e6d658661749dc" category="list-text">Verifique e liste todos os nós.</block>
  <block id="6a21679cbbcb8a64de6016e8efb6b2ea" category="list-text">Especifique um nome de cluster no arquivo de definição de cluster.</block>
  <block id="0e890aabbc215ad4497b26965a0435ad" category="list-text">Especifique o perfil.</block>
  <block id="3296b6b95878e4a01015b9d97691cd23" category="list-text">Especifique o binário do shell remoto a ser usado pelo GPFS; use<block ref="f8b2a03096b35c105ccb9e1687ea4d21" prefix=" " category="inline-code"></block> .</block>
  <block id="6b1edec7f7c05cc2bc9fb41ef76dc8c9" category="list-text">Especifique o binário de cópia de arquivo remoto a ser usado pelo GPFS; use<block ref="795f05204859c09fe2f151b742bf82f9" prefix=" " category="inline-code"></block> .</block>
  <block id="f35c3f5ce8fa5fca13e0eb96082b73fe" category="list-text">Especifique o intervalo de portas a ser definido em todos os nós GPFS; use<block ref="3b552a3fb3ecdff1af07892680e6d03a" prefix=" " category="inline-code"></block> .</block>
  <block id="84807c9c164a1fd83db3680e7b5a6587" category="list-text">Veja as configurações do GPFS.</block>
  <block id="0addd886868e88c985dddc68658e5767" category="list-text">Adicione um nó de administrador.</block>
  <block id="d2e4082ff74b3d592d15b584ec3e64a9" category="list-text">Habilitar NTP.</block>
  <block id="bc5f73d061ad4090dd4180838b34fc5a" category="list-text">Verifique previamente as configurações antes da instalação.</block>
  <block id="7f2019dce6ead5054cb5c0d5ccac9d68" category="list-text">Configurar os discos NSD.</block>
  <block id="bd625aeaf0eb9674912c4c51a421cdb6" category="list-text">Crie os discos NSD.</block>
  <block id="bfc7a92fefcdbb8be49ae2f09a04c609" category="list-text">Verifique o status do disco NSD.</block>
  <block id="abe092e554a73bb99bd2fd85086ffdce" category="list-text">Verifique e forneça as permissões necessárias ao GPFS.</block>
  <block id="737cdea6c4302200061636f408685896" category="list-text">Verifique a leitura e gravação do GPFS executando o<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> comando.</block>
  <block id="978d4e591d532e5741bf55bbe09b8672" category="paragraph">Para exportar GPFS para NFS, conclua as seguintes etapas:</block>
  <block id="67ae9e67c637e0c39f8d92303b0a9c01" category="list-text">Liste os arquivos no GPFS para validar o cliente NFS.</block>
  <block id="e90c8e55eda7dc2ebdbef5659a22a517" category="section-title">Configurar o cliente NFS</block>
  <block id="bc2bba568f2fe74e5616fa8f5953b1bf" category="list-text">Instalar pacotes no cliente NFS.</block>
  <block id="7e4215ed068d7218ec28fe900e8feb16" category="list-text">Valide a lista de arquivos GPFS na pasta montada no NFS.</block>
  <block id="77086f36ad335fd9c2cc6a63c1d21d84" category="list-text">Mova os dados do NFS exportado pelo GPFS para o NetApp NFS usando o XCP.</block>
  <block id="29fb90c4a1468e178582858240052f4c" category="summary">Para esta solução, a NetApp validou a migração de dados do data lake (HDFS) e dos dados do cluster MapR para o ONTAP NFS.  Os dados residiam no MapR-FS e no HDFS.  O NetApp XCP introduziu um novo recurso que migra diretamente os dados de um sistema de arquivos distribuído, como HDFS e MapR-FS, para o ONTAP NFS.</block>
  <block id="d233c10a88f93c454d0e84cd34840512" category="doc">HDFS e MapR-FS para ONTAP NFS</block>
  <block id="676df8e27b06b6dd639822191d432dc2" category="paragraph">Para esta solução, a NetApp validou a migração de dados do data lake (HDFS) e dos dados do cluster MapR para o ONTAP NFS.  Os dados residiam no MapR-FS e no HDFS.  O NetApp XCP introduziu um novo recurso que migra diretamente os dados de um sistema de arquivos distribuído, como HDFS e MapR-FS, para o ONTAP NFS.  O XCP usa threads assíncronos e chamadas de API C do HDFS para comunicar e transferir dados do MapR-FS e do HDFS.</block>
  <block id="adc95e83c5f5ce743bb6468ffdef4fc3" category="paragraph">A figura abaixo mostra a migração de dados do data lake (HDFS) e MapR-FS para o ONTAP NFS.  Com esse novo recurso, você não precisa exportar a origem como um compartilhamento NFS.</block>
  <block id="3789ec0eac19c6a55506d3fe4f2e880e" category="paragraph"><block ref="3789ec0eac19c6a55506d3fe4f2e880e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11c71088d0987243547dd8fc322c2ad" category="section-title">Por que os clientes estão migrando do HDFS e do MapR-FS para o NFS?</block>
  <block id="8616e2393304ffc26da9b5e853b8db33" category="paragraph">A maioria das distribuições Hadoop, como Cloudera e Hortonworks, usam HDFS e as distribuições MapR usam seu próprio sistema de arquivos chamado Mapr-FS para armazenar dados.  Os dados HDFS e MapR-FS fornecem insights valiosos aos cientistas de dados que podem ser aproveitados em aprendizado de máquina (ML) e aprendizado profundo (DL).  Os dados no HDFS e no MapR-FS não são compartilhados, o que significa que não podem ser usados por outros aplicativos.  Os clientes buscam dados compartilhados, especialmente no setor bancário, onde os dados confidenciais dos clientes são usados por diversos aplicativos.  A versão mais recente do Hadoop (3.x ou posterior) oferece suporte à fonte de dados NFS, que pode ser acessada sem software adicional de terceiros.  Com o novo recurso NetApp XCP, os dados podem ser movidos diretamente do HDFS e do MapR-FS para o NetApp NFS para fornecer acesso a vários aplicativos</block>
  <block id="fa2772759fe171754d3e04460b417464" category="paragraph">Os testes foram feitos no Amazon Web Services (AWS) para transferir os dados do MapR-FS para o NFS para o teste de desempenho inicial com 12 nós MAPR e 4 servidores NFS.</block>
  <block id="694e8d1f2ee056f98ee488bdc4982d73" category="cell">Quantidade</block>
  <block id="6f6cb72d544962fa333e2e34ce64f719" category="cell">Tamanho</block>
  <block id="5d56dbd20d9ee1ab8a722ff12e331953" category="cell">vCPU</block>
  <block id="4789f23283b3a61f858b641a1bef19a3" category="cell">Memória</block>
  <block id="8c4aa541ee911e8d80451ef8cc304806" category="cell">Armazenar</block>
  <block id="eec89088ee408b80387155272b113256" category="cell">Rede</block>
  <block id="e83e5674ab295a6613b60f5e12d1bfe3" category="cell">Servidor NFS</block>
  <block id="6215b1525ff41917096b1eb923fe894f" category="cell">i3en.24xlarge</block>
  <block id="26657d5ff9020d2abefe558796b99584" category="cell">96</block>
  <block id="c45b008ff7fe72f83bb47cba575960c7" category="cell">488GiB</block>
  <block id="9f8ce2ff912e3931e4fc14876f3097f2" category="cell">8x SSD 7500 NVMe</block>
  <block id="f899139df5e1059396431415e770c6dd" category="cell">100</block>
  <block id="899f7b8a7c3e28d3161a77da8f1c8e33" category="cell">Nós MapR</block>
  <block id="6ac0fbf236c6d341a7f2c6c92933f744" category="cell">I3en.12xlarge</block>
  <block id="642e92efb79421734881b53e1e1b18b6" category="cell">48</block>
  <block id="1aa80378346dacbf8ce58aaadcefc35e" category="cell">384GiB</block>
  <block id="3ce58620106227953b9e12e2e0633095" category="cell">4x SSD 7500 NVMe</block>
  <block id="c0c7c76d30bd3dcaefc96f40275bdc0a" category="cell">50</block>
  <block id="03e4c674f628169124f81fb7b98f9c92" category="paragraph">Com base nos testes iniciais, obtivemos uma taxa de transferência de 20 GBps e conseguimos transferir 2 PB de dados por dia.</block>
  <block id="fce5332d471cfbe0baf7fa83eb2d427d" category="inline-link-macro">TR-4863: Diretrizes de práticas recomendadas para NetApp XCP - Movimentação de dados, migração de arquivos e análise</block>
  <block id="d7b251f310540db8b677090e4068b718" category="paragraph">Para obter mais informações sobre a migração de dados HDFS sem exportar HDFS para NFS, consulte a seção "Etapas de implantação - NAS" em<block ref="8057f0a15e6751a5fa14293a5e88f017" category="inline-link-macro-rx"></block> .</block>
  <block id="5e1ee998c60aed58b6080afc9d8903a3" category="summary">Este artigo fornece diretrizes para mover dados de análise de big data e dados de HPC para IA usando NetApp XCP e NIPAM.  Também discutimos os benefícios comerciais de mover dados de big data e HPC para IA.</block>
  <block id="82a406843faa25e62de32fd044584709" category="doc">TR-4732: Análise de big data para inteligência artificial</block>
  <block id="439be0f3df9ab229e224aa3c8dbeca77" category="paragraph">Karthikeyan Nagalingam, NetApp</block>
  <block id="bdd40c24689e02e4043333640734a44e" category="paragraph">Este documento descreve como mover dados de análise de big data e dados de HPC para IA.  A IA processa dados NFS por meio de exportações NFS, enquanto os clientes geralmente têm seus dados de IA em uma plataforma de análise de big data, como HDFS, Blob ou armazenamento S3, bem como plataformas HPC, como GPFS.  Este artigo fornece diretrizes para mover dados de análise de big data e dados de HPC para IA usando NetApp XCP e NIPAM.  Também discutimos os benefícios comerciais de mover dados de big data e HPC para IA.</block>
  <block id="9895310afc8a3755fef2e679c38f32f8" category="section-title">Conceitos e componentes</block>
  <block id="8ba5fcae463371ff85de74be48ced059" category="section-title">Armazenamento de análise de big data</block>
  <block id="b5b25f8714075ee7aa7cae37cabc6e77" category="paragraph">A análise de big data é o principal provedor de armazenamento para HDFS.  Um cliente geralmente usa um sistema de arquivos compatível com Hadoop (HCFS), como o Windows Azure Blob Storage, o MapR File System (MapR-FS) e o armazenamento de objetos S3.</block>
  <block id="201dde15c75147909c8154fe3e727aed" category="section-title">Sistema de arquivos paralelo geral</block>
  <block id="510b2e746f7cab5126465c64edad8541" category="paragraph">O GPFS da IBM é um sistema de arquivos corporativo que oferece uma alternativa ao HDFS.  O GPFS fornece flexibilidade para que os aplicativos decidam o tamanho do bloco e o layout de replicação, o que proporciona bom desempenho e eficiência.</block>
  <block id="49d7c87b66a2b688ec65b1a4fe9b5ddc" category="section-title">Módulo de análise in-loco da NetApp</block>
  <block id="f1b570aebec7f92867ad62cf2fe7c50c" category="paragraph">O NetApp In-Place Analytics Module (NIPAM) serve como um driver para clusters Hadoop acessarem dados NFS.  Ele tem quatro componentes: um pool de conexão, um NFS InputStream, um cache de identificador de arquivo e um NFS OutputStream. Para obter mais informações, consulte <block ref="ead8bf031afc74347ebd06de968e5895" category="inline-link-rx"></block> .</block>
  <block id="0be6a753178a606f6e24a10fde5ec644" category="section-title">Cópia Distribuída do Hadoop</block>
  <block id="3cc73009b533164939781f9f6a4a1aa0" category="paragraph">Hadoop Distributed Copy (DistCp) é uma ferramenta de cópia distribuída usada para grandes tarefas de cópia entre clusters e dentro de clusters.  Esta ferramenta usa o MapReduce para distribuição de dados, tratamento de erros e relatórios.  Ele expande a lista de arquivos e diretórios e os insere em tarefas de mapeamento para copiar os dados da lista de origem.  A imagem abaixo mostra a operação DistCp em HDFS e não HDFS.</block>
  <block id="513bd70b6fe800dda2548dae1bc404df" category="paragraph"><block ref="513bd70b6fe800dda2548dae1bc404df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8f54af1bdcb54a020503d81bc3b2114" category="paragraph">O Hadoop DistCp move dados entre os dois sistemas HDFS sem usar um driver adicional.  A NetApp fornece o driver para sistemas não HDFS.  Para um destino NFS, o NIPAM fornece o driver para copiar dados que o Hadoop DistCp usa para se comunicar com destinos NFS ao copiar dados.</block>
  <block id="1215f8190533dfdf63d2224a6d88266f" category="section-title">Google Cloud NetApp Volumes</block>
  <block id="e6b6086807cb6588f15ae36a2a999e8f" category="paragraph">O Google Cloud NetApp Volumes é um serviço de arquivos nativo da nuvem com desempenho extremo.  Este serviço ajuda os clientes a acelerar o tempo de colocação do produto no mercado, aumentando e diminuindo rapidamente os recursos e usando os recursos do NetApp para melhorar a produtividade e reduzir o tempo de inatividade da equipe.  O Google Cloud NetApp Volumes é a alternativa certa para recuperação de desastres e backup na nuvem porque reduz o espaço total do data center e consome menos armazenamento nativo na nuvem pública.</block>
  <block id="6efa8f47d1a76af77ce311b436e4dca9" category="section-title">NetApp XCP</block>
  <block id="a12ce47d330a9ea070b4fd322ca5f890" category="paragraph">O NetApp XCP é um software cliente que permite a migração rápida e confiável de dados de qualquer para NetApp e de NetApp para NetApp .  Esta ferramenta foi projetada para copiar uma grande quantidade de dados NAS não estruturados de qualquer sistema NAS para um controlador de armazenamento NetApp .  A Ferramenta de Migração XCP usa um mecanismo de streaming de E/S multicanal e multinúcleo que pode processar muitas solicitações em paralelo, como migração de dados, listagens de arquivos ou diretórios e relatórios de espaço.  Esta é a ferramenta de migração de dados padrão do NetApp .  Você pode usar o XCP para copiar dados de um cluster Hadoop e HPC para o armazenamento NetApp NFS.  O diagrama abaixo mostra a transferência de dados de um cluster Hadoop e HPC para um volume NetApp NFS usando XCP.</block>
  <block id="31e2e6a49223ff3b99782fced8ae2f33" category="paragraph"><block ref="31e2e6a49223ff3b99782fced8ae2f33" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ccf66760432e212bf920c4b630bf24a8" category="section-title">Cópia e sincronização do NetApp BlueXP</block>
  <block id="182c915d2a513090f731fbf85d4576bd" category="paragraph">O NetApp BlueXP Copy and Sync é um software como serviço de replicação de dados híbrido que transfere e sincroniza dados NFS, S3 e CIFS de forma integrada e segura entre o armazenamento local e o armazenamento em nuvem.  Este software é usado para migração de dados, arquivamento, colaboração, análise e muito mais.  Após a transferência dos dados, o BlueXP Copy and Sync sincroniza continuamente os dados entre a origem e o destino.  Daqui para frente, ele então transfere o delta.  Ele também protege os dados dentro da sua própria rede, na nuvem ou no local.  Este software é baseado em um modelo de pagamento conforme o uso, que fornece uma solução econômica e fornece recursos de monitoramento e relatórios para sua transferência de dados.</block>
  <block id="600c9e3e31c7cdf2c69044801b9ea998" category="summary">Esta seção fornece as etapas detalhadas necessárias para mover dados do MapR-FS para o ONTAP NFS usando o NetApp XCP.</block>
  <block id="6a848946dc9169e87668bb9f057c56c2" category="doc">MapR-FS para ONTAP NFS</block>
  <block id="3362be4f8dc0d043bec6bb8bf22a565b" category="list-text">Provisione três LUNs para cada nó do MapR e conceda aos LUNs a propriedade de todos os nós do MapR.</block>
  <block id="a74eeec8d29cc5a609b980af2aee2fb3" category="list-text">Durante a instalação, escolha os LUNs recém-adicionados para os discos de cluster do MapR que são usados para o MapR-FS.</block>
  <block id="87ae055df3def21f83bbbb9e287167b6" category="list-text">Instale um cluster MapR de acordo com a documentação do MapR 6.1.</block>
  <block id="7549eec0595c1177d1a3b1a8c556ea8e" category="list-text">Verifique as operações básicas do Hadoop usando comandos MapReduce como<block ref="b5a58cfcf19813db2fae678c75e004c8" prefix=" " category="inline-code"></block> .</block>
  <block id="455177bd981566b3ae1e0084e3381b11" category="list-text">Mantenha os dados do cliente no MapR-FS.  Por exemplo, geramos aproximadamente um terabyte de dados de amostra no MapR-FS usando o Teragen.</block>
  <block id="570bd2111387f5da50ad7d54e23e5fb2" category="list-text">Configurar o MapR-FS como exportação NFS.</block>
  <block id="4fe9587feb0e4de26dff3d33bbaf046e" category="list-text">Desabilite o serviço nlockmgr em todos os nós do MapR.</block>
  <block id="8c5d6c82648b5d5b2a4c82d33569b1c4" category="list-text">Exportar pastas específicas do MapR-FS em todos os nós do MapR no<block ref="84a05a173e6cd86a4169f3dbd5897873" prefix=" " category="inline-code"></block> arquivo.  Não exporte a pasta pai com permissões diferentes ao exportar subpastas.</block>
  <block id="e78b84d9c1ff3b973293510503e86b95" category="list-text">Atualize o serviço MapR-FS NFS.</block>
  <block id="341009af7864703863b08f0bd1df43b5" category="list-text">Atribua um intervalo de IP virtual a um servidor específico ou a um conjunto de servidores no cluster MapR.  Em seguida, o cluster MapR atribui um IP a um servidor específico para acesso a dados NFS.  Os IPs permitem alta disponibilidade, o que significa que, se um servidor ou rede com um IP específico apresentar falha, o próximo IP do intervalo de IPs poderá ser usado para acesso NFS.</block>
  <block id="5165f49b44f610d03a79da336b53e8f2" category="admonition">Se você quiser fornecer acesso NFS de todos os nós do MapR, poderá atribuir um conjunto de IPs virtuais a cada servidor e usar os recursos de cada nó do MapR para acesso a dados NFS.</block>
  <block id="c508683f7afca451e58f95b67197d51f" category="paragraph"><block ref="c508683f7afca451e58f95b67197d51f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54b9596f082ff106a71134b100eee486" category="paragraph"><block ref="54b9596f082ff106a71134b100eee486" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be91199bb393028826e953c78a526a54" category="paragraph"><block ref="be91199bb393028826e953c78a526a54" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97532f358124e4f3087e522bb35f2cb8" category="list-text">Verifique os IPs virtuais atribuídos em cada nó do MapR e use-os para acesso a dados NFS.</block>
  <block id="d1ed36990409b90ebe749d4e8ddab8b7" category="list-text">Monte o MapR-FS exportado pelo NFS usando o IP virtual atribuído para verificar a operação do NFS.  No entanto, esta etapa não é necessária para transferência de dados usando o NetApp XCP.</block>
  <block id="6288e9b84b4573721ff701d3bdc55fed" category="list-text">Configure o NetApp XCP para transferir dados do gateway MapR-FS NFS para o ONTAP NFS.</block>
  <block id="47bcc9815ee0b47ea9de7729c9c727f7" category="list-text">Configure o local do catálogo para o XCP.</block>
  <block id="e125588061821db7957020ded3b976f0" category="list-text">Copie o arquivo de licença para<block ref="0c8468e8bc6e9c8ce8e4de412fee0c10" prefix=" " category="inline-code"></block> .</block>
  <block id="76725a579a117275c078f16fdbe1fd04" category="list-text">Ative o XCP usando o<block ref="974d7928831087bfbec5968aec9bea85" prefix=" " category="inline-code"></block> comando.</block>
  <block id="07f3313db35fd32ada5426648ae5817d" category="list-text">Verifique a origem da exportação NFS.</block>
  <block id="7eefcefaba7483a2c7d6c71e934d0f28" category="list-text">Transfira os dados usando XCP de vários nós MapR de vários IPs de origem e vários IPs de destino (LIFs ONTAP ).</block>
  <block id="c2cb3a97c34a702522aba4d19b7a1d39" category="list-text">Verifique a distribuição de carga no controlador de armazenamento.</block>
  <block id="af7ba099603ccd4070a5102166f2c998" category="summary">Com base nessa validação, cientistas e engenheiros de dados podem acessar dados NFS de notebooks Jupyter do AWS SageMaker por meio de buckets S3 do NetApp Cloud Volumes ONTAP.  Essa abordagem permite fácil acesso e compartilhamento dos mesmos dados do NFS e do S3 sem a necessidade de software adicional.</block>
  <block id="8053f00cf5e08f449b7cafe189c73a39" category="list-text">Classificação de texto usando SageMaker BlazingText</block>
  <block id="d6667429b7c60bcbf5e5d593e91d6cae" category="list-text">Suporte à versão ONTAP para armazenamento de objetos S3</block>
  <block id="91ef54d96688b56bf968f57803df6675" category="inline-link"><block ref="91ef54d96688b56bf968f57803df6675" category="inline-link-rx"></block></block>
  <block id="53a581d907d105a589be9419e91b16fa" category="paragraph"><block ref="53a581d907d105a589be9419e91b16fa" category="inline-link-rx"></block></block>
  <block id="6e74710636e2da95cda4899adcdf891e" category="summary">Os dados estão disponíveis no NFS e acessados do S3 pelo AWS SageMaker.</block>
  <block id="8394db253ec71ed9d59b9429983b8eb4" category="doc">Dualidade de dados para cientistas de dados e outras aplicações</block>
  <block id="3c438be737391744e2fed6f73c418638" category="section-title">Requisitos de tecnologia</block>
  <block id="f4900d1d4a0a26325c4c9514e57c2c75" category="paragraph">Você precisa do NetApp BlueXP, NetApp Cloud Volumes ONTAP e AWS SageMaker Notebooks para o caso de uso de dualidade de dados.</block>
  <block id="7ddb33edf227a18eb76201fcb9e2c9db" category="section-title">Requisitos de software</block>
  <block id="6e6b6052efed2574e2dc05cbdc5d66d5" category="paragraph">A tabela a seguir lista os componentes de software necessários para implementar o caso de uso.</block>
  <block id="9b9477e579c3b44dd623d5a6e1ea8d78" category="cell">BlueXP</block>
  <block id="0f0b99ea2f70cd363c2c6a279f74e760" category="cell">NetApp Cloud Volumes ONTAP</block>
  <block id="dda9f6d67571441afa5cfb6b54b70873" category="cell">Caderno do AWS SageMaker</block>
  <block id="5ac7b083aa99c6ec0d7a272c37dc611d" category="section-title">Procedimentos de implantação</block>
  <block id="cc5f7f3bee6dcb16913051d6fc267977" category="paragraph">A implantação da solução de dualidade de dados envolve as seguintes tarefas:</block>
  <block id="6bb1f60bf0d00924a1bba54557e1feae" category="list-text">Conector BlueXP</block>
  <block id="cf25fa6cf104cc1a67119acb6d4d364d" category="list-text">Dados para aprendizado de máquina</block>
  <block id="59b20c2117a395af59d54a6533498e99" category="list-text">Aprendizado de máquina validado de Jupyter Notebooks</block>
  <block id="46e0bb4f28dbf5013a68a8a69a3cf9f5" category="section-title">Conector BlueXP</block>
  <block id="6ff27f6b5b95b177c735d22a2783e9ef" category="paragraph">Nesta validação, usamos a AWS.  Também é aplicável ao Azure e ao Google Cloud.  Para criar um conector BlueXP na AWS, conclua as seguintes etapas:</block>
  <block id="4d7b48a5181bdd203b2ff52910c67d94" category="list-text">Usamos as credenciais baseadas no mcarl-marketplace-subscription no BlueXP.</block>
  <block id="c0caffb5ab49caead75d39f6416ba841" category="list-text">Escolha a região adequada para seu ambiente (por exemplo, us-east-1 [N. Virginia]) e selecione o método de autenticação (por exemplo, Assumir função ou chaves da AWS).  Nesta validação, usamos chaves da AWS.</block>
  <block id="86b72593a2ce2f4e46e7669ced916111" category="list-text">Forneça o nome do conector e crie uma função.</block>
  <block id="71ffd00d3592df40d0db94a71ceab12d" category="list-text">Forneça os detalhes da rede, como VPC, sub-rede ou par de chaves, dependendo se você precisa de um IP público ou não.</block>
  <block id="b5b37cef840fa0a17af0ef55c09a0e1f" category="list-text">Forneça os detalhes do grupo de segurança, como acesso HTTP, HTTPS ou SSH do tipo de origem, como qualquer lugar e informações de intervalo de IP.</block>
  <block id="45b20434e20aeebd5991cd84f2cf11c9" category="list-text">Revise e crie o Conector BlueXP .</block>
  <block id="92043f8a1dc0b0180854c25bcf5ff79d" category="list-text">Verifique se o estado da instância do BlueXP EC2 está em execução no console da AWS e verifique o endereço IP na guia *Rede*.</block>
  <block id="7044ee6a43ee2152ca6d008fcb8228c3" category="list-text">Efetue login na interface do usuário do conector no portal BlueXP ou use o endereço IP para acesso pelo navegador.</block>
  <block id="064d933c0c02c4fe7ef1a07ad3a537d7" category="paragraph">Para criar uma instância do Cloud Volumes ONTAP no BlueXP, conclua as seguintes etapas:</block>
  <block id="35d88740e5ca53f6cabb06b3fce807b7" category="list-text">Crie um novo ambiente de trabalho, selecione o provedor de nuvem e selecione o tipo de instância do Cloud Volumes ONTAP (como CVO único, HA ou Amazon FSx ONTAP para ONTAP).</block>
  <block id="dcb89e397dde3dedb1a32224f0c15b78" category="list-text">Forneça detalhes como o nome e as credenciais do cluster Cloud Volumes ONTAP .  Nesta validação, criamos uma instância do Cloud Volumes ONTAP chamada<block ref="c7e44ecb645a5c83f843ae05090c5940" prefix=" " category="inline-code"></block> .</block>
  <block id="9cf479af21359b2928a1b672d60577f2" category="list-text">Selecione os serviços necessários para o Cloud Volumes ONTAP.  Nesta validação, optamos por apenas monitorar, então desabilitamos *Data Sense &amp; Compliance* e *Backup to Cloud Services*.</block>
  <block id="cb95ef3838d59d553c71f50b1cadee27" category="list-text">Na seção *Localização e conectividade*, selecione a região da AWS, a VPC, a sub-rede, o grupo de segurança, o método de autenticação SSH e uma senha ou um par de chaves.</block>
  <block id="fdd5d37c21ee01084537317345b3d78b" category="list-text">Selecione o método de carregamento.  Usamos *Professional* para esta validação.</block>
  <block id="00efec60d606ea6ad0bafe93bc77df92" category="list-text">Você pode escolher um pacote pré-configurado, como *POC e pequenas cargas de trabalho*, *cargas de trabalho de produção de dados de banco de dados e aplicativos*, *DR com boa relação custo-benefício* ou *cargas de trabalho de produção de alto desempenho*.  Nesta validação, escolhemos *Poc e Small Workloads*.</block>
  <block id="f22934293c2f2a761ea26fa4ae1828e1" category="list-text">Crie um volume com um tamanho específico, protocolos permitidos e opções de exportação.  Nesta validação, criamos um volume chamado<block ref="2b0d59c7031769e80c8e5118b6ec7694" prefix=" " category="inline-code"></block> .</block>
  <block id="f2706214c4a60177d14fb8495cbc6924" category="list-text">Escolha um tipo de disco de perfil e uma política de camadas.  Nesta validação, desabilitamos *Eficiência de armazenamento* e *SSD de uso geral – Desempenho dinâmico*.</block>
  <block id="40d3f73a73f67ce67b286aef7a5d3ecb" category="list-text">Por fim, revise e crie a instância do Cloud Volumes ONTAP .  Aguarde de 15 a 20 minutos para que o BlueXP crie o ambiente de trabalho do Cloud Volumes ONTAP .</block>
  <block id="a8b538b74c3f662c2248af9c6d4742db" category="list-text">Configure os seguintes parâmetros para habilitar o protocolo Duality.  O protocolo Duality (NFS/S3) é suportado pelo ONTAP 9.  12.1 e posteriores.</block>
  <block id="15b53c14b58ee146309847451d1eb90a" category="list-text">Nesta validação, criamos uma SVM chamada<block ref="c7e44ecb645a5c83f843ae05090c5940" prefix=" " category="inline-code"></block> e volume<block ref="2b0d59c7031769e80c8e5118b6ec7694" prefix=" " category="inline-code"></block> .</block>
  <block id="3514969b2381af83551c246e34b74403" category="list-text">Verifique se o SVM tem suporte de protocolo para NFS e S3.  Caso contrário, modifique o SVM para suportá-los.</block>
  <block id="e41c06ffff0f8c9cadbc7f8bb37f8ae5" category="list-text">Crie e instale um certificado CA, se necessário.</block>
  <block id="0395f8062a8a7f4af05113bae8133737" category="list-text">Crie uma política de dados de serviço.</block>
  <block id="6e16e110899749a795fe713253d850e7" category="list-text">Verifique os detalhes agregados.</block>
  <block id="5d3f8e127103f0d5cf3de305db892b4d" category="list-text">Crie um usuário e um grupo.</block>
  <block id="efa22127bde2d3ab2e4f5b9a42d14814" category="list-text">Crie um bucket no volume NFS.</block>
  <block id="c3fd6f44bf88d3f0eae4742edb58eafc" category="paragraph">Para criar um AWS Notebook a partir do AWS SageMaker, conclua as seguintes etapas:</block>
  <block id="31378aab1ee6190e0b7fe33c501a5625" category="list-text">Certifique-se de que o usuário que está criando a instância do Notebook tenha uma política do IAM AmazonSageMakerFullAccess ou faça parte de um grupo existente que tenha direitos AmazonSageMakerFullAccess.  Nesta validação, o usuário faz parte de um grupo existente.</block>
  <block id="13c1455885d16af64f1bb96c4e48680a" category="list-text">Forneça as seguintes informações:</block>
  <block id="bb8101aed18120fa18dedaa994ffeea0" category="list-text">Nome da instância do notebook.</block>
  <block id="6239d232142a089e53e7a13fa721237a" category="list-text">Tipo de instância.</block>
  <block id="37056dac7373f7e1b74382036d25b69e" category="list-text">Identificador de plataforma.</block>
  <block id="38e2059c32c628cf89e90a6844a93800" category="list-text">Selecione a função do IAM que tem direitos AmazonSageMakerFullAccess.</block>
  <block id="55d7da5ede713135b1c2ebd7a615c3b4" category="list-text">Acesso root – habilitar.</block>
  <block id="8f0e92e4434abc32ff62a914ae9f2ba6" category="list-text">Chave de criptografia - Selecione nenhuma criptografia personalizada.</block>
  <block id="8b77028d248afd826900d895636b4e98" category="list-text">Mantenha as opções padrão restantes.</block>
  <block id="78456ee20793f732edfa9105bbb4e490" category="list-text">Nesta validação, os detalhes da instância do SageMaker são os seguintes:</block>
  <block id="e90e797343ea3f751b0c32e808edaff8" category="inline-image-macro">Captura de tela representando a etapa.</block>
  <block id="e987fe9ec5699958a73a8f310b4d99e8" category="paragraph"><block ref="e987fe9ec5699958a73a8f310b4d99e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4414f1275568cfaaea91b68f1514516e" category="paragraph"><block ref="4414f1275568cfaaea91b68f1514516e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4789a9ab6472480889e111503d068623" category="list-text">Inicie o AWS Notebook.</block>
  <block id="ce1d8475b6a4d461318eb3139cc54a3b" category="paragraph"><block ref="ce1d8475b6a4d461318eb3139cc54a3b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbfbebd805ee7945ad38bc26f8fa9f1b" category="list-text">Abra o laboratório Jupyter.</block>
  <block id="d81c10b932515c107a06a3737d985eaf" category="paragraph"><block ref="d81c10b932515c107a06a3737d985eaf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab3269ab0de58f5611205f6ace06f3af" category="list-text">Efetue login no terminal e monte o volume Cloud Volumes ONTAP .</block>
  <block id="cc0649b0871fde24c4a46e09186a36e0" category="list-text">Verifique o bucket criado no volume Cloud Volumes ONTAP usando os comandos da AWS CLI.</block>
  <block id="4f31ff9815d3a8a959e7c557213068d6" category="paragraph">Nesta validação, usamos um conjunto de dados da DBpedia, um esforço comunitário de crowdsourcing, para extrair conteúdo estruturado das informações criadas em vários projetos da Wikimedia.</block>
  <block id="06d6ccf33b49ed20a34cdc26b6820253" category="list-text">Baixe os dados do local do GitHub da DBpedia e extraia-os.  Utilize o mesmo terminal usado na seção anterior.</block>
  <block id="7f50b7f719282741fdf7ce5b8ca1f3dd" category="list-text">Copie os dados para o local Cloud Volumes ONTAP e verifique-os no bucket do S3 usando a AWS CLI.</block>
  <block id="0ecfbac978ab3f5979ec31eb5574d93e" category="list-text">Execute a validação básica para garantir que a funcionalidade de leitura/gravação funcione no bucket S3.</block>
  <block id="877169a066e14f0512d5f119945ef14d" category="section-title">Validar o aprendizado de máquina dos Jupyter Notebooks</block>
  <block id="6f73420916237ed836932ccf967d82ba" category="paragraph">A validação a seguir fornece os modelos de construção, treinamento e implantação de aprendizado de máquina por meio da classificação de texto usando o exemplo SageMaker BlazingText abaixo:</block>
  <block id="3cf03767e04159d1ec88e7fb0827b487" category="list-text">Instale os pacotes boto3 e SageMaker.</block>
  <block id="b1282d58a4dcde0a2015d98ad33afd4c" category="paragraph">Saída:</block>
  <block id="39017441ac701ebaef8de7116e7f71a0" category="list-text">Na etapa seguinte, os dados<block ref="0a726fdd06082d233cd4eade40f12612" prefix="(" category="inline-code"></block> ) é baixado do bucket s3<block ref="90d9a986b9b5e7c07c50a03ccc06a244" prefix=" " category="inline-code"></block> para uma instância do Jupyter Notebook usada em aprendizado de máquina.</block>
  <block id="a270350e3527fea9a36815fa5fe04ba0" category="list-text">O código a seguir cria o mapeamento de índices inteiros para rótulos de classe que são usados para recuperar o nome da classe real durante a inferência.</block>
  <block id="d17fa3d0aed3f8aaa5e78b447054126d" category="paragraph">A saída lista os arquivos e pastas no<block ref="90d9a986b9b5e7c07c50a03ccc06a244" prefix=" " category="inline-code"></block> bucket que são usados como dados para a validação de aprendizado de máquina do AWS SageMaker.</block>
  <block id="0cfbf64679378e3e5367734fd2bd69aa" category="list-text">Inicie a fase de pré-processamento de dados para pré-processar os dados de treinamento em um formato de texto tokenizado e separado por espaços que pode ser consumido pelo algoritmo BlazingText e pela biblioteca nltk para tokenizar as frases de entrada do conjunto de dados DBPedia.  Baixe o tokenizador nltk e outras bibliotecas.  O<block ref="6d49a792c1080aa5b33d27ec694621b6" prefix=" " category="inline-code"></block> aplicado a cada instância de dados em paralelo usa o módulo de multiprocessamento Python.</block>
  <block id="d68566815a7248bae03e105c2db8853a" category="list-text">Carregue o conjunto de dados formatado e de treinamento no S3 para que ele possa ser usado pelo SageMaker para executar tarefas de treinamento.  Em seguida, carregue dois arquivos no bucket e no local do prefixo usando o Python SDK.</block>
  <block id="e886ad36e527d85b26c492618651edad" category="list-text">Configure um local de saída no S3 onde o artefato do modelo é carregado para que os artefatos possam ser a saída do trabalho de treinamento do algoritmo.  Criar um<block ref="6e3281884db83f9ee468a6e798b6bdfb" prefix=" " category="inline-code"></block> objeto para iniciar o trabalho de treinamento.</block>
  <block id="41215e143c2b3810b37c4e4f47819077" category="list-text">Defina o SageMaker<block ref="a0b1f5f7b93af313b6e2452f52c8f3f6" prefix=" " category="inline-code"></block> com configurações de recursos e hiperparâmetros para treinar a classificação de texto no conjunto de dados DBPedia usando o modo supervisionado em uma instância c4.4xlarge.</block>
  <block id="6c773c4d6e4a7dda7e00352894786bdb" category="list-text">Prepare um handshake entre os canais de dados e o algoritmo.  Para fazer isso, crie o<block ref="0e021845d2c0e4ad94a91ce444c13681" prefix=" " category="inline-code"></block> objetos dos canais de dados e mantê-los em um dicionário para o algoritmo consumir.</block>
  <block id="3b29bef19a742b8ab66cddf620871d31" category="list-text">Após a conclusão do trabalho, uma mensagem de Trabalho Concluído será exibida.  O modelo treinado pode ser encontrado no bucket S3 que foi configurado como<block ref="212ad7a4c11069727ffd02f333d7d8b1" prefix=" " category="inline-code"></block> no estimador.</block>
  <block id="6cb5683d87e53b375bd915572f960759" category="list-text">Após a conclusão do treinamento, implante o modelo treinado como um endpoint hospedado em tempo real do Amazon SageMaker para fazer previsões.</block>
  <block id="4254a612097ca58653de7c0c39da8df2" category="list-text">Por padrão, o modelo retorna uma previsão com a maior probabilidade.  Para recuperar o topo<block ref="8ce4b16b22b58894aa86c421e8759df3" prefix=" " category="inline-code"></block> previsões, conjunto<block ref="8ce4b16b22b58894aa86c421e8759df3" prefix=" " category="inline-code"></block> no arquivo de configuração.</block>
  <block id="67be4f1bb90039baec0d8f73ff82a47e" category="list-text">Exclua o ponto de extremidade antes de fechar o notebook.</block>
  <block id="16147684eb6910d9d73a43bb83091da4" category="summary">Cientistas e engenheiros de dados geralmente precisam acessar dados armazenados no formato NFS, mas acessar esses dados diretamente do protocolo S3 no AWS SageMaker pode ser desafiador porque a AWS só oferece suporte ao acesso ao bucket S3.  No entanto, o NetApp ONTAP fornece uma solução ao habilitar o acesso de protocolo duplo para NFS e S3.  Com esta solução, cientistas e engenheiros de dados podem acessar dados NFS de notebooks do AWS SageMaker por meio de buckets S3 do NetApp Cloud Volumes ONTAP.  Essa abordagem permite fácil acesso e compartilhamento dos mesmos dados do NFS e do S3 sem a necessidade de software adicional.</block>
  <block id="e8ce8afdd7d335aed5b93d4a41ae0115" category="doc">TR-4967: Gerenciamento de dados em nuvem com NetApp File-Object Duality e AWS SageMaker</block>
  <block id="7caace9abf76a798c629a9134d1bb259" category="summary">Um caso de uso potencial para acesso de protocolo duplo de NFS e S3 está nas áreas de aprendizado de máquina e ciência de dados.  Por exemplo, uma equipe de cientistas de dados pode estar trabalhando em um projeto de aprendizado de máquina usando o AWS SageMaker, o que requer acesso a dados armazenados no formato NFS.  No entanto, os dados também podem precisar ser acessados e compartilhados por meio de buckets do S3 para colaborar com outros membros da equipe ou para integração com outros aplicativos que usam o S3.</block>
  <block id="ee8cf3bf54dea46135e299d79fa1c179" category="paragraph">Esta solução utiliza as seguintes tecnologias:</block>
  <block id="a03ea23912d3b35c875ff398aa4888af" category="list-text">*Caderno AWS SageMaker.*  Oferece recursos de aprendizado de máquina para desenvolvedores e cientistas de dados criarem, treinarem e implantarem modelos de ML de alta qualidade com eficiência.</block>
  <block id="bbe2552dc6295d353c02fd85c243f334" category="list-text">* NetApp BlueXP.*  Permite a descoberta, implantação e operação de armazenamento local, bem como na AWS, Azure e Google Cloud.  Ele fornece proteção de dados contra perda de dados, ameaças cibernéticas e interrupções não planejadas e otimiza o armazenamento e a infraestrutura de dados.</block>
  <block id="aa6fa71ab9848c5875470d36bbc2138a" category="list-text">* NetApp Cloud Volumes ONTAP.*  Fornece volumes de armazenamento de nível empresarial com protocolos NFS, SMB/CIFS, iSCSI e S3 na AWS, Azure e Google Cloud, dando aos usuários maior flexibilidade no acesso e gerenciamento de seus dados na nuvem.</block>
  <block id="eea496572a01ca3e5ced1dfe99a5809c" category="paragraph">NetApp Cloud Volumes ONTAP criado a partir do BlueXP para armazenar dados de ML.</block>
  <block id="923baf107dc23ca10f968a4fdecd4f4f" category="paragraph">A figura a seguir mostra os componentes técnicos da solução.</block>
  <block id="8afbfe3aeb9c594404d5c244cf8f6024" category="inline-image-macro">Esta figura mostra os componentes técnicos da solução.</block>
  <block id="d3d9ae40ce6d205245ae4b8c9649b6e2" category="paragraph"><block ref="d3d9ae40ce6d205245ae4b8c9649b6e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55c5281d80934f950192f768715495f0" category="paragraph">Ao utilizar o NetApp Cloud Volumes ONTAP, a equipe pode armazenar seus dados em um único local e torná-los acessíveis com os protocolos NFS e S3.  Os cientistas de dados podem acessar os dados no formato NFS diretamente do AWS SageMaker, enquanto outros membros da equipe ou aplicativos podem acessar os mesmos dados por meio de buckets S3.</block>
  <block id="f8ba1b513231e9ca54a5c3b94733c28d" category="paragraph">Essa abordagem permite que os dados sejam acessados e compartilhados de forma fácil e eficiente, sem a necessidade de software adicional ou migração de dados entre diferentes soluções de armazenamento.  Ele também permite um fluxo de trabalho mais simplificado e colaboração entre os membros da equipe, resultando em um desenvolvimento mais rápido e eficaz de modelos de aprendizado de máquina.</block>
  <block id="7747c0c1913888384e25d3a99b247187" category="summary">Este documento fornece diretrizes de práticas recomendadas para usar o Kafka com armazenamento NetApp , incluindo testes de certificação do Confluent Kafka, resultados de desempenho, ajuste, conectores Kafka e o recurso de auto-rebalanceamento.</block>
  <block id="d17096a4e247d84eba8c623e8df7bb38" category="paragraph">Este documento fornece diretrizes de práticas recomendadas para usar o Confluent Tiered Storage com o armazenamento NetApp , incluindo testes de verificação, resultados de desempenho de armazenamento em camadas, ajuste, conectores Confluent S3 e o recurso de autobalanceamento.  Considerando as políticas de ILM, o desempenho do Confluent com vários testes de desempenho para verificação e as APIs S3 padrão do setor, o armazenamento de objetos NetApp StorageGRID é uma escolha ideal para o armazenamento em camadas do Confluent.</block>
  <block id="06bf7cdac46014ea728ea73ea94f29ed" category="list-text">O que é Apache Kafka</block>
  <block id="9411b66537bb375699af4bbf90c682d3" category="inline-link"><block ref="9411b66537bb375699af4bbf90c682d3" category="inline-link-rx"></block></block>
  <block id="a2b6e6fe4a206b71df85cc00f128ef0c" category="paragraph"><block ref="a2b6e6fe4a206b71df85cc00f128ef0c" category="inline-link-rx"></block></block>
  <block id="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link"><block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="6bfac05f3cc2c0adace9c385ef708fd9" category="paragraph"><block ref="6bfac05f3cc2c0adace9c385ef708fd9" category="inline-link-rx"></block></block>
  <block id="8f74869149421fffb3c139e146a83d10" category="list-text">Detalhes do parâmetro S3-sink</block>
  <block id="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link"><block ref="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link-rx"></block></block>
  <block id="26f8d9a8c1177c17a089f9a5c18628f4" category="paragraph"><block ref="26f8d9a8c1177c17a089f9a5c18628f4" category="inline-link-rx"></block></block>
  <block id="bb2bd99338b18762ef6953ad2cbfafc7" category="list-text">Apache Kafka</block>
  <block id="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link"><block ref="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link-rx"></block></block>
  <block id="c001bbfb62e45f662fe697182fa82240" category="paragraph"><block ref="c001bbfb62e45f662fe697182fa82240" category="inline-link-rx"></block></block>
  <block id="4f6236b021284cc85e87f1145d34e74b" category="list-text">Armazenamento infinito na plataforma Confluent</block>
  <block id="43a9697f317e04e185bacb99ee76b7fb" category="inline-link"><block ref="43a9697f317e04e185bacb99ee76b7fb" category="inline-link-rx"></block></block>
  <block id="a156036c426dcb5d87fc97e5eacdc183" category="paragraph"><block ref="a156036c426dcb5d87fc97e5eacdc183" category="inline-link-rx"></block></block>
  <block id="a53b0667612f6e25b1d426569d860cac" category="list-text">Armazenamento em camadas Confluent - Melhores práticas e dimensionamento</block>
  <block id="a2e63818a36c6308885f4c0109e99b56" category="inline-link"><block ref="a2e63818a36c6308885f4c0109e99b56" category="inline-link-rx"></block></block>
  <block id="0c2ea24bb29ad03d1f43efe9a08c7da0" category="paragraph"><block ref="0c2ea24bb29ad03d1f43efe9a08c7da0" category="inline-link-rx"></block></block>
  <block id="ee764f7614a20c6500a54f1abc769567" category="list-text">Conector de coletor Amazon S3 para plataforma Confluent</block>
  <block id="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link"><block ref="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link-rx"></block></block>
  <block id="ca80d8d3004f0fce6bc195b6b43ccaeb" category="paragraph"><block ref="ca80d8d3004f0fce6bc195b6b43ccaeb" category="inline-link-rx"></block></block>
  <block id="5cbad2383ea03d52c73feba910ccb4a9" category="list-text">Dimensionamento de Kafka</block>
  <block id="7a8c563c1b96991ca597759bb447eb65" category="inline-link"><block ref="7a8c563c1b96991ca597759bb447eb65" category="inline-link-rx"></block></block>
  <block id="a2d2c0cad325abb54e33c688d54ce125" category="paragraph"><block ref="a2d2c0cad325abb54e33c688d54ce125" category="inline-link-rx"></block></block>
  <block id="989772944133ad8cd766bbdfe91cb365" category="list-text">Dimensionamento do StorageGRID</block>
  <block id="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link"><block ref="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link-rx"></block></block>
  <block id="1e9dcc0360cfc46d71d6e0c3effa6379" category="paragraph"><block ref="1e9dcc0360cfc46d71d6e0c3effa6379" category="inline-link-rx"></block></block>
  <block id="5f750332aea13a67a316c81c03a35752" category="list-text">Casos de uso do Kafka</block>
  <block id="c97a8ddb222f78361f59ac027aa08c70" category="inline-link"><block ref="c97a8ddb222f78361f59ac027aa08c70" category="inline-link-rx"></block></block>
  <block id="58f7c8dd51e4199a8f2caf79409bada1" category="paragraph"><block ref="58f7c8dd51e4199a8f2caf79409bada1" category="inline-link-rx"></block></block>
  <block id="f51439b4d8807e7a73cb24b6f11e16e2" category="list-text">Clusters Kafka autobalanceados na plataforma confluente 6.0</block>
  <block id="866d1bcab8bac705e171a01e8fe2e717" category="inline-link"><block ref="866d1bcab8bac705e171a01e8fe2e717" category="inline-link-rx"></block></block>
  <block id="b6251e175649ca2d0108725f99fc225f" category="paragraph"><block ref="b6251e175649ca2d0108725f99fc225f" category="inline-link-rx"></block></block>
  <block id="aa3c3c6442ddbda62fd0694691e34122" category="inline-link"><block ref="aa3c3c6442ddbda62fd0694691e34122" category="inline-link-rx"></block></block>
  <block id="f7365ec0514100387d644210374998c1" category="paragraph"><block ref="f7365ec0514100387d644210374998c1" category="inline-link-rx"></block></block>
  <block id="69fc1008ccb741113af5042f04fcbc8b" category="summary">Este documento descreve as diretrizes de práticas recomendadas para usar o Kafka em um controlador de armazenamento NetApp .</block>
  <block id="a29b982ab81cd1d74045ee43e3378135" category="paragraph">Karthikeyan Nagalingam, Joseph Kandatilparambil, NetApp Rankesh Kumar, Confluente</block>
  <block id="37281d123cc59a7c05b3ce30b5ea435e" category="paragraph">O Apache Kafka é uma plataforma de streaming de eventos distribuída pela comunidade, capaz de lidar com trilhões de eventos por dia.  Inicialmente concebido como uma fila de mensagens, o Kafka é baseado em uma abstração de um log de confirmação distribuído.  Desde que foi criado e disponibilizado de código aberto pelo LinkedIn em 2011, o Kafka evoluiu de uma fila de mensagens para uma plataforma completa de transmissão de eventos.  A Confluent fornece a distribuição do Apache Kafka com a Confluent Platform.  A plataforma Confluent complementa o Kafka com recursos comunitários e comerciais adicionais projetados para melhorar a experiência de streaming de operadores e desenvolvedores em produção em grande escala.</block>
  <block id="4a967c3b711955b2fd888bf0abedb515" category="paragraph">Este documento descreve as diretrizes de práticas recomendadas para usar o Confluent Tiered Storage em uma oferta de armazenamento de objetos da NetApp, fornecendo o seguinte conteúdo:</block>
  <block id="2717b4b699259a5e59279aac92d526a2" category="list-text">Verificação confluente com armazenamento de objetos NetApp – NetApp StorageGRID</block>
  <block id="0939eec6a072b9deba2d6aa39249110d" category="list-text">Testes de desempenho de armazenamento em camadas</block>
  <block id="7607a859995debe77df0676d09d8270b" category="list-text">Diretrizes de práticas recomendadas para Confluent em sistemas de armazenamento NetApp</block>
  <block id="59cb8890508bcaf057fd0360eb8ff783" category="section-title">Por que usar o armazenamento em camadas da Confluent?</block>
  <block id="7a3966946c615eb57ae930f6948a1c65" category="inline-link-macro">este artigo da Confluent</block>
  <block id="eced8e0ff3a0cd0f66b3a8845f1e08be" category="paragraph">O Confluent se tornou a plataforma de streaming em tempo real padrão para muitas aplicações, especialmente para big data, análise e cargas de trabalho de streaming.  O armazenamento em camadas permite que os usuários separem a computação do armazenamento na plataforma Confluent.  Ele torna o armazenamento de dados mais econômico, permite que você armazene quantidades virtualmente infinitas de dados e aumente (ou diminua) as cargas de trabalho sob demanda, além de facilitar tarefas administrativas como rebalanceamento de dados e locatários.  Os sistemas de armazenamento compatíveis com S3 podem aproveitar todos esses recursos para democratizar dados com todos os eventos em um só lugar, eliminando a necessidade de engenharia de dados complexa.  Para obter mais informações sobre por que você deve usar armazenamento em camadas para Kafka, verifique<block ref="3c87b0bff8160b787f5bf29d10131d5e" category="inline-link-macro-rx"></block> .</block>
  <block id="911086e7904dbc449b09545eba850304" category="section-title">Por que usar o NetApp StorageGRID para armazenamento em camadas?</block>
  <block id="ee6c2a9cd0205695027987ec8da32dfe" category="paragraph">StorageGRID é uma plataforma de armazenamento de objetos líder do setor da NetApp.  O StorageGRID é uma solução de armazenamento baseada em objetos e definida por software que oferece suporte a APIs de objetos padrão do setor, incluindo a API do Amazon Simple Storage Service (S3).  O StorageGRID armazena e gerencia dados não estruturados em escala para fornecer armazenamento de objetos seguro e durável.  O conteúdo é colocado no local certo, na hora certa e no nível de armazenamento certo, otimizando fluxos de trabalho e reduzindo custos para mídia avançada distribuída globalmente.</block>
  <block id="5e5ef53b540f19d6746e6645de37cbb4" category="paragraph">O maior diferencial do StorageGRID é seu mecanismo de política de gerenciamento do ciclo de vida das informações (ILM), que permite o gerenciamento do ciclo de vida dos dados orientado por políticas.  O mecanismo de política pode usar metadados para gerenciar como os dados são armazenados ao longo de sua vida útil para otimizar inicialmente o desempenho e otimizar automaticamente o custo e a durabilidade à medida que os dados envelhecem.</block>
  <block id="a7f9d3e4bde145f56bcbec81a6dc2ef3" category="section-title">Habilitando o armazenamento em camadas do Confluent</block>
  <block id="a5cb83c3eb7e8757a8f985f8d935e700" category="paragraph">A ideia básica do armazenamento em camadas é separar as tarefas de armazenamento de dados do processamento de dados.  Com essa separação, fica muito mais fácil para a camada de armazenamento de dados e a camada de processamento de dados escalarem de forma independente.</block>
  <block id="ec4d623bd1019ab2fabc3a02ae9dc70d" category="paragraph">Uma solução de armazenamento em camadas para o Confluent deve atender a dois fatores.  Primeiro, ele deve contornar ou evitar propriedades comuns de consistência e disponibilidade de armazenamento de objetos, como inconsistências em operações LIST e indisponibilidade ocasional de objetos.  Em segundo lugar, ele deve lidar corretamente com a interação entre o armazenamento em camadas e o modelo de replicação e tolerância a falhas do Kafka, incluindo a possibilidade de líderes zumbis continuarem a estratificar intervalos de deslocamento.  O armazenamento de objetos da NetApp fornece disponibilidade consistente de objetos e o modelo de alta disponibilidade torna o armazenamento desgastado disponível para intervalos de deslocamento de camadas.  O armazenamento de objetos da NetApp fornece disponibilidade consistente de objetos e um modelo de alta disponibilidade para disponibilizar o armazenamento desgastado para intervalos de deslocamento de camadas.</block>
  <block id="104f1daa661d4c74d5bfd4e54946a4f4" category="paragraph">Com o armazenamento em camadas, você pode usar plataformas de alto desempenho para leituras e gravações de baixa latência perto do final dos seus dados de streaming e também pode usar armazenamentos de objetos mais baratos e escaláveis, como o NetApp StorageGRID , para leituras históricas de alto rendimento.  Também temos uma solução técnica para Spark com controlador de armazenamento netapp e os detalhes estão aqui.  A figura a seguir mostra como o Kafka se encaixa em um pipeline de análise em tempo real.</block>
  <block id="eea5b5aaa7bc893f83efe26850f04584" category="paragraph"><block ref="eea5b5aaa7bc893f83efe26850f04584" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0977e5b84fa31f5087efbbc1dc355236" category="paragraph">A figura a seguir mostra como o NetApp StorageGRID se encaixa na camada de armazenamento de objetos do Confluent Kafka.</block>
  <block id="baa92f35a9209359bb52e9fa325d0e29" category="paragraph"><block ref="baa92f35a9209359bb52e9fa325d0e29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="35f99fa939062899487754f637210a25" category="summary">Esta seção aborda o hardware e o software usados para a certificação Confluent.  Estas informações são aplicáveis à implantação do Kafka com armazenamento NetApp .</block>
  <block id="92672a7a2b909945fbfa9f44f057c7a1" category="doc">Dimensionamento</block>
  <block id="faa5cf9412df3e7266db15b6f1a5070d" category="paragraph">O dimensionamento do Kafka pode ser executado com quatro modos de configuração: simples, granular, reverso e partições.</block>
  <block id="1fbb1e3943c2c6c560247ac8f9289780" category="section-title">Simples</block>
  <block id="580c6adb23970405f45409b06eb3ba39" category="paragraph">O modo simples é apropriado para usuários iniciantes do Apache Kafka ou casos de uso em estágio inicial.  Para este modo, você fornece requisitos como taxa de transferência em MBps, distribuição de leitura, retenção e porcentagem de utilização de recursos (60% é o padrão).  Você também entra no ambiente, como no local (bare-metal, VMware, Kubernetes ou OpenStack) ou na nuvem.  Com base nessas informações, o dimensionamento de um cluster Kafka fornece o número de servidores necessários para o broker, o zookeeper, os trabalhadores de conexão do Apache Kafka, o registro de esquema, um proxy REST, o ksqlDB e o centro de controle do Confluent.</block>
  <block id="ae20e37661048a8d6cd37c4dbacac985" category="paragraph">Para armazenamento em camadas, considere o modo de configuração granular para dimensionar um cluster Kafka.  O modo granular é apropriado para usuários experientes do Apache Kafka ou casos de uso bem definidos.  Esta seção descreve o dimensionamento para produtores, processadores de fluxo e consumidores.</block>
  <block id="40d2d6f5a1dfde1a3b5ba2a70377fa0f" category="section-title">Produtores</block>
  <block id="05318fa579b7e76a65531afd94250ed3" category="paragraph">Para descrever os produtores do Apache Kafka (por exemplo, um cliente nativo, proxy REST ou conector Kafka), forneça as seguintes informações:</block>
  <block id="91be21e4458c6c8f0d6f61c307faf194" category="list-text">*Nome.*  Fagulha.</block>
  <block id="b39a7ae16ea364375daa4f600ebed072" category="list-text">*Tipo de produtor.*  Aplicação ou serviço, proxy (REST, MQTT, outro) e banco de dados existente (RDBMS, NOSQL, outro).  Você também pode selecionar "Não sei".</block>
  <block id="3fd4bc385cb0a0f62ae4183f316ff707" category="list-text">*Rendimento médio.*  Em eventos por segundo (1.000.000 por exemplo).</block>
  <block id="14ec4c2c8c9edf10c6aeefaf27f1f713" category="list-text">*Pico de rendimento.*  Em eventos por segundo (4.000.000 por exemplo).</block>
  <block id="b4672ddde5cb9c30e0e682084a411123" category="list-text">*Tamanho médio da mensagem.*  Em bytes, não compactado (máx. 1 MB; 1000 por exemplo).</block>
  <block id="f56fd2104d8bf51910ee81196e8b4751" category="list-text">*Formato da mensagem.*  As opções incluem Avro, JSON, buffers de protocolo, binário, texto, "Não sei" e outros.</block>
  <block id="b26274df5f3f47d18e40ee961fa8c5b5" category="list-text">*Fator de replicação.*  As opções são 1, 2, 3 (recomendação da Confluent), 4, 5 ou 6.</block>
  <block id="6320400b940be83033b0ce5ea91a3799" category="list-text">*Tempo de retenção.*  Um dia (por exemplo).  Por quanto tempo você deseja que seus dados sejam armazenados no Apache Kafka?  Digite -1 com qualquer unidade por um tempo infinito.  A calculadora assume um tempo de retenção de 10 anos para retenção infinita.</block>
  <block id="eb46bfc819d70448200241a8f1efec72" category="list-text">Marque a caixa de seleção "Habilitar armazenamento em camadas para diminuir a contagem de corretores e permitir armazenamento infinito?"</block>
  <block id="d66063041931961a7565ee71f7a7dd67" category="list-text">Quando o armazenamento em camadas está habilitado, os campos de retenção controlam o conjunto ativo de dados armazenados localmente no broker.  Os campos de retenção de arquivamento controlam por quanto tempo os dados são armazenados no armazenamento de objetos de arquivamento.</block>
  <block id="13bc2bec2c4039bad2d63b4ccf9611d4" category="list-text">*Retenção de armazenamento de arquivo.*  Um ano (por exemplo).  Por quanto tempo você deseja que seus dados sejam armazenados em armazenamento de arquivo?  Digite -1 com qualquer unidade por uma duração infinita.  A calculadora assume uma retenção de 10 anos para retenção infinita.</block>
  <block id="841d5d94c8cc645b8a35f0b58d3d5c6d" category="list-text">*Multiplicador de crescimento.*  1 (por exemplo).  Se o valor deste parâmetro for baseado na taxa de transferência atual, defina-o como 1.  Para dimensionar com base no crescimento adicional, defina este parâmetro como um multiplicador de crescimento.</block>
  <block id="5f044353fac0e72b8b68a9608cdfea2d" category="list-text">*Número de instâncias do produtor.*  10 (por exemplo).  Quantas instâncias de produtor estarão em execução?  Esta entrada é necessária para incorporar a carga da CPU no cálculo de dimensionamento.  Um valor em branco indica que a carga da CPU não está incorporada no cálculo.</block>
  <block id="585e13820ff765aec3c094fbb66fb358" category="paragraph">Com base neste exemplo de entrada, o dimensionamento tem o seguinte efeito sobre os produtores:</block>
  <block id="5504abde59477d70ee34b7c970af3ed2" category="list-text">Taxa de transferência média em bytes não compactados: 1 GBps.  Taxa de transferência máxima em bytes não compactados: 4 GBps.  Taxa de transferência média em bytes compactados: 400 MBps.  Taxa de transferência máxima em bytes compactados: 1,6 GBps.  Isso se baseia em uma taxa de compressão padrão de 60% (você pode alterar esse valor).</block>
  <block id="fe685c6164262035f3c0407347a3d38d" category="inline-link-macro"><block ref="fe685c6164262035f3c0407347a3d38d" category="inline-link-rx"></block></block>
  <block id="d6730cec7284a7856088b8a49563caef" category="list-text">Armazenamento total de hotset no broker necessário: 31.104 TB, incluindo replicação, compactado.  Total de armazenamento de arquivo off-broker necessário: 378.432 TB, compactado.  Usar<block ref="e132e1b42fc350f637835189d38d8bdf" category="inline-link-macro-rx"></block> para dimensionamento do StorageGRID .</block>
  <block id="65541f1c1daa682e605090dda4f5581b" category="paragraph">Os processadores de fluxo devem descrever seus aplicativos ou serviços que consomem dados do Apache Kafka e os produzem de volta no Apache Kafka.  Na maioria dos casos, eles são criados no ksqlDB ou no Kafka Streams.</block>
  <block id="47bf3a39e68a8e88ad9fff34b58afc0a" category="list-text">*Nome.*  Serpentina de faíscas.</block>
  <block id="23f4b8037342e7943a6f549d7868281e" category="list-text">*Tempo de processamento.*  Quanto tempo esse processador leva para processar uma única mensagem?</block>
  <block id="0d4a13e2166384d926575e139fe3c68c" category="list-text">1 ms (transformação simples e sem estado) [exemplo], 10 ms (operação com estado na memória).</block>
  <block id="a1d2bac0d8ed78c0ce6bb941328bc680" category="list-text">100 ms (operação de rede ou disco com estado), 1000 ms (chamada REST de terceiros).</block>
  <block id="8b74c5757b588cdfea993715c0ce3b58" category="list-text">Eu comparei esse parâmetro e sei exatamente quanto tempo leva.</block>
  <block id="df8cd4e4488e4a8198132e46fc2beec9" category="list-text">*Retenção de saída.*  1 dia (exemplo).  Um processador de fluxo produz sua saída de volta para o Apache Kafka.  Por quanto tempo você deseja que esses dados de saída sejam armazenados no Apache Kafka?  Digite -1 com qualquer unidade por uma duração infinita.</block>
  <block id="108b072da5b6fab64d55b4f1d69690d4" category="list-text">Marque a caixa de seleção "Habilitar armazenamento em camadas para diminuir a contagem de corretores e permitir armazenamento infinito?"</block>
  <block id="c4462b25651379530a9eea9b2b478755" category="list-text">*Retenção de armazenamento de arquivo.*  1 ano (por exemplo).  Por quanto tempo você deseja que seus dados sejam armazenados em armazenamento de arquivo?  Digite -1 com qualquer unidade por uma duração infinita.  A calculadora assume uma retenção de 10 anos para retenção infinita.</block>
  <block id="6507507d73f33bc3d1077b4454d9d3dd" category="list-text">*Porcentagem de passagem de saída.*  100 (por exemplo).  Um processador de fluxo produz sua saída de volta para o Apache Kafka.  Qual porcentagem da taxa de transferência de entrada será retornada ao Apache Kafka?  Por exemplo, se a taxa de transferência de entrada for 20 MBps e esse valor for 10, a taxa de transferência de saída será 2 MBps.</block>
  <block id="aa35062fd231efb888b1d664e6480c1d" category="list-text">De quais aplicativos isso é lido?  Selecione "Spark", o nome usado no dimensionamento baseado no tipo de produtor.  Com base na entrada acima, você pode esperar os seguintes efeitos de dimensionamento em instâncias do processador de fluxo e estimativas de partição de tópicos:</block>
  <block id="bbc0ea8f6decb55572d395615cd02a3b" category="list-text">Este aplicativo de processador de fluxo requer o seguinte número de instâncias.  Os tópicos recebidos provavelmente também exigirão essa quantidade de partições.  Entre em contato com a Confluent para confirmar este parâmetro.</block>
  <block id="0a206846c82be8eef261c4c686599582" category="list-text">1.000 para rendimento médio sem multiplicador de crescimento</block>
  <block id="b032c5d1deed2d1b75c4f8019b5155e3" category="list-text">4.000 para pico de rendimento sem multiplicador de crescimento</block>
  <block id="5cbe73cfdf68ec8b04b4506b237d8af9" category="list-text">1.000 para rendimento médio com um multiplicador de crescimento</block>
  <block id="f51843d6cdec756114fb7f153ab79f46" category="list-text">4.000 para pico de rendimento com um multiplicador de crescimento</block>
  <block id="1ebe06b1421d14bafea4a4d9a545d956" category="section-title">Consumidores</block>
  <block id="4d2351cfaa069bdffc56cd73486deacb" category="paragraph">Descreva seus aplicativos ou serviços que consomem dados do Apache Kafka e não os produzem de volta no Apache Kafka; por exemplo, um cliente nativo ou um conector Kafka.</block>
  <block id="21af20352468dedb23eb4b6fa7362e32" category="list-text">*Nome.*  Consumidor Spark.</block>
  <block id="9e3b25cc5e8806da459be0a41ecfce10" category="list-text">*Tempo de processamento.*  Quanto tempo esse consumidor leva para processar uma única mensagem?</block>
  <block id="39ad97382609f7463897aa49624f20d4" category="list-text">1 ms (por exemplo, uma tarefa simples e sem estado, como registro)</block>
  <block id="3d74518bdd6cfa27a42a16145872cc59" category="list-text">10 ms (gravações rápidas em um armazenamento de dados)</block>
  <block id="9f44c2afdbd671220f00e45494646aa6" category="list-text">100 ms (gravações lentas em um armazenamento de dados)</block>
  <block id="1284667da9611e925a39eee76e44e565" category="list-text">1000 ms (chamada REST de terceiros)</block>
  <block id="fff6a4b96ed9fb45c7eab95aeb8eb684" category="list-text">Algum outro processo de referência de duração conhecida.</block>
  <block id="6490501e3342b6bea241de7194a60bba" category="list-text">*Tipo de consumidor.*  Aplicação, proxy ou coletor para um armazenamento de dados existente (RDBMS, NoSQL, outro).</block>
  <block id="23a444b3f78a63619b03bea8301f4edb" category="list-text">De quais aplicativos isso é lido?  Conecte este parâmetro ao produtor e ao dimensionamento do fluxo determinados anteriormente.</block>
  <block id="2feb2ea8e1991424930eda0c7cdeb393" category="paragraph">Com base na entrada acima, você deve determinar o dimensionamento para instâncias do consumidor e estimativas de partição de tópicos.  Um aplicativo de consumidor requer o seguinte número de instâncias.</block>
  <block id="90e1e02e655ca52c281e9b5ac01ca245" category="list-text">2.000 para rendimento médio, sem multiplicador de crescimento</block>
  <block id="228e2cc32e2eedd0cfaf646cb26ad562" category="list-text">8.000 para pico de rendimento, sem multiplicador de crescimento</block>
  <block id="622c202fad5851b4699d8679ec9d3ce4" category="list-text">2.000 para rendimento médio, incluindo multiplicador de crescimento</block>
  <block id="da18372dd9e384fd5a4fd97fa6bdb872" category="list-text">8.000 para pico de rendimento, incluindo multiplicador de crescimento</block>
  <block id="5992882fb5e2f68b36cbf47d5ffc182a" category="paragraph">Os tópicos recebidos provavelmente também precisam desse número de partições.  Entre em contato com a Confluent para confirmar.</block>
  <block id="152f9b32fca1ce5e9a3fc34e8c9e69c0" category="paragraph">Além dos requisitos para produtores, processadores de fluxo e consumidores, você deve fornecer os seguintes requisitos adicionais:</block>
  <block id="aea71dcdb94c855eb0655cb615bdcfe2" category="list-text">*Hora da reconstrução.*  Por exemplo, 4 horas.  Se um host do broker do Apache Kafka falhar, seus dados serão perdidos e um novo host for provisionado para substituir o host com falha. Com que rapidez esse novo host deve se reconstruir?  Deixe este parâmetro em branco se o valor for desconhecido.</block>
  <block id="3bc49d2594090d023892da5211f6f7a4" category="list-text">*Meta de utilização de recursos (porcentagem).*  Por exemplo, 60.  Quão utilizados você quer que seus hosts sejam durante a taxa de transferência média?  A Confluent recomenda uma utilização de 60%, a menos que você esteja usando clusters de autobalanceamento Confluent, caso em que a utilização pode ser maior.</block>
  <block id="9fa691f61c91ce32c6fb2dcc53a9d09c" category="section-title">Descreva seu ambiente</block>
  <block id="7e431f8959ae4a79bcfc6e55728ead5a" category="list-text">*Em qual ambiente seu cluster será executado?*  Amazon Web Services, Microsoft Azure, plataforma de nuvem do Google, bare-metal local, VMware local, OpenStack local ou Kubernates local?</block>
  <block id="34946a533795a145eb4c6d66ee12e56b" category="list-text">*Detalhes do anfitrião.*  Número de núcleos: 48 (por exemplo), tipo de placa de rede (10GbE, 40GbE, 16GbE, 1GbE ou outro tipo).</block>
  <block id="a50ad1bade1c614aa4ceaa766944b0e1" category="list-text">*Volumes de armazenamento.*  Anfitrião: 12 (por exemplo).  Quantos discos rígidos ou SSDs são suportados por host?  A Confluent recomenda 12 discos rígidos por host.</block>
  <block id="bf903fced4e4e598ede3fb2a9dd5427a" category="list-text">*Capacidade/volume de armazenamento (em GB).*  1000 (por exemplo).  Quanto armazenamento um único volume pode armazenar em gigabytes?  A Confluent recomenda discos de 1 TB.</block>
  <block id="85a140efdb29007799d7d5e7c16691d5" category="list-text">*Configuração de armazenamento.*  Como os volumes de armazenamento são configurados?  A Confluent recomenda RAID10 para aproveitar todos os recursos da Confluent.  JBOD, SAN, RAID 1, RAID 0, RAID 5 e outros tipos também são suportados.</block>
  <block id="237d14e07eccd0d6535cf69ee4507805" category="list-text">*Taxa de transferência de volume único (MBps).*  125 (por exemplo).  Qual a velocidade com que um único volume de armazenamento pode ler ou gravar em megabytes por segundo?  A Confluent recomenda discos rígidos padrão, que normalmente têm taxa de transferência de 125 MBps.</block>
  <block id="57499d42a69c4ed9f1e7994a0bad7e9f" category="list-text">*Capacidade de memória (GB).*  64 (por exemplo).</block>
  <block id="9db0153ae987c66e360fc7027c7819c8" category="paragraph">Depois de determinar suas variáveis ambientais, selecione Dimensionar meu cluster.  Com base nos parâmetros de exemplo indicados acima, determinamos o seguinte dimensionamento para o Confluent Kafka:</block>
  <block id="fc644e6661f2118a6b0733f85424f3fa" category="list-text">*Apache Kafka.*  Contagem de corretores: 22.  Seu cluster está vinculado ao armazenamento.  Considere habilitar o armazenamento em camadas para diminuir sua contagem de hosts e permitir armazenamento infinito.</block>
  <block id="689921f4781dfd392aedc0eac4116284" category="list-text">*Apache ZooKeeper.*  Contagem: 5; Trabalhadores de conexão do Apache Kafka: Contagem: 2; Registro de esquema: Contagem: 2; Proxy REST: Contagem: 2; ksqlDB: Contagem: 2; Centro de controle Confluent: Contagem: 1.</block>
  <block id="df1673ed6a212d182bedbf3a4bdc79a7" category="paragraph">Use o modo reverso para equipes de plataforma sem um caso de uso em mente.  Use o modo de partições para calcular quantas partições um único tópico requer.  Ver<block ref="d971ea0f6ada2eeb1a618f5145544e00" category="inline-link-rx"></block> para dimensionamento com base nos modos reverso e de partições.</block>
  <block id="16d17bd11d09e7ab044f85f158c4ee5c" category="doc">Detalhes da arquitetura da solução</block>
  <block id="096d10f0062b97cca959118975fa506a" category="paragraph">Esta seção aborda o hardware e o software usados para verificação do Confluent.  Estas informações são aplicáveis à implantação da Confluent Platform com armazenamento NetApp .  A tabela a seguir abrange a arquitetura da solução testada e os componentes básicos.</block>
  <block id="7e897f23ed71aef1c0a8acf1ae54e9e4" category="cell">Componentes da solução</block>
  <block id="3ec365dd533ddb7ef3d1c111186ce872" category="cell">Detalhes</block>
  <block id="cd6b218ceb186591718799f941a99fd0" category="cell">Confluent Kafka versão 6.2</block>
  <block id="8a1732b4cde6f106471a0e6dbb186bed" category="list-text">Três tratadores de zoológico</block>
  <block id="fde5b2c6fa48108e02c6a3587ce451b4" category="list-text">Cinco servidores de corretores</block>
  <block id="cd2e7d4aa00a79a9a92980e984ec50d7" category="list-text">Cinco ferramentas de servidores</block>
  <block id="e9617e461b2b6597095fc0d3c26666c5" category="list-text">Uma Grafana</block>
  <block id="5d96f98a638cf23ac2f3dfe513198e9a" category="list-text">Um centro de controle</block>
  <block id="a2a44121136232f1f2dcfb5e5ce5cf22" category="cell">Linux (ubuntu 18.04)</block>
  <block id="a0681d05c825936a4afc9d89f305934c" category="cell">Todos os servidores</block>
  <block id="cc3bec1f9974aef63e75985fed9c343e" category="cell">NetApp StorageGRID para armazenamento em camadas</block>
  <block id="2d4f4568ad652ff08727bc044f1373cc" category="list-text">Software StorageGRID</block>
  <block id="4ebcee22d98fbad50cf1c7e108dd9541" category="list-text">1 x SG1000 (balanceador de carga)</block>
  <block id="a51cb0f5fd275943954c8d687912e458" category="list-text">4 x SGF6024</block>
  <block id="83cc5cf13ad44caf6aa94887d189cd3a" category="list-text">4 x 24 x 800 SSDs</block>
  <block id="7ccdc7c1d04d9b48b4b016417504685b" category="list-text">Protocolo S3</block>
  <block id="e185a6ccd16ce2c64c7e948bbc46f45a" category="list-text">4 x 100GbE (conectividade de rede entre o broker e as instâncias do StorageGRID )</block>
  <block id="5ecafb7b42f662438e20bd643feb79c9" category="cell">15 servidores Fujitsu PRIMERGY RX2540</block>
  <block id="cdb0680ecb0e0ed91d8293e41334b379" category="cell">Cada um equipado com: * 2 CPUs, 16 núcleos físicos no total * Intel Xeon * 256 GB de memória física * Porta dupla de 100 GbE</block>
  <block id="06a768157cb89879ca041da1b730da6e" category="summary">Este documento fornece diretrizes de práticas recomendadas para usar o Dremio com armazenamento NetApp , incluindo testes de certificação TPCDS, ajustes e detalhes de casos de uso do cliente.</block>
  <block id="5539c6da3e2032488a631305f1265434" category="paragraph">Concluindo, este relatório técnico forneceu detalhes abrangentes de implantação do q Hybrid Iceberg Lakehouse com Dremio em conjunto com várias fontes de dados de controladores de armazenamento NetApp , incluindo ONTAP S3, NAS e StorageGRID.  O processo de implantação foi executado com sucesso, e a ferramenta de benchmarking TPC-DS foi utilizada para executar 99 consultas SQL nas diferentes fontes de dados.  O relatório também explorou casos de uso de clientes dentro do NetApp, demonstrando a versatilidade e eficácia do Dremio em atender a diversos requisitos de negócios.  Além disso, um caso de uso específico envolvendo um cliente de vendas de peças automotivas foi examinado, destacando a aplicação prática e os benefícios de aproveitar o Dremio para análises de dados e insights.</block>
  <block id="682cc1e627af4457882db17515ccaf5b" category="paragraph">No geral, este documento serve como um recurso valioso para entender a implantação e o uso do Dremio com controladores de armazenamento NetApp , mostrando seus recursos e potencial para impulsionar a tomada de decisões e a otimização baseadas em dados em vários setores.</block>
  <block id="c63354da3a3a21f3ae0083d0a275540c" category="list-text">Instalação do tratador de zoológico</block>
  <block id="661fab58be11f3fe0e5fd03c183c9a3b" category="paragraph"><block ref="661fab58be11f3fe0e5fd03c183c9a3b" category="inline-link-rx"></block></block>
  <block id="288e0e9ab8b8ac8737afefecf16f61fd" category="list-text">Dremio</block>
  <block id="d9f3b0f9c66b1c99f5e01fefb31f3280" category="paragraph"><block ref="d9f3b0f9c66b1c99f5e01fefb31f3280" category="inline-link-rx"></block></block>
  <block id="7d56340ec96dd44dedf67654c4b228a9" category="list-text">Configurando Dremio com storageGRID</block>
  <block id="d6a7c21494adf18f10c2f9b2b6da5584" category="paragraph"><block ref="d6a7c21494adf18f10c2f9b2b6da5584" category="inline-link-rx"></block></block>
  <block id="719a5826913817829f2d138a33720835" category="list-text">Caso de uso do NetApp</block>
  <block id="abd766d13b2562c1684015edb41ddc75" category="paragraph"><block ref="abd766d13b2562c1684015edb41ddc75" category="inline-link-rx"></block></block>
  <block id="108f231402daaaf5b7a58841053615dd" category="summary">Realizamos a certificação com a plataforma Dremio com validação lakehouse no armazenamento de objetos NetApp .</block>
  <block id="3cd3290a9231e38be51fc2cb3ce01572" category="doc">Procedimento de Implantação</block>
  <block id="d44c5f08c906e8f8bc746c8e4083522e" category="inline-image-macro">Figura mostrando a arquitetura do Dremio com o controlador de armazenamento NetApp</block>
  <block id="5e5f3a2661fa2ba525c6c6d493b1058d" category="paragraph">Nesta validação da arquitetura de referência, utilizamos uma configuração Dremio composta por um coordenador e quatro executores<block ref="b76f8c360d80a001aee0571894d68ba2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="07efd46e12f0d695c6aa9e2abf057781" category="section-title">Configuração do NetApp</block>
  <block id="82c8a5cee83d98576ecd7fb9135c1b41" category="list-text">Inicialização do sistema de armazenamento</block>
  <block id="8028442c79907b3f88933ff5c16fac5e" category="list-text">Criação de máquina virtual de armazenamento (SVM)</block>
  <block id="ff602335ea946bbb0494a8ca5aa58bf5" category="list-text">Atribuição de interfaces de rede lógicas</block>
  <block id="c1d1275f7bc999e53ce84a9b2a48cc7f" category="list-text">NFS, configuração e licenciamento S3</block>
  <block id="bbc1adf735eb5e7f9c1e5bae1fb2aed8" category="paragraph">Siga os passos abaixo para NFS (Network File System): 1.  Crie um volume Flex Group para NFSv4 ou NFSv3.  Em nossa configuração para esta validação, usamos 48 SSDs, 1 SSD dedicado ao volume raiz do controlador e 47 SSDs distribuídos para NFSv4.  Verifique se a política de exportação NFS para o volume do Flex Group tem permissões de leitura/gravação para a rede de servidores Dremio.</block>
  <block id="77cf539931cef9f508e194dbd28a0bc0" category="list-text">Em todos os servidores Dremio, crie uma pasta e monte o volume do Flex Group nessa pasta por meio de uma Interface Lógica (LIF) em cada servidor Dremio.</block>
  <block id="575afa472f95d77f2af74b7f99bc9d28" category="paragraph">Siga as etapas abaixo para o S3 (Serviço de Armazenamento Simples):</block>
  <block id="28863b320894e844cb1d2df9a479aa31" category="list-text">Configure um servidor de armazenamento de objetos com HTTP habilitado e o status do administrador definido como 'ativo' usando o comando "vserver object-store-server create".  Você tem a opção de habilitar HTTPS e definir uma porta de escuta personalizada.</block>
  <block id="993520e0cce3e5f87179d01caa10a746" category="list-text">Crie um usuário object-store-server usando o comando "vserver object-store-server user create -user &lt;nome de usuário&gt;".</block>
  <block id="4c7b617c418e3a5f7073d2d64ba8cb1c" category="list-text">Para obter a chave de acesso e a chave secreta, você pode executar o seguinte comando: "set diag; vserver object-store-server user show -user &lt;nome de usuário&gt;".  No entanto, a partir de agora, essas chaves serão fornecidas durante o processo de criação do usuário ou poderão ser recuperadas usando chamadas de API REST.</block>
  <block id="c3d4f7a6161c482cb921db78c64d1543" category="list-text">Estabeleça um grupo de objetos-armazenamento-servidor usando o usuário criado na etapa 2 e conceda acesso.  Neste exemplo, fornecemos "FullAccess".</block>
  <block id="f346ebaf71f9d3850361e0b732a352f5" category="list-text">Crie dois buckets S3 definindo seu tipo como "S3".  Um para configuração do Dremio e um para dados do cliente.</block>
  <block id="3c29c74ed24f85f4cf464243c6d69bc7" category="section-title">Configuração do tratador de zoológico</block>
  <block id="a284e9d9802d2b863fce5aa237106342" category="paragraph">Você pode usar a configuração do zookeeper fornecida pelo Dremio.  Nesta validação, usamos um zookeeper separado. Seguimos os passos mencionados neste link da web<block ref="757110f854f50ea29baeb536bc067417" category="inline-link-rx"></block></block>
  <block id="fb6e0f74d4f2cd819e198308d0e560c8" category="section-title">Configuração do Dremio</block>
  <block id="3e793dc4b6b41d43692a24d29150ed55" category="paragraph">Seguimos este link para instalar o Dremio via tar ball.</block>
  <block id="694299a05f621f9d6c47fbc0cdd75cdb" category="list-text">Crie um grupo Dremio.</block>
  <block id="28b115fb542519f28216941113c7fc69" category="list-text">Crie um usuário dremio.</block>
  <block id="6190c0f96190f68e7387989b98fecd3c" category="list-text">Crie diretórios Dremio.</block>
  <block id="b8d53340c1af1590a07a31d4782e75c8" category="list-text">Baixe o arquivo tar de<block ref="993599c5d8336ec040e5e84c23246c65" category="inline-link-rx"></block></block>
  <block id="38152bcebb8f6d46160b6d2462ce40a0" category="list-text">Descompacte o Dremio no diretório /opt/dremio.</block>
  <block id="9af78d03c81be6e6dd350c73be883f9b" category="list-text">Crie um link simbólico para a pasta de configuração.</block>
  <block id="a16cec17e87f61728dcdd563b7d8ecc7" category="list-text">Configure sua configuração de serviço (configuração do SystemD).</block>
  <block id="44aba27523001647040cfa3dab851cbb" category="list-text">Copie o arquivo de unidade do daemon dremio de /opt/dremio/share/dremio.service para /etc/systemd/system/dremio.service.</block>
  <block id="617a522470fb25e0b60757c2347779fd" category="list-text">Reiniciar o sistema</block>
  <block id="b0a645a7658dbbe597c81a61d8095535" category="list-text">Habilitar o dremio para iniciar na inicialização.</block>
  <block id="715ae8a49286aaa14659522218602fba" category="list-text">Configurar o Dremio no coordenador.  Veja a configuração do Dremio para mais informações</block>
  <block id="940845b76f9832cb794ce21b8053c3d9" category="list-text">Dremio.conf</block>
  <block id="e49741f6cfbc4fdc21eaf59a034e694c" category="list-text">Core-site.xml</block>
  <block id="157bf0c98c644ad5d09f3dda0843bb8d" category="list-text">A configuração do Dremio é armazenada no armazenamento de objetos do NetApp .  Em nossa validação, o bucket "dremioconf" reside em um bucket ontap S3.  A imagem abaixo mostra alguns detalhes das pastas "scratch" e "uploads" do bucket S3 "dremioconf".</block>
  <block id="dec65ddc4408a5fd22bf6eef9c5dc2c4" category="inline-image-macro">Figura mostrando o dremio com armazenamento de objetos NetApp</block>
  <block id="3f6534c1dba4ce90c550aec7ec304146" category="paragraph"><block ref="3f6534c1dba4ce90c550aec7ec304146" category="inline-image-macro-rx" type="image"></block></block>
  <block id="536241c2f7d1f3fbe227bc001b56b949" category="list-text">Configurar o Dremio nos executores.  Em nossa configuração, temos 3 executores.</block>
  <block id="98acd539813ecdb677a633c1e8d72ba9" category="list-text">dremio.conf</block>
  <block id="19aac463221a9324b146be45c5f27561" category="list-text">Core-site.xml – o mesmo que a configuração do coordenador.</block>
  <block id="9ebe81db6df147f3eea7002c858d2821" category="admonition">A NetApp recomenda o StorageGRID como sua principal solução de armazenamento de objetos para ambientes Datalake e Lakehouse.  Além disso, o NetApp ONTAP é empregado para dualidade arquivo/objeto.  No contexto deste documento, conduzimos testes no ONTAP S3 em resposta a uma solicitação do cliente, e ele funciona com sucesso como uma fonte de dados.</block>
  <block id="5b8d6104bd7d25e99e47f619fdfd8f81" category="section-title">Configuração de múltiplas fontes</block>
  <block id="4ee12bc75bcc4f7fb3bbf527ef1d2720" category="list-text">Configure o ONTAP S3 e o storageGRID como uma fonte s3 no Dremio.</block>
  <block id="dbd1ae231acf755d63de74b16a8cbeb7" category="list-text">Painel do Dremio -&gt; conjuntos de dados -&gt; fontes -&gt; adicionar fonte.</block>
  <block id="c102e8893995a295f2cc62063b2e0cd5" category="list-text">Na seção geral, atualize o acesso e a chave secreta da AWS</block>
  <block id="71a7d593565f192b138481a0e8d335c4" category="list-text">Na opção avançada, ative o modo de compatibilidade e atualize as propriedades de conexão com os detalhes abaixo.  O IP/nome do ponto de extremidade do controlador de armazenamento NetApp do ontap S3 ou do storageGRID.</block>
  <block id="4f594a255a564afe3df4ac263caedbb5" category="list-text">Habilitar o cache local quando possível, Percentual máximo do cache total disponível para uso quando possível = 100</block>
  <block id="c71df1ddac771fdc9b484b0ed6f6d9f7" category="inline-image-macro">Figura mostrando a lista de arquivos do armazenamento de objetos do NetApp</block>
  <block id="a4d1986a0b1a4f12d2237b0963d2e43d" category="list-text">Em seguida, visualize a lista de buckets do armazenamento de objetos do NetApp .<block ref="3774299f093c28855158f425c629b55d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c80afe9a6ef853e0d394059a332a406d" category="list-text">Exibição de exemplo dos detalhes do bucket storageGRID<block ref="e0f51eae5ca0e68849adc9661a7def73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18ebb902e9ccb331331d9d1b8b5e0f76" category="list-text">Configure o NAS (especificamente o NFS) como uma fonte no Dremio.</block>
  <block id="08a5aec8691cede64f84acb42700e07d" category="list-text">Na seção geral, insira o nome e o caminho de montagem do NFS.  Certifique-se de que o caminho de montagem do NFS esteja montado na mesma pasta em todos os nós do cluster Dremio.</block>
  <block id="eaa2d3817be8fb7b330c01f9605f0808" category="paragraph"><block ref="eaa2d3817be8fb7b330c01f9605f0808" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26b17225b626fb9238849fd60eabdf60" category="paragraph">+</block>
  <block id="b134468afaa618eaef2e7bfaf5f30da7" category="summary">Este documento descreve as diretrizes de práticas recomendadas para usar o Dremio em um controlador de armazenamento NetApp .</block>
  <block id="53bd7dac219a2662a137c6de870224d2" category="doc">A solução Iceberg Lakehouse híbrida de última geração da NetApp e Dremio</block>
  <block id="0c74f27a6d1c41b83e5cc59468f24a0d" category="paragraph">Neste documento, discutimos os detalhes de implantação do Dremio com diferentes fontes de dados de controladores de armazenamento NetApp , incluindo ONTAP S3, NAS e StorageGRID.  Durante a implantação, usamos a ferramenta de benchmarking TPC-DS para executar 99 consultas SQL em várias fontes.  O documento também explora casos de uso de clientes dentro da NetApp, bem como um caso de uso envolvendo um cliente de vendas de peças automotivas.</block>
  <block id="d4b28ab5babb078bc6498faee7c53a81" category="summary">Esta seção aborda o hardware e o software usados para a certificação do Dremio.  Estas informações são aplicáveis à implantação do Dremio com armazenamento NetApp .</block>
  <block id="cb2418c01859c7704da751aa5a7d2421" category="doc">Visão geral da solução</block>
  <block id="9953e901936889810e67ec0949c6b2fc" category="paragraph">A solução Hybrid Iceberg Lakehouse oferece benefícios exclusivos para abordar os desafios enfrentados pelos clientes do data lake.  Ao aproveitar a plataforma Dremio Unified Lakehouse e as soluções NetApp ONTAP, StorageGRID e NetApp Cloud, as empresas podem agregar valor significativo às suas operações comerciais.  A solução não apenas fornece acesso a várias fontes de dados, incluindo fontes da NetApp , mas também melhora o desempenho analítico geral e ajuda as empresas a gerar insights de negócios que levam ao crescimento dos negócios.</block>
  <block id="91c847ff0ec1e96ccc74039eaf1b5bf3" category="section-title">Visão geral da NetApp</block>
  <block id="b630104207f28e8a0523849fe77c1e9f" category="list-text">As ofertas da NetApp, como ONTAP e StorageGRID, permitem a separação de armazenamento e computação, possibilitando a utilização ideal de recursos com base em requisitos específicos.  Essa flexibilidade permite que os clientes dimensionem seu armazenamento de forma independente usando soluções de armazenamento da NetApp</block>
  <block id="bc213af00312a8c2d752b8b42715eed6" category="list-text">Ao aproveitar os controladores de armazenamento da NetApp, os clientes podem fornecer dados de forma eficiente para seu banco de dados vetorial usando os protocolos NFS e S3.  Esses protocolos facilitam o armazenamento de dados do cliente e gerenciam o índice do banco de dados vetorial, eliminando a necessidade de múltiplas cópias de dados acessadas por meio de métodos de arquivo e objeto.</block>
  <block id="1557c431be0fea4f212f4006eafc9a8c" category="list-text">O NetApp ONTAP fornece suporte nativo para NAS e armazenamento de objetos nos principais provedores de serviços de nuvem, como AWS, Azure e Google Cloud.  Essa ampla compatibilidade garante integração perfeita, permitindo mobilidade de dados do cliente, acessibilidade global, recuperação de desastres, escalabilidade dinâmica e alto desempenho.</block>
  <block id="392d70ca39f31f10bd637936769788df" category="section-title">StorageGRID</block>
  <block id="9409f64cd9405163cc619bf89c44eaf4" category="paragraph">Nosso armazenamento de objetos líder do setor, o storageGRID, oferece um poderoso mecanismo de política para posicionamento automatizado de dados, opções flexíveis de implantação e durabilidade incomparável com codificação de eliminação em camadas.  Ele tem uma arquitetura escalável que suporta bilhões de objetos e petabytes de dados em um único namespace.  A solução permite a integração de nuvem híbrida, permitindo a hierarquização de dados nas principais plataformas de nuvem.  Ela foi reconhecida como líder na Avaliação de Fornecedores Baseada em Objetos do IDC Marketscape Worldwide de 2019.</block>
  <block id="546a8027b219510c369554288fd7eff4" category="paragraph">Além disso, o storageGRID se destaca no gerenciamento de dados não estruturados em escala com armazenamento de objetos definidos por software, redundância geográfica e recursos multisite.  Ele incorpora gerenciamento de ciclo de vida de informações baseado em políticas e oferece recursos de integração em nuvem, como espelhamento e pesquisa.  Possui diversas certificações, incluindo Common Criteria, NF203 Digital Safe Component, ISO/IEC 25051, KPMG e Cohasset Compliance Assessment.</block>
  <block id="030de30483fabd3aca42be7503592961" category="paragraph">Em resumo, o NetApp storageGRID oferece recursos poderosos, escalabilidade, integração de nuvem híbrida e certificações de conformidade para gerenciamento eficiente de dados não estruturados em escala.</block>
  <block id="7b02ea300aef2e0bff0d7f6111053284" category="section-title">NetApp ONTAP</block>
  <block id="185a43d593912638c2bb37ef99444fc9" category="paragraph">O NetApp ONTAP é uma solução de armazenamento robusta que oferece uma ampla gama de recursos empresariais.  Inclui o Snapshot, que fornece backups instantâneos consistentes com o aplicativo e à prova de violação.  O SnapRestore permite restauração quase instantânea de backups sob demanda, enquanto o SnapMirror oferece recursos integrados de backup remoto e recuperação de desastres.  A solução também incorpora a Proteção Autônoma contra Ransomware (ARP), garantindo a segurança dos dados com recursos como verificação de vários administradores, criptografia de dados em repouso com certificação FIPS, criptografia de dados em trânsito, autenticação multifator (MFA) e controle de acesso baseado em função (RBAC).  Registro abrangente, auditoria, gerenciamento de chaves internas e externas, limpeza segura e gerenciamento seguro de múltiplos locatários aprimoram ainda mais a segurança e a conformidade dos dados.</block>
  <block id="48af054a9eb5d217f15aab37f5fe9b91" category="paragraph">O NetApp ONTAP também conta com o SnapLock, que fornece retenção de dados em conformidade com regulamentações, com altos níveis de integridade, desempenho e retenção a um baixo custo total de propriedade.  Ele é totalmente integrado ao NetApp ONTAP 9 e oferece proteção contra atos maliciosos, administradores desonestos e ransomware.</block>
  <block id="afd4da5566327275499951d8db99e683" category="paragraph">A solução abrange criptografia NSE/NVE para criptografia de dados em voo e em repouso, acesso de administrador multifator e verificação de vários administradores.  O Active IQ fornece análises preditivas e ações corretivas baseadas em IA, enquanto o QoS garante o controle da carga de trabalho de qualidade do serviço.  A integração de gerenciamento e automação é intuitiva por meio de SysMgr/GUI/CLI/API.  O FabricPool permite a hierarquização automática de dados, e a solução oferece eficiência por meio de compactação, desduplicação e compactação de dados em linha.  A NetApp garante o cumprimento das metas de eficiência da carga de trabalho sem nenhum custo para o cliente.</block>
  <block id="327b294a4782dbbd617ca02b0227198e" category="paragraph">O NetApp ONTAP oferece suporte a vários protocolos, incluindo NVMe/FC, FC, NVMe/TCP, iSCSI, NFS, SMB e S3, o que o torna uma solução de armazenamento unificada.  No geral, o NetApp ONTAP oferece amplos recursos empresariais, segurança robusta, conformidade, eficiência e versatilidade para atender a diversas necessidades de armazenamento.</block>
  <block id="5504df296ab63119754ecfd92e6a07d7" category="section-title">Visão geral do Dremio</block>
  <block id="46664b9047c24c224cf4898236ac4159" category="paragraph">Dremio é a plataforma Lakehouse unificada para análises de autoatendimento e IA.  A plataforma Dremio Unified Analytics aproxima os usuários dos dados com flexibilidade, escalabilidade e desempenho do lakehouse por uma fração do custo das soluções de data warehouse legadas.  O Dremio permite análises "shift-left" para eliminar a integração de dados complexa e dispendiosa e ETL, proporcionando análises contínuas em escala empresarial sem movimentação de dados.  O Dremio também apresenta:</block>
  <block id="2f0acfc3dbf17a0571810cc0dedaf64f" category="list-text">Análises de autoatendimento fáceis de usar, possibilitadas por uma camada semântica universal e um mecanismo de consulta SQL altamente integrado e de alto desempenho, facilitando a conexão, o controle e a análise de todos os dados, tanto na nuvem quanto no local.</block>
  <block id="88be140c20067da1baf354c05223a2c6" category="list-text">Os recursos de gerenciamento de lakehouse nativos do Apache Iceberg do Dremio simplificam a descoberta de dados e automatizam a otimização de dados, oferecendo análises de alto desempenho com controle de versão de dados inspirado no Git.</block>
  <block id="fe08740b7cac34b055da6ec6bfe79c3f" category="list-text">Baseado em código aberto e padrões abertos, o Dremio permite que as empresas evitem a dependência e permaneçam posicionadas para a inovação.  Empresas corporativas confiam no Dremio como a plataforma lakehouse mais fácil de usar, com o melhor custo-benefício em todas as cargas de trabalho.</block>
  <block id="e95806f0d7b4743b250387c094acef2b" category="section-title">Que valor a solução Dremio e NetApp Hybrid Iceberg Lakehouse oferece aos clientes?</block>
  <block id="81c79525dc5cb78051ffe86a4b85377f" category="list-text">*Gerenciamento de dados e acessibilidade aprimorados*: A Dremio é conhecida por sua plataforma de data lakehouse que permite que organizações consultem dados diretamente de seus data lakes em alta velocidade.  A NetApp, por outro lado, é uma provedora líder de serviços de dados em nuvem e soluções de armazenamento de dados.  A oferta conjunta fornece aos clientes uma solução abrangente para armazenar, gerenciar, acessar e analisar os dados de sua empresa de forma eficiente e eficiente.</block>
  <block id="4bb8954089d2a9fb6c99825861c39f62" category="list-text">*Otimização de desempenho*: Com a experiência da NetApp em armazenamento de dados e os recursos da Dremio em processamento e otimização de dados, a parceria oferece uma solução que melhora o desempenho das operações de dados, reduz a latência e aumenta a velocidade do insight de negócios.  O Dremio até mesmo trouxe benefícios de desempenho para a infraestrutura analítica de TI interna da NetApp.</block>
  <block id="737f740962d700c8fb65a99e34900bc9" category="list-text">*Escalabilidade*: Tanto o Dremio quanto o NetApp oferecem uma solução projetada para escalar.  A solução conjunta fornece aos clientes ambientes de armazenamento, gerenciamento de dados e análise de dados altamente escaláveis.  Em um ambiente Hybrid Iceberg Lakehouse, o mecanismo de consulta Dremio SQL emparelhado com o NetApp StorageGRID oferece escalabilidade, simultaneidade e desempenho de consulta incomparáveis, capaz de lidar com as necessidades analíticas de qualquer negócio.</block>
  <block id="38eb37e9ecd9ccb05b8fda4a7890c571" category="list-text">*Segurança e governança de dados*: Ambas as empresas têm um forte foco em segurança e governança de dados.  Juntos, eles oferecem recursos robustos de segurança e governança de dados, garantindo que os dados sejam protegidos e que os requisitos de governança de dados sejam atendidos.  Recursos como controles de acesso detalhados e baseados em funções, auditoria abrangente, linhagem de dados de ponta a ponta, gerenciamento unificado de identidade e SSO com uma ampla estrutura de conformidade e segurança garantem que os ambientes de dados analíticos das empresas sejam seguros e governados.</block>
  <block id="b10c860483a8763cd915a0459af4c444" category="list-text">*Eficiência de custos*: Ao integrar o mecanismo de data lake da Dremio com as soluções de armazenamento da NetApp, os clientes podem reduzir os custos associados ao gerenciamento e à movimentação de dados.  As organizações também podem migrar de ambientes de data lake legados para uma solução de lakehouse mais moderna, composta por NetApp e Dremio.  Esta solução Hybrid Iceberg Lakehouse oferece desempenho de consulta de alta velocidade e simultaneidade de consulta líder de mercado, o que reduz o TCO e o tempo para obter insights de negócios.</block>
  <block id="55473d705d75e19b6040dbe34242319c" category="summary">Esta seção descreve a tecnologia usada nesta solução.</block>
  <block id="910af13beca7193218f534b5af1d8881" category="doc">Requisitos de tecnologia</block>
  <block id="915f99cb757b24fafb485b82cc5fe20e" category="paragraph">As configurações de hardware e software descritas abaixo foram utilizadas para validações realizadas neste documento.  Essas configurações servem como um guia para ajudar você a configurar seu ambiente. No entanto, observe que os componentes específicos podem variar dependendo dos requisitos individuais do cliente.</block>
  <block id="47dee50ad0138b8f5ca70e40e86e6c04" category="section-title">Requisitos de hardware</block>
  <block id="3c02a379965ab0dfcd77b1c484450433" category="cell">Hardware</block>
  <block id="74cc4ae913d72260c083ab2b346121ec" category="cell">Par de matriz de armazenamento AFF da NetApp HA</block>
  <block id="e4044b704224bc11ad4a58e92f2131d7" category="list-text">A800</block>
  <block id="8020ad245e7cbc2ac49c84b7f4ace684" category="list-text">ONTAP 9.14.1</block>
  <block id="4c365c4afab33ac328254bd7c2ae19a9" category="list-text">48 SSDs NVM de 3,49 TB</block>
  <block id="fe001f20ed0495ea55b4938631878b7a" category="list-text">Dois buckets S3: metadados do Dremio e dados do cliente.</block>
  <block id="637071f2d4a8f15942d2e18657010fa9" category="cell">4 x FUJITSU PRIMERGY RX2540 M4</block>
  <block id="e0c5e2628a6e691fa3fafe35f3bf20c3" category="list-text">64 CPUs</block>
  <block id="319d86787ef65ef260e666cc63f6e1a3" category="list-text">CPU Intel Xeon Gold 6142 a 2,60 GHz</block>
  <block id="d6b9b9dc5caf5833c325bc02278f4817" category="list-text">256 GM de memória física</block>
  <block id="81555075e106886f4be11de9599425a6" category="list-text">1 porta de rede 100GbE</block>
  <block id="a5fa5746370b608090b994a97b49e98b" category="cell">Rede</block>
  <block id="edcd3f3adc6d51b309e9115847fa497f" category="list-text">100 GbE</block>
  <block id="9de4526063d2d5dc8600f1abb273fb87" category="cell">* 1 x SG100, 3xSGF6024 * 3 x 24 x 7,68 TB * Dois buckets S3: metadados Dremio e dados do cliente.</block>
  <block id="500084ff15a1d3831b2b0a0cc8efb3b4" category="list-text">versão - 25.0.3-202405170357270647-d2042e1b</block>
  <block id="b5251cb924b1e27d2fa914e7b3dbd75c" category="list-text">Edição Enterprise</block>
  <block id="cea575677c47839fde1e59dbfc9ad5bb" category="cell">No local</block>
  <block id="fd50fb0f59921345e87394051ed99e40" category="list-text">Cluster Dremio de 5 nós</block>
  <block id="743d1e7bf62dfc8a183c666693662dc6" category="list-text">1 coordenador mestre e 4 executores</block>
  <block id="cce86ec0e697036ce6aa6105904b06de" category="summary">Esta seção aborda os detalhes do caso de uso do cliente do Dremio com armazenamento de objetos netapp.</block>
  <block id="fe0bd5fc290c9a203c8e8f18a2b6e647" category="doc">Casos de uso do cliente</block>
  <block id="46233f9bd0306ff790c810922b25e957" category="section-title">Caso de uso do NetApp ActiveIQ</block>
  <block id="994534c401b3a0f86cd899f3b7b6ec57" category="inline-image-macro">Arquitetura antiga do ActiveIQ</block>
  <block id="3002c8327e7407633cb1d61c6e798c05" category="paragraph"><block ref="3002c8327e7407633cb1d61c6e798c05" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e9e9a9c8ceef33ee9b9839f01cdf06a" category="paragraph">*Desafio*: A solução interna Active IQ da NetApp, projetada inicialmente para dar suporte a diversos casos de uso, evoluiu para uma oferta abrangente para usuários internos e clientes.  No entanto, a infraestrutura de backend subjacente baseada em Hadoop/MapR apresentou desafios em termos de custo e desempenho, devido ao rápido crescimento de dados e à necessidade de acesso eficiente aos dados.  Aumentar a escala do armazenamento significava adicionar recursos de computação desnecessários, resultando em aumento de custos.</block>
  <block id="66c90395e80a7e0f428abf5cf77fa1f4" category="paragraph">Além disso, gerenciar o cluster Hadoop consumia tempo e exigia conhecimento especializado.  Problemas de desempenho e gerenciamento de dados complicaram ainda mais a situação, com consultas levando em média 45 minutos e escassez de recursos devido a configurações incorretas.  Para enfrentar esses desafios, a NetApp buscou uma alternativa ao ambiente Hadoop legado existente e determinou que uma nova solução moderna construída no Dremio reduziria custos, separaria o armazenamento e a computação, melhoraria o desempenho, simplificaria o gerenciamento de dados, ofereceria controles detalhados e forneceria recursos de recuperação de desastres.</block>
  <block id="f4327571cd8b76a68a25a1d8487a0db0" category="inline-image-macro">Nova arquitetura ActiveIQ com dremio</block>
  <block id="954cc37909c75a2221a99b0c02a26f82" category="paragraph">*Solução*:<block ref="4a878fba67d10f0324250d8d1dafdcc5" category="inline-image-macro-rx" type="image"></block> A Dremio permitiu que a NetApp modernizasse sua infraestrutura de dados baseada em Hadoop em uma abordagem em fases, fornecendo um roteiro para análises unificadas.  Ao contrário de outros fornecedores que exigiram mudanças significativas no processamento de dados, a Dremio se integrou perfeitamente aos pipelines existentes, economizando tempo e despesas durante a migração.  Ao fazer a transição para um ambiente totalmente conteinerizado, a NetApp reduziu a sobrecarga de gerenciamento, melhorou a segurança e aumentou a resiliência.  A adoção de ecossistemas abertos como Apache Iceberg e Arrow pela Dremio garantiu proteção para o futuro, transparência e extensibilidade.</block>
  <block id="6f323477260e85221bf9876e157b69d0" category="paragraph">Como substituição para a infraestrutura Hadoop/Hive, o Dremio ofereceu funcionalidade para casos de uso secundários por meio da camada semântica.  Embora os mecanismos existentes de ETL e ingestão de dados baseados em Spark tenham permanecido, o Dremio forneceu uma camada de acesso unificada para facilitar a descoberta e a exploração de dados sem duplicação.  Essa abordagem reduziu significativamente os fatores de replicação de dados e desvinculou o armazenamento e a computação.</block>
  <block id="ef3e4aef01dbcfe8475e127bc34ac240" category="paragraph">*Benefícios*: Com o Dremio, a NetApp obteve reduções de custos significativas ao minimizar o consumo de computação e os requisitos de espaço em disco em seus ambientes de dados.  O novo Active IQ Data Lake é composto por 8.900 tabelas que armazenam 3 petabytes de dados, em comparação com a infraestrutura anterior, com mais de 7 petabytes.  A migração para o Dremio também envolveu a transição de 33 miniclusters e 4.000 núcleos para 16 nós executores em clusters do Kubernetes.  Mesmo com reduções significativas nos recursos de computação, a NetApp experimentou melhorias notáveis de desempenho.  Ao acessar os dados diretamente pelo Dremio, o tempo de execução da consulta diminuiu de 45 minutos para 2 minutos, resultando em um tempo 95% mais rápido para obter insights para manutenção preditiva e otimização.  A migração também resultou em uma redução de mais de 60% nos custos de computação, consultas mais de 20 vezes mais rápidas e uma economia de mais de 30% no custo total de propriedade (TCO).</block>
  <block id="a0c64f41c7126c9e86274e0e58d4bc01" category="section-title">Caso de uso do cliente de vendas de peças automotivas.</block>
  <block id="866dec6bda5d640e2bb5d1c8de8d6f67" category="paragraph">*Desafios*: Nesta empresa global de vendas de peças automotivas, os grupos executivos e corporativos de planejamento financeiro e análise não conseguiram obter uma visão consolidada dos relatórios de vendas e foram forçados a ler os relatórios de métricas de vendas de cada linha de negócios e tentar consolidá-los.  Isso fez com que os clientes tomassem decisões com dados que tinham pelo menos um dia.  O tempo de espera para obter novos insights analíticos normalmente levaria mais de quatro semanas.  A solução de problemas em pipelines de dados exigiria ainda mais tempo, acrescentando três dias ou mais ao cronograma já longo.  O lento processo de desenvolvimento de relatórios, bem como o desempenho dos relatórios, forçava a comunidade de analistas a esperar continuamente que os dados fossem processados ou carregados, em vez de permitir que eles encontrassem novos insights de negócios e impulsionassem novos comportamentos empresariais.  Esses ambientes problemáticos eram compostos por vários bancos de dados diferentes para diferentes linhas de negócios, resultando em vários silos de dados.  O ambiente lento e fragmentado complicou a governança de dados, pois havia muitas maneiras de os analistas chegarem à sua própria versão da verdade em vez de uma única fonte de verdade.  A abordagem custou mais de US$ 1,9 milhão em custos com plataforma de dados e pessoas.  Manter a plataforma legada e atender às solicitações de dados exigia sete engenheiros técnicos de campo (FTEs) por ano.  Com o aumento das solicitações de dados, a equipe de inteligência de dados não conseguiu dimensionar o ambiente legado para atender às necessidades futuras</block>
  <block id="9de1ea6ce232738b38a6f50397411de0" category="paragraph">*Solução*: Armazene e gerencie de forma econômica grandes tabelas Iceberg no NetApp Object Store.  Crie domínios de dados usando a camada semântica do Dremio, permitindo que usuários empresariais criem, pesquisem e compartilhem produtos de dados facilmente.</block>
  <block id="859dc66fff375d140e35011f5d94d363" category="paragraph">*Benefícios para o cliente*: • Arquitetura de dados existente melhorada e otimizada e tempo reduzido para insights de quatro semanas para apenas algumas horas • Tempo de solução de problemas reduzido de três dias para apenas algumas horas • Custos de plataforma e gerenciamento de dados reduzidos em mais de US$ 380.000 • (2) FTEs de esforço de inteligência de dados economizados por ano</block>
  <block id="4bf80525d5b2bad7362ea2ddc1239135" category="summary">Realizamos o teste tpc-ds com cinco nós para cargas de trabalho SQL com o armazenamento de objetos NetApp , como no ONTAP e no storagegrid.</block>
  <block id="07c6b8ec7b7d3f9f4e97f8cab49e9952" category="doc">Visão geral da verificação da solução</block>
  <block id="d234b1c706880318f115c69f47d6dfa1" category="paragraph">Nesta seção, executamos consultas de teste SQL de várias fontes para verificar a funcionalidade, testar e verificar o transbordamento para o armazenamento NetApp .</block>
  <block id="399acee44d644dcec9afa1fb807677db" category="section-title">Consulta SQL no armazenamento de objetos</block>
  <block id="fdbf3a00f4ffd80f1b71f818ac8c17b1" category="list-text">Defina a memória para 250 GB por servidor em dremio.env</block>
  <block id="f01e72d5763f7ff9b6212ae55fe5a618" category="list-text">Verifique o local do spillover (${DREMIO_HOME}"/dremiocache) no arquivo dremio.conf e os detalhes de armazenamento.</block>
  <block id="c1fd3f5160a9be68b59f1459ab2d43ab" category="list-text">Aponte o local de vazamento do Dremio para o armazenamento NetApp NFS</block>
  <block id="876f04ac63af2ea2d5f8fa3785b310ca" category="list-text">Selecione o contexto.  Em nosso teste, executamos o teste em arquivos parquet gerados pelo TPCDS residentes no ONTAP S3.  Painel Dremio -&gt; SQL runner -&gt; contexto -&gt; NetAppONTAPS3-&gt;Parquet1TB</block>
  <block id="005d28008e05dae0767805243a8fb4e4" category="inline-image-macro">defina o contexto para a pasta parquet do ontaps3</block>
  <block id="1737725edbb24ea279e1a45444de8083" category="paragraph"><block ref="1737725edbb24ea279e1a45444de8083" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d627092b3c15550dd7a319a2762deb9" category="list-text">Execute a consulta TPC-DS67 no painel do Dremio</block>
  <block id="d73e35125ec82123636d65f59cd30912" category="inline-image-macro">Execute a consulta 67, que é uma das 99 consultas no TPC-DS</block>
  <block id="af576e90e15d8a6ff15105e65b4de6ca" category="paragraph"><block ref="af576e90e15d8a6ff15105e65b4de6ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2f6a29c6a6cbd53a7eb78e09592b591" category="list-text">Verifique se o trabalho está sendo executado em todos os executores.  Painel do Dremio -&gt; jobs -&gt; &lt;jobid&gt; -&gt; perfil bruto -&gt; selecione EXTERNAL_SORT -&gt; Nome do host</block>
  <block id="cc8a9d0051ce4ea66245ee1201332dba" category="inline-image-macro">lista de nós na consulta Q67</block>
  <block id="de7e26680d69dfee92356b33d4b9e852" category="paragraph"><block ref="de7e26680d69dfee92356b33d4b9e852" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d8ae43960f655adfac548cc72fd74e60" category="list-text">Quando a consulta SQL estiver em execução, você poderá verificar a pasta dividida para armazenamento em cache de dados no controlador de armazenamento NetApp .</block>
  <block id="a6b711eedf77bebde70bdfc6f869c41f" category="inline-image-macro">transbordar detalhes quando a consulta 67 for concluída</block>
  <block id="9e9d6f8f3555c800bdfb98b69c82c2df" category="list-text">A consulta SQL foi concluída com transbordamento<block ref="d1b3ed2b7bf78249ccd584f190063118" category="inline-image-macro-rx" type="image"></block></block>
  <block id="29f8ef4d2e7065fbaf7af29841718352" category="inline-image-macro">Resumo do trabalho da consulta concluída 67</block>
  <block id="af756b25baef2ba53e554daaf6f7d4b3" category="list-text">Resumo da conclusão do trabalho.<block ref="91ffddffe841fcfba2fc7aad3683dff3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0de80fdbcc7438b84f536fcf74c03921" category="inline-image-macro">detalhes dos dados distribuídos do resultado da consulta</block>
  <block id="eacfb80ed9b3da589a06f11817a18a8e" category="list-text">Verifique o tamanho dos dados vazados<block ref="c25c4cfe2a16a40eeaf1652c7ba5d9f4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f8d7f6ab5b07156f7006507270c9869" category="paragraph">O mesmo procedimento se aplica ao armazenamento de objetos NAS e StorageGRID .</block>
  <block id="a64b3943d4911d301243b8ac8779ba53" category="summary">Esta seção fornece um resumo dos casos de uso e soluções fornecidas pela NetApp para atender a vários requisitos de proteção de dados do Hadoop.</block>
  <block id="ac81718eacd21c51db78a7185a5c0a96" category="paragraph">Esta seção fornece um resumo dos casos de uso e soluções fornecidas pela NetApp para atender a vários requisitos de proteção de dados do Hadoop.  Ao usar a malha de dados fornecida pela NetApp, os clientes podem:</block>
  <block id="095ece35729c37846889cf00d16bb141" category="list-text">Tenha a flexibilidade de escolher as soluções certas de proteção de dados aproveitando os recursos avançados de gerenciamento de dados da NetApp e a integração com fluxos de trabalho nativos do Hadoop.</block>
  <block id="925b1719b2db8532854b1de76f928f31" category="list-text">Reduza o tempo de janela de backup do cluster Hadoop em quase 70%.</block>
  <block id="7de96884f777b768ef12e40582f4d816" category="list-text">Elimine qualquer efeito de desempenho resultante de backups de cluster do Hadoop.</block>
  <block id="d5235d7ce8947322a12272f0c6dc7e24" category="list-text">Forneça proteção de dados multicloud e acesso a dados de diferentes provedores de nuvem simultaneamente para uma única fonte de dados analíticos.</block>
  <block id="61e7eb3536cca4c51ae700159e1d247a" category="list-text">Crie cópias de cluster Hadoop rápidas e com economia de espaço usando a tecnologia FlexClone .</block>
  <block id="64bb4a6337ad7b2efa8dc5d43d492edf" category="paragraph">Para saber mais sobre as informações descritas neste documento, consulte os seguintes documentos e/ou sites:</block>
  <block id="253914d41704f0f326f6595e14005170" category="list-text">Soluções de análise de Big Data da NetApp</block>
  <block id="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link"><block ref="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link-rx"></block></block>
  <block id="f87d78d98a2357057eba948402e285f0" category="paragraph"><block ref="f87d78d98a2357057eba948402e285f0" category="inline-link-rx"></block></block>
  <block id="b2eb92b872fe536c4a859e695eaf280d" category="list-text">Carga de trabalho do Apache Spark com armazenamento NetApp</block>
  <block id="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link"><block ref="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link-rx"></block></block>
  <block id="3db0ab5f6c6b92b8d32d80cb1a83e214" category="paragraph"><block ref="3db0ab5f6c6b92b8d32d80cb1a83e214" category="inline-link-rx"></block></block>
  <block id="1bff250c7118efa9007019415bb2730d" category="list-text">Soluções de armazenamento NetApp para Apache Spark</block>
  <block id="83d445161ea1f91a19d552f783018ea5" category="inline-link"><block ref="83d445161ea1f91a19d552f783018ea5" category="inline-link-rx"></block></block>
  <block id="142c737f7563ed12b8b08b6fc8779b8c" category="paragraph"><block ref="142c737f7563ed12b8b08b6fc8779b8c" category="inline-link-rx"></block></block>
  <block id="df245018c012fa9deefc0e1d65196e46" category="list-text">Apache Hadoop em malha de dados habilitada pela NetApp</block>
  <block id="143ece864a38e1c8267bd8318d458955" category="inline-link"><block ref="143ece864a38e1c8267bd8318d458955" category="inline-link-rx"></block></block>
  <block id="b890b67174812331efb42656a186fa42" category="paragraph"><block ref="b890b67174812331efb42656a186fa42" category="inline-link-rx"></block></block>
  <block id="0407c27180c9b019e644e8ad4c6a9324" category="section-title">Agradecimentos</block>
  <block id="c4f052e8512b2541f8154dd256a529d6" category="list-text">Paul Burland, Representante de Vendas, Vendas Distritais de Victoria da ANZ, NetApp</block>
  <block id="5d14432aa90b3b3ebfa87b98a1844edb" category="list-text">Hoseb Dermanilian, Gerente de Desenvolvimento de Negócios, NetApp</block>
  <block id="929bdc02c2d9943ae8cb52786476e6c6" category="list-text">Lee Dorrier, Diretor MPSG, NetApp</block>
  <block id="a3ed56594a87e322fbcf5a6e705a4134" category="list-text">David Thiessen, Engenheiro de Sistemas, ANZ Victoria District SE, NetApp</block>
  <block id="f6a738f75f76f62a241636eca02cd87d" category="section-title">Histórico de versões</block>
  <block id="44749712dbec183e983dcd78a7736c41" category="cell">Data</block>
  <block id="8002bc13927c65b5f265b031079ce1d4" category="cell">Histórico de versões do documento</block>
  <block id="3798985ee5e15c84c4263815d5a4d0b7" category="cell">Versão 1.0</block>
  <block id="effdc6a5d743a9db1cd347a2ac8d6b80" category="cell">Janeiro de 2018</block>
  <block id="dfd02aef9802f4824ead7c08b8f81f1f" category="cell">Lançamento inicial</block>
  <block id="304f30474edd152dc34aef7dbb123607" category="cell">Versão 2.0</block>
  <block id="a5f3f63c2f6e1d6d4605650633b9ce8a" category="cell">Outubro de 2021</block>
  <block id="81d2cd2b484f8c425c2146303b9f1c55" category="cell">Atualizado com o caso de uso nº 5: Acelerar a carga de trabalho analítica</block>
  <block id="46b9839969e4bc429da9cc245c756450" category="cell">Versão 3.0</block>
  <block id="fb784db76f57bc935639ba5340089d77" category="cell">Novembro de 2023</block>
  <block id="11ec45d75a4ad726423d44fadee3074a" category="cell">Detalhes do NIPAM removidos</block>
  <block id="5e524f38cae9a99f3ebbaf012df2894e" category="summary">A estrutura de dados fornecida pela NetApp simplifica e integra o gerenciamento de dados em ambientes de nuvem e locais para acelerar a transformação digital.  A estrutura de dados fornecida pela NetApp fornece serviços e aplicativos de gerenciamento de dados consistentes e integrados (blocos de construção) para visibilidade e insights de dados, acesso e controle de dados, além de proteção e segurança de dados.</block>
  <block id="3c2db15f0fee10b08496ec1701f104d8" category="doc">Estrutura de dados com tecnologia NetApp para arquitetura de big data</block>
  <block id="981d357acc471e35d8d150f861ff1828" category="paragraph">A estrutura de dados fornecida pela NetApp simplifica e integra o gerenciamento de dados em ambientes de nuvem e locais para acelerar a transformação digital.</block>
  <block id="d5a64464c1e1f9d8be4cafc8b2325fa6" category="paragraph">A estrutura de dados alimentada pela NetApp fornece serviços e aplicativos de gerenciamento de dados consistentes e integrados (blocos de construção) para visibilidade e insights de dados, acesso e controle de dados, além de proteção e segurança de dados, conforme mostrado na figura abaixo.</block>
  <block id="42e5faac50fa6c299b9293560a7e7052" category="paragraph"><block ref="42e5faac50fa6c299b9293560a7e7052" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5083bdadc0fe82e6398670e5dcc6bff9" category="section-title">Casos de uso comprovados de clientes de tecido de dados</block>
  <block id="3c1223e53bc7b972a018d3e2597e0bfd" category="paragraph">A estrutura de dados fornecida pela NetApp fornece os nove casos de uso comprovados a seguir para os clientes:</block>
  <block id="a6800f5cacde75e6f1cfb931a6f2dba6" category="list-text">Acelere as cargas de trabalho de análise</block>
  <block id="5b0fa9517345824f19ceddd9d0cd39de" category="list-text">Acelere a transformação do DevOps</block>
  <block id="90ed50a34505fc6883bd65c36ed8b810" category="list-text">Crie uma infraestrutura de hospedagem em nuvem</block>
  <block id="f3933541659deec9d28aa584238f0468" category="list-text">Integrar serviços de dados em nuvem</block>
  <block id="d70909396aef5247a5a1b17dd15cf43d" category="list-text">Proteja e garanta a segurança dos dados</block>
  <block id="7af5a6e7f241b8d284656f20880db36f" category="list-text">Otimizar dados não estruturados</block>
  <block id="2c63452d476328fa43a39c00bef366f1" category="list-text">Obtenha eficiência no data center</block>
  <block id="0f72ba4c2b371e4f9f47e7d8c61468a5" category="list-text">Forneça insights e controle de dados</block>
  <block id="0da79db0a9974fc0002f744165467752" category="list-text">Simplifique e automatize</block>
  <block id="5d5b69e7e19270db49a42eb4e96be2ee" category="paragraph">Este documento abrange dois dos nove casos de uso (junto com suas soluções):</block>
  <block id="7adb8b5c573e74594feeb2f74e1ffc96" category="section-title">Acesso direto ao NetApp NFS</block>
  <block id="c2915c2b980396a00c86766bff7195e3" category="paragraph">O NetApp NFS permite que os clientes executem trabalhos de análise de big data em seus dados NFSv3 ou NFSv4 existentes ou novos sem mover ou copiar os dados.  Ele evita múltiplas cópias de dados e elimina a necessidade de sincronizar os dados com uma fonte.  Por exemplo, no setor financeiro, a movimentação de dados de um lugar para outro deve atender a obrigações legais, o que não é uma tarefa fácil.  Neste cenário, o acesso direto do NetApp NFS analisa os dados financeiros de seu local original.  Outro benefício importante é que o uso do acesso direto do NetApp NFS simplifica a proteção de dados do Hadoop usando comandos nativos do Hadoop e permite fluxos de trabalho de proteção de dados aproveitando o rico portfólio de gerenciamento de dados da NetApp.</block>
  <block id="1e72dcaa767fcc4be580ce5e9e1b52ea" category="paragraph"><block ref="1e72dcaa767fcc4be580ce5e9e1b52ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa47c768dc0f007b4606d394be4330c3" category="paragraph">O acesso direto do NetApp NFS fornece dois tipos de opções de implantação para clusters Hadoop/Spark:</block>
  <block id="cc7514a5b2b35641026a81211ae7fe9a" category="list-text">Por padrão, os clusters Hadoop/Spark usam o Hadoop Distributed File System (HDFS) para armazenamento de dados e o sistema de arquivos padrão.  O acesso direto do NetApp NFS pode substituir o HDFS padrão pelo armazenamento NFS como o sistema de arquivos padrão, permitindo operações de análise direta em dados NFS.</block>
  <block id="5a5dace50e75999dec9323da42fe5410" category="list-text">Em outra opção de implantação, o acesso direto do NetApp NFS oferece suporte à configuração do NFS como armazenamento adicional junto com o HDFS em um único cluster Hadoop/Spark.  Nesse caso, o cliente pode compartilhar dados por meio de exportações NFS e acessá-los do mesmo cluster junto com os dados HDFS.</block>
  <block id="933871f01596456078e75585ab9480ae" category="paragraph">Os principais benefícios de usar o acesso direto do NetApp NFS incluem:</block>
  <block id="bc3221e251e23e5ee9782e37b0337c38" category="list-text">Analisa os dados de seu local atual, o que evita a tarefa demorada e de alto desempenho de mover dados analíticos para uma infraestrutura Hadoop, como o HDFS.</block>
  <block id="fe5efea0cd6733d158bfb04016f055f0" category="list-text">Reduz o número de réplicas de três para uma.</block>
  <block id="21b00f92397ca3c72f6407dd3a873e23" category="list-text">Permite que os usuários dissociem a computação e o armazenamento para dimensioná-los de forma independente.</block>
  <block id="be7e2eb6e940a1e798db3abedc75b7a8" category="list-text">Fornece proteção de dados empresariais aproveitando os recursos avançados de gerenciamento de dados do ONTAP.</block>
  <block id="acc50ec5f7ffe1b08ee357afcb502a0f" category="list-text">É certificado com a plataforma de dados Hortonworks.</block>
  <block id="be5acbdc2ea462a8345ea92d4c42511c" category="list-text">Permite implantações de análise de dados híbrida.</block>
  <block id="227afbdb4ab9214131d6ca5ca3df3cd6" category="list-text">Reduz o tempo de backup aproveitando a capacidade multithread dinâmica.</block>
  <block id="787364630dc10cfc2657bc82f289a9fb" category="section-title">Blocos de construção para big data</block>
  <block id="7698deb733ad601844c58f0102d0470c" category="paragraph">A estrutura de dados alimentada pela NetApp integra serviços e aplicativos de gerenciamento de dados (blocos de construção) para acesso, controle, proteção e segurança de dados, conforme mostrado na figura abaixo.</block>
  <block id="daa25861e76d8b4617b478f8cd89c0b2" category="paragraph"><block ref="daa25861e76d8b4617b478f8cd89c0b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="162f2b2249f4b8bda40b0c01043779b3" category="paragraph">Os blocos de construção na figura acima incluem:</block>
  <block id="e64f250539a531b81423d6f3f4729665" category="list-text">* Acesso direto ao NetApp NFS.*  Fornece os clusters Hadoop e Spark mais recentes com acesso direto aos volumes NetApp NFS sem requisitos adicionais de software ou driver.</block>
  <block id="f79865a14977797753199d8c238eade6" category="list-text">* NetApp Cloud Volumes ONTAP e Google Cloud NetApp Volumes.*  Armazenamento conectado definido por software baseado em ONTAP em execução no Amazon Web Services (AWS) ou no Azure NetApp Files (ANF) nos serviços de nuvem do Microsoft Azure.</block>
  <block id="5d382bdcedb0a9c7aa214b09e129e5e7" category="list-text">* Tecnologia NetApp SnapMirror *.  Fornece recursos de proteção de dados entre instâncias locais e ONTAP Cloud ou NPS.</block>
  <block id="e2d911047fad9851fae1d7c4e71b2fab" category="list-text">*Provedores de serviços em nuvem.*  Esses provedores incluem AWS, Microsoft Azure, Google Cloud e IBM Cloud.</block>
  <block id="486add91df5cb94a1fee5fccffe4f39b" category="list-text">*PaaS.*  Serviços de análise baseados em nuvem, como Amazon Elastic MapReduce (EMR) e Databricks na AWS, bem como Microsoft Azure HDInsight e Azure Databricks.</block>
  <block id="df343d31543826a7505d157cf243c96a" category="summary">O Hadoop DistCp é uma ferramenta nativa usada para cópias intercluster e intracluster de grandes dimensões.  O processo básico do Hadoop DistCp é um fluxo de trabalho de backup típico que usa ferramentas nativas do Hadoop, como o MapReduce, para copiar dados do Hadoop de uma origem HDFS para um destino correspondente.</block>
  <block id="2a377dc939cca8cab65101c1869d628d" category="doc">Proteção de dados Hadoop e NetApp</block>
  <block id="1d766990d66db8e06b462398928288cd" category="paragraph">O Hadoop DistCp é uma ferramenta nativa usada para cópias intercluster e intracluster de grandes dimensões.  O processo básico do Hadoop DistCp mostrado na figura abaixo é um fluxo de trabalho de backup típico usando ferramentas nativas do Hadoop, como o MapReduce, para copiar dados do Hadoop de uma origem HDFS para um destino correspondente.</block>
  <block id="7cded69de10ed23fb288e8f481913718" category="paragraph">O acesso direto do NetApp NFS permite que os clientes definam o NFS como o destino para a ferramenta Hadoop DistCp copiar os dados da origem HDFS para um compartilhamento NFS por meio do MapReduce.  O acesso direto do NetApp NFS atua como um driver NFS para a ferramenta DistCp.</block>
  <block id="3225c81e14f83a90295391be9d81302a" category="paragraph"><block ref="3225c81e14f83a90295391be9d81302a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cedd54d52b90b58fb9615e956db81629" category="summary">Este documento descreve soluções de dados em nuvem híbrida usando sistemas de armazenamento NetApp AFF e FAS , NetApp Cloud Volumes ONTAP, armazenamento conectado NetApp e tecnologia NetApp FlexClone para Spark e Hadoop.  Essas arquiteturas de solução permitem que os clientes escolham uma solução de proteção de dados apropriada para seu ambiente.  A NetApp projetou essas soluções com base na interação com os clientes e seus casos de uso comercial.</block>
  <block id="71932d00608c3a9fe13a866ab35227f6" category="paragraph">Karthikeyan Nagalingam e Sathish Thyagarajan, NetApp</block>
  <block id="8b6b60ca3f35331d22d686d9c4e12871" category="paragraph">Este documento descreve soluções de dados em nuvem híbrida usando sistemas de armazenamento NetApp AFF e FAS , NetApp Cloud Volumes ONTAP, armazenamento conectado NetApp e tecnologia NetApp FlexClone para Spark e Hadoop.  Essas arquiteturas de solução permitem que os clientes escolham uma solução de proteção de dados apropriada para seu ambiente.  A NetApp projetou essas soluções com base na interação com os clientes e seus casos de uso comercial.  Este documento fornece as seguintes informações detalhadas:</block>
  <block id="d928ac205302ed3d60386e2a4759c6d6" category="list-text">Por que precisamos de proteção de dados para ambientes Spark e Hadoop e os desafios dos clientes.</block>
  <block id="4444991e618ed955b12fdbcf746ad762" category="list-text">A estrutura de dados alimentada pela visão da NetApp e seus blocos de construção e serviços.</block>
  <block id="018b3e5bb8ca92450618b4f5ff9719f7" category="list-text">Como esses blocos de construção podem ser usados para arquitetar fluxos de trabalho flexíveis de proteção de dados.</block>
  <block id="30b68051de2b69f7d6ab186bed865f7c" category="list-text">Os prós e contras de diversas arquiteturas baseadas em casos de uso de clientes do mundo real.  Cada caso de uso fornece os seguintes componentes:</block>
  <block id="acf055fa7efae33ce06471f448ae1267" category="list-text">Cenários de clientes</block>
  <block id="5f5e12d29ffccf33e8cb5a30f4d2fe8c" category="list-text">Requisitos e desafios</block>
  <block id="2a9dbfa4b74c53d7304fc8b79a1874d3" category="list-text">Soluções</block>
  <block id="cb9825c3c7619f7000c8452d9005aa5b" category="list-text">Resumo das soluções</block>
  <block id="40300466f60ef41f731d7fd45a1024e2" category="section-title">Por que a proteção de dados do Hadoop?</block>
  <block id="d54234515a0cb2905eb88ccb03d85491" category="paragraph">Em um ambiente Hadoop e Spark, as seguintes preocupações devem ser abordadas:</block>
  <block id="9ed257b8e8a9504946fcf430ea2e12e3" category="list-text">*Falhas de software ou humanas.*  Erros humanos em atualizações de software durante a execução de operações de dados do Hadoop podem levar a comportamentos defeituosos que podem causar resultados inesperados no trabalho.  Nesse caso, precisamos proteger os dados para evitar falhas ou resultados irracionais.  Por exemplo, como resultado de uma atualização de software mal executada em um aplicativo de análise de sinais de trânsito, um novo recurso que não analisa corretamente os dados de sinais de trânsito no formato de texto simples.  O software ainda analisa JSON e outros formatos de arquivo não textuais, resultando no sistema de análise de controle de tráfego em tempo real produzindo resultados de previsão sem pontos de dados.  Essa situação pode causar saídas defeituosas que podem levar a acidentes nos semáforos.  A proteção de dados pode resolver esse problema fornecendo a capacidade de retornar rapidamente à versão anterior do aplicativo funcional.</block>
  <block id="38b145294d087c4d733df994e6a7b6c1" category="list-text">*Tamanho e escala.*  O tamanho dos dados analíticos cresce dia a dia devido ao número cada vez maior de fontes e volumes de dados.  Mídias sociais, aplicativos móveis, análise de dados e plataformas de computação em nuvem são as principais fontes de dados no atual mercado de big data, que está crescendo muito rapidamente e, portanto, os dados precisam ser protegidos para garantir operações de dados precisas.</block>
  <block id="612be5fe1026c2566014b79f77403701" category="list-text">*Proteção de dados nativa do Hadoop.*  O Hadoop tem um comando nativo para proteger os dados, mas esse comando não fornece consistência de dados durante o backup.  Ele suporta apenas backup em nível de diretório.  Os snapshots criados pelo Hadoop são somente leitura e não podem ser usados para reutilizar os dados de backup diretamente.</block>
  <block id="e664ca405ed3e90fecf2e085985fe24c" category="section-title">Desafios de proteção de dados para clientes do Hadoop e Spark</block>
  <block id="c2d49a2ee903d6d86976c3618079a61d" category="paragraph">Um desafio comum para clientes do Hadoop e do Spark é reduzir o tempo de backup e aumentar a confiabilidade do backup sem afetar negativamente o desempenho no cluster de produção durante a proteção de dados.</block>
  <block id="8d54bea5cb89e665d1a703529f703765" category="paragraph">Os clientes também precisam minimizar o tempo de inatividade do objetivo de ponto de recuperação (RPO) e do objetivo de tempo de recuperação (RTO) e controlar seus sites de recuperação de desastres locais e baseados na nuvem para uma continuidade ideal dos negócios.  Esse controle normalmente vem de ferramentas de gerenciamento de nível empresarial.</block>
  <block id="042be4d2813fd31d6b49e6eeaa1a42c3" category="paragraph">Os ambientes Hadoop e Spark são complicados não só porque o volume de dados é enorme e crescente, mas também porque a taxa em que esses dados chegam está aumentando.  Esse cenário dificulta a criação rápida de ambientes de DevTest e QA eficientes e atualizados a partir dos dados de origem.  A NetApp reconhece esses desafios e oferece as soluções apresentadas neste artigo.</block>
  <block id="7d617748001976c06ae87f824ca77b2d" category="summary">Nesse cenário, a plataforma de análise de um grande banco de serviços financeiros e investimentos foi modernizada usando a solução de armazenamento NetApp NFS para obter uma melhoria significativa na análise de riscos de investimento e derivativos para sua unidade de negócios quantitativa e de gestão de ativos.</block>
  <block id="0158648474e8dffab94ca58af2257b92" category="doc">Caso de uso 5: Acelerar cargas de trabalho analíticas</block>
  <block id="54861efdd06fc309e1c9a420feff98eb" category="section-title">Cenário</block>
  <block id="f3274c43bc916b05ebe766167f47a1ad" category="paragraph">No ambiente existente do cliente, a infraestrutura do Hadoop usada para a plataforma de análise aproveitava o armazenamento interno dos servidores do Hadoop.  Devido à natureza proprietária do ambiente JBOD, muitos clientes internos da organização não conseguiram aproveitar seu modelo quantitativo de Monte Carlo, uma simulação que se baseia em amostras recorrentes de dados em tempo real.  A capacidade abaixo do ideal de entender os efeitos da incerteza nos movimentos do mercado estava prejudicando a unidade de negócios de gestão quantitativa de ativos.</block>
  <block id="788ab145281501314f18747a0ab1eaea" category="paragraph">A unidade de negócios quantitativa do banco queria um método de previsão eficiente para obter previsões precisas e oportunas.  Para isso, a equipe reconheceu a necessidade de modernizar a infraestrutura, reduzir o tempo de espera de E/S existente e melhorar o desempenho em aplicativos analíticos, como Hadoop e Spark, para simular com eficiência modelos de investimento, medir ganhos potenciais e analisar riscos.</block>
  <block id="49b21ad0d38942f635877e7bbc5d7a1e" category="section-title">Solução</block>
  <block id="43b3ece7a28edcf11ee066112179b834" category="paragraph">O cliente tinha JBOD para sua solução Spark existente.  O NetApp ONTAP, o NetApp StorageGRID e o MinIO Gateway para NFS foram então aproveitados para reduzir o tempo de espera de E/S para o grupo financeiro quantitativo do banco, que executa simulações e análises em modelos de investimento que avaliam ganhos e riscos potenciais.  Esta imagem mostra a solução Spark com armazenamento NetApp .</block>
  <block id="d9e962022f714fc5ed8bccce82c920ac" category="paragraph"><block ref="d9e962022f714fc5ed8bccce82c920ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3a052314babbb25c995c7b6b2b18d04" category="paragraph">Conforme mostrado na figura acima, os sistemas AFF A800, A700 e StorageGRID foram implantados para acessar arquivos parquet por meio dos protocolos NFS e S3 em um cluster Hadoop de seis nós com Spark e serviços de metadados YARN e Hive para operações analíticas de dados.</block>
  <block id="473d88a5512cc81d2571425bbea591d2" category="paragraph">Uma solução de armazenamento conectado diretamente (DAS) no antigo ambiente do cliente tinha a desvantagem de dimensionar a computação e o armazenamento de forma independente.  Com a solução NetApp ONTAP para Spark, a unidade de negócios de análise financeira do banco conseguiu desvincular o armazenamento da computação e disponibilizar recursos de infraestrutura de forma mais eficaz, conforme necessário.</block>
  <block id="fceb3129a02a41b3231baa9b6f633217" category="paragraph">Ao usar o ONTAP com NFS, as CPUs do servidor de computação foram quase totalmente utilizadas para trabalhos do Spark SQL e o tempo de espera de E/S foi reduzido em quase 70%, proporcionando, portanto, melhor poder de computação e aumento de desempenho para cargas de trabalho do Spark.  Posteriormente, o aumento da utilização da CPU também permitiu que o cliente aproveitasse GPUs, como GPUDirect, para maior modernização da plataforma.  Além disso, o StorageGRID oferece uma opção de armazenamento de baixo custo para cargas de trabalho do Spark e o MinIO Gateway fornece acesso seguro aos dados NFS por meio do protocolo S3.  Para dados na nuvem, a NetApp recomenda o Cloud Volumes ONTAP, o Azure NetApp Files e o Google Cloud NetApp Volumes.</block>
  <block id="9d9b3c1914053d9ff102d01b77ab40a9" category="summary">Este caso de uso se baseia em um cliente de transmissão que precisa fazer backup de dados analíticos baseados em nuvem em seu data center local.</block>
  <block id="0abf694ae9fa8ac43b805ba39a10d143" category="doc">Caso de uso 2: backup e recuperação de desastres da nuvem para o local</block>
  <block id="733d8d14fe9ffb98d02b33079e3d3db2" category="paragraph">Este caso de uso se baseia em um cliente de transmissão que precisa fazer backup de dados analíticos baseados em nuvem em seu data center local, conforme ilustrado na figura abaixo.</block>
  <block id="56f5fb8db5f5326b20e3fe17ce11efa4" category="paragraph"><block ref="56f5fb8db5f5326b20e3fe17ce11efa4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26fea23389e404e4cb8cf9be2c100cbd" category="paragraph">Neste cenário, os dados do sensor de IoT são inseridos na nuvem e analisados usando um cluster Apache Spark de código aberto na AWS.  O requisito é fazer backup dos dados processados da nuvem para o local.</block>
  <block id="c04f16bb8233216a472d30b6c509b230" category="paragraph">Os principais requisitos e desafios para este caso de uso incluem:</block>
  <block id="bb446485afc21a80bc5f26a9131de160" category="list-text">Habilitar a proteção de dados não deve causar nenhum efeito de desempenho no cluster de produção Spark/Hadoop na nuvem.</block>
  <block id="dbb6231aec34eed7c53cff2d4a2d43ef" category="list-text">Os dados do sensor de nuvem precisam ser movidos e protegidos para o local de forma eficiente e segura.</block>
  <block id="848b66ad8aca524142404de79ce64c73" category="list-text">Flexibilidade para transferir dados da nuvem para o local sob diferentes condições, como sob demanda, instantaneamente e durante tempos de baixa carga do cluster.</block>
  <block id="4d8011e28e4ef4359ca7c169e7797091" category="paragraph">O cliente usa o AWS Elastic Block Store (EBS) para seu armazenamento HDFS do cluster Spark para receber e ingerir dados de sensores remotos por meio do Kafka.  Consequentemente, o armazenamento HDFS atua como a fonte dos dados de backup.</block>
  <block id="e55d60f6f17896ce9b53a0ef23e23413" category="paragraph">Para atender a esses requisitos, o NetApp ONTAP Cloud é implantado na AWS, e um compartilhamento NFS é criado para atuar como destino de backup para o cluster Spark/Hadoop.</block>
  <block id="3c0f76e2d6fa82b2004270ec86f39aa7" category="paragraph">Após a criação do compartilhamento NFS, copie os dados do armazenamento EBS do HDFS para o compartilhamento NFS do ONTAP .  Depois que os dados residem no NFS no ONTAP Cloud, a tecnologia SnapMirror pode ser usada para espelhar os dados da nuvem para o armazenamento local, conforme necessário, de forma segura e eficiente.</block>
  <block id="aecad7c5bdfba92aa6cd945a9045c37f" category="paragraph">Esta imagem mostra o backup e a recuperação de desastres da nuvem para a solução local.</block>
  <block id="6d742f93cf04e332b07c93ce2bc96163" category="paragraph"><block ref="6d742f93cf04e332b07c93ce2bc96163" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dca3067f5c6c2fa6b32ef683fcab56f" category="summary">Neste cenário, o cliente tem um grande repositório Hadoop local e deseja fazer backup dele para fins de recuperação de desastres.  No entanto, a solução de backup atual do cliente é cara e sofre com uma longa janela de backup de mais de 24 horas.</block>
  <block id="817ac2975197bd6c376a7918a798981f" category="doc">Caso de uso 1: Fazendo backup de dados do Hadoop</block>
  <block id="7ffe71c29f8ea391bbd80c1e8441af9a" category="list-text">Compatibilidade com versões anteriores do software:</block>
  <block id="d96828d85e8cc053407a391bee52257f" category="list-text">A solução de backup alternativa proposta deve ser compatível com as versões atuais do software em execução usadas no cluster Hadoop de produção.</block>
  <block id="dd5bb530e532c011487ffc3a69e56f57" category="list-text">Para cumprir os SLAs comprometidos, a solução alternativa proposta deve atingir RPOs e RTOs muito baixos.</block>
  <block id="4783ab1f0401dc9c24cc9afa6dc5823e" category="list-text">O backup criado pela solução de backup da NetApp pode ser usado no cluster Hadoop criado localmente no data center, bem como no cluster Hadoop em execução no local de recuperação de desastres no site remoto.</block>
  <block id="1dbc869d2df036d4d6e732e9c680ab6b" category="list-text">A solução proposta deve ser econômica.</block>
  <block id="7405e6ba4b630f11b88a7976325a95e4" category="list-text">A solução proposta deve reduzir o efeito no desempenho dos trabalhos analíticos em execução e em produção durante os períodos de backup.</block>
  <block id="265e759e2a3b4c55776e0de53887b3b4" category="section-title">Solução de backup existente do cliente</block>
  <block id="f350f804f84a5bf788cd78cd4aae7eab" category="paragraph">A figura abaixo mostra a solução original de backup nativa do Hadoop.</block>
  <block id="f9efb12aa8582a65d79ac1fcd7574665" category="paragraph"><block ref="f9efb12aa8582a65d79ac1fcd7574665" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b8e496c38192b97fdfa6cae2ba2bb4" category="paragraph">Os dados de produção são protegidos em fita por meio do cluster de backup intermediário:</block>
  <block id="d07ca391addc59b7408fb88541552b43" category="list-text">Os dados do HDFS1 são copiados para o HDFS2 executando o<block ref="56eafdf3e9748260b9403493314dc20d" prefix=" " category="inline-code"></block> comando.</block>
  <block id="2c4cadbb7f122d1d0cd988a11681248a" category="list-text">O cluster de backup atua como um gateway NFS e os dados são copiados manualmente para a fita por meio do Linux<block ref="9c95319bf274672d6eae7eb97c3dfda5" prefix=" " category="inline-code"></block> comando por meio da biblioteca de fitas.</block>
  <block id="b73035943c8623cbdb7bd67992201012" category="paragraph">Os benefícios da solução de backup nativa original do Hadoop incluem:</block>
  <block id="5bdb90a1352ca42ab8dde5b9ab7ffac3" category="list-text">A solução é baseada em comandos nativos do Hadoop, o que evita que o usuário tenha que aprender novos procedimentos.</block>
  <block id="f581d1b5f93adda1865bad95e215a7b9" category="list-text">A solução aproveita arquitetura e hardware padrão do setor.</block>
  <block id="ddd131647a4d5e1b5bcb983ec8872ff9" category="paragraph">As desvantagens da solução de backup nativa original do Hadoop incluem:</block>
  <block id="2cd5e9eae715f3bb0475ed032bf56190" category="list-text">O longo tempo de janela de backup excede 24 horas, o que torna os dados de produção vulneráveis.</block>
  <block id="b22d500a5624a2c57ec5bda86aa57011" category="list-text">Degradação significativa do desempenho do cluster durante os períodos de backup.</block>
  <block id="69bfe7f4231b0c1d65247d0abfc89cb3" category="list-text">Copiar para fita é um processo manual.</block>
  <block id="6ef8e4ec49425ac5ded9c6cc599c17d2" category="list-text">A solução de backup é cara em termos de hardware necessário e horas humanas necessárias para processos manuais.</block>
  <block id="1b4d2bf420e7f05ecb82ecf2197ab810" category="section-title">Soluções de backup</block>
  <block id="6d977e36854ae6439cbc4fe8e0c1b227" category="paragraph">Com base nesses desafios e requisitos, e levando em consideração o sistema de backup existente, três possíveis soluções de backup foram sugeridas.  As subseções a seguir descrevem cada uma dessas três soluções de backup diferentes, rotuladas de solução A a solução C.</block>
  <block id="c5a6c012dc14dc7f9d2fa0df0ccb0cdf" category="section-title">Solução A</block>
  <block id="bc98837ed486c01d428d23d0c3a83d6a" category="paragraph">Na Solução A, o cluster de backup do Hadoop envia os backups secundários para os sistemas de armazenamento NetApp NFS, eliminando a necessidade de fita, conforme mostrado na figura abaixo.</block>
  <block id="c7446a7fd101a1f229e62b8dfc3f2627" category="paragraph"><block ref="c7446a7fd101a1f229e62b8dfc3f2627" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2813f022c034c63ad3d6efeeb503eb70" category="paragraph">As tarefas detalhadas para a solução A incluem:</block>
  <block id="0406c5ca05cfb5f7a0c02971c3962460" category="list-text">O cluster de produção do Hadoop tem os dados analíticos do cliente no HDFS que exigem proteção.</block>
  <block id="feb7749ff700168c127dfbd8376b35f7" category="list-text">O cluster Hadoop de backup com HDFS atua como um local intermediário para os dados.  Apenas um conjunto de discos (JBOD) fornece o armazenamento para HDFS nos clusters Hadoop de produção e de backup.</block>
  <block id="b3f54540429c806b8cf0080fd78b34bc" category="list-text">Proteja os dados de produção do Hadoop do cluster de produção HDFS para o cluster de backup HDFS executando o<block ref="900bb9daf20a55f63530a23a8ff21d21" prefix=" " category="inline-code"></block> comando.</block>
  <block id="2de4833848a0b94bd672bdf9bc60d4aa" category="admonition">O snapshot do Hadoop é usado para proteger os dados da produção para o cluster de backup do Hadoop.</block>
  <block id="79ef8fc2c565c69b33f5918c3a0bdd9a" category="list-text">O controlador de armazenamento NetApp ONTAP fornece um volume exportado NFS, que é provisionado para o cluster Hadoop de backup.</block>
  <block id="1b449b0ea4a324dc81f41259db2c13e9" category="list-text">Ao executar o<block ref="e23fdb1dae75e2830274d92fdf2535ed" prefix=" " category="inline-code"></block> comando aproveitando o MapReduce e vários mapeadores, os dados analíticos são protegidos do cluster Hadoop de backup para o NFS.</block>
  <block id="738997de22c6371f563f69e1bb57b6e5" category="paragraph">Depois que os dados são armazenados no NFS no sistema de armazenamento NetApp , as tecnologias NetApp Snapshot, SnapRestore e FlexClone são usadas para fazer backup, restaurar e duplicar os dados do Hadoop, conforme necessário.</block>
  <block id="0bd252182290e872b264ad65d369637f" category="admonition">Os dados do Hadoop podem ser protegidos na nuvem, bem como em locais de recuperação de desastres, usando a tecnologia SnapMirror .</block>
  <block id="4a1b9aaeaa6487c6df7072326cf3798e" category="paragraph">Os benefícios da solução A incluem:</block>
  <block id="0843e6a882cae98851adbefb52d05827" category="list-text">Os dados de produção do Hadoop são protegidos do cluster de backup.</block>
  <block id="522d0cf303cbf1b16ea5cc33480ce02f" category="list-text">Os dados do HDFS são protegidos pelo NFS, permitindo proteção em locais de nuvem e recuperação de desastres.</block>
  <block id="298d20d1ae9110668e52c07776f62948" category="list-text">Melhora o desempenho transferindo as operações de backup para o cluster de backup.</block>
  <block id="4c10451e9e5bf987bc3ab16a9fce3966" category="list-text">Elimina operações manuais de fita</block>
  <block id="0ff20f264e79e773549ded37f50f4b3b" category="list-text">Permite funções de gerenciamento empresarial por meio de ferramentas NetApp .</block>
  <block id="4c84f95e2dad9b5385151a736e89f0c3" category="list-text">Requer mudanças mínimas no ambiente existente.</block>
  <block id="66f3b3a8c99e03a363a88a58fabe03cc" category="list-text">É uma solução econômica.</block>
  <block id="4e941dea7920913a2c3a6d2a11a0936f" category="paragraph">A desvantagem dessa solução é que ela requer um cluster de backup e mapeadores adicionais para melhorar o desempenho.</block>
  <block id="0628ac302dce6afb9d95a6b8ebd0d013" category="paragraph">O cliente implantou recentemente a solução A devido à sua simplicidade, custo e desempenho geral.</block>
  <block id="7a3ba8b554aec9832f399bff2ba17c74" category="paragraph">Nesta solução, discos SAN do ONTAP podem ser usados em vez de JBOD.  Esta opção transfere a carga de armazenamento do cluster de backup para o ONTAP; no entanto, a desvantagem é que são necessários switches de malha SAN.</block>
  <block id="501a1b4ce382e8e2da0089aded30d11e" category="section-title">Solução B</block>
  <block id="099eafc2208317136c2902383d7b0755" category="paragraph">A solução B adiciona um volume NFS ao cluster de produção do Hadoop, o que elimina a necessidade do cluster de backup do Hadoop, conforme mostrado na figura abaixo.</block>
  <block id="5b70fb212e3f22443316e06668fb7eaf" category="paragraph"><block ref="5b70fb212e3f22443316e06668fb7eaf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ca30c628556726e2038c5df9689fd91" category="paragraph">As tarefas detalhadas para a solução B incluem:</block>
  <block id="e493f6dc701d2253466d5705af2e5bb1" category="list-text">O controlador de armazenamento NetApp ONTAP provisiona a exportação NFS para o cluster de produção do Hadoop.</block>
  <block id="b8c0e409f361575b0a2787968f3e6737" category="paragraph">O nativo do Hadoop<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> O comando protege os dados do Hadoop do cluster de produção HDFS para NFS.</block>
  <block id="665cfb3949b836c368d9be47d34bcbba" category="list-text">Depois que os dados são armazenados no NFS no sistema de armazenamento NetApp , as tecnologias Snapshot, SnapRestore e FlexClone são usadas para fazer backup, restaurar e duplicar os dados do Hadoop, conforme necessário.</block>
  <block id="4f1aeb2a94e89562b7bef27c368ed9cc" category="paragraph">Os benefícios da solução B incluem:</block>
  <block id="748dc25f775dc78e1da24328f753d1e1" category="list-text">O cluster de produção é ligeiramente modificado para a solução de backup, o que simplifica a implementação e reduz o custo adicional de infraestrutura.</block>
  <block id="a565a40a6656693466a7da18be6d44ca" category="list-text">Não é necessário um cluster de backup para a operação de backup.</block>
  <block id="fa6ae9dfac02b933ef93450603114fce" category="list-text">Os dados de produção do HDFS são protegidos na conversão para dados NFS.</block>
  <block id="cf7952142a1253af6b9394a3f01408b3" category="list-text">A solução permite funções de gerenciamento empresarial por meio de ferramentas NetApp .</block>
  <block id="f4ffcfc00594c5a445a43499130eb8d3" category="paragraph">A desvantagem dessa solução é que ela é implementada no cluster de produção, o que pode adicionar tarefas adicionais de administrador no cluster de produção.</block>
  <block id="0a3b8c5fab2a32545423ade2927b1185" category="section-title">Solução C</block>
  <block id="6c176725a15c1c609d24387ddf6600da" category="paragraph">Na solução C, os volumes NetApp SAN são provisionados diretamente no cluster de produção do Hadoop para armazenamento HDFS, conforme mostrado na figura abaixo.</block>
  <block id="016077aafc394500fb21c4f233724258" category="paragraph"><block ref="016077aafc394500fb21c4f233724258" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0d09b63c2b939de22a3b5d0f4cb3c87" category="paragraph">As etapas detalhadas para a solução C incluem:</block>
  <block id="35edf0b5a2042b4561d4d499298010e6" category="list-text">O armazenamento NetApp ONTAP SAN é provisionado no cluster Hadoop de produção para armazenamento de dados HDFS.</block>
  <block id="3b694951a08990d1243da1dd36e6cd07" category="list-text">As tecnologias NetApp Snapshot e SnapMirror são usadas para fazer backup dos dados HDFS do cluster de produção do Hadoop.</block>
  <block id="c32b4eb407751e515d7d037629b66dfb" category="list-text">Não há efeito de desempenho na produção do cluster Hadoop/Spark durante o processo de backup da cópia do Snapshot porque o backup está na camada de armazenamento.</block>
  <block id="ef54974b65426daa87a86290447ed9a6" category="admonition">A tecnologia Snapshot fornece backups concluídos em segundos, independentemente do tamanho dos dados.</block>
  <block id="f499d7fd731eb2bb1efe6c4069efcb47" category="paragraph">Os benefícios da solução C incluem:</block>
  <block id="abe0be0b8deb695793caa75a1dcfc4b3" category="list-text">É possível criar backups com economia de espaço usando a tecnologia Snapshot.</block>
  <block id="2c755351ada495582a6d9015943de077" category="summary">Neste caso de uso, o requisito do cliente é criar de forma rápida e eficiente novos clusters Hadoop/Spark com base em um cluster Hadoop existente contendo uma grande quantidade de dados analíticos para fins de DevTest e relatórios no mesmo data center, bem como em locais remotos.</block>
  <block id="acb2dd720b2161405c8cb1ca6035618b" category="doc">Caso de uso 3: Habilitando o DevTest em dados Hadoop existentes</block>
  <block id="4e19c1aafa6d3711ae619f7e1621a61e" category="paragraph">Neste cenário, vários clusters Spark/Hadoop são criados a partir de uma grande implementação de data lake Hadoop no local, bem como em locais de recuperação de desastres.</block>
  <block id="5768edca640abf2b08dd5ba0e593dcc7" category="list-text">Crie vários clusters Hadoop para DevTest, QA ou qualquer outro propósito que exija acesso aos mesmos dados de produção.  O desafio aqui é clonar um cluster Hadoop muito grande várias vezes, instantaneamente e de uma maneira muito eficiente em termos de espaço.</block>
  <block id="529c78f9988d342b33707ecaae7d2576" category="list-text">Sincronize os dados do Hadoop com as equipes de DevTest e relatórios para eficiência operacional.</block>
  <block id="07178cfd87815398d5079e55c257f96c" category="list-text">Distribua os dados do Hadoop usando as mesmas credenciais nos clusters de produção e novos.</block>
  <block id="b26eaa756d7ec14dcec5c25d7d9ad6b6" category="list-text">Use políticas agendadas para criar clusters de QA com eficiência sem afetar o cluster de produção.</block>
  <block id="6442ec446d11bbd47497299e0ffceed5" category="paragraph">A tecnologia FlexClone é usada para responder aos requisitos descritos.  A tecnologia FlexClone é a cópia de leitura/gravação de uma cópia do Snapshot.  Ele lê os dados da cópia do Snapshot pai e consome apenas espaço adicional para blocos novos/modificados.  É rápido e economiza espaço.</block>
  <block id="51a22383ed7ac5a70a455d81a9bad789" category="paragraph">Primeiro, uma cópia instantânea do cluster existente foi criada usando um grupo de consistência do NetApp .</block>
  <block id="ff0e15997f709c232408a5055738df05" category="paragraph">Cópias de snapshot no NetApp System Manager ou no prompt do administrador de armazenamento.  As cópias de instantâneo do grupo de consistência são cópias de instantâneo do grupo consistentes com o aplicativo, e o volume FlexClone é criado com base nas cópias de instantâneo do grupo de consistência.  Vale a pena mencionar que um volume FlexClone herda a política de exportação NFS do volume pai.  Após a criação da cópia do Snapshot, um novo cluster Hadoop deve ser instalado para fins de DevTest e relatórios, conforme mostrado na figura abaixo.  O volume NFS clonado do novo cluster Hadoop acessa os dados NFS.</block>
  <block id="6ee7e035a9c46bb26ee76c40aa671148" category="paragraph">Esta imagem mostra o cluster Hadoop para DevTest.</block>
  <block id="abc9a1c20fcf276389f79d3093665e5c" category="paragraph"><block ref="abc9a1c20fcf276389f79d3093665e5c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa7dcae8e4f7d8ecc191c3ce8547a53a" category="summary">Este caso de uso é relevante para um parceiro de serviço de nuvem encarregado de fornecer conectividade multinuvem para dados de análise de big data dos clientes.</block>
  <block id="2268700ee8bd2216d594273e566b0cc9" category="doc">Caso de uso 4: Proteção de dados e conectividade multicloud</block>
  <block id="3cec8f6cf1ce867e7f73dd5132b7fbf3" category="paragraph">Neste cenário, os dados de IoT recebidos na AWS de diferentes fontes são armazenados em um local central no NPS.  O armazenamento NPS está conectado a clusters Spark/Hadoop localizados na AWS e no Azure, permitindo que aplicativos de análise de big data sejam executados em várias nuvens acessando os mesmos dados.</block>
  <block id="bed6436414550585ccb4ac4c67a449a3" category="list-text">Os clientes desejam executar tarefas analíticas nos mesmos dados usando várias nuvens.</block>
  <block id="6af3e1f448b2a56e9bd0fbbd43b31bc8" category="list-text">Os dados devem ser recebidos de diferentes fontes, como no local e na nuvem, por meio de diferentes sensores e hubs.</block>
  <block id="e3c7f1ced05166adfc90c26337389e3e" category="list-text">A solução deve ser eficiente e econômica.</block>
  <block id="b320f1b1ab6d0a21e40ee3d444669645" category="list-text">O principal desafio é criar uma solução econômica e eficiente que ofereça serviços de análise híbridos entre ambientes locais e entre diferentes nuvens.</block>
  <block id="0d4b3cfa555ff36cd92fb4e36fb69fbf" category="paragraph">Esta imagem ilustra a solução de proteção de dados e conectividade multicloud.</block>
  <block id="5308dad4844e43fdad02844ec50752c0" category="paragraph"><block ref="5308dad4844e43fdad02844ec50752c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ea48e5206de42785842cb864377766c" category="paragraph">Conforme mostrado na figura acima, os dados dos sensores são transmitidos e ingeridos no cluster do AWS Spark por meio do Kafka.  Os dados são armazenados em um compartilhamento NFS que reside no NPS, que está localizado fora do provedor de nuvem, dentro de um data center da Equinix.  Como o NetApp NPS está conectado ao Amazon AWS e ao Microsoft Azure por meio de conexões Direct Connect e Express Route, respectivamente, os clientes podem acessar os dados do NFS de clusters de análise da Amazon e da AWS.  Essa abordagem resolve ter análises de nuvem em vários hiperescaladores.</block>
  <block id="4089db0b43263b1f59a9c2db909edf6e" category="paragraph">Consequentemente, como tanto o armazenamento local quanto o NPS executam o software ONTAP , o SnapMirror pode espelhar os dados do NPS no cluster local, fornecendo análises de nuvem híbrida no local e em várias nuvens.</block>
  <block id="d446808fb03b5fae4f2e518cbc7d767f" category="paragraph">Para obter o melhor desempenho, a NetApp normalmente recomenda o uso de várias interfaces de rede e conexões diretas/rotas expressas para acessar os dados de instâncias de nuvem.</block>
  <block id="f9fe6a27dc7f13d26e9416153b950597" category="summary">Esta seção fornece uma descrição de alto nível dos casos de uso de proteção de dados, que constituem o foco deste artigo.  As seções restantes fornecem mais detalhes para cada caso de uso, como o problema do cliente (cenário), requisitos e desafios, e soluções.</block>
  <block id="6a15e1dac7cc5c330a1da84c32b3ff2e" category="doc">Visão geral dos casos de uso de proteção de dados do Hadoop</block>
  <block id="6f2c5dcd0294b9c34430b1de4713c06d" category="paragraph">Neste caso de uso, o volume NetApp NFS ajudou uma grande instituição financeira a reduzir o longo tempo de janela de backup de mais de 24 horas para pouco menos de algumas horas.</block>
  <block id="06b83cb579d9aaf1f26d8c4284a5a42e" category="paragraph">Ao usar a malha de dados fornecida pela NetApp como blocos de construção, uma grande empresa de transmissão conseguiu atender à sua exigência de fazer backup de dados em nuvem em seu data center local, dependendo dos diferentes modos de transferência de dados, como sob demanda, instantâneo ou com base na carga do cluster Hadoop/Spark.</block>
  <block id="da17b6db6e3e50f66b5bcaee1d74f8b1" category="paragraph">As soluções da NetApp ajudaram um distribuidor de música on-line a criar rapidamente vários clusters Hadoop com eficiência de espaço em diferentes filiais para criar relatórios e executar tarefas diárias de DevTest usando políticas agendadas.</block>
  <block id="90fc62f886a8c33032d4db8b79ec5814" category="paragraph">Um grande provedor de serviços usou a malha de dados fornecida pela NetApp para fornecer análises multinuvem aos seus clientes de diferentes instâncias de nuvem.</block>
  <block id="67f07a55567ecfc26b3c7b54823a43ee" category="paragraph">Um dos maiores bancos de serviços financeiros e investimentos usou a solução de armazenamento conectado à rede da NetApp para reduzir o tempo de espera de E/S e acelerar sua plataforma de análise financeira quantitativa.</block>
  <block id="139709c8a32ed1bcce233da863c5efda" category="summary">Esta seção apresenta lições aprendidas com esta certificação.</block>
  <block id="eab9ac0f00ca7c338d71f9acf8885092" category="doc">Diretrizes de melhores práticas</block>
  <block id="1bd6648fc95556a0a0fde4774f780085" category="list-text">Com base em nossa validação, o armazenamento de objetos S3 é melhor para o Confluent manter dados.</block>
  <block id="18f3dd1f96633e1c3f4b4473c8f63239" category="list-text">Podemos usar SAN de alto rendimento (especificamente FC) para manter os dados ativos do broker ou o disco local, porque, na configuração de armazenamento em camadas do Confluent, o tamanho dos dados mantidos no diretório de dados do broker é baseado no tamanho do segmento e no tempo de retenção quando os dados são movidos para o armazenamento de objetos.</block>
  <block id="992e82f9c5ce28bbe0068e8ff7ea8a09" category="list-text">Os armazenamentos de objetos fornecem melhor desempenho quando segment.bytes é maior; testamos 512 MB.</block>
  <block id="f165ec9e9849281afaf2162f6396907c" category="list-text">No Kafka, o comprimento da chave ou valor (em bytes) para cada registro produzido no tópico é controlado pelo<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block> parâmetro.  Para StorageGRID, o desempenho de ingestão e recuperação de objetos S3 aumentou para valores mais altos.  Por exemplo, 512 bytes forneceram uma recuperação de 5,8 GBps, 1.024 bytes forneceram uma recuperação s3 de 7,5 GBps e 2.048 bytes forneceram perto de 10 GBps.</block>
  <block id="92a9c9d4753636cd8ef8008380f5de9b" category="paragraph">A figura a seguir apresenta a ingestão e recuperação de objetos S3 com base em<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block> .</block>
  <block id="88108446d5ab5e54118010ab8c716e93" category="paragraph"><block ref="88108446d5ab5e54118010ab8c716e93" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9432e98ec213778ab349305141050c42" category="list-text">*Afinação de Kafka.*  Para melhorar o desempenho do armazenamento em camadas, você pode aumentar TierFetcherNumThreads e TierArchiverNumThreads.  Como orientação geral, você deve aumentar TierFetcherNumThreads para corresponder ao número de núcleos físicos da CPU e aumentar TierArchiverNumThreads para metade do número de núcleos da CPU.  Por exemplo, nas propriedades do servidor, se você tiver uma máquina com oito núcleos físicos, defina confluent.tier.fetcher.num.threads = 8 e confluent.tier.archiver.num.threads = 4.</block>
  <block id="ed3ecb8a7183dd06de652f3dc38b1037" category="list-text">*Intervalo de tempo para exclusão de tópicos.*  Quando um tópico é excluído, a exclusão dos arquivos de segmento de log no armazenamento de objetos não começa imediatamente.  Em vez disso, há um intervalo de tempo com um valor padrão de 3 horas antes que a exclusão desses arquivos ocorra.  Você pode modificar a configuração, confluent.tier.topic.delete.check.interval.ms, para alterar o valor deste intervalo.  Se você excluir um tópico ou cluster, também poderá excluir manualmente os objetos no respectivo bucket.</block>
  <block id="3833b7b3d2c8a15e32f72248bab1add9" category="list-text">*ACLs sobre tópicos internos de armazenamento em camadas.*  Uma prática recomendada para implantações locais é habilitar um autorizador de ACL nos tópicos internos usados para armazenamento em camadas.  Defina regras de ACL para limitar o acesso a esses dados somente ao usuário do broker.  Isso protege os tópicos internos e impede o acesso não autorizado a dados de armazenamento em camadas e metadados.</block>
  <block id="ebcb583d4445a2a39076c7fa4627f79a" category="admonition">Substituir o usuário<block ref="a802c5bf62b7c5970725474468cf46f4" prefix=" " category="inline-code"></block> com o principal corretor atual em sua implantação.</block>
  <block id="0ca954cd7923be900c49b3b807caf2b6" category="paragraph">Por exemplo, o comando<block ref="bccf46e0861de44696513d6cbea91e4c" prefix=" " category="inline-code"></block> define ACLs no tópico interno para armazenamento em camadas.  Atualmente, há apenas um único tópico interno relacionado ao armazenamento em camadas.  O exemplo cria uma ACL que fornece a permissão principal do Kafka para todas as operações no tópico interno.</block>
  <block id="663d826f2d39c93c218bb619244537b3" category="summary">Realizamos a certificação com Confluent Platform com Kafka para armazenamento em camadas no NetApp StorageGRID.</block>
  <block id="5436c2a5438619c1dbe68551a8297494" category="doc">Verificação confluente</block>
  <block id="0c112d1616223eaa5f0484a9499d587f" category="paragraph">Realizamos a verificação com o Confluent Platform 6.2 Tiered Storage no NetApp StorageGRID.  As equipes da NetApp e da Confluent trabalharam juntas nessa verificação e executaram os casos de teste necessários para a verificação.</block>
  <block id="ba5b5ff137c16b8859e6ac90b55d071c" category="section-title">Configuração da plataforma Confluent</block>
  <block id="d8802fa9749bdc5ddc844a1f86c9461d" category="paragraph">Usamos a seguinte configuração para verificação.</block>
  <block id="7b5948d7f6534813c3989b6697841566" category="paragraph">Para verificação, usamos três tratadores, cinco corretores, cinco servidores de execução de scripts de teste, servidores de ferramentas nomeadas com 256 GB de RAM e 16 CPUs.  Para armazenamento NetApp , usamos o StorageGRID com um balanceador de carga SG1000 com quatro SGF6024s.  O armazenamento e os corretores foram conectados por meio de conexões de 100 GbE.</block>
  <block id="e9f968cb8cc147519310d7290c28f99d" category="paragraph">A figura a seguir mostra a topologia de rede da configuração usada para verificação do Confluent.</block>
  <block id="275745d9c13bf80b7275e6f8633d15e4" category="paragraph"><block ref="275745d9c13bf80b7275e6f8633d15e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8a85abadadde0e32bd269b5667b6226" category="paragraph">Os servidores de ferramentas atuam como clientes de aplicativos que enviam solicitações aos nós do Confluent.</block>
  <block id="a0b3c1e592076debe73b163734ed8e2b" category="section-title">Configuração de armazenamento em camadas confluente</block>
  <block id="81082f7982ae1144f7662efde7446f1f" category="paragraph">A configuração de armazenamento em camadas requer os seguintes parâmetros no Kafka:</block>
  <block id="c78850251892556ff1c48a03b16cf1bf" category="paragraph">Para verificação, usamos StorageGRID com o protocolo HTTP, mas HTTPS também funciona.  A chave de acesso e a chave secreta são armazenadas no nome do arquivo fornecido no<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block> parâmetro.</block>
  <block id="4e19f24a6f1bb774911253be7f9d487f" category="section-title">Armazenamento de objetos NetApp - StorageGRID</block>
  <block id="2d5dff5c754356b277b47604fee26e79" category="paragraph">Configuramos a configuração de site único no StorageGRID para verificação.</block>
  <block id="dddbd2d03db81f9c6cb7d2dc1329df76" category="paragraph"><block ref="dddbd2d03db81f9c6cb7d2dc1329df76" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829026ce89cdb29d9f59599cb2244752" category="section-title">Testes de verificação</block>
  <block id="f97246b7185276a5fe91aba0dd7311ae" category="paragraph">Concluímos os cinco casos de teste a seguir para verificação.  Esses testes são executados no framework Trogdor.  Os dois primeiros foram testes de funcionalidade e os três restantes foram testes de desempenho.</block>
  <block id="4c5791ce7d906a384ff35dab9f635d41" category="section-title">Teste de correção de armazenamento de objetos</block>
  <block id="a0a36b11d315565a64a50eb2a0ed8c35" category="paragraph">Este teste determina se todas as operações básicas (por exemplo, obter/colocar/excluir) na API de armazenamento de objetos funcionam bem de acordo com as necessidades do armazenamento em camadas.  É um teste básico que todo serviço de armazenamento de objetos deve esperar passar antes dos testes seguintes.  É um teste assertivo que pode ser aprovado ou reprovado.</block>
  <block id="7cf5be835d50b9e5b598a4363e5a1310" category="section-title">Teste de correção da funcionalidade de hierarquização</block>
  <block id="afca9446d059f239c7c73699ec215b35" category="paragraph">Este teste determina se a funcionalidade de armazenamento em camadas de ponta a ponta funciona bem com um teste assertivo que passa ou falha.  O teste cria um tópico de teste que, por padrão, é configurado com camadas habilitadas e um tamanho de hotset altamente reduzido.  Ele produz um fluxo de eventos para o tópico de teste recém-criado, aguarda que os corretores arquivem os segmentos no armazenamento de objetos e, então, consome o fluxo de eventos e valida se o fluxo consumido corresponde ao fluxo produzido.  O número de mensagens produzidas no fluxo de eventos é configurável, o que permite ao usuário gerar uma carga de trabalho suficientemente grande de acordo com as necessidades de teste.  O tamanho reduzido do hotset garante que as buscas do consumidor fora do segmento ativo sejam atendidas somente pelo armazenamento de objetos; isso ajuda a testar a exatidão do armazenamento de objetos para leituras.  Realizamos este teste com e sem uma injeção de falha de armazenamento de objeto.  Simulamos uma falha de nó interrompendo o serviço do gerenciador de serviços em um dos nós no StorageGRID e validando se a funcionalidade de ponta a ponta funciona com o armazenamento de objetos.</block>
  <block id="88960bc44aa73a667c97d6168a27332a" category="section-title">Benchmark de busca de nível</block>
  <block id="777c3235446f781652127bde532a7d6e" category="paragraph">Este teste validou o desempenho de leitura do armazenamento de objetos em camadas e verificou o intervalo de solicitações de leitura de busca sob carga pesada de segmentos gerados pelo benchmark.  Neste benchmark, a Confluent desenvolveu clientes personalizados para atender às solicitações de busca de camadas.</block>
  <block id="07b15abc12bd3f43d57ebd95fce23917" category="section-title">Benchmark de carga de trabalho de produção e consumo</block>
  <block id="82ac7c284d524e3dba7699721633a674" category="paragraph">Este teste gerou indiretamente carga de trabalho de gravação no armazenamento de objetos por meio do arquivamento de segmentos.  A carga de trabalho de leitura (segmentos lidos) foi gerada a partir do armazenamento de objetos quando grupos de consumidores buscavam os segmentos.  Esta carga de trabalho foi gerada pelo script de teste.  Este teste verificou o desempenho de leitura e gravação no armazenamento de objetos em threads paralelos.  Testamos com e sem injeção de falha de armazenamento de objetos, assim como fizemos para o teste de correção da funcionalidade de camadas.</block>
  <block id="fc8cd6782366e38a4c0191fff79825b0" category="section-title">Referência de carga de trabalho de retenção</block>
  <block id="c51c74edfaecd19ad2258d1dd18ba5d5" category="paragraph">Este teste verificou o desempenho de exclusão de um armazenamento de objetos sob uma carga de trabalho pesada de retenção de tópicos.  A carga de trabalho de retenção foi gerada usando um script de teste que produz muitas mensagens em paralelo a um tópico de teste.  O tópico de teste foi a configuração com uma configuração agressiva de retenção baseada em tamanho e tempo que fazia com que o fluxo de eventos fosse continuamente eliminado do armazenamento de objetos.  Os segmentos foram então arquivados.  Isso levou a um grande número de exclusões no armazenamento de objetos pelo broker e à cobrança do desempenho das operações de exclusão do armazenamento de objetos.</block>
  <block id="996099c5b9fa96634feb727528db335e" category="list-text">O que é Apache Kafka?</block>
  <block id="64512a184434b7e7734cf3c0a7283f2a" category="list-text">O que é renomeação boba?</block>
  <block id="c4fe8f5f0b73bc80c0f8289fac9a6123" category="inline-link"><block ref="c4fe8f5f0b73bc80c0f8289fac9a6123" category="inline-link-rx"></block></block>
  <block id="0bf644a00aca415462aeb30f96e502cf" category="paragraph"><block ref="0bf644a00aca415462aeb30f96e502cf" category="inline-link-rx"></block></block>
  <block id="4a15e598cdac14bbb90bb0e4020f4a79" category="list-text">ONATP é lido para aplicações de streaming.</block>
  <block id="90bd054ee4c47533d08a6c79bd89dc5a" category="inline-link"><block ref="90bd054ee4c47533d08a6c79bd89dc5a" category="inline-link-rx"></block></block>
  <block id="05c0a7e8a1aa7fd9f25faae2cfd814e9" category="paragraph"><block ref="05c0a7e8a1aa7fd9f25faae2cfd814e9" category="inline-link-rx"></block></block>
  <block id="02aed7d7f25878a636d26b696ed151bb" category="list-text">Documentação do produto NetApp</block>
  <block id="e861ab8ac55c9110672ee8b4ba3c5990" category="list-text">O que é NFS?</block>
  <block id="bbdb25bd27a345174d3b4ea622b9ec26" category="inline-link"><block ref="bbdb25bd27a345174d3b4ea622b9ec26" category="inline-link-rx"></block></block>
  <block id="6b6d6a7e1bfbb25506c4af7f443a7b25" category="paragraph"><block ref="6b6d6a7e1bfbb25506c4af7f443a7b25" category="inline-link-rx"></block></block>
  <block id="9fee8c35c177577e85d941aa2c9dedc4" category="list-text">O que é reatribuição de partição do Kafka?</block>
  <block id="2363cdcf0f5fc9a387ed87b925979747" category="inline-link"><block ref="2363cdcf0f5fc9a387ed87b925979747" category="inline-link-rx"></block></block>
  <block id="12b4d09f121a118c1b63eba5f3523fa2" category="paragraph"><block ref="12b4d09f121a118c1b63eba5f3523fa2" category="inline-link-rx"></block></block>
  <block id="f06a814ac7d838a2d019219102377120" category="list-text">O que é o OpenMessaging Benchmark?</block>
  <block id="9466397f90b4d13297982537f7f1f157" category="inline-link"><block ref="9466397f90b4d13297982537f7f1f157" category="inline-link-rx"></block></block>
  <block id="f42769fbe9abef93dd4da40d8f886c4a" category="paragraph"><block ref="f42769fbe9abef93dd4da40d8f886c4a" category="inline-link-rx"></block></block>
  <block id="bcc483eab76f7252a6d3060ae223f024" category="list-text">Como você migra um corretor Kafka?</block>
  <block id="7702dea2646d94249d97c22a4dcb6f96" category="inline-link"><block ref="7702dea2646d94249d97c22a4dcb6f96" category="inline-link-rx"></block></block>
  <block id="ebdd7bc6eaa2157f5f400c61c1826417" category="paragraph"><block ref="ebdd7bc6eaa2157f5f400c61c1826417" category="inline-link-rx"></block></block>
  <block id="3f7e227a8b3d0fc0cdcbf84e2bc565ac" category="list-text">Como monitorar o corretor Kafka com o Prometheus?</block>
  <block id="2d2cb8fe8b8d32b7fb984622e41036f1" category="paragraph"><block ref="2d2cb8fe8b8d32b7fb984622e41036f1" category="inline-link-rx"></block></block>
  <block id="c8219112931de58f84e7a14a0d24d1ce" category="list-text">Plataforma gerenciada para Apache Kafka</block>
  <block id="a96e98488edf9123c2fb5281e71c6ec2" category="paragraph"><block ref="a96e98488edf9123c2fb5281e71c6ec2" category="inline-link-rx"></block></block>
  <block id="0cb1f340d12ba20e283d00e1e0823526" category="list-text">Suporte para Apache Kafka</block>
  <block id="14bb5ca8b6287991417f8f43b4d9eb0c" category="paragraph"><block ref="14bb5ca8b6287991417f8f43b4d9eb0c" category="inline-link-rx"></block></block>
  <block id="9d5591555b2fbddd314212720dc97729" category="list-text">Serviços de consultoria para Apache Kafka</block>
  <block id="583ea5ea8c7ad81fed86a1925483124c" category="paragraph"><block ref="583ea5ea8c7ad81fed86a1925483124c" category="inline-link-rx"></block></block>
  <block id="bf06620c2cdf1b79a1673e62b409eae0" category="summary">A solução da NetApp para o problema bobo de renomeação fornece uma forma de armazenamento simples, barata e gerenciada centralmente para cargas de trabalho que antes eram incompatíveis com o NFS.</block>
  <block id="5fe141c77d102adcaccfa6da33564741" category="paragraph">Esse novo paradigma permite que os clientes criem clusters Kafka mais gerenciáveis, mais fáceis de migrar e espelhar para fins de recuperação de desastres e proteção de dados.  Também vimos que o NFS oferece benefícios adicionais, como menor utilização da CPU e um tempo de recuperação mais rápido, eficiência de armazenamento significativamente melhorada e melhor desempenho por meio do NetApp ONTAP.</block>
  <block id="34ea6423c17a78bdf284132538078bac" category="summary">Este documento descreve os seguintes assuntos: o problema de renomeação simples e a validação da solução, redução da utilização da CPU para reduzir o tempo de espera de E/S, tempo de recuperação mais rápido do agente Kafka e desempenho na nuvem e no local.</block>
  <block id="47e33b895b285760d0d1bcb64e42e5d0" category="doc">TR-4947: Carga de trabalho do Apache Kafka com armazenamento NetApp NFS - Validação funcional e desempenho</block>
  <block id="62233ad21bd81bbbff938616c0106477" category="paragraph">Shantanu Chakole, Karthikeyan Nagalingam e Joe Scott, NetApp</block>
  <block id="8150fcf9bdcb89b4901e10f34571667e" category="paragraph">Kafka é um sistema de mensagens de publicação e assinatura distribuído com uma fila robusta que pode aceitar grandes quantidades de dados de mensagens.  Com o Kafka, os aplicativos podem gravar e ler dados em tópicos de maneira muito rápida.  Devido à sua tolerância a falhas e escalabilidade, o Kafka é frequentemente usado no espaço de big data como uma maneira confiável de ingerir e mover muitos fluxos de dados muito rapidamente.  Os casos de uso incluem processamento de fluxo, rastreamento de atividade do site, coleta e monitoramento de métricas, agregação de logs, análises em tempo real e assim por diante.</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link">aqui</block>
  <block id="e1304dc2c6d37619b73112fae0bd8411" category="paragraph">Embora as operações normais do Kafka no NFS funcionem bem, o problema bobo de renomeação trava o aplicativo durante o redimensionamento ou reparticionamento de um cluster do Kafka em execução no NFS.  Este é um problema significativo porque um cluster Kafka precisa ser redimensionado ou reparticionado para fins de balanceamento de carga ou manutenção.  Você pode encontrar detalhes adicionais<block ref="eff8c14b44ddf611b2ff09607d7665a2" category="inline-link-rx"></block> .</block>
  <block id="229b214236b3c346dc9f6c75d096604b" category="paragraph">Este documento descreve os seguintes assuntos:</block>
  <block id="995fd45f2f5174bc9a5d8029655c1b88" category="list-text">O problema da renomeação boba e a validação da solução</block>
  <block id="7c9e8a4fdb767e60565e9c4b4d95eed2" category="list-text">Reduzir a utilização da CPU para reduzir o tempo de espera de E/S</block>
  <block id="915a1ce7d578786f5aa93e503452d2b9" category="list-text">Tempo de recuperação mais rápido do corretor Kafka</block>
  <block id="5810e3ce10e4e8edfee5f25cae3459c1" category="list-text">Desempenho na nuvem e no local</block>
  <block id="7910f734d679965fb4e725f87dcb3c61" category="section-title">Por que usar armazenamento NFS para cargas de trabalho do Kafka?</block>
  <block id="932e5edaa1f66c6b109d045d3c7ba0bc" category="paragraph">As cargas de trabalho do Kafka em aplicativos de produção podem transmitir grandes quantidades de dados entre aplicativos.  Esses dados são mantidos e armazenados nos nós do broker Kafka no cluster Kafka.  O Kafka também é conhecido por disponibilidade e paralelismo, que ele consegue dividindo tópicos em partições e depois replicando essas partições por todo o cluster.  Isso significa que a enorme quantidade de dados que flui por um cluster Kafka geralmente é multiplicada em tamanho.  O NFS torna o rebalanceamento de dados muito rápido e fácil, à medida que o número de corretores muda.  Para ambientes grandes, o rebalanceamento de dados no DAS quando o número de corretores muda consome muito tempo e, na maioria dos ambientes Kafka, o número de corretores muda com frequência.</block>
  <block id="a49afd0b2827b8f1d1b83a36f75d3efc" category="paragraph">Outros benefícios incluem o seguinte:</block>
  <block id="889d2761ec65245a621931da633b8cfe" category="list-text">*Maturidade.*  O NFS é um protocolo maduro, o que significa que a maioria dos aspectos de implementação, proteção e uso são bem compreendidos.</block>
  <block id="c231daeb716325a2bca62a5e30431c8d" category="list-text">*Abrir.*  O NFS é um protocolo aberto e seu desenvolvimento contínuo está documentado nas especificações da Internet como um protocolo de rede livre e aberto.</block>
  <block id="6526aeb62806bf842c7ab66949c2de0c" category="list-text">*Custo-benefício.*  O NFS é uma solução de baixo custo para compartilhamento de arquivos em rede que é fácil de configurar porque usa a infraestrutura de rede existente.</block>
  <block id="8c70ad2ab84f33f7d462109fc8edc329" category="list-text">*Gerenciado centralmente.*  O gerenciamento centralizado do NFS diminui a necessidade de software adicional e espaço em disco em sistemas de usuários individuais.</block>
  <block id="dbb4f7d4eb0147816ffd5d84e4a79e19" category="list-text">*Distribuído.*  O NFS pode ser usado como um sistema de arquivos distribuído, reduzindo a necessidade de dispositivos de armazenamento de mídia removíveis.</block>
  <block id="37377984e38462f1628867b8e7a1e772" category="section-title">Por que usar o NetApp para cargas de trabalho do Kafka?</block>
  <block id="300fdb82e8f9a8b6ebb6d42a92483544" category="paragraph">A implementação do NetApp NFS é considerada um padrão ouro para o protocolo e é usada em inúmeros ambientes NAS empresariais. Além da credibilidade da NetApp, ela também oferece os seguintes benefícios:</block>
  <block id="f7e7d6aebe6163c0f639238b2e1a0333" category="list-text">Confiabilidade e eficiência</block>
  <block id="735980c2ea138788423c50ba2ef7c6c5" category="list-text">Escalabilidade e desempenho</block>
  <block id="a8fbd78750bfdd72ecb8371fa5fa9648" category="list-text">Alta disponibilidade (parceiro de HA em um cluster NetApp ONTAP )</block>
  <block id="7e7397a7b79323762c61941fc0e6b5f9" category="list-text">Proteção de dados</block>
  <block id="e005f1a13de2a01927e39ecb29ff1a7c" category="list-text">*Recuperação de desastres (NetApp SnapMirror).*  Seu site sai do ar ou você quer começar em um site diferente e continuar de onde parou.</block>
  <block id="81757222cee28779fe25327e8ef3f5a2" category="list-text">Capacidade de gerenciamento do seu sistema de armazenamento (administração e gerenciamento usando NetApp OnCommand).</block>
  <block id="7d411cbcfa7cf122ac8423795b89a4b8" category="list-text">*Balanceamento de carga.*  O cluster permite que você acesse diferentes volumes de LIFs de dados hospedados em diferentes nós.</block>
  <block id="6c38013b179499c32ccf05a98b927de6" category="list-text">*Operações não disruptivas.*  LIFs ou movimentações de volume são transparentes para os clientes NFS.</block>
  <block id="d4baa2e552beefa00e93883ed51f3ba2" category="summary">No local, usamos o controlador de armazenamento NetApp AFF A900 com ONTAP 9.12.1RC1 para validar o desempenho e o dimensionamento de um cluster Kafka.  Usamos o mesmo ambiente de teste de nossas práticas recomendadas de armazenamento em camadas anteriores com ONTAP e AFF.</block>
  <block id="1e753c720a0b773dd9d69024ca734577" category="doc">Visão geral de desempenho e validação com AFF A900 local</block>
  <block id="94391d4f56386aadb6f39e1a596f2427" category="paragraph">No local, usamos o controlador de armazenamento NetApp AFF A900 com ONTAP 9.12.1RC1 para validar o desempenho e o dimensionamento de um cluster Kafka.  Usamos o mesmo ambiente de teste de nossas práticas recomendadas de armazenamento em camadas anteriores com ONTAP e AFF.</block>
  <block id="b1e7584c9874b52caeb25c3646e8f273" category="paragraph">Usamos o Confluent Kafka 6.2.0 para avaliar o AFF A900.  O cluster conta com oito nós de corretores e três nós de tratadores de zoológicos.  Para testes de desempenho, usamos cinco nós de trabalho OMB.</block>
  <block id="7d23a6a699d760fc27aa7ce39406c010" category="paragraph"><block ref="7d23a6a699d760fc27aa7ce39406c010" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e8775bd755a8835ce86806d669677ea" category="section-title">Configuração de armazenamento</block>
  <block id="637d24b49cc32320a5e44ea905f65d10" category="paragraph">Usamos instâncias do NetApp FlexGroups para fornecer um único namespace para diretórios de log, simplificando a recuperação e a configuração.  Usamos NFSv4.1 e pNFS para fornecer acesso direto ao caminho para dados de segmento de log.</block>
  <block id="50ff5e789ae0742f2485b5147c072643" category="section-title">Ajuste de cliente</block>
  <block id="fc3a7751877b7f4e9a71c82ad3da7e44" category="paragraph">Cada cliente montou a instância do FlexGroup com o seguinte comando.</block>
  <block id="a5b2794b174e20f0b6dd9350cba3df82" category="paragraph">Além disso, aumentamos a<block ref="44d907b0e69e5aa31320f9e86a7ef440" prefix=" " category="inline-code"></block> do padrão<block ref="ea5d2f1c4608232e07d3aa3d998e5135" prefix=" " category="inline-code"></block> para<block ref="045117b0e0a11a242b9765e79cbf113f" prefix=" " category="inline-code"></block> .  Isso corresponde ao limite de slot de sessão padrão no ONTAP.</block>
  <block id="31305973da10c7b492918a2ad2b3deee" category="section-title">Ajuste do corretor Kafka</block>
  <block id="4ed38f0369b8bb562a96594ca860ab81" category="paragraph">Para maximizar o rendimento no sistema em teste, aumentamos significativamente os parâmetros padrão para determinados pools de threads principais.  Recomendamos seguir as práticas recomendadas do Confluent Kafka para a maioria das configurações.  Esse ajuste foi usado para maximizar a simultaneidade de E/S pendentes para armazenamento.  Esses parâmetros podem ser ajustados para corresponder aos recursos de computação e atributos de armazenamento do seu corretor.</block>
  <block id="0e80721091b1e58209e2877462ebbd21" category="section-title">Metodologia de teste do gerador de carga de trabalho</block>
  <block id="9707ee58e22a2478985c56025e656cad" category="paragraph">Usamos as mesmas configurações de OMB usadas nos testes de nuvem para o driver de throughput e a configuração do tópico.</block>
  <block id="dbdfae7d08a693255815e0890397b78f" category="list-text">Uma instância do FlexGroup foi provisionada usando o Ansible em um cluster AFF .</block>
  <block id="6c2577e00543c33096c33e1b2e79742d" category="list-text">O pNFS foi habilitado no ONTAP SVM.</block>
  <block id="62313ead30e5ae09df5e2329bfe44784" category="list-text">A carga de trabalho foi acionada com o driver Throughput usando a mesma configuração de carga de trabalho do Cloud Volumes ONTAP.  Veja a seção "<block ref="f628eac6c1ff8c1b0462e81ea7b2efc1" category="inline-xref-macro-rx"></block> " abaixo.  A carga de trabalho usou um fator de replicação de 3, o que significa que três cópias de segmentos de log foram mantidas no NFS.</block>
  <block id="823002616491cde5a10847131e46b9a6" category="list-text">Por fim, concluímos medições usando um backlog para medir a capacidade dos consumidores de acompanhar as mensagens mais recentes.  O OMB cria um backlog pausando os consumidores durante o início de uma medição.  Isso produz três fases distintas: criação de backlog (tráfego somente do produtor), redução de backlog (uma fase com grande demanda do consumidor, na qual os consumidores recuperam os eventos perdidos em um tópico) e o estado estável. Veja a seção "<block ref="67d9096f7dc6dfc3943f178b4a30cff8" category="inline-xref-macro-rx"></block> " para mais informações.</block>
  <block id="158bb82f009332b2fe16aba7bebc0c15" category="section-title">Desempenho em estado estacionário</block>
  <block id="216824b7a5a0da585075bc35333402f6" category="paragraph">Avaliamos o AFF A900 usando o OpenMessaging Benchmark para fornecer uma comparação semelhante à do Cloud Volumes ONTAP na AWS e do DAS na AWS.  Todos os valores de desempenho representam a taxa de transferência do cluster Kafka no nível do produtor e do consumidor.</block>
  <block id="34121e3b81b5330bbb499603af5609e6" category="paragraph">O desempenho em estado estável com o Confluent Kafka e o AFF A900 atingiu uma taxa de transferência média de mais de 3,4 GBps para produtores e consumidores.  Isso representa mais de 3,4 milhões de mensagens no cluster Kafka.  Ao visualizar a taxa de transferência sustentada em bytes por segundo para BrokerTopicMetrics, vemos o excelente desempenho de estado estável e o tráfego suportado pelo AFF A900.</block>
  <block id="c99b1e0f8a1447330448c8c7dc3df6b6" category="inline-image-macro">Este gráfico mostra a taxa de transferência da rede de corretores.</block>
  <block id="7965f443cb0aaaa8c5c51bc5dec6bed3" category="paragraph"><block ref="7965f443cb0aaaa8c5c51bc5dec6bed3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9877d3e22635e0b37f0b74ab2d832d05" category="paragraph">Isso se alinha bem com a visão de mensagens entregues por tópico.  O gráfico a seguir fornece uma análise por tópico.  Na configuração testada, vimos quase 900 mil mensagens por tópico em quatro tópicos.</block>
  <block id="a6f05b2032cdce5554a9058f33e2d728" category="paragraph"><block ref="a6f05b2032cdce5554a9058f33e2d728" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc35bf5a15bb7c42ab972c7038f773f5" category="section-title">Desempenho extremo e exploração de limites de armazenamento</block>
  <block id="58b4fe8d21ee892b9633349960eaa7ab" category="paragraph">Para o AFF, também testamos com o OMB usando o recurso de backlog.  O recurso de backlog pausa as assinaturas do consumidor enquanto um backlog de eventos é criado no cluster do Kafka.  Durante esta fase, ocorre apenas o tráfego do produtor, o que gera eventos que são confirmados em logs.  Isso emula mais de perto o processamento em lote ou os fluxos de trabalho de análise offline; nesses fluxos de trabalho, as assinaturas do consumidor são iniciadas e devem ler dados históricos que já foram removidos do cache do corretor.</block>
  <block id="2aeeb1b752e68f3fabc8026c34af1e23" category="paragraph">Para entender as limitações de armazenamento na taxa de transferência do consumidor nesta configuração, medimos a fase somente do produtor para entender quanto tráfego de gravação o A900 poderia absorver.  Veja a próxima seção "<block ref="dbf93a9130703fe2432219c42c2bf311" category="inline-xref-macro-rx"></block> " para entender como aproveitar esses dados.</block>
  <block id="feec11a45c1fd079250c6f3603d708cd" category="paragraph">Durante a parte exclusiva do produtor dessa medição, observamos um alto pico de rendimento que ultrapassou os limites de desempenho do A900 (quando outros recursos do corretor não estavam saturados, atendendo ao tráfego de produtores e consumidores).</block>
  <block id="bab88ff8b10be68a7d1ab6839852ce6b" category="paragraph"><block ref="bab88ff8b10be68a7d1ab6839852ce6b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f237b36d09d10702066fb620cf352dcf" category="admonition">Aumentamos o tamanho da mensagem para 16k para esta medição para limitar as sobrecargas por mensagem e maximizar a taxa de transferência de armazenamento para pontos de montagem NFS.</block>
  <block id="9e1dbe9319ed19b15341f3000f56398a" category="paragraph">O cluster Confluent Kafka atingiu um pico de produtividade do produtor de 4,03 GBps.</block>
  <block id="3355268f822f520fe03b272691c2e428" category="paragraph">Depois que o OMB concluiu o preenchimento do eventbacklog, o tráfego do consumidor foi reiniciado.  Durante as medições com drenagem de backlog, observamos um pico de rendimento do consumidor de mais de 20 GBps em todos os tópicos.  A taxa de transferência combinada para o volume NFS que armazena os dados de log OMB se aproximou de ~30 GBps.</block>
  <block id="157a25969caf77d231e319ce70f0b637" category="section-title">Orientação de dimensionamento</block>
  <block id="2e4bacad236b9e36d868b929042e2bad" category="inline-link">guia de tamanhos</block>
  <block id="eec877a6f9c2530996fae2423259c2c6" category="paragraph">A Amazon Web Services oferece uma<block ref="e9ae0e8f89540055129f0fae422bdb9a" category="inline-link-rx"></block> para dimensionamento e escalonamento de clusters do Kafka.</block>
  <block id="cc4abcaa3ba3e4f795b82759d3dcd056" category="paragraph">Esse dimensionamento fornece uma fórmula útil para determinar os requisitos de taxa de transferência de armazenamento para seu cluster Kafka:</block>
  <block id="f2fb73fb163775775c1145d28c68ad20" category="paragraph">Para uma taxa de transferência agregada produzida no cluster de tcluster com um fator de replicação de r, a taxa de transferência recebida pelo armazenamento do broker é a seguinte:</block>
  <block id="0acbbdd0cc159664d8baab43c6d168bd" category="paragraph">Isso pode ser simplificado ainda mais:</block>
  <block id="28c949d6bdead032a1410c176cbf74cb" category="paragraph">Usar esta fórmula permite que você selecione a plataforma ONTAP apropriada para suas necessidades de nível ativo do Kafka.</block>
  <block id="df3f8ed04b35156def4360bb05a77cc1" category="paragraph">A tabela a seguir explica a produtividade esperada do produtor para o A900 com diferentes fatores de replicação:</block>
  <block id="329589e3ff014cb50ee2238aecc6a867" category="cell">Fator de replicação</block>
  <block id="75ec49708cc8881a7762e3740e342ca3" category="cell">Taxa de transferência do produtor (GPps)</block>
  <block id="c2b3050f7fde2050bb86e4e9ef0f7567" category="cell">3 (medido)</block>
  <block id="31053ad0506e935470ca21b43cae98cf" category="cell">3,4</block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="cell">2</block>
  <block id="43ff194f410f3e93a8680bef5ba51e50" category="cell">5,1</block>
  <block id="a9d9d1b0257dda96d595bd00149cccdb" category="cell">10,2</block>
  <block id="bc0316be7ba1d2f8b53c282f09f9b532" category="summary">Um cluster Kafka com a camada de armazenamento montada no NetApp NFS foi avaliado quanto ao desempenho na nuvem AWS.  Os exemplos de benchmarking são descritos nas seções a seguir.</block>
  <block id="bf57de8e029ea3108f102be3202cff5f" category="doc">Visão geral de desempenho e validação no AWS FSx ONTAP</block>
  <block id="71db594c48140b244b2b54ff2bdedb71" category="paragraph">Um cluster Kafka com a camada de armazenamento montada no NetApp NFS foi avaliado quanto ao desempenho no AWS FSx ONTAP.  Os exemplos de benchmarking são descritos nas seções a seguir.</block>
  <block id="1c036e91476215fff31a2c45fdf276f9" category="section-title">Apache Kafka no AWS FSx ONTAP</block>
  <block id="29144a8d530212e5210d98eceae62106" category="paragraph">O Network File System (NFS) é um sistema de arquivos de rede amplamente utilizado para armazenar grandes quantidades de dados.  Na maioria das organizações, os dados estão sendo cada vez mais gerados por aplicativos de streaming como o Apache Kafka.  Essas cargas de trabalho exigem escalabilidade, baixa latência e uma arquitetura de ingestão de dados robusta com recursos de armazenamento modernos.  Para permitir análises em tempo real e fornecer insights acionáveis, é necessária uma infraestrutura bem projetada e de alto desempenho.</block>
  <block id="3c10ee4415fe854b95a1b3d124b0f0ea" category="paragraph">O Kafka funciona, por padrão, com um sistema de arquivos compatível com POSIX e depende do sistema de arquivos para manipular operações de arquivo, mas ao armazenar dados em um sistema de arquivos NFSv3, o cliente NFS do broker Kafka pode interpretar as operações de arquivo de forma diferente de um sistema de arquivos local, como XFS ou Ext4.  Um exemplo comum é a renomeação do NFS Silly, que fazia com que os corretores do Kafka falhassem ao expandir clusters e realocar partições.  Para lidar com esse desafio, a NetApp atualizou o cliente Linux NFS de código aberto com alterações agora disponíveis no RHEL8.7, RHEL9.1 e com suporte da versão atual do FSx ONTAP , ONTAP 9.12.1.</block>
  <block id="2c69958ee453c213417e415ee57b1690" category="paragraph">O Amazon FSx ONTAP fornece um sistema de arquivos NFS totalmente gerenciado, escalável e de alto desempenho na nuvem.  Os dados do Kafka no FSx ONTAP podem ser dimensionados para lidar com grandes quantidades de dados e garantir tolerância a falhas.  O NFS fornece gerenciamento de armazenamento centralizado e proteção de dados para conjuntos de dados críticos e sensíveis.</block>
  <block id="542c651fdfac42519bffb9b7ebf01539" category="paragraph">Esses aprimoramentos possibilitam que os clientes da AWS aproveitem o FSx ONTAP ao executar cargas de trabalho do Kafka nos serviços de computação da AWS.  Esses benefícios são: * Redução da utilização da CPU para reduzir o tempo de espera de E/S * Tempo de recuperação mais rápido do broker Kafka.  * Confiabilidade e eficiência.  * Escalabilidade e desempenho.  * Disponibilidade de Zona de Multidisponibilidade.  * Proteção de dados.</block>
  <block id="cafd94f15e4ecd146a2af6ea620cc490" category="section-title">Kafka no AWS FSx ONTAP</block>
  <block id="7e3b8d1a53f4bf4f127be8ea0fda504d" category="paragraph">Um cluster Kafka com AWS FSx ONTAP foi avaliado quanto ao desempenho na nuvem AWS.  Esse benchmarking é descrito nas seções a seguir.</block>
  <block id="029bc8dc2b20f11a166635df18b0a419" category="section-title">Configuração arquitetônica</block>
  <block id="6d14883a196c6b234f62d60a400fe708" category="paragraph">A tabela a seguir mostra a configuração ambiental para um cluster Kafka usando o AWS FSx ONTAP.</block>
  <block id="7a785978a6b38bb45ae8786c30a1781e" category="cell">Componente de plataforma</block>
  <block id="c704d8c873b1a8d5d0243075656aa1f5" category="cell">Configuração do ambiente</block>
  <block id="f874b8bfe50ce846d8156aabe96e5a34" category="cell">Kafka 3.2.3</block>
  <block id="e2322efe17a0927e7f855686b9597301" category="list-text">3 tratadores de zoológico – t2.small</block>
  <block id="ea55ea3b374458b5777457efaf0db679" category="list-text">3 servidores de corretor – i3en.2xlarge</block>
  <block id="d521f24278937c9ada520622e97168d8" category="list-text">1 x Grafana – c5n.2xgrande</block>
  <block id="747684069b5286f0282d40e544a04812" category="list-text">4 x produtor/consumidor -- c5n.2xlarge *</block>
  <block id="29c331c65dbb1c85faa29881b295fbfc" category="cell">Sistema operacional em todos os nós</block>
  <block id="a0d574b61a80df70bd921b269853cc18" category="cell">RHEL8.6</block>
  <block id="9e813193a6755822d3c1628326e814e6" category="cell">Multi-AZ com taxa de transferência de 4 GB/s e 160.000 IOPS</block>
  <block id="8eb6827eb8f798501ab14f58155a9982" category="section-title">Configuração do NetApp FSx ONTAP</block>
  <block id="eb1e12842ba64aa1b662a4e95a406d45" category="list-text">Para nossos testes iniciais, criamos um sistema de arquivos FSx ONTAP com 2 TB de capacidade e 40.000 IOPs para uma taxa de transferência de 2 GB/s.</block>
  <block id="7ce8d5b94f98d9eb7023e64b4f92f5fd" category="paragraph">Em nosso exemplo, estamos implantando o FSx ONTAP por meio do AWS CLI.  Você precisará personalizar ainda mais o comando em seu ambiente, conforme necessário.  O FSx ONTAP também pode ser implantado e gerenciado por meio do AWS Console para uma experiência de implantação mais fácil e otimizada, com menos entrada de linha de comando.</block>
  <block id="81656db36243146de24c60a68b7b395c" category="paragraph">Documentação No FSx ONTAP, o IOPS máximo atingível para um sistema de arquivos com taxa de transferência de 2 GB/s em nossa região de teste (US-East-1) é de 80.000 iops.  O total máximo de iops para um sistema de arquivos FSx ONTAP é de 160.000 iops, o que requer uma implantação de taxa de transferência de 4 GB/s para ser alcançado, o que demonstraremos mais adiante neste documento.</block>
  <block id="3c50ca3005ca0da0071db25317a45f47" category="paragraph">Para obter mais informações sobre as especificações de desempenho do FSx ONTAP , visite a documentação do AWS FSx ONTAP aqui:<block ref="f270bb91d9718c264ef59ceaf9562990" category="inline-link-rx"></block> .</block>
  <block id="ac3f15100beedf3665df00f75c6a126e" category="paragraph">A sintaxe detalhada da linha de comando para FSx "create-file-system" pode ser encontrada aqui:<block ref="6dfaa72a4db79e3cd69acb6bd09e3928" category="inline-link-rx"></block></block>
  <block id="4510c1fa7d54bc22137fc99fdee7ec14" category="paragraph">Por exemplo, você pode especificar uma chave KMS específica em vez da chave mestra padrão do AWS FSx que é usada quando nenhuma chave KMS é especificada.</block>
  <block id="b2d4bc4b14215051ed2eea3eff254d84" category="list-text">Ao criar o sistema de arquivos FSx ONTAP , aguarde até que o status "LifeCycle" mude para "AVAILABLE" no seu retorno JSON após descrever seu sistema de arquivos da seguinte maneira:</block>
  <block id="fcd00639267fd24b3c25a30b3abcd5b0" category="list-text">Valide as credenciais fazendo login no FSx ONTAP SSH com o usuário fsxadmin: Fsxadmin é a conta de administrador padrão para sistemas de arquivos FSx ONTAP na criação.  A senha para fsxadmin é a senha que foi configurada ao criar o sistema de arquivos pela primeira vez no Console da AWS ou com a CLI da AWS, conforme concluímos na Etapa 1.</block>
  <block id="89fd702da938a0842ce8bbbd1978c407" category="list-text">Depois que suas credenciais forem validadas, crie a máquina virtual de armazenamento no sistema de arquivos FSx ONTAP</block>
  <block id="52140a6ade484065f20232f9d150ea61" category="paragraph">Uma Máquina Virtual de Armazenamento (SVM) é um servidor de arquivos isolado com suas próprias credenciais administrativas e pontos de extremidade para administrar e acessar dados em volumes FSx ONTAP e fornece multilocação do FSx ONTAP .</block>
  <block id="e05c7d2454cf3006c8871c25085ec858" category="list-text">Depois de configurar sua máquina virtual de armazenamento primária, faça SSH no sistema de arquivos FSx ONTAP recém-criado e crie volumes na máquina virtual de armazenamento usando o comando de exemplo abaixo. Da mesma forma, criamos 6 volumes para essa validação.  Com base em nossa validação, mantenha o constituinte padrão (8) ou menos constituintes, o que proporcionará melhor desempenho ao Kafka.</block>
  <block id="f82c8c9ef7e5f94bfc60abe80b30a2c1" category="list-text">Precisaremos de capacidade adicional em nossos volumes para nossos testes.  Aumente o tamanho do volume para 2 TB e monte no caminho de junção.</block>
  <block id="401223c85704727381abb64f33f1e700" category="paragraph">No FSx ONTAP, os volumes podem ser provisionados de forma fina.  Em nosso exemplo, a capacidade total do volume estendido excede a capacidade total do sistema de arquivos, então precisaremos estender a capacidade total do sistema de arquivos para desbloquear capacidade adicional do volume provisionado, o que demonstraremos na próxima etapa.</block>
  <block id="980bf78b74033a80493ead9ead18533e" category="list-text">Em seguida, para desempenho e capacidade adicionais, ampliamos a capacidade de transferência do FSx ONTAP de 2 GB/seg para 4 GB/seg e IOPS para 160.000, e a capacidade para 5 TB</block>
  <block id="cfd6d8adc21dc264014c117cc1a95fda" category="paragraph">A sintaxe detalhada da linha de comando para FSx "update-file-system" pode ser encontrada aqui:<block ref="f3196344ef0cf3de8d956a0736aba68b" category="inline-link-rx"></block></block>
  <block id="d067a587144a5c3f420cd628e1e5e9ae" category="list-text">Os volumes FSx ONTAP são montados com nconnect e opções padrão em corretores Kafka</block>
  <block id="fe25ee0c1614b7db9e4a6cec9f2cd488" category="paragraph">A imagem a seguir mostra nossa arquitetura final do cluster Kafka baseado no FSx ONTAP :</block>
  <block id="a09d4eb20485c4e2d2f9ed81274d727a" category="inline-image-macro">Esta imagem mostra a arquitetura de um cluster Kafka baseado em FSx ONTAP.</block>
  <block id="f230dbbbd1d967f5675641bd1e9ff03e" category="paragraph"><block ref="f230dbbbd1d967f5675641bd1e9ff03e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a205c51d74e59d28030cda2886e41130" category="list-text">Calcular.  Usamos um cluster Kafka de três nós com um conjunto zookeeper de três nós em execução em servidores dedicados.  Cada corretor tinha seis pontos de montagem NFS para seis volumes na instância FSx ONTAP .</block>
  <block id="447931d0542671d1817df0b8bdc35ff4" category="list-text">Monitoramento.  Usamos dois nós para uma combinação Prometheus-Grafana.  Para gerar cargas de trabalho, usamos um cluster separado de três nós que poderia produzir e consumir neste cluster Kafka.</block>
  <block id="35f0ed4ee5bc59733f7cd41a36cf4721" category="list-text">Armazenar.  Usamos um FSx ONTAP com seis volumes de 2 TB montados.  O volume foi então exportado para o broker Kafka com uma montagem NFS. Os volumes FSx ONTAP são montados com 16 sessões nconnect e opções padrão nos brokers Kafka.</block>
  <block id="c06018aab55e4fa9ef871b34b2cf7897" category="section-title">Configurações de benchmarking do OpenMessage.</block>
  <block id="9300a7a969a31b3c5371c03474456ec3" category="paragraph">Usamos a mesma configuração usada para os volumes ONTAP do NetApp Cloud e seus detalhes estão aqui - link:kafka-nfs-performance-overview-and-validation-in-aws.html#architectural-setup</block>
  <block id="91c26176df142d17ab999313541632c5" category="section-title">Metodologia de testes</block>
  <block id="79f0e8e2c892a7ffb6c02f9be47fd6f5" category="list-text">Um cluster Kafka foi provisionado conforme a especificação descrita acima usando Terraform e Ansible.  O Terraform é usado para construir a infraestrutura usando instâncias da AWS para o cluster Kafka e o Ansible constrói o cluster Kafka nelas.</block>
  <block id="d9a3b4ca51b8378374ab25c3f90ec2a2" category="list-text">Uma carga de trabalho OMB foi acionada com a configuração de carga de trabalho descrita acima e o driver Sync.</block>
  <block id="3f6a85702112dff5bcd0970b7ceb3f02" category="list-text">Outra carga de trabalho foi acionada com o driver Throughput com a mesma configuração de carga de trabalho.</block>
  <block id="c680d437163cc6bab4f9bdb35c3073d0" category="section-title">Observação</block>
  <block id="5f2da6c069f19294c52f39a18639f0d2" category="paragraph">Dois tipos diferentes de drivers foram usados para gerar cargas de trabalho para comparar o desempenho de uma instância do Kafka em execução no NFS.  A diferença entre os drivers é a propriedade log flush.</block>
  <block id="6e3e5905f95f1d3670a864fd2b1e1855" category="paragraph">Para um fator de replicação Kafka 1 e o FSx ONTAP:</block>
  <block id="477397883986e4a6ef0944db3f171a9a" category="list-text">Taxa de transferência total gerada consistentemente pelo driver Sync: ~ 3218 MBps e desempenho máximo em ~ 3652 MBps.</block>
  <block id="526cf61e40ed54cf3e36bc48e608fe6a" category="list-text">Taxa de transferência total gerada consistentemente pelo driver Throughput: ~ 3679 MBps e desempenho máximo em ~ 3908 MBps.</block>
  <block id="5c677e3834aab5345e650615a307b653" category="paragraph">Para Kafka com fator de replicação 3 e FSx ONTAP :</block>
  <block id="1d0957e5fc4340aeed631639b2076501" category="list-text">Taxa de transferência total gerada consistentemente pelo driver Sync: ~ 1252 MBps e desempenho máximo em ~ 1382 MBps.</block>
  <block id="e18b6be6753e1c55e4474648e1073e75" category="list-text">Taxa de transferência total gerada consistentemente pelo driver Throughput: ~ 1218 MBps e desempenho máximo em ~ 1328 MBps.</block>
  <block id="9e99c55380b9b536ec73cd9bdfbad865" category="paragraph">No fator 3 de replicação do Kafka, a operação de leitura e gravação ocorreu três vezes no FSx ONTAP. No fator 1 de replicação do Kafka, a operação de leitura e gravação ocorreu uma vez no FSx ONTAP, portanto, em ambas as validações, conseguimos atingir a taxa de transferência máxima de 4 GB/s.</block>
  <block id="4bb1ab47e2a029960970bd2e246f9a57" category="paragraph">O driver Sync pode gerar uma taxa de transferência consistente, pois os logs são liberados no disco instantaneamente, enquanto o driver Throughput gera picos de taxa de transferência, pois os logs são confirmados no disco em massa.</block>
  <block id="920a7d00fe9032493a9a70c1e6c8972a" category="paragraph">Esses números de taxa de transferência são gerados para a configuração da AWS fornecida.  Para requisitos de desempenho mais altos, os tipos de instância podem ser ampliados e ajustados ainda mais para obter melhores números de taxa de transferência.  A produção total ou taxa total é a combinação das taxas do produtor e do consumidor.</block>
  <block id="5d4902b750979a6daa75a334daf3b4dd" category="inline-image-macro">Esta imagem mostra o desempenho do kafka com RF1 e RF3</block>
  <block id="67731dd79a61f656bfde458fade09eb2" category="paragraph"><block ref="67731dd79a61f656bfde458fade09eb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3293059261e00d42aa4678d1677be1b1" category="paragraph">O gráfico abaixo mostra o desempenho de 2 GB/s do FSx ONTAP e de 4 GB/s para o fator de replicação 3 do Kafka.  O fator de replicação 3 realiza a operação de leitura e gravação três vezes no armazenamento FSx ONTAP .  A taxa total para o driver de transferência é de 881 MB/s, o que faz com que a operação de leitura e gravação do Kafka seja de aproximadamente 2,64 GB/s no sistema de arquivos FSx ONTAP de 2 GB/s, e a taxa total para o driver de transferência é de 1328 MB/s, o que faz com que a operação de leitura e gravação do Kafka seja de aproximadamente 3,98 GB/s.  O desempenho do Kafka é linear e escalável com base na taxa de transferência do FSx ONTAP .</block>
  <block id="a7ddac9765853f96e59270871b8a3925" category="inline-image-macro">Esta imagem mostra o desempenho de expansão de 2 GB/s e 4 GB/s.</block>
  <block id="94043e4666620e8e09ceedcb705c7951" category="paragraph"><block ref="94043e4666620e8e09ceedcb705c7951" category="inline-image-macro-rx" type="image"></block></block>
  <block id="61f2d83a3758c796ac8892836cada117" category="paragraph">O gráfico abaixo mostra o desempenho entre a instância EC2 vs FSx ONTAP (Fator de Replicação Kafka: 3)</block>
  <block id="b891a78e120a481bc23346cb210b2fa2" category="inline-image-macro">Esta imagem mostra a comparação de desempenho do EC2 vs FSx ONTAP no RF3.</block>
  <block id="59b617ab46ce09f11c02ed94c18645e4" category="paragraph"><block ref="59b617ab46ce09f11c02ed94c18645e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02b742a6a1f227191aecb81d8822d2ee" category="doc">Visão geral de desempenho e validação na AWS</block>
  <block id="28e2dfa4242e2b504727dab8605d1432" category="section-title">Kafka na nuvem AWS com NetApp Cloud Volumes ONTAP (par de alta disponibilidade e nó único)</block>
  <block id="1dc7a426b0cbf7d35c5edda73f68403d" category="paragraph">Um cluster Kafka com NetApp Cloud Volumes ONTAP (par HA) foi avaliado quanto ao desempenho na nuvem AWS.  Esse benchmarking é descrito nas seções a seguir.</block>
  <block id="61c964c4267b0fa60eeaa1a7ccdf706e" category="paragraph">A tabela a seguir mostra a configuração ambiental para um cluster Kafka usando NAS.</block>
  <block id="4f04a8a7e04e79aafa7150a5ae2bab1b" category="cell">Instância NetApp Cloud Volumes ONTAP</block>
  <block id="462fed98d4e5a4d1be4d08b1fdd3f0df" category="cell">Instância de par HA – m5dn.12xLarge x 2node Instância de nó único – m5dn.12xLarge x 1 nó</block>
  <block id="29e8b4fdf26266c94b184b76858f935e" category="section-title">Configuração do volume do cluster NetApp ONTAP</block>
  <block id="febbbf2a22b781c8cb2d828a8cbf52d6" category="list-text">Para o par Cloud Volumes ONTAP HA, criamos dois agregados com três volumes em cada agregado em cada controlador de armazenamento.  Para o nó único do Cloud Volumes ONTAP , criamos seis volumes em um agregado.</block>
  <block id="72bcc37cf8850d4e74a6305d71727956" category="inline-image-macro">Esta imagem descreve as propriedades de aggr3 e aggr22.</block>
  <block id="cc5972f21a1c1b3f25fd1c54ca580885" category="paragraph"><block ref="cc5972f21a1c1b3f25fd1c54ca580885" category="inline-image-macro-rx" type="image"></block></block>
  <block id="518fcf406a83698c4ba5d2f41cafab41" category="inline-image-macro">Esta imagem descreve as propriedades do aggr2.</block>
  <block id="7bf987d778dee1c98d1b0b2d5fb00a9c" category="paragraph"><block ref="7bf987d778dee1c98d1b0b2d5fb00a9c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a6501fcefae41cda9ecf425cdc1ef15" category="list-text">Para obter melhor desempenho de rede, habilitamos a rede de alta velocidade para o par HA e o nó único.</block>
  <block id="a4de9e1c332b656e2e19024cce28f939" category="inline-image-macro">Esta imagem mostra como habilitar redes de alta velocidade.</block>
  <block id="49c32669e9d6be5a2b08ff5d8eb59127" category="paragraph"><block ref="49c32669e9d6be5a2b08ff5d8eb59127" category="inline-image-macro-rx" type="image"></block></block>
  <block id="678217b29dc6cbf917f08c79a1819f92" category="list-text">Percebemos que a NVRAM ONTAP tinha mais IOPS, então alteramos o IOPS para 2350 para o volume raiz Cloud Volumes ONTAP .  O disco de volume raiz no Cloud Volumes ONTAP tinha 47 GB de tamanho.  O seguinte comando ONTAP é para o par HA, e a mesma etapa é aplicável para o nó único.</block>
  <block id="71ac6dbf3d671b6b9db5497aad37fc67" category="inline-image-macro">Esta imagem mostra como modificar propriedades de volume.</block>
  <block id="044b1cecac787ba4da45dc749881f5a1" category="paragraph"><block ref="044b1cecac787ba4da45dc749881f5a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c2cacbcd5f4927358fee9d8a0b60252" category="paragraph">A figura a seguir descreve a arquitetura de um cluster Kafka baseado em NAS.</block>
  <block id="a5f2ebf87b5aa37d2e02d041ede98e4f" category="list-text">*Calcular.*  Usamos um cluster Kafka de três nós com um conjunto zookeeper de três nós em execução em servidores dedicados.  Cada broker tinha dois pontos de montagem NFS para um único volume na instância do Cloud Volumes ONTAP por meio de um LIF dedicado.</block>
  <block id="493b3bd02a683f505d957bb27957e1b6" category="list-text">*Monitoramento.*  Usamos dois nós para uma combinação Prometheus-Grafana.  Para gerar cargas de trabalho, usamos um cluster separado de três nós que poderia produzir e consumir neste cluster Kafka.</block>
  <block id="dcb39d8372b01f5eb051372b3d943fbd" category="list-text">*Armazenar.*  Usamos uma instância ONTAP de volumes em nuvem de par HA com um volume GP3 AWS-EBS de 6 TB montado na instância.  O volume foi então exportado para o broker Kafka com uma montagem NFS.</block>
  <block id="78f0f1d311c4aae35de324851ecea08a" category="inline-image-macro">Esta figura descreve a arquitetura de um cluster Kafka baseado em NAS.</block>
  <block id="474d97e74219f2fc9511f3691ed0ae94" category="paragraph"><block ref="474d97e74219f2fc9511f3691ed0ae94" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cce0ad6ab772599285bd32c539025c1f" category="section-title">Configurações de benchmarking do OpenMessage</block>
  <block id="6a1fe63829e046313e1b3073459bf538" category="list-text">Para melhor desempenho do NFS, precisamos de mais conexões de rede entre o servidor NFS e o cliente NFS, que podem ser criadas usando nconnect.  Monte os volumes NFS nos nós do broker com a opção nconnect executando o seguinte comando:</block>
  <block id="a973eefced896f4a698ed64af6dc0199" category="list-text">Verifique as conexões de rede no Cloud Volumes ONTAP.  O seguinte comando ONTAP é usado a partir do nó Cloud Volumes ONTAP .  A mesma etapa é aplicável ao par Cloud Volumes ONTAP HA.</block>
  <block id="828ed34406e4dab30166070e0af1f142" category="list-text">Usamos o seguinte Kafka<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block> em todos os corretores Kafka para o par Cloud Volumes ONTAP HA.  O<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> a propriedade é diferente para cada corretor, e as propriedades restantes são comuns para os corretores.  Para o broker1, o<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> o valor é o seguinte:</block>
  <block id="66ddebf2d4ab98ff8682a008dc466ce6" category="list-text">Para o broker2, o<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> o valor do imóvel é o seguinte:</block>
  <block id="fcfc381980a9ed554f51cbfd5b77616a" category="list-text">Para o broker3, o<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> o valor do imóvel é o seguinte:</block>
  <block id="00d57462d7009374713be86d6c491d89" category="list-text">Para o nó único do Cloud Volumes ONTAP , o Kafka<block ref="21d5034d4d99d6ca0da314367f1cccd6" prefix=" " category="inline-code"></block> é o mesmo que para o par Cloud Volumes ONTAP HA, exceto para<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> propriedade.</block>
  <block id="cf168cce281f1eccdc9f9fb55c933d29" category="list-text">Para o broker1, o<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> o valor é o seguinte:</block>
  <block id="1692ac5191f19e15cf0e3a8af0820752" category="list-text">Para o broker2, o<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> o valor é o seguinte:</block>
  <block id="4b0728fa62359454465b3a26a608d83c" category="list-text">A carga de trabalho no OMB é configurada com as seguintes propriedades:<block ref="9a97642a426510e31f49e0a98ed35e46" prefix=" " category="inline-code"></block> .</block>
  <block id="433b44cf3e6084d97e5162a06d481873" category="paragraph">O<block ref="f21d26061df60c086aedb156e38f66b5" prefix=" " category="inline-code"></block> pode variar para cada caso de uso.  Em nosso teste de desempenho, usamos 3K.</block>
  <block id="bd9348653b0cfa7f0962b694fa058428" category="paragraph">Usamos dois drivers diferentes, Sync ou Throughput, do OMB para gerar a carga de trabalho no cluster Kafka.</block>
  <block id="50e5861dab89d00bf88787e044b2c24f" category="list-text">O arquivo yaml usado para propriedades do driver de sincronização é o seguinte<block ref="46c2adf6b9dc6e5883c47b1d76feb008" prefix=" " category="inline-code"></block> :</block>
  <block id="9ae100f8fb1875133a485c355266af55" category="list-text">O arquivo yaml usado para as propriedades do driver Throughput é o seguinte<block ref="658e4b47fcd8812e9b0b2886af867717" prefix=" " category="inline-code"></block> :</block>
  <block id="a887b430cb278fa8f52827a223308324" category="list-text">Um cluster Kafka foi provisionado conforme a especificação descrita acima usando Terraform e Ansible.  O Terraform é usado para construir a infraestrutura usando instâncias da AWS para o cluster Kafka e o Ansible constrói o cluster Kafka nelas.</block>
  <block id="59f70e2d523801f5ede7c9bb7b48cc76" category="paragraph">Para um par de Cloud Volumes ONTAP HA:</block>
  <block id="ffb03fd768825b381d478b114716f8cf" category="list-text">Taxa de transferência total gerada consistentemente pelo driver de sincronização: ~1236 MBps.</block>
  <block id="84c96e7c92d1f10aac5f3600c7df9299" category="list-text">Taxa de transferência total gerada para o driver de taxa de transferência: pico de ~1412 MBps.</block>
  <block id="5896e2cd1e01fb8ef69cdf280a9a38e3" category="paragraph">Para um único nó Cloud Volumes ONTAP :</block>
  <block id="d3c9dedf3eb9fce5e9a983948c3cef0e" category="list-text">Taxa de transferência total gerada consistentemente pelo driver de sincronização: ~ 1962 MBps.</block>
  <block id="86acf2bdaf8de60bbc77d3dc8f0e1b12" category="list-text">Taxa de transferência total gerada pelo driver de taxa de transferência: pico ~1660 MBps</block>
  <block id="c5616509b949bfcdee10d7e87918ec9d" category="inline-image-macro">Quatro gráficos diferentes são apresentados aqui.  Driver de taxa de transferência do par CVO-HA.  Driver de sincronização do par CVO-HA.  Driver de taxa de transferência de nó único CVO.  Driver de sincronização de nó único CVO.</block>
  <block id="d2fc51602d60125ca82c279f8a8e03af" category="paragraph"><block ref="d2fc51602d60125ca82c279f8a8e03af" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8c6ad6fcb6db991d86273d33ed35d3c9" category="paragraph">Certifique-se de verificar a taxa de transferência de armazenamento ao executar o benchmark de taxa de transferência ou driver de sincronização.</block>
  <block id="22156e4cc2df3388f0f9dfe0c178db37" category="inline-image-macro">Este gráfico mostra o desempenho em latência, IOPS e taxa de transferência.</block>
  <block id="e34c5c483b0b104d0cc1453f3be5f6b4" category="paragraph"><block ref="e34c5c483b0b104d0cc1453f3be5f6b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc2e9a005ff6b9d50a1fca9914e8eac0" category="summary">Esta seção descreve o problema de renomeação e as alterações necessárias para que o servidor NFS e o cliente NFS resolvam o problema.</block>
  <block id="0d5e61a5d0c056718a15d6df7037a50c" category="doc">Solução da NetApp para problema de renomeação de cargas de trabalho NFS para Kafka</block>
  <block id="e5ee0fc73f4f4f38e75acb2c0b2343be" category="paragraph">O Kafka é criado com a suposição de que o sistema de arquivos subjacente seja compatível com POSIX: por exemplo, XFS ou Ext4.  O rebalanceamento de recursos do Kafka remove arquivos enquanto o aplicativo ainda os está utilizando.  Um sistema de arquivos compatível com POSIX permite que o unlink prossiga.  No entanto, ele só remove o arquivo depois que todas as referências a ele desaparecem.  Se o sistema de arquivos subjacente estiver conectado à rede, o cliente NFS interceptará as chamadas de desvinculação e gerenciará o fluxo de trabalho.  Como há aberturas pendentes no arquivo que está sendo desvinculado, o cliente NFS envia uma solicitação de renomeação ao servidor NFS e, no último fechamento do arquivo desvinculado, emite uma operação de remoção no arquivo renomeado.  Esse comportamento é comumente chamado de renomeação boba do NFS e é orquestrado pelo cliente NFS.</block>
  <block id="f17efbdff90d69935a8d84a6215665a5" category="paragraph">Qualquer corretor Kafka que use armazenamento de um servidor NFSv3 terá problemas por causa desse comportamento.  No entanto, o protocolo NFSv4.x tem recursos para resolver esse problema, permitindo que o servidor assuma a responsabilidade pelos arquivos abertos e desvinculados.  Os servidores NFS que oferecem suporte a esse recurso opcional comunicam a capacidade de propriedade ao cliente NFS no momento da abertura do arquivo.  O cliente NFS então cessa o gerenciamento de desvinculação quando há aberturas pendentes e permite que o servidor gerencie o fluxo.  Embora a especificação NFSv4 forneça diretrizes para implementação, até agora não havia nenhuma implementação de servidor NFS conhecida que suportasse esse recurso opcional.</block>
  <block id="219af746424bba4643138d0820ab40b5" category="paragraph">As seguintes alterações são necessárias para que o servidor NFS e o cliente NFS resolvam o problema bobo de renomeação:</block>
  <block id="36efd47a4ba95b58e3b2a0f2ed7420ad" category="list-text">*Alterações no cliente NFS (Linux).*  No momento da abertura do arquivo, o servidor NFS responde com um sinalizador, indicando a capacidade de lidar com a desvinculação de arquivos abertos.  As alterações do lado do cliente NFS permitem que o servidor NFS manipule a desvinculação na presença do sinalizador.  A NetApp atualizou o cliente Linux NFS de código aberto com essas alterações.  O cliente NFS atualizado agora está disponível para o RHEL 8.7 e RHEL 9.1.</block>
  <block id="f400588f268c9f90112ff6290a81575a" category="list-text">*Alterações no servidor NFS.*  O servidor NFS monitora as aberturas.  A desvinculação de um arquivo aberto existente agora é gerenciada pelo servidor para corresponder à semântica POSIX.  Quando o último arquivo aberto é fechado, o servidor NFS inicia a remoção real do arquivo, evitando assim o processo bobo de renomeação.  O servidor ONTAP NFS implementou esse recurso em sua versão mais recente, o ONTAP 9.12.1.</block>
  <block id="21a87b96dd7bfc9863d6bca5fc12f005" category="paragraph">Com as alterações acima no cliente e servidor NFS, o Kafka pode colher com segurança todos os benefícios do armazenamento NFS conectado à rede.</block>
  <block id="8a1762b0db0285b0ca6661669e3a9aec" category="summary">Para a validação funcional, mostramos que um cluster Kafka com uma montagem NFSv3 para armazenamento falha ao executar operações Kafka, como redistribuição de partições, enquanto outro cluster montado em NFSv4 com a correção pode executar as mesmas operações sem interrupções.</block>
  <block id="2b1635c7ae2a72d0b26454157a03e197" category="doc">Validação funcional - Correção de renomeação boba</block>
  <block id="a8ead7a6a54d47ea0a38e64908ab321f" category="section-title">Configuração de validação</block>
  <block id="e087dbbdc5792f1e574cdf41c135d858" category="paragraph">A configuração é executada na AWS.  A tabela a seguir mostra os diferentes componentes da plataforma e a configuração ambiental usados para a validação.</block>
  <block id="cccdd75af54f32ac7f570bbcca39f516" category="cell">Plataforma Confluent versão 7.2.1</block>
  <block id="185b9d1a84206af090c5f70ac68f24ad" category="list-text">3 x tratadores de zoológico – t3.xlarge</block>
  <block id="6677060ff0c6c4620e427121a576713c" category="list-text">4 x servidores de corretores – r3.xlarge</block>
  <block id="61e62294effd3d2046982e7d5a22b824" category="list-text">1 x Grafana – t3.xlarge</block>
  <block id="1e2657a43dca2051e4684eb73c2a856c" category="list-text">1 x centro de controle – t3.xlarge</block>
  <block id="2dcca349e332f9e312cebc29485dadf0" category="list-text">3 x Produtor/consumidor</block>
  <block id="00ecb59dfdd1b1378b38c6b7bf8e91dc" category="cell">RHEL8.7 ou posterior</block>
  <block id="d09d15c71c68b596f76c57a87a19e0e5" category="cell">Instância de nó único – M5.2xLarge</block>
  <block id="3ba4ec8d167c12be652d6829ce6e51d8" category="paragraph">A figura a seguir mostra a configuração arquitetônica desta solução.</block>
  <block id="b3c6c8984f5671892932b2a7eacc5bf4" category="inline-image-macro">Estas imagens mostram a topologia da AWS contendo uma VPC contendo três sub-redes privadas com um enxame de produtores, o cluster Kafka e uma instância CVO, respectivamente.</block>
  <block id="2046377162498de9fec810aafa41c2b3" category="paragraph"><block ref="2046377162498de9fec810aafa41c2b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d580bb4c55b441a712ec6c9dc12d38b" category="section-title">Fluxo arquitetônico</block>
  <block id="82c8c0c94e152cc00496c6c5a1fa76b0" category="list-text">*Calcular.*  Usamos um cluster Kafka de quatro nós com um conjunto de zookeepers de três nós em execução em servidores dedicados.</block>
  <block id="e236bd14d5d59a952978645a606dd7f9" category="list-text">*Monitoramento.*  Usamos dois nós para uma combinação Prometheus-Grafana.</block>
  <block id="c375f003dbf6b1accc45fd3811ce2b82" category="list-text">*Carga de trabalho.*  Para gerar cargas de trabalho, usamos um cluster separado de três nós que pode produzir e consumir deste cluster Kafka.</block>
  <block id="ada284cbb65ff7bad5814ecb0c6ecb2f" category="list-text">*Armazenar.*  Usamos uma instância ONTAP de volumes NetApp Cloud de nó único com dois volumes GP2 AWS-EBS de 500 GB anexados à instância.  Esses volumes foram então expostos ao cluster Kafka como um único volume NFSv4.1 por meio de um LIF.</block>
  <block id="e86dc7584f98dc172fd46661ef8b935a" category="paragraph">As propriedades padrões do Kafka foram escolhidas para todos os servidores.  O mesmo foi feito para o enxame de tratadores do zoológico.</block>
  <block id="c31fea06105fe5260bb879284c6181e0" category="list-text">Atualizar<block ref="9733772c7c0780d4ef7a6a8d6a9dbd7d" prefix=" " category="inline-code"></block> ao volume de Kafka, como segue:</block>
  <block id="5ca41832794ba1f8118f718465d6ffe4" category="list-text">Dois clusters Kafka semelhantes foram criados com a seguinte diferença:</block>
  <block id="fc1a46a26a283c18443e516b58cb0a58" category="list-text">*Grupo 1.*  O servidor NFS v4.1 de backend executando o ONTAP versão 9.12.1 pronto para produção foi hospedado por uma instância NetApp CVO.  RHEL 8.7/RHEL 9.1 foram instalados nos corretores.</block>
  <block id="183a9a6c4f97a876554696844cf5cd19" category="list-text">*Grupo 2.*  O servidor NFS de backend era um servidor Linux NFSv3 genérico criado manualmente.</block>
  <block id="8dac413f2b3b7fdfc73d642ae6e79a33" category="list-text">Um tópico de demonstração foi criado em ambos os clusters do Kafka.</block>
  <block id="dc30a10b7f3dac3bcce7b54e12502e89" category="paragraph">Cluster 1:</block>
  <block id="0cdb385ae4a7f7449cf10919962c71c8" category="inline-image-macro">Esta captura de tela mostra o tópico de demonstração criado no Cluster 1.</block>
  <block id="23e2fb3a3a7caf11826a6ddc3650812b" category="paragraph"><block ref="23e2fb3a3a7caf11826a6ddc3650812b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="83655cf6beab33b344c9ae17bec532d0" category="paragraph">Cluster 2:</block>
  <block id="772ab3218dd37dea5c304575fe358498" category="inline-image-macro">Esta captura de tela mostra o tópico de demonstração criado no Cluster 2.</block>
  <block id="2d82e26036412c43987356c7c8ca8fb3" category="paragraph"><block ref="2d82e26036412c43987356c7c8ca8fb3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb392c27040a7eb25cfeb1d96323917e" category="list-text">Os dados foram carregados nesses tópicos recém-criados para ambos os clusters.  Isso foi feito usando o kit de ferramentas producer-perf-test que vem no pacote padrão do Kafka:</block>
  <block id="bd5bb4c79c0fd5aea6e14277bbd9c5fe" category="list-text">Uma verificação de integridade foi realizada para o broker-1 para cada um dos clusters usando telnet:</block>
  <block id="ec97e8f78ae99ff145018ede90a47c77" category="list-text">telnet<block ref="da440d4c50d5bbb0ffa4021d6db8332c" prefix=" " category="inline-code"></block></block>
  <block id="a93dad1338160e3b828529ad6a585d13" category="list-text">telnet<block ref="2a3da46f5894b7e15be0ea3be46975cc" prefix=" " category="inline-code"></block></block>
  <block id="a7892fb38856d45eb1f6cd89d3118830" category="paragraph">Uma verificação de integridade bem-sucedida para corretores em ambos os clusters é mostrada na próxima captura de tela:</block>
  <block id="855ba5b1fb4b822400c8e412d08df6e4" category="inline-image-macro">Esta captura de tela mostra a leitura de uma verificação de integridade bem-sucedida em ambos os corretores.</block>
  <block id="abe3c89cfc6f09b3a5f31df9bcf7ac04" category="paragraph"><block ref="abe3c89cfc6f09b3a5f31df9bcf7ac04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a63ad47b1692dcaccf39fb2a5c42e393" category="list-text">Para acionar a condição de falha que faz com que os clusters do Kafka que usam volumes de armazenamento NFSv3 travem, iniciamos o processo de reatribuição de partições em ambos os clusters.  A reatribuição da partição foi realizada usando<block ref="5cbd65bd2e4824bbb4876b792e513e10" prefix=" " category="inline-code"></block> .  O processo detalhado é o seguinte:</block>
  <block id="9ea6b7d5de4fbe3c468699ad3c8bb6ef" category="list-text">Para reatribuir as partições de um tópico em um cluster Kafka, geramos a configuração de reatribuição proposta JSON (isso foi executado para ambos os clusters).</block>
  <block id="c4c8306a70b22c96715a3f79fe60eca9" category="list-text">O JSON de reatribuição gerado foi então salvo em<block ref="d773b1c180323b61e54dc5acaa6fb66f" prefix=" " category="inline-code"></block> .</block>
  <block id="05e65fb821eccc3b4cb26cc7285d75f8" category="list-text">O processo real de reatribuição de partição foi acionado pelo seguinte comando:</block>
  <block id="83c299e30316ef5659e9b3bbd34b40ad" category="list-text">Após alguns minutos, quando a reatribuição foi concluída, outra verificação de integridade nos corretores mostrou que o cluster usando volumes de armazenamento NFSv3 teve um problema de renomeação e travou, enquanto o Cluster 1 usando volumes de armazenamento NetApp ONTAP NFSv4.1 com a correção continuou as operações sem nenhuma interrupção.</block>
  <block id="197bc98012d3a74f45e086c86b7237bc" category="inline-image-macro">Esta captura de tela mostra a saída de um corretor travado.</block>
  <block id="3a51f6a0340d9026c9fc6619a6584b83" category="paragraph"><block ref="3a51f6a0340d9026c9fc6619a6584b83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7796cd6b11de5af34093097d2db9b94f" category="list-text">Cluster1-Broker-1 está ativo.</block>
  <block id="fef78f6445fec5a3c0d0cb2008e6c34e" category="list-text">Cluster2-broker-1 está morto.</block>
  <block id="e413a6c934b14b11c478c905d8c0489b" category="list-text">Ao verificar os diretórios de log do Kafka, ficou claro que o Cluster 1 usando volumes de armazenamento NetApp ONTAP NFSv4.1 com a correção tinha atribuição de partição limpa, enquanto o Cluster 2 usando armazenamento NFSv3 genérico não tinha devido a problemas de renomeação, o que levou à falha.  A imagem a seguir mostra o rebalanceamento de partições do Cluster 2, o que resultou em um problema de renomeação no armazenamento NFSv3.</block>
  <block id="1c2cca9f5ca8cce4b11ebdc970e4a78c" category="inline-image-macro">Esta captura de tela mostra a saída do log para falha do Cluster 2.</block>
  <block id="587e107619187efb07b3bd05f8bcf7f9" category="paragraph"><block ref="587e107619187efb07b3bd05f8bcf7f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43fea21bb45bdea6ebc007efbf3c0053" category="paragraph">A imagem a seguir mostra um rebalanceamento limpo da partição do Cluster 1 usando o armazenamento NetApp NFSv4.1.</block>
  <block id="1ac73d9186e013f2157d22422bc044ff" category="inline-image-macro">Esta captura de tela mostra a saída do log para uma atribuição de partição limpa bem-sucedida para o Cluster 1, enquanto</block>
  <block id="f3d0f09c5b4a3c2f532881572a744b6c" category="paragraph"><block ref="f3d0f09c5b4a3c2f532881572a744b6c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8eac57fa6403d9c896c24cb94767e954" category="summary">Agora que há uma solução para o problema bobo de renomeação no armazenamento NFS com o Kafka, você pode criar implantações robustas que aproveitam o armazenamento NetApp ONTAP para sua carga de trabalho do Kafka.  Isso não apenas reduz significativamente a sobrecarga operacional, como também traz os seguintes benefícios aos seus clusters Kafka.</block>
  <block id="76827cff700415303c6b7420a1869192" category="doc">Por que usar o NetApp NFS para cargas de trabalho do Kafka?</block>
  <block id="984b2b530f32710e640393a80677e426" category="paragraph">Agora que há uma solução para o problema bobo de renomeação no armazenamento NFS com o Kafka, você pode criar implantações robustas que aproveitam o armazenamento NetApp ONTAP para sua carga de trabalho do Kafka.  Isso não apenas reduz significativamente a sobrecarga operacional, mas também traz os seguintes benefícios aos seus clusters Kafka:</block>
  <block id="2dbec01439aed1c5b5fbe8a521623f2d" category="list-text">*Utilização reduzida da CPU em corretores Kafka.*  O uso do armazenamento NetApp ONTAP desagregado separa as operações de E/S de disco do broker e, portanto, reduz sua pegada de CPU.</block>
  <block id="24c6011da569f3cc3fede5c4eafff91e" category="list-text">*Tempo de recuperação mais rápido do corretor.*  Como o armazenamento desagregado do NetApp ONTAP é compartilhado entre os nós do broker do Kafka, uma nova instância de computação pode substituir um broker defeituoso a qualquer momento em uma fração do tempo em comparação às implantações convencionais do Kafka, sem reconstruir os dados.</block>
  <block id="04615fed33ad7a5a209c685460f2c557" category="list-text">*Eficiência de armazenamento.* Como a camada de armazenamento do aplicativo agora é provisionada pelo NetApp ONTAP, os clientes podem aproveitar todos os benefícios da eficiência de armazenamento que vem com o ONTAP, como compactação, desduplicação e compactação de dados em linha.</block>
  <block id="c7444ea1ca211e0d3dd1b89c4f792d00" category="paragraph">Esses benefícios foram testados e validados em casos de teste que discutimos em detalhes nesta seção.</block>
  <block id="454cd026e1a6a7761ee25bf6682aeb2b" category="section-title">Utilização reduzida da CPU no broker Kafka</block>
  <block id="70c59ac3ed6ee89fe977676b2dba2f05" category="paragraph">Descobrimos que a utilização geral da CPU é menor do que a do DAS quando executamos cargas de trabalho semelhantes em dois clusters Kafka separados que eram idênticos em suas especificações técnicas, mas diferiam em suas tecnologias de armazenamento.  Não apenas a utilização geral da CPU é menor quando o cluster Kafka usa armazenamento ONTAP , mas o aumento na utilização da CPU demonstrou um gradiente mais suave do que em um cluster Kafka baseado em DAS.</block>
  <block id="c9d177e7e6018d464567bf6a8f9773e7" category="paragraph">A tabela a seguir mostra a configuração ambiental usada para demonstrar a utilização reduzida da CPU.</block>
  <block id="5ed4a4dbe122b39d7103642bff11de54" category="cell">Ferramenta de benchmarking do Kafka 3.2.3: OpenMessaging</block>
  <block id="3cb61b8b67329a8a20d9128458cf6633" category="list-text">4 x Produtor/Consumidor -- c5n.2xlarge</block>
  <block id="d34010cfee0f2a6d774e450acd135088" category="cell">RHEL 8.7 ou posterior</block>
  <block id="bce5fbe7fa89f635a887c6af2f95a9be" category="cell">Instância de nó único – M5.2xLarge</block>
  <block id="a27bb92a9fdd5b8b4c084b824b810232" category="section-title">Ferramenta de benchmarking</block>
  <block id="d483516be45a355eab4c7f9b129540c9" category="inline-link">Mensagens abertas</block>
  <block id="0a48e066bcee681066419fb01ccd9f16" category="paragraph">A ferramenta de benchmarking usada neste caso de teste é a<block ref="3990ab384d3299fd4c655b02444eb5d6" category="inline-link-rx"></block> estrutura.  O OpenMessaging é neutro em relação a fornecedores e independente de linguagem; ele fornece diretrizes do setor para finanças, comércio eletrônico, IoT e big data; e ajuda a desenvolver aplicativos de mensagens e streaming em sistemas e plataformas heterogêneos.  A figura a seguir descreve a interação de clientes do OpenMessaging com um cluster Kafka.</block>
  <block id="ac6d62ee86368b8c24366434f9b5d5a1" category="inline-image-macro">Esta imagem descreve a interação de clientes OpenMessaging com um cluster Kafka.</block>
  <block id="9cb3e560e852dc92918678c092a4105e" category="paragraph"><block ref="9cb3e560e852dc92918678c092a4105e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6250495e61aa2eb3c47f71d21f58c6f8" category="list-text">*Calcular.*  Usamos um cluster Kafka de três nós com um conjunto zookeeper de três nós em execução em servidores dedicados.  Cada broker tinha dois pontos de montagem NFSv4.1 em um único volume na instância NetApp CVO por meio de um LIF dedicado.</block>
  <block id="f91ee5c5359f2260d72c50f2c8009925" category="list-text">*Monitoramento.*  Usamos dois nós para uma combinação Prometheus-Grafana.  Para gerar cargas de trabalho, temos um cluster separado de três nós que pode produzir e consumir deste cluster Kafka.</block>
  <block id="e2b1493c4214be739b2c9349a2c481ef" category="list-text">*Armazenar.*  Usamos uma instância ONTAP de volumes NetApp Cloud de nó único com seis volumes GP2 AWS-EBS de 250 GB montados na instância.  Esses volumes foram então expostos ao cluster Kafka como seis volumes NFSv4.1 por meio de LIFs dedicados.</block>
  <block id="ede634748bd4515e69245593cfc4478c" category="list-text">*Configuração.*  Os dois elementos configuráveis neste caso de teste foram os corretores Kafka e as cargas de trabalho do OpenMessaging.</block>
  <block id="b053d1656e3b9dcaa2b4834fbdc4fb86" category="list-text">*Configuração do corretor*  As seguintes especificações foram selecionadas para os corretores Kafka.  Utilizamos um fator de replicação de 3 para todas as medições, conforme destacado abaixo.</block>
  <block id="d5ee20b40da2061d10bff33a6f13467a" category="inline-image-macro">Esta imagem descreve as especificações selecionadas para os corretores Kafka.</block>
  <block id="41b835894ba02ffb1ba3f3fdae71877c" category="paragraph"><block ref="41b835894ba02ffb1ba3f3fdae71877c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82f54619faeaa86063f362102c160601" category="list-text">*Configuração de carga de trabalho do benchmark OpenMessaging (OMB).*  As seguintes especificações foram fornecidas.  Especificamos uma taxa de produtor alvo, destacada abaixo.</block>
  <block id="da43f96a4bfe17af8039df6b15f4f6da" category="inline-image-macro">Esta imagem descreve as especificações selecionadas para a configuração da carga de trabalho do benchmark OpenMessaging.</block>
  <block id="41106ec7ad546fdd6a08b370c8093ab9" category="paragraph"><block ref="41106ec7ad546fdd6a08b370c8093ab9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6067cc387407f4d8dc9d623c770cfd" category="list-text">Dois clusters semelhantes foram criados, cada um com seu próprio conjunto de enxames de clusters de referência.</block>
  <block id="c85bb905404dda665035e21b11ab1a58" category="list-text">*Grupo 1.*  Cluster Kafka baseado em NFS.</block>
  <block id="9ed0b3eccef17299a0119b0f28568e78" category="list-text">*Grupo 2.*  Cluster Kafka baseado em DAS.</block>
  <block id="a38c46362b3feb9b3bb5f53b1957d50f" category="list-text">Usando um comando OpenMessaging, cargas de trabalho semelhantes foram acionadas em cada cluster.</block>
  <block id="c18ed3feb8720fe4fc76d90a9fa6a6e3" category="list-text">A configuração da taxa de produção foi aumentada em quatro iterações, e a utilização da CPU foi registrada com o Grafana.  A taxa de produção foi definida nos seguintes níveis:</block>
  <block id="04207e7bb62b9b5d14bdb603f74e683c" category="list-text">10.000</block>
  <block id="e19784a5420512b2876c7b24680652b5" category="list-text">40.000</block>
  <block id="e57650a6c15f273334d41da58fa72111" category="list-text">80.000</block>
  <block id="ee70718f6a92d6c1b099a6942f594963" category="list-text">100.000</block>
  <block id="524fdb84d137ea63c19f5efab343f82b" category="paragraph">Há dois benefícios principais em usar o armazenamento NetApp NFS com o Kafka:</block>
  <block id="612e27ad9fd383437f1445cf80d554b1" category="list-text">*Você pode reduzir o uso da CPU em quase um terço.*  O uso geral da CPU em cargas de trabalho semelhantes foi menor para NFS em comparação aos SSDs DAS; a economia variou de 5% para taxas de produção mais baixas a 32% para taxas de produção mais altas.</block>
  <block id="bc31b9852409e970a3a4659fef4b4f93" category="list-text">*Uma redução de três vezes no desvio de utilização da CPU em taxas de produção mais altas.*  Como esperado, houve um aumento na utilização da CPU à medida que as taxas de produção foram aumentadas.  No entanto, a utilização da CPU em corretores Kafka usando DAS aumentou de 31% para a menor taxa de produção para 70% para a maior taxa de produção, um aumento de 39%.  No entanto, com um backend de armazenamento NFS, a utilização da CPU aumentou de 26% para 38%, um aumento de 12%.</block>
  <block id="6299b9c8f7a14a0a0ca7407cbb9a187a" category="inline-image-macro">Este gráfico descreve o comportamento de um cluster baseado em DAS.</block>
  <block id="9630ee6aa29406a977bc5179849d2639" category="paragraph"><block ref="9630ee6aa29406a977bc5179849d2639" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60e393621d29424b529201d4bc48e3b4" category="inline-image-macro">Este gráfico descreve o comportamento de um cluster baseado em NFS.</block>
  <block id="74336896d4b61e55ed364028f046f35b" category="paragraph"><block ref="74336896d4b61e55ed364028f046f35b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03d4293a3bcf73010216e2f0399fd571" category="paragraph">Além disso, com 100.000 mensagens, o DAS mostra mais utilização de CPU do que um cluster NFS.</block>
  <block id="a0e6052c526d2d343fa217b609c943a6" category="inline-image-macro">Este gráfico descreve o comportamento de um cluster baseado em DAS em 100.000 mensagens.</block>
  <block id="73c360518d32a693e133ab63604b2ab4" category="paragraph"><block ref="73c360518d32a693e133ab63604b2ab4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9d76c4aeb68cf4d7ef9bf3ce121bdd2" category="inline-image-macro">Este gráfico descreve o comportamento de um cluster baseado em NFS em 100.000 mensagens.</block>
  <block id="be31c668debc31c9573036c63b1b4f49" category="paragraph"><block ref="be31c668debc31c9573036c63b1b4f49" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60a5caa55d79e52e0af298cf19b5c73d" category="section-title">Recuperação mais rápida do corretor</block>
  <block id="bc0ed21388f4042414a88362de068e14" category="paragraph">Descobrimos que os corretores do Kafka se recuperam mais rápido quando usam armazenamento NFS compartilhado da NetApp .  Quando um broker falha em um cluster do Kafka, esse broker pode ser substituído por um broker íntegro com o mesmo ID de broker.  Ao executar este caso de teste, descobrimos que, no caso de um cluster Kafka baseado em DAS, o cluster reconstrói os dados em um broker saudável recém-adicionado, o que consome tempo.  No caso de um cluster Kafka baseado em NetApp NFS, o broker substituto continua lendo dados do diretório de log anterior e se recupera muito mais rápido.</block>
  <block id="687972ccb765e5204fa2220ba3dff130" category="list-text">4 x produtor/consumidor -- c5n.2xlarge</block>
  <block id="31638173210d76d464e93c8f3f53711c" category="list-text">1 x nó Kafka de backup – i3en.2xlarge</block>
  <block id="5d27021addda02398c54d28a4ceee767" category="cell">RHEL8.7 ou posterior</block>
  <block id="477284b661c88fdd810eb7273729b5ed" category="paragraph"><block ref="477284b661c88fdd810eb7273729b5ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="64898c42d1ced91d44ff2e383b066de3" category="list-text">*Calcular.*  Um cluster Kafka de três nós com um conjunto de zookeepers de três nós em execução em servidores dedicados.  Cada broker tem dois pontos de montagem NFS em um único volume na instância NetApp CVO por meio de um LIF dedicado.</block>
  <block id="06e870f499bc90bbe828323be8625621" category="list-text">*Monitoramento.*  Dois nós para uma combinação Prometheus-Grafana.  Para gerar cargas de trabalho, usamos um cluster separado de três nós que pode produzir e consumir neste cluster Kafka.</block>
  <block id="1a5c8241b05feb71d0733c2cc2f073c2" category="list-text">*Armazenar.*  Uma instância ONTAP de volumes NetApp Cloud de nó único com seis volumes GP2 AWS-EBS de 250 GB montados na instância.  Esses volumes são então expostos ao cluster Kafka como seis volumes NFS por meio de LIFs dedicados.</block>
  <block id="7a4e5e874bf6fcf8217de7f8f0af5acb" category="list-text">*Configuração do corretor.*  O único elemento configurável neste caso de teste são os corretores Kafka.  As seguintes especificações foram selecionadas para os corretores Kafka.  O<block ref="2aa7cd054835892b354c130576c17b61" prefix=" " category="inline-code"></block> é definido como um valor alto porque isso determina a rapidez com que um nó específico é retirado da lista ISR.  Ao alternar entre nós ruins e saudáveis, você não quer que o ID do broker seja excluído da lista de ISR.</block>
  <block id="d6068b616491b51ff179d0138965bba4" category="inline-image-macro">Esta imagem mostra as especificações escolhidas para os corretores Kafka.</block>
  <block id="ce565ed35fddb2c8191f4b8496e98245" category="paragraph"><block ref="ce565ed35fddb2c8191f4b8496e98245" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7f6ea5961f5640ce4fa828022abc91c1" category="list-text">Dois clusters semelhantes foram criados:</block>
  <block id="71754d8c640cd0a117a3c82af0bd3646" category="list-text">Um cluster confluente baseado em EC2.</block>
  <block id="c4b4e0617e4a38a83a00fc9bd8083465" category="list-text">Um cluster confluente baseado em NetApp NFS.</block>
  <block id="fbbf8c78f6f01371b1caa7b79bfa91b9" category="list-text">Um nó Kafka de espera foi criado com uma configuração idêntica aos nós do cluster Kafka original.</block>
  <block id="b2d04ce59538c1ba125aa91697b3854f" category="list-text">Em cada um dos clusters, um tópico de amostra foi criado e aproximadamente 110 GB de dados foram preenchidos em cada um dos corretores.</block>
  <block id="25bb70a763a5456f70f68d98646ecbd6" category="list-text">*Cluster baseado em EC2.*  Um diretório de dados do corretor Kafka é mapeado em<block ref="8463a3643fa4431218a88d6e1e85f064" prefix=" " category="inline-code"></block> (Na figura a seguir, Broker-1 do cluster1 [terminal esquerdo]).</block>
  <block id="bbec1799f53d01620bdd78881b0f0310" category="list-text">* Cluster baseado em NetApp NFS.*  Um diretório de dados do broker Kafka é montado no ponto NFS<block ref="ecabd55f704fe0f0dcc41be6e7e7ab83" prefix=" " category="inline-code"></block> (Na figura a seguir, Broker-1 do cluster2 [terminal direito]).</block>
  <block id="86f85a2a5eed8a784f9a06a8fe205c9a" category="inline-image-macro">Esta imagem mostra duas telas de terminal.</block>
  <block id="3a534dc7ed1f2e8444c4b278dd70aa7e" category="paragraph"><block ref="3a534dc7ed1f2e8444c4b278dd70aa7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02296aafa9e3a6424418dd97a673e931" category="list-text">Em cada um dos clusters, o Broker-1 foi encerrado para acionar um processo de recuperação do broker com falha.</block>
  <block id="fe4c3f604a59eb786f64f0fc5a7cfa01" category="list-text">Após o encerramento do broker, o endereço IP do broker foi atribuído como um IP secundário ao broker em espera.  Isso foi necessário porque um corretor em um cluster Kafka é identificado pelo seguinte:</block>
  <block id="597bfb23e3e10c354a661882e4728565" category="list-text">*Endereço IP.*  Atribuído pela reatribuição do IP do broker com falha ao broker em espera.</block>
  <block id="d86a6ec6cd64cd7365ad5d46f7c32d85" category="list-text">*ID do corretor.*  Isso foi configurado no corretor standby<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block> .</block>
  <block id="c71af5d75ff28fc80b8aa2c6c6832c39" category="list-text">Após a atribuição de IP, o serviço Kafka foi iniciado no broker em espera.</block>
  <block id="e6f0e1804a85ff41f08342fa0cd0e8c5" category="list-text">Depois de um tempo, os logs do servidor foram extraídos para verificar o tempo necessário para construir dados no nó de substituição no cluster.</block>
  <block id="b4e6de827ba8af76c3d7cf0e11dee63e" category="paragraph">A recuperação do corretor Kafka foi quase nove vezes mais rápida.  O tempo necessário para recuperar um nó de broker com falha foi significativamente mais rápido ao usar o armazenamento compartilhado NetApp NFS em comparação ao uso de SSDs DAS em um cluster Kafka.  Para 1 TB de dados de tópicos, o tempo de recuperação para um cluster baseado em DAS foi de 48 minutos, em comparação com menos de 5 minutos para um cluster Kafka baseado em NetApp-NFS.</block>
  <block id="fcd5351f741ba27a03aeaa4aff141fde" category="paragraph">Observamos que o cluster baseado em EC2 levou 10 minutos para reconstruir os 110 GB de dados no novo nó do broker, enquanto o cluster baseado em NFS concluiu a recuperação em 3 minutos.  Também observamos nos logs que os deslocamentos do consumidor para as partições do EC2 eram 0, enquanto, no cluster NFS, os deslocamentos do consumidor eram coletados do broker anterior.</block>
  <block id="01a0d5c558a836a74adf3dc3fe1de25d" category="section-title">Cluster baseado em DAS</block>
  <block id="542ac5d9dd4769eb5fb4a8a7da3aa594" category="list-text">O nó de backup foi iniciado em 08:55:53.730.</block>
  <block id="b5f0acf8be0dd329b7dae7c96c9b3dc8" category="inline-image-macro">Esta imagem mostra a saída de log para um cluster baseado em DAS.</block>
  <block id="91569a3f4fee956cd801e625cc8eb34f" category="paragraph"><block ref="91569a3f4fee956cd801e625cc8eb34f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d48d1996a0b89fc5aa313e48f1c2c149" category="list-text">O processo de reconstrução de dados terminou em 09:05:24.860.  O processamento de 110 GB de dados levou aproximadamente 10 minutos.</block>
  <block id="d598dda290e226574121bf65a66222c1" category="paragraph"><block ref="d598dda290e226574121bf65a66222c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d10d1e0d7dc7546ca2ee585553c90f24" category="section-title">Cluster baseado em NFS</block>
  <block id="e163d6812be40c2618b43cc9d2ed21a1" category="list-text">O nó de backup foi iniciado em 09:39:17.213.  A entrada de log inicial é destacada abaixo.</block>
  <block id="1af763f7fe72be73a16f6a9010023e1f" category="inline-image-macro">Esta imagem mostra a saída de log para um cluster baseado em NFS.</block>
  <block id="bbb8038819966fa92b04b31dfe935e66" category="paragraph"><block ref="bbb8038819966fa92b04b31dfe935e66" category="inline-image-macro-rx" type="image"></block></block>
  <block id="459f0a82f7fc8505de6db94698f5e9c8" category="list-text">O processo de reconstrução de dados terminou em 09:42:29.115.  O processamento de 110 GB de dados levou aproximadamente 3 minutos.</block>
  <block id="bb69fdfb2a75f135682b3880999f8c2e" category="paragraph"><block ref="bb69fdfb2a75f135682b3880999f8c2e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="24c9b21a2ca87ae467a56b044593521b" category="paragraph">O teste foi repetido para corretores contendo cerca de 1 TB de dados, o que levou aproximadamente 48 minutos para o DAS e 3 minutos para o NFS.  Os resultados são mostrados no gráfico a seguir.</block>
  <block id="6994918ac91afbe69dd9a20ab257afa1" category="inline-image-macro">Este gráfico mostra o tempo necessário para recuperação do broker dependendo da quantidade de dados carregados no broker para um cluster baseado em DAS ou um cluster baseado em NFS.</block>
  <block id="fcc7c3e745c4c2ba0f4fe48c8d589122" category="paragraph"><block ref="fcc7c3e745c4c2ba0f4fe48c8d589122" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd18465573ec21a6218982055981f6b1" category="section-title">Eficiência de armazenamento</block>
  <block id="f94ef2603834178da773ec5ccd97683b" category="paragraph">Como a camada de armazenamento do cluster Kafka foi provisionada pelo NetApp ONTAP, obtivemos todos os recursos de eficiência de armazenamento do ONTAP.  Isso foi testado gerando uma quantidade significativa de dados em um cluster Kafka com armazenamento NFS provisionado no Cloud Volumes ONTAP.  Pudemos ver que houve uma redução significativa de espaço devido aos recursos do ONTAP .</block>
  <block id="d1030267f4090d953bd3cabbb565b51b" category="cell">Instância de nó único – M5.2xLarge</block>
  <block id="717373873e977ccdc16d9a371e92b55b" category="list-text">*Calcular.*  Usamos um cluster Kafka de três nós com um conjunto zookeeper de três nós em execução em servidores dedicados.  Cada corretor tinha dois pontos de montagem NFS em um único volume na instância NetApp CVO por meio de um LIF dedicado.</block>
  <block id="cce21f164c30f5ce10f914c4542e252f" category="list-text">*Armazenar.*  Usamos uma instância NetApp Cloud Volumes ONTAP de nó único com seis volumes GP2 AWS-EBS de 250 GB montados na instância.  Esses volumes foram então expostos ao cluster Kafka como seis volumes NFS por meio de LIFs dedicados.</block>
  <block id="68f29d01fbebb4ad998127522e13950b" category="list-text">*Configuração.*  Os elementos configuráveis neste caso de teste foram os corretores Kafka.</block>
  <block id="8e44bdd37fc66a06e9780582642d0c37" category="paragraph">A compressão foi desativada pelo produtor, permitindo assim que ele gerasse alto rendimento.  A eficiência do armazenamento era gerenciada pela camada de computação.</block>
  <block id="7da10cbdbba2e826cd4954054b5c1843" category="list-text">Um cluster Kafka foi provisionado com as especificações mencionadas acima.</block>
  <block id="e857c1394ce43b04a9548d5a3dec0ee5" category="list-text">No cluster, cerca de 350 GB de dados foram produzidos usando a ferramenta OpenMessaging Benchmarking.</block>
  <block id="efc4a3d9bfed3a9a80b0caea9016ca6c" category="list-text">Após a conclusão da carga de trabalho, as estatísticas de eficiência de armazenamento foram coletadas usando o ONTAP System Manager e a CLI.</block>
  <block id="9c9850d81b369454a9610d48c5bfe8a0" category="paragraph">Para dados gerados usando a ferramenta OMB, observamos uma economia de espaço de ~33%, com uma taxa de eficiência de armazenamento de 1,70:1.  Como visto nas figuras a seguir, o espaço lógico utilizado pelos dados produzidos foi de 420,3 GB e o espaço físico utilizado para armazenar os dados foi de 281,7 GB.</block>
  <block id="f11c8594ca77ceb3e0ab124768dd061d" category="inline-image-macro">Esta imagem mostra a economia de espaço no VMDISK.</block>
  <block id="565d9cbc0c15374b9bdebe62dd5efe32" category="paragraph"><block ref="565d9cbc0c15374b9bdebe62dd5efe32" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3afbd9828e011526955ca93b48b57524" category="inline-image-macro">Captura de tela</block>
  <block id="50abdfc5295b4aedbb53a46e0bd7512b" category="paragraph"><block ref="50abdfc5295b4aedbb53a46e0bd7512b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6c6f7c15f1d0324567be0828cb855f7" category="paragraph"><block ref="c6c6f7c15f1d0324567be0828cb855f7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9fee86e220b694a9ca26cb5d3943276" category="summary">Este documento descreve benchmarks de desempenho para a plataforma Confluent no NetApp ONTAP usando um kit de benchmarking de armazenamento em camadas.</block>
  <block id="5514e652e396365ccb56f1b2b5371569" category="doc">TR-4941: Confluente com controladores de armazenamento NetApp ONTAP</block>
  <block id="1e0e02def11263577d232ee8ce69c727" category="paragraph">Karthikeyan Nagalingam, Joe Scott, NetApp Rankesh Kumar, Confluente</block>
  <block id="30f774bc5050b82b9a42fe5d8f4bc99f" category="paragraph">Para tornar a Plataforma Confluent mais escalável e elástica, ela deve ser capaz de dimensionar e balancear cargas de trabalho muito rapidamente.  O armazenamento em camadas torna o armazenamento de grandes volumes de dados no Confluent gerenciável, reduzindo essa carga operacional.</block>
  <block id="981ac9f1443bdd13b0920d6ca1ee4eb3" category="paragraph">A ideia fundamental é separar o armazenamento de dados do processamento de dados, o que torna muito mais fácil dimensionar cada um de forma independente.</block>
  <block id="44f523cee834fac14fc6966d940c5e92" category="paragraph">Equipado com inovações líderes do setor, o software de gerenciamento de dados NetApp ONTAP oferece à Confluent muitas vantagens onde quer que os dados estejam.</block>
  <block id="7e936a7640e03dad09e0b76d68277d56" category="summary">Realizamos testes de armazenamento em camadas com três a quatro nós para cargas de trabalho de produção e consumo com a configuração NetApp StorageGRID .</block>
  <block id="3c2fe55c24192bbec6d6d3aede570213" category="doc">Testes de desempenho com escalabilidade</block>
  <block id="7d962aad50ee059cfbd23de23ab5a916" category="paragraph">Realizamos testes de armazenamento em camadas com três a quatro nós para cargas de trabalho de produtor e consumidor com a configuração NetApp StorageGRID .  De acordo com nossos testes, o tempo de conclusão e os resultados de desempenho foram diretamente proporcionais ao número de nós StorageGRID .  A configuração do StorageGRID exigiu no mínimo três nós.</block>
  <block id="4e6097966a711c7acf606365a2925b64" category="list-text">O tempo para concluir a operação de produção e consumo diminuiu linearmente quando o número de nós de armazenamento aumentou.</block>
  <block id="5393f806598ea16510805a4ab3b20623" category="paragraph"><block ref="5393f806598ea16510805a4ab3b20623" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d098e780afaaad433dd6982bbc5af988" category="list-text">O desempenho da operação de recuperação s3 aumentou linearmente com base no número de nós StorageGRID .  O StorageGRID suporta até 200 nós StorgeGRID.</block>
  <block id="d73d827635c7a6fcfa52120cc6f3b96d" category="paragraph"><block ref="d73d827635c7a6fcfa52120cc6f3b96d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43f0735f931622d61f6837a0eb61f87e" category="summary">Este teste é baseado no recurso de clusters de autobalanceamento, que automatiza o rebalanceamento com base em alterações na topologia do cluster ou carga irregular.</block>
  <block id="565b2f1bfcd6857afba2efa000b83759" category="doc">Aglomerados autobalanceados confluentes</block>
  <block id="d3975bd93d0a2c24b382774d34b5a963" category="paragraph">Se você já gerenciou um cluster Kafka antes, provavelmente está familiarizado com os desafios que surgem ao reatribuir manualmente partições a diferentes brokers para garantir que a carga de trabalho seja balanceada no cluster.  Para organizações com grandes implantações do Kafka, reorganizar grandes quantidades de dados pode ser assustador, tedioso e arriscado, especialmente se aplicativos de missão crítica forem criados no cluster.  Entretanto, mesmo para os menores casos de uso do Kafka, o processo é demorado e propenso a erros humanos.</block>
  <block id="3c404a9102e2cb3ac7b75fa7ff7a2cb2" category="paragraph">Em nosso laboratório, testamos o recurso de clusters de autobalanceamento do Confluent, que automatiza o rebalanceamento com base em alterações na topologia do cluster ou carga irregular.  O teste de rebalanceamento do Confluent ajuda a medir o tempo para adicionar um novo broker quando ocorre uma falha no nó ou o nó de dimensionamento exige o rebalanceamento de dados entre os brokers.  Em configurações clássicas do Kafka, a quantidade de dados a serem rebalanceados aumenta à medida que o cluster cresce, mas, no armazenamento em camadas, o rebalanceamento é restrito a uma pequena quantidade de dados.  Com base em nossa validação, o rebalanceamento no armazenamento em camadas leva segundos ou minutos em uma arquitetura Kafka clássica e cresce linearmente conforme o cluster cresce.</block>
  <block id="829c663686b68c76ea97bd7a23d534b6" category="paragraph">Em clusters de autobalanceamento, os rebalanceamentos de partições são totalmente automatizados para otimizar a taxa de transferência do Kafka, acelerar o dimensionamento do broker e reduzir a carga operacional de execução de um cluster grande.  Em estado estável, os clusters autobalanceados monitoram a distorção de dados entre os corretores e reatribuem partições continuamente para otimizar o desempenho do cluster.  Ao dimensionar a plataforma para cima ou para baixo, os clusters de autobalanceamento reconhecem automaticamente a presença de novos corretores ou a remoção de corretores antigos e acionam uma reatribuição de partição subsequente.  Isso permite que você adicione e desative corretores facilmente, tornando seus clusters Kafka fundamentalmente mais elásticos.  Esses benefícios não exigem intervenção manual, cálculos matemáticos complexos ou o risco de erro humano que as reatribuições de partições normalmente envolvem.  Como resultado, os rebalanceamentos de dados são concluídos em muito menos tempo, e você fica livre para se concentrar em projetos de streaming de eventos de maior valor, em vez de precisar supervisionar constantemente seus clusters.</block>
  <block id="bc15ae13f16a39532174d0aec78a6432" category="summary">Nesta configuração, mostramos como ler e escrever tópicos no armazenamento de objetos do Kafka diretamente usando o conector de coletor S3 do Kafka.  Para este teste, usamos um cluster Confluent autônomo, mas esta configuração é aplicável a um cluster distribuído.</block>
  <block id="8b7e627b574df4c4813de77ed2896ad8" category="doc">Conector Confluent s3</block>
  <block id="524b95dc71b518ce734757656cf9594c" category="paragraph">O conector Amazon S3 Sink exporta dados de tópicos do Apache Kafka para objetos S3 nos formatos Avro, JSON ou Bytes.  O conector de coletor do Amazon S3 pesquisa periodicamente dados do Kafka e, por sua vez, os carrega no S3.  Um particionador é usado para dividir os dados de cada partição do Kafka em pedaços.  Cada bloco de dados é representado como um objeto S3.  O nome da chave codifica o tópico, a partição do Kafka e o deslocamento inicial deste bloco de dados.</block>
  <block id="b5829317a86f448ffca89934abe420d3" category="list-text">Baixe o Confluent Kafka do site da Confluent.</block>
  <block id="99eec7bbd3416776cb76d9d8f52bfddc" category="list-text">Descompacte o pacote em uma pasta no seu servidor.</block>
  <block id="2d025d1c11796b49f323ce393e802635" category="list-text">Exporte duas variáveis.</block>
  <block id="e238a3352503bcd61be91778a307f02e" category="list-text">Para uma configuração autônoma do Confluent Kafka, o cluster cria uma pasta raiz temporária em<block ref="d42b9c57d24cf5db3bd8d332dc35437f" prefix=" " category="inline-code"></block> . Ele também cria Zookeeper, Kafka, um registro de esquema, connect, um ksql-server e pastas do centro de controle e copia seus respectivos arquivos de configuração de<block ref="5f8dd6e4b96ae5c78585ed0293d4338d" prefix=" " category="inline-code"></block> .  Veja o exemplo a seguir:</block>
  <block id="ed529b17b192b6bcfa1fb220aa0f37e4" category="list-text">Configurar o Zookeeper.  Você não precisa alterar nada se usar os parâmetros padrões.</block>
  <block id="ad2d4e5ed593359b5d1fe13997541e6f" category="paragraph">Na configuração acima, atualizamos o<block ref="2f11dbffae155119df4dc4d60229477e" prefix=" " category="inline-code"></block> propriedade.  Por padrão, você precisa de três tratadores para a seleção do líder Kafka.</block>
  <block id="b7eb15647b54e1bfd5b79f04012f19ce" category="list-text">Criamos um arquivo myid em<block ref="417022983f4126687b04c2a16a36183c" prefix=" " category="inline-code"></block> com um ID único:</block>
  <block id="78f7f3d70d7fc386cde6a61b7d08bc07" category="paragraph">Usamos o último número de endereços IP para o arquivo myid.  Usamos valores padrão para as configurações Kafka, connect, control-center, Kafka, Kafka-rest, ksql-server e schema-registry.</block>
  <block id="5ad6084775d1229b3edcbda0f353315c" category="list-text">Inicie os serviços do Kafka.</block>
  <block id="67228b3b71aba311ab74c0946efe35e8" category="paragraph">Há uma pasta de log para cada configuração, o que ajuda a solucionar problemas.  Em alguns casos, os serviços demoram mais para iniciar.  Certifique-se de que todos os serviços estejam funcionando.</block>
  <block id="65272a6acb72513d0bfa2bdd8b0c6d1b" category="list-text">Instalar o Kafka Connect usando<block ref="dcd3bd9446852f6dec3cf416e98154dc" prefix=" " category="inline-code"></block> .</block>
  <block id="4bdaf464a75dbea14d9240c6722a822a" category="paragraph">Você também pode instalar uma versão específica usando<block ref="edb107f75d4831212ad61dd615bc468f" prefix=" " category="inline-code"></block> .</block>
  <block id="004220cf4b170d47a455040fde149eaf" category="list-text">Por padrão,<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block> está instalado em<block ref="6ae652b878f3c54eeaed9d623a1a8c82" prefix=" " category="inline-code"></block> .</block>
  <block id="fe4b44765b8ad323e0d6a2e6b7325246" category="list-text">Atualize o caminho do plug-in com o novo<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block> .</block>
  <block id="331885900730ee061e0f6b4f55e62ece" category="list-text">Pare os serviços do Confluent e reinicie-os.</block>
  <block id="7fe69cf1bb033725fdeb56839e70fe4e" category="list-text">Configure o ID de acesso e a chave secreta no<block ref="40f203cedcd08f7589920d1a469a96d9" prefix=" " category="inline-code"></block> arquivo.</block>
  <block id="fac7d16b475df7919931f2de707a4a45" category="list-text">Verifique se o balde está acessível.</block>
  <block id="369f5700a42f83495e179b9e947587fb" category="list-text">Configure o arquivo de propriedades s3-sink para configuração do s3 e do bucket.</block>
  <block id="3d3c898205223806be88ccecb8f0598c" category="list-text">Importe alguns registros para o bucket s3.</block>
  <block id="50b781543cad31f75eed99b8efb20e79" category="list-text">Carregue o conector s3-sink.</block>
  <block id="6e773b2ab9703d3433d0ebfb5a45a3a1" category="list-text">Verifique o status do s3-sink.</block>
  <block id="b533fadf7b5ac18085d65eb6814528cf" category="list-text">Verifique o log para ter certeza de que o s3-sink está pronto para aceitar tópicos.</block>
  <block id="613093505fc60a58e7893af8aee3b7b8" category="list-text">Confira os tópicos em Kafka.</block>
  <block id="38f7472ee233ba1cc1a7d724a0ca6542" category="list-text">Verifique os objetos no bucket s3.</block>
  <block id="09fa6729fb808be555e2da157c07e47e" category="list-text">Para verificar o conteúdo, copie cada arquivo do S3 para o seu sistema de arquivos local executando o seguinte comando:</block>
  <block id="e8eeb400cc1af7c80b7561572c879a12" category="inline-link">Arquivos Apache</block>
  <block id="7d059565bbab6abb5da76e3abcfe6f90" category="list-text">Para imprimir os registros, use avro-tools-1.11.0.1.jar (disponível no<block ref="55ee52f435d2dbbc99b651e203ff837e" category="inline-link-rx"></block> ).</block>
  <block id="331c0d2ba7a09b3ae7f6fac4652625da" category="summary">Esta página descreve as melhores práticas para melhorar o desempenho desta solução.</block>
  <block id="69cefd131c612b28f058caddd20f5cac" category="doc">Diretrizes de melhores práticas de desempenho</block>
  <block id="21414169b395738292b2ac2fd8ca50a9" category="list-text">Para ONTAP, quando possível, use um tamanho GET &gt;=1 MB.</block>
  <block id="ce2e9b8aaceb2d2993c90188d874af95" category="list-text">Aumentando<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block> e<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block> em<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block> nos nós do corretor permite que você envie maior atividade de hierarquização para a camada S3.  Esses resultados são com<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block> e<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block> definido como 32.</block>
  <block id="1a48e01d01924d18e32943982eb6d924" category="list-text">Os buckets do S3 devem ter como alvo oito constituintes por agregado de membros.</block>
  <block id="b5a9dc3c7ec54467d103e00eaa0efb21" category="list-text">Os links Ethernet que direcionam o tráfego S3 devem usar uma MTU de 9k quando possível, tanto no armazenamento quanto no cliente.</block>
  <block id="4ea8220421596c898f8150bfebdf4ccb" category="summary">Este teste de verificação atingiu 31,74 GBps de taxa de transferência em camadas no Confluent com um controlador de armazenamento NetApp ONTAP .</block>
  <block id="93a10982e8e304323ad8af9a9387d775" category="paragraph">Este teste de verificação atingiu 31,74 GBps de taxa de transferência em camadas no Confluent com o NetApp ONTAP Storage Controller.</block>
  <block id="0f2f674cce6910ae97ee7ecc7bd9de18" category="list-text">O que é Confluent?</block>
  <block id="e6deab0ab2821160c056af4c7766624c" category="inline-link"><block ref="e6deab0ab2821160c056af4c7766624c" category="inline-link-rx"></block></block>
  <block id="ce3026317a00b57c81627bd64a1b3311" category="paragraph"><block ref="ce3026317a00b57c81627bd64a1b3311" category="inline-link-rx"></block></block>
  <block id="58a229be829dc9196abdaff6a4a26864" category="list-text">S3 nas melhores práticas do ONTAP</block>
  <block id="f47b79954bb4ad3165d7f99db02fe933" category="inline-link"><block ref="f47b79954bb4ad3165d7f99db02fe933" category="inline-link-rx"></block></block>
  <block id="e98b34b649783312d3b317c7441a20a5" category="paragraph"><block ref="e98b34b649783312d3b317c7441a20a5" category="inline-link-rx"></block></block>
  <block id="3075344c29b864c90ae1411c1db26e87" category="list-text">Gerenciamento de armazenamento de objetos S3</block>
  <block id="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link"><block ref="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link-rx"></block></block>
  <block id="8a93310a8dd4b405a8711f82adeb3c23" category="paragraph"><block ref="8a93310a8dd4b405a8711f82adeb3c23" category="inline-link-rx"></block></block>
  <block id="614eb548d72efbb3690b5c131745db1b" category="summary">Esta página descreve a validação de desempenho do Confluent dentro dos parâmetros desta solução.</block>
  <block id="28052d386826afbb88768d0629570b19" category="doc">Validação de desempenho confluente</block>
  <block id="3ec7b1ca1aaf25c9bbca707f1ca8e466" category="paragraph">Realizamos a verificação com a Confluent Platform para armazenamento em camadas no NetApp ONTAP.  As equipes da NetApp e da Confluent trabalharam juntas nessa verificação e executaram os casos de teste necessários para isso.</block>
  <block id="1f567e45477749710cbc14cf6b10afc4" category="section-title">Configuração confluente</block>
  <block id="99b45ae42dbbf816c910ba27197525dc" category="paragraph">Para a configuração, usamos três tratadores, cinco corretores e cinco servidores de teste com 256 GB de RAM e 16 CPUs.  Para armazenamento NetApp , usamos o ONTAP com um par AFF A900 HA.  O armazenamento e os corretores foram conectados por meio de conexões de 100 GbE.</block>
  <block id="77727c2ca2ac5beb0de2853929b43367" category="paragraph">A figura a seguir mostra a topologia de rede da configuração usada para verificação de armazenamento em camadas.</block>
  <block id="57e8d3257fec5774d2e8d38588771a69" category="inline-image-macro">Este gráfico mostra a topologia de rede da configuração usada para verificação de armazenamento em camadas.</block>
  <block id="b460294b1898fd26dfbb545338caacee" category="paragraph"><block ref="b460294b1898fd26dfbb545338caacee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d9b75f4efe285b9777255f14c81323b" category="paragraph">Os servidores de ferramentas atuam como clientes de aplicativos que enviam ou recebem eventos de ou para nós do Confluent.</block>
  <block id="1068af448bd05a968329fd2341036bfb" category="paragraph">Utilizamos os seguintes parâmetros de teste:</block>
  <block id="3bfb3f2755d25ed45d39dad8b3ed3008" category="paragraph">Para verificação, usamos o ONTAP com o protocolo HTTP, mas o HTTPS também funcionou.  A chave de acesso e a chave secreta são armazenadas no nome do arquivo fornecido no<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block> parâmetro.</block>
  <block id="86d7ae5e1e87e4958b4fafcbca603956" category="section-title">Controlador de armazenamento NetApp – ONTAP</block>
  <block id="b915ce35d395a0d68a794b87705f95fa" category="paragraph">Configuramos uma única configuração de par HA no ONTAP para verificação.</block>
  <block id="b9d2b35b3cfffa153fd4ed3401cb9dd9" category="inline-image-macro">Este gráfico descreve como o ambiente foi configurado como um único par de HA para verificação.</block>
  <block id="267b459a69088e0dc82f7fe972205f92" category="paragraph"><block ref="267b459a69088e0dc82f7fe972205f92" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7069b530e46a91698a16159b7d083019" category="section-title">Resultados da verificação</block>
  <block id="3af1efc909fae49a716fe2d22ba24290" category="paragraph">Concluímos os cinco casos de teste a seguir para verificação.  Os dois primeiros foram testes de funcionalidade e os três restantes foram testes de desempenho.</block>
  <block id="09da8339466c8b6111e4f310f1b78cb5" category="paragraph">Este teste executa operações básicas como obter, colocar e excluir no armazenamento de objetos usado para armazenamento em camadas usando chamadas de API.</block>
  <block id="622ce818e2b8228cee071a827a43e1b2" category="paragraph">Este teste verifica a funcionalidade de ponta a ponta do armazenamento de objetos.  Ele cria um tópico, produz um fluxo de eventos para o tópico recém-criado, aguarda que os corretores arquivem os segmentos no armazenamento de objetos, consome o fluxo de eventos e valida as correspondências do fluxo consumido com o fluxo produzido.  Realizamos este teste com e sem uma injeção de falha de armazenamento de objeto.  Simulamos uma falha de nó interrompendo o serviço do gerenciador de serviços em um dos nós no ONTAP e validando se a funcionalidade de ponta a ponta funciona com o armazenamento de objetos.</block>
  <block id="2712a580ff4c3586c7ba3534b78aad18" category="section-title">Gerador de carga de trabalho de produção e consumo</block>
  <block id="0c22172129c2d0d58a5685fa1094fca0" category="paragraph">Este teste gera indiretamente carga de trabalho de gravação no armazenamento de objetos por meio do arquivamento de segmentos.  A carga de trabalho de leitura (segmentos lidos) foi gerada a partir do armazenamento de objetos quando grupos de consumidores buscavam os segmentos.  Esta carga de trabalho foi gerada por um script TOCC.  Este teste verificou o desempenho de leitura e gravação no armazenamento de objetos em threads paralelos.  Testamos com e sem injeção de falha de armazenamento de objetos, assim como fizemos para o teste de correção da funcionalidade de camadas.</block>
  <block id="2a7273e52c0214e6f0b27bf1e870960e" category="section-title">Gerador de carga de trabalho de retenção</block>
  <block id="48771387cb6a84889bc1db951598f78c" category="paragraph">Este teste verificou o desempenho de exclusão de um armazenamento de objetos sob uma carga de trabalho pesada de retenção de tópicos.  A carga de trabalho de retenção foi gerada usando um script TOCC que produz muitas mensagens em paralelo a um tópico de teste.  O tópico de teste foi a configuração com uma configuração agressiva de retenção baseada em tamanho e tempo que fazia com que o fluxo de eventos fosse continuamente eliminado do armazenamento de objetos.  Os segmentos foram então arquivados.  Isso levou a muitas exclusões no armazenamento de objetos pelo corretor e à coleta do desempenho das operações de exclusão do armazenamento de objetos.</block>
  <block id="a03d0d99a3287875dda3d19daa736d0c" category="inline-link">Confluente</block>
  <block id="047fb529cf71ef63efe04d4185302684" category="paragraph">Para obter detalhes de verificação, consulte o<block ref="86830f666762f920df1dddf1c71e6509" category="inline-link-rx"></block> site.</block>
  <block id="dbb940c31f0b7d7563745993661f70d4" category="summary">Realizamos testes de armazenamento em camadas com cinco ou oito nós de broker durante uma carga de trabalho de produção e consumo com o controlador de armazenamento NetApp de um par AFF A900 HA.  De acordo com nossos testes, o tempo de conclusão e os resultados de desempenho foram dimensionados com o número de nós do broker até que a utilização de recursos do AFF A900 atingiu cem por cento.  A configuração do controlador de armazenamento ONTAP exigiu no mínimo um par de HA.</block>
  <block id="91e1cb9730965860cb465802520e6a45" category="doc">Testes de desempenho com gerador de carga de trabalho de produção e consumo</block>
  <block id="b15c40872cdd0b1e0a152907f2194e69" category="paragraph">O desempenho da operação de recuperação do S3 aumentou linearmente com base no número de nós do broker Confluent.  O controlador de armazenamento ONTAP suporta até 12 pares de HA em uma única implantação.</block>
  <block id="ec043d5e2714e1035038cbeb1aa3cba8" category="paragraph">O gráfico a seguir mostra o tráfego combinado de camadas S3 com cinco ou oito nós de corretor.  Maximizamos o desempenho do par HA único AFF A900 .</block>
  <block id="ffff2891cfdd07445c4e1e5261739c68" category="inline-image-macro">Este gráfico de dados mostra o tráfego combinado de camadas S3 com cinco ou oito nós de corretores.</block>
  <block id="d1912fadda4ef80cc1a01c7f3f919602" category="paragraph"><block ref="d1912fadda4ef80cc1a01c7f3f919602" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1efe906cedfd00618bda4d39b41a52fd" category="paragraph">O gráfico a seguir mostra a taxa de transferência do Kafka em aproximadamente 31,74 GBps.</block>
  <block id="e7aff80741661a5eb60f57649077f9c5" category="inline-image-macro">Este gráfico de dados mostra a taxa de transferência do Kafka em aproximadamente 31,74 GBps.</block>
  <block id="a9504735d0b0cbb3b424919bb1328a7d" category="paragraph"><block ref="a9504735d0b0cbb3b424919bb1328a7d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6821411dfc3b7f483da21b37082dfc" category="paragraph">Também observamos uma taxa de transferência semelhante no controlador de armazenamento ONTAP<block ref="d40e53103e181690f77a04eadc8aa6cc" prefix=" " category="inline-code"></block> relatório.</block>
  <block id="b0c400a1c1ac5de2cbdc877645b349a0" category="summary">Esta seção aborda o hardware e o software usados para verificação de desempenho na implantação da Confluent Platform com o NetApp ONTAP para armazenamento em camadas.  A tabela a seguir abrange a arquitetura da solução e os componentes básicos.</block>
  <block id="5197b1c9433e86b5ed33786625f77786" category="paragraph">O Confluent e o controlador de armazenamento NetApp AFF A900 com tecnologia ONTAP são sistemas distribuídos projetados para fluxos de dados.  Ambos são escaláveis horizontalmente, tolerantes a falhas e oferecem excelente desempenho sob carga.  Eles se complementam no streaming de dados distribuídos e no processamento de fluxo com custos de armazenamento mais baixos e tecnologias de redução de dados que minimizam a pegada de dados.  O controlador de armazenamento AFF A900 oferece ótimo desempenho, ao mesmo tempo que permite a dissociação de recursos de computação e armazenamento de dados.  Isso simplifica a administração do sistema e permite que os recursos sejam dimensionados de forma independente.</block>
  <block id="8ebef54f33ae0fdc7c4dcb83539b6eac" category="inline-image-macro">Imagem representando a visão geral da solução.</block>
  <block id="c7c06ecce0e6f1e46fab6853d4d45058" category="paragraph"><block ref="c7c06ecce0e6f1e46fab6853d4d45058" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f75094292f4afb812bc29237348d9948" category="cell">Plataforma Confluent versão 6.2</block>
  <block id="5cc4fd015c7740c575d319eefacbce83" category="list-text">3 tratadores de zoológico</block>
  <block id="8f6a506566bd03a47cafb69561bafe0f" category="list-text">8 servidores de corretores</block>
  <block id="aa76981d988c82fc8b387682968887e6" category="list-text">5 x servidores de ferramentas</block>
  <block id="b56d58a9a181bae1fa65f36407ea002c" category="list-text">1 x Grafana</block>
  <block id="4af3adf9207f6f8d2d6d9edda08f0638" category="list-text">1 x centro de controle</block>
  <block id="de4d788671df5cf79fda01236d8fc9a6" category="cell">NetApp ONTAP para buckets quentes</block>
  <block id="37e0c77638b1388d83b997c8dffdb6d3" category="list-text">1 x par de alta disponibilidade (HA) AFF A900</block>
  <block id="2e1c9b5ce764f890af0aebf38f1a500a" category="list-text">100GbE</block>
  <block id="983e16c42b860c2511053f17d60918c8" category="list-text">2 CPUs; 16 núcleos físicos no total</block>
  <block id="ce4750dd79017960eed95bd3b2677eb4" category="list-text">Intel Xeon</block>
  <block id="01dcc4e221fc9ff7472c5102b082eaf4" category="list-text">256 GB de memória física</block>
  <block id="433304c312dd41f05955324749c0a47f" category="list-text">Porta dupla 100GbE</block>
  <block id="b7d338a537a3a1d0186080c4c4ba47eb" category="summary">Esta página descreve a tecnologia usada nesta solução.</block>
  <block id="a1f13b9a0674cc0beb81e208dfb68d05" category="doc">Visão geral da tecnologia</block>
  <block id="7f1512274139985d5f21a72e13808522" category="section-title">Controlador de armazenamento NetApp ONTAP</block>
  <block id="b691cb82ce5ecb3d94f82b73ef3c2219" category="paragraph">O NetApp ONTAP é um sistema operacional de armazenamento de alto desempenho e nível empresarial.</block>
  <block id="f8b80927eb906c831742041c4c139be1" category="paragraph">O NetApp ONTAP 9.8 apresenta suporte para APIs do Amazon Simple Storage Service (S3).  O ONTAP oferece suporte a um subconjunto de ações da API S3 da Amazon Web Services (AWS) e permite que os dados sejam representados como objetos em sistemas baseados em ONTAP em provedores de nuvem (AWS, Azure e GCP) e no local.</block>
  <block id="9496ba5a97ab04d734dc449f86646ffe" category="paragraph">O software NetApp StorageGRID é a principal solução da NetApp para armazenamento de objetos.  O ONTAP complementa o StorageGRID fornecendo um ponto de ingestão e pré-processamento na borda, expandindo a estrutura de dados alimentada pela NetApp para dados de objetos e aumentando o valor do portfólio de produtos da NetApp .</block>
  <block id="d6e8f345bdd21d285f35171c2da8cd3a" category="paragraph">O acesso a um bucket S3 é fornecido por meio de aplicativos de cliente e usuários autorizados.  O diagrama a seguir mostra o aplicativo acessando um bucket S3.</block>
  <block id="a38dfb3b286ff4854c6f5d67ebc15e13" category="inline-image-macro">Este gráfico mostra o aplicativo acessando um bucket S3.</block>
  <block id="185bab9f8946071e86896c051a520617" category="paragraph"><block ref="185bab9f8946071e86896c051a520617" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5088428c842a8d5e45f2e6597af4138" category="section-title">Casos de uso primários</block>
  <block id="5c2f4a513e63ae351e5dc0b7412a43c2" category="paragraph">O objetivo principal do suporte às APIs do S3 é fornecer acesso a objetos no ONTAP.  A arquitetura de armazenamento unificado ONTAP agora oferece suporte a arquivos (NFS e SMB), blocos (FC e iSCSI) e objetos (S3).</block>
  <block id="1af2e65957e458000d1181bb9eba2517" category="section-title">Aplicações nativas S3</block>
  <block id="c0889d6b193afe7d0069e3d99bc5f310" category="paragraph">Um número crescente de aplicativos consegue aproveitar o suporte ONTAP para acesso a objetos usando o S3.  Embora seja adequado para cargas de trabalho de arquivamento de alta capacidade, a necessidade de alto desempenho em aplicativos S3 nativos está crescendo rapidamente e inclui:</block>
  <block id="a768caa988605a2846599cf7e2d0c26a" category="list-text">Análise</block>
  <block id="9d0996a44c6d51cf223e833dceecb286" category="list-text">Inteligência artificial</block>
  <block id="1669cbc398e4228e7e05d6b2e030cbe7" category="list-text">Ingestão de ponta a ponta</block>
  <block id="bd1a4166acf45c62946d7592a64ad52d" category="paragraph">Os clientes agora podem usar ferramentas de gerenciamento conhecidas, como o ONTAP System Manager, para provisionar rapidamente armazenamento de objetos de alto desempenho para desenvolvimento e operações no ONTAP, aproveitando a eficiência e a segurança do armazenamento do ONTAP ao fazer isso.</block>
  <block id="50472ac5cace1b7798b3f92db5c3049e" category="section-title">Pontos de extremidade do FabricPool</block>
  <block id="5050f2389b47df5462550d8e11451e9d" category="paragraph">A partir do ONTAP 9.8, o FabricPool oferece suporte à hierarquização de buckets no ONTAP, permitindo a hierarquização de ONTAP para ONTAP .  Esta é uma excelente opção para clientes que desejam reutilizar a infraestrutura FAS existente como um ponto de extremidade de armazenamento de objetos.</block>
  <block id="10beb552e5ed01d5c890a260a1d6af16" category="paragraph">O FabricPool oferece suporte à hierarquização do ONTAP de duas maneiras:</block>
  <block id="1e53159984d41f5ea848cdf412430a06" category="list-text">*Classificação de cluster local.*  Dados inativos são colocados em camadas em um bucket localizado no cluster local usando LIFs de cluster.</block>
  <block id="08be0ca0511f2294cbbaf9d92327996b" category="list-text">*Classificação de cluster remoto.*  Os dados inativos são colocados em camadas em um bucket localizado em um cluster remoto de maneira semelhante a uma camada de nuvem tradicional do FabricPool usando LIFs de IC no cliente do FabricPool e LIFs de dados no armazenamento de objetos do ONTAP .</block>
  <block id="bda29d8d2c5de29e5ec15858a0f72c79" category="paragraph">O ONTAP S3 é apropriado se você deseja recursos S3 em clusters existentes sem hardware e gerenciamento adicionais.  Para implantações maiores que 300 TB, o software NetApp StorageGRID continua sendo a principal solução da NetApp para armazenamento de objetos.  Uma licença FabricPool não é necessária ao usar ONTAP ou StorageGRID como camada de nuvem.</block>
  <block id="5a7adb78ef640711a870d82123f00775" category="section-title">Armazenamento em camadas NetApp ONTAP para Confluent</block>
  <block id="9a5bc88300f877a695de175398887e0e" category="paragraph">Todo data center precisa manter aplicativos essenciais aos negócios em execução e dados importantes disponíveis e seguros.  O novo sistema NetApp AFF A900 é equipado com o software ONTAP Enterprise Edition e um design de alta resiliência.  Nosso novo sistema de armazenamento NVMe ultrarrápido elimina interrupções em operações de missão crítica, minimiza o ajuste de desempenho e protege seus dados contra ataques de ransomware.</block>
  <block id="42dfa85904e1fd1b7fb41d4278c38047" category="paragraph">Da implantação inicial ao dimensionamento do seu cluster Confluent, seu ambiente exige adaptação rápida a mudanças que não causem interrupções em seus aplicativos essenciais aos negócios.  O gerenciamento de dados empresariais, a qualidade de serviço (QoS) e o desempenho do ONTAP permitem que você planeje e se adapte ao seu ambiente.</block>
  <block id="36509bd95b243830a012c72c8a2d5844" category="paragraph">O uso conjunto do NetApp ONTAP e do Confluent Tiered Storage simplifica o gerenciamento de clusters do Apache Kafka, aproveitando o ONTAP como um destino de armazenamento de expansão e permite o dimensionamento independente de recursos de computação e armazenamento para o Confluent.</block>
  <block id="e09818a7d7d98185cdb0309cf3aca8f5" category="paragraph">Um servidor ONTAP S3 é criado com base nos recursos de armazenamento escaláveis e maduros do ONTAP.  O dimensionamento do seu cluster ONTAP pode ser feito perfeitamente estendendo seus buckets S3 para usar nós recém-adicionados ao cluster ONTAP .</block>
  <block id="1ccfe00aee80492f09968d6b208801d5" category="section-title">Gerenciamento simples com o ONTAP System Manager</block>
  <block id="4fdad8328864e9de2db5338bb25291fc" category="paragraph">O ONTAP System Manager é uma interface gráfica baseada em navegador que permite configurar, gerenciar e monitorar seu controlador de armazenamento ONTAP em locais distribuídos globalmente em um único painel.</block>
  <block id="c99eb67a4e6cbe9ba119a72c95161fab" category="inline-image-macro">Este gráfico mostra o espaço de trabalho do ONTAP System Manager.</block>
  <block id="db8cf11125f7909f889c4894d1b8c042" category="paragraph"><block ref="db8cf11125f7909f889c4894d1b8c042" category="inline-image-macro-rx" type="image"></block></block>
  <block id="783157c9c38b4e88d7eefffe21cd97d3" category="paragraph">Você pode configurar e gerenciar o ONTAP S3 com o System Manager e o ONTAP CLI.  Quando você habilita o S3 e cria buckets usando o Gerenciador do Sistema, o ONTAP fornece padrões de práticas recomendadas para uma configuração simplificada.  Se você configurar o servidor S3 e os buckets da CLI, ainda poderá gerenciá-los com o System Manager, se desejar, ou vice-versa.</block>
  <block id="d1623a9fec2de2642847391236e62e9b" category="paragraph">Ao criar um bucket S3 usando o System Manager, o ONTAP configura um nível de serviço de desempenho padrão que é o mais alto disponível no seu sistema.  Por exemplo, em um sistema AFF , a configuração padrão seria Extremo.  Os níveis de serviço de desempenho são grupos de políticas de QoS adaptativos predefinidos.  Em vez de um dos níveis de serviço padrão, você pode especificar um grupo de políticas de QoS personalizado ou nenhum grupo de políticas.</block>
  <block id="bbcb9e2700fba39c3b7b7fd438155100" category="paragraph">Os grupos de políticas de QoS adaptáveis predefinidos incluem o seguinte:</block>
  <block id="f1ec0b0c482a42bad395f01e7f2b6c1d" category="list-text">*Extremo.*  Usado para aplicativos que exigem a menor latência e o maior desempenho.</block>
  <block id="06e90efc82fff7e3090ba9ff1a3bd2a3" category="list-text">*Desempenho.*  Usado para aplicativos com necessidades de desempenho e latência modestas.</block>
  <block id="7aa0f5702784b1be0a3c5ed9e6f3df8e" category="list-text">*Valor.*  Usado para aplicações em que a taxa de transferência e a capacidade são mais importantes que a latência.</block>
  <block id="113d20f8cc4d864cdfea1b0f611cbb0a" category="list-text">*Personalizado.*  Especifique uma política de QoS personalizada ou nenhuma política de QoS.</block>
  <block id="42cc32e2c7857ba980019c70438e92ed" category="paragraph">Se você selecionar *Usar para camadas*, nenhum nível de serviço de desempenho será selecionado e o sistema tentará selecionar mídia de baixo custo com desempenho ideal para os dados em camadas.</block>
  <block id="5cc287af927b81043d030fc6a1ece879" category="paragraph">O ONTAP tenta provisionar esse bucket em camadas locais que tenham os discos mais apropriados, satisfazendo o nível de serviço escolhido.  No entanto, se você precisar especificar quais discos incluir no bucket, considere configurar o armazenamento de objetos do S3 na CLI especificando as camadas locais (agregadas).  Se você configurar o servidor S3 a partir da CLI, ainda poderá gerenciá-lo com o Gerenciador de Sistema, se desejar.</block>
  <block id="74869eb3dfe4756dab5491da2a3de2ad" category="paragraph">Se você quiser poder especificar quais agregados serão usados para buckets, você só poderá fazer isso usando a CLI.</block>
  <block id="0c0e3a803cf68a8772ebf58a68b20124" category="paragraph">A Confluent Platform é uma plataforma de streaming de dados em grande escala que permite que você acesse, armazene e gerencie dados facilmente como fluxos contínuos e em tempo real.  Desenvolvido pelos criadores originais do Apache Kafka, o Confluent expande os benefícios do Kafka com recursos de nível empresarial, ao mesmo tempo em que elimina o fardo do gerenciamento ou monitoramento do Kafka.  Hoje, mais de 80% das empresas da Fortune 100 são alimentadas por tecnologia de streaming de dados, e a maioria usa Confluent.</block>
  <block id="3bcbf4072ba1e23a48434530e19a485d" category="section-title">Por que Confluent?</block>
  <block id="0fcb60f8560b74a641f556dbf96faf91" category="paragraph">Ao integrar dados históricos e em tempo real em uma única fonte central de verdade, a Confluent facilita a criação de uma categoria inteiramente nova de aplicativos modernos e orientados a eventos, obtém um pipeline de dados universal e desbloqueia novos e poderosos casos de uso com total escalabilidade, desempenho e confiabilidade.</block>
  <block id="f781b7a8a0d145997db9cf8449512bb8" category="section-title">Para que é usado o Confluent?</block>
  <block id="d3c11d67f567698de4c90210b84c554d" category="paragraph">A Confluent Platform permite que você se concentre em como derivar valor comercial dos seus dados em vez de se preocupar com a mecânica subjacente, como a forma como os dados estão sendo transportados ou integrados entre sistemas distintos.  Especificamente, a Confluent Platform simplifica a conexão de fontes de dados ao Kafka, a criação de aplicativos de streaming, bem como a proteção, o monitoramento e o gerenciamento da sua infraestrutura Kafka.  Hoje, a Confluent Platform é usada para uma ampla gama de casos de uso em vários setores, desde serviços financeiros, varejo omnicanal e carros autônomos até detecção de fraudes, microsserviços e IoT.</block>
  <block id="870b2318ccfd123ac0f7e9ef1396d49d" category="paragraph">A figura a seguir mostra os componentes da Plataforma Confluent.</block>
  <block id="9d880468cb22c04bd894fc612814dbab" category="inline-image-macro">Este gráfico mostra os componentes da Plataforma Confluent.</block>
  <block id="e21a51ac4ed645780def5d56f85ac9a8" category="paragraph"><block ref="e21a51ac4ed645780def5d56f85ac9a8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05fafb4336e843d4634bd9ac122177c8" category="section-title">Visão geral da tecnologia de streaming de eventos Confluent</block>
  <block id="51be25b0145a0beca811de24a62b5cb4" category="inline-link">Kafka</block>
  <block id="0139d991fe55319f2e19e039da969fcf" category="paragraph">No centro da Plataforma Confluent está<block ref="66a1a9ec54e6ef0a1c109ad94b972ac9" category="inline-link-rx"></block> , a plataforma de streaming distribuída de código aberto mais popular.  Os principais recursos do Kafka incluem o seguinte:</block>
  <block id="f630f472aeeab8697846e0f1f2f730aa" category="list-text">Publique e assine fluxos de registros.</block>
  <block id="176fc2b349b906f6eb7a8f49c7ce9780" category="list-text">Armazene fluxos de registros de forma tolerante a falhas.</block>
  <block id="6026e29e86fd0ddcb6cba3908f85691f" category="list-text">Processar fluxos de registros.</block>
  <block id="f7ec60663c6d3ee6fd5abe343b34f2b4" category="paragraph">Pronto para uso, o Confluent Platform também inclui Schema Registry, REST Proxy, mais de 100 conectores Kafka pré-criados e ksqlDB.</block>
  <block id="82ff0b3d0476bb8ca2283ff06c017658" category="section-title">Visão geral dos recursos empresariais da plataforma Confluent</block>
  <block id="ed2c640e88db15d474de830703c8783b" category="list-text">*Centro de Controle Confluente.*  Um sistema baseado em interface de usuário para gerenciar e monitorar o Kafka.  Ele permite que você gerencie facilmente o Kafka Connect e crie, edite e gerencie conexões com outros sistemas.</block>
  <block id="da2f1a857a79ec960671ee4c735cc96e" category="list-text">*Confluent para Kubernetes.*  Confluent for Kubernetes é um operador do Kubernetes.  Os operadores do Kubernetes estendem os recursos de orquestração do Kubernetes, fornecendo recursos e requisitos exclusivos para um aplicativo de plataforma específico.  Para a Confluent Platform, isso inclui simplificar bastante o processo de implantação do Kafka no Kubernetes e automatizar tarefas típicas do ciclo de vida da infraestrutura.</block>
  <block id="d63f46631d40c1c76b1a1a46445584aa" category="list-text">*Conectores Kafka Connect.*  Os conectores usam a API do Kafka Connect para conectar o Kafka a outros sistemas, como bancos de dados, armazenamentos de chave-valor, índices de pesquisa e sistemas de arquivos.  O Confluent Hub tem conectores para download para as fontes e coletores de dados mais populares, incluindo versões totalmente testadas e suportadas desses conectores com a Confluent Platform.  Mais detalhes podem ser encontrados<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block> .</block>
  <block id="9103a2961d6b4c593517d3d641763e5c" category="list-text">*Aglomerados autobalanceados.*  Fornece balanceamento de carga automatizado, detecção de falhas e autocorreção.  Ele também fornece suporte para adicionar ou desativar corretores conforme necessário, sem ajuste manual.</block>
  <block id="776a13408286748f8c985c409604e8b6" category="list-text">*Ligação de cluster confluente.*  Conecta clusters diretamente e espelha tópicos de um cluster para outro por meio de uma ponte de link.  A vinculação de clusters simplifica a configuração de implantações de vários datacenters, vários clusters e nuvens híbridas.</block>
  <block id="c1712fa040f6accce664a82ba6d58b94" category="list-text">*Balanceador automático de dados Confluent.*  Monitora seu cluster em busca do número de corretores, do tamanho das partições, do número de partições e do número de líderes dentro do cluster.  Ele permite que você transfira dados para criar uma carga de trabalho uniforme em seu cluster, ao mesmo tempo em que reequilibra o tráfego para minimizar o efeito nas cargas de trabalho de produção durante o rebalanceamento.</block>
  <block id="0f97179e1bb10c15685ca78b035b4956" category="list-text">*Replicador confluente.*  Torna mais fácil do que nunca manter vários clusters Kafka em vários data centers.</block>
  <block id="a409602cf12dbcb436352a95146b6407" category="list-text">*Armazenamento em camadas.*  Oferece opções para armazenar grandes volumes de dados do Kafka usando seu provedor de nuvem favorito, reduzindo assim a carga operacional e os custos.  Com o armazenamento em camadas, você pode manter dados em armazenamento de objetos econômico e escalar corretores somente quando precisar de mais recursos de computação.</block>
  <block id="ce61411f1780c30f58dd5aed90a77ad3" category="list-text">*Cliente JMS Confluent.*  A Confluent Platform inclui um cliente compatível com JMS para Kafka.  Este cliente Kafka implementa a API padrão do JMS 1.1, usando corretores Kafka como backend.  Isso é útil se você tiver aplicativos legados usando JMS e quiser substituir o broker de mensagens JMS existente pelo Kafka.</block>
  <block id="b38f5ff9be3975e499ba273a01035420" category="list-text">*Proxy MQTT Confluent.*  Fornece uma maneira de publicar dados diretamente no Kafka a partir de dispositivos e gateways MQTT sem a necessidade de um broker MQTT no meio.</block>
  <block id="ab05a802c02076dd0f0b419529e71ccd" category="list-text">*Plugins de segurança Confluent.*  Os plugins de segurança Confluent são usados para adicionar recursos de segurança a várias ferramentas e produtos da plataforma Confluent.  Atualmente, há um plugin disponível para o proxy REST do Confluent que ajuda a autenticar as solicitações recebidas e a propagar o principal autenticado para as solicitações ao Kafka.  Isso permite que os clientes proxy REST da Confluent utilizem os recursos de segurança multilocatários do broker Kafka.</block>
  <block id="55cf1a0f0fce69fd543500e5761dd26d" category="section-title">NetApp StorageGRID</block>
  <block id="d82d42ad0a2161d02e1d8ce74ffcf0ab" category="paragraph">O NetApp StorageGRID é uma plataforma de armazenamento de objetos de alto desempenho e econômica.  Ao usar o armazenamento em camadas, a maioria dos dados no Confluent Kafka, que são armazenados no armazenamento local ou no armazenamento SAN do broker, são descarregados para o armazenamento de objetos remoto.  Essa configuração resulta em melhorias operacionais significativas ao reduzir o tempo e o custo de rebalanceamento, expansão ou redução de clusters ou substituição de um broker com falha.  O armazenamento de objetos desempenha um papel importante no gerenciamento de dados que residem na camada de armazenamento de objetos, e é por isso que escolher o armazenamento de objetos correto é importante.</block>
  <block id="3fa5e29e13fc3b3448ca388750ef38f0" category="paragraph">O StorageGRID oferece gerenciamento de dados globais inteligente e orientado por políticas usando uma arquitetura de grade distribuída baseada em nós.  Ele simplifica o gerenciamento de petabytes de dados não estruturados e bilhões de objetos por meio de seu onipresente namespace de objetos globais combinado com recursos sofisticados de gerenciamento de dados.  O acesso a objetos de chamada única se estende por todos os sites e simplifica arquiteturas de alta disponibilidade, ao mesmo tempo em que garante acesso contínuo a objetos, independentemente de interrupções no site ou na infraestrutura.</block>
  <block id="30f28784f61df7a2f8e7069cefea91eb" category="paragraph">A multilocação permite que vários aplicativos de dados corporativos e de nuvem não estruturados sejam atendidos com segurança na mesma grade, aumentando o ROI e os casos de uso do NetApp StorageGRID.  Você pode criar vários níveis de serviço com políticas de ciclo de vida de objetos orientadas por metadados, otimizando durabilidade, proteção, desempenho e localidade em várias regiões geográficas.  Os usuários podem ajustar as políticas de gerenciamento de dados, além de monitorar e aplicar limites de tráfego para se realinhar com o cenário de dados sem interrupções, conforme seus requisitos mudam em ambientes de TI em constante mudança.</block>
  <block id="dc10add739549f11a9f3d6ac44bf7fcc" category="section-title">Gerenciamento simples com Grid Manager</block>
  <block id="494ed2651e6b5b87a49cfe7ab40d5253" category="paragraph">O StorageGRID Grid Manager é uma interface gráfica baseada em navegador que permite configurar, gerenciar e monitorar seu sistema StorageGRID em locais distribuídos globalmente em um único painel.</block>
  <block id="772a64d9b71789d3f7910c440c370541" category="paragraph"><block ref="772a64d9b71789d3f7910c440c370541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3784ac64ff307aaceedbc4045a0d047c" category="paragraph">Você pode executar as seguintes tarefas com a interface do StorageGRID Grid Manager:</block>
  <block id="57d56613e28a4b5b4e9f351d17e228f7" category="list-text">Gerencie repositórios de objetos, como imagens, vídeos e registros, distribuídos globalmente e em escala de petabytes.</block>
  <block id="5865c6ada208cf4e21f121f0d367b25a" category="list-text">Monitore nós e serviços de grade para garantir a disponibilidade dos objetos.</block>
  <block id="e21286be18c417a3042cb53e1dd1e8da" category="list-text">Gerencie o posicionamento de dados de objetos ao longo do tempo usando regras de gerenciamento do ciclo de vida das informações (ILM).  Essas regras controlam o que acontece com os dados de um objeto depois que eles são ingeridos, como eles são protegidos contra perdas, onde os dados do objeto são armazenados e por quanto tempo.</block>
  <block id="5c578eee23496659cea7dda27021c318" category="list-text">Monitore transações, desempenho e operações dentro do sistema.</block>
  <block id="c91fcac1d7192250f9c73d72ad06e051" category="section-title">Políticas de Gestão do Ciclo de Vida da Informação</block>
  <block id="0550f1f7df7311673165b9915b4d10b2" category="paragraph">O StorageGRID tem políticas flexíveis de gerenciamento de dados que incluem manter cópias de réplicas dos seus objetos e usar esquemas de EC (codificação de eliminação) como 2+1 e 4+2 (entre outros) para armazenar seus objetos, dependendo de requisitos específicos de desempenho e proteção de dados.  Como as cargas de trabalho e os requisitos mudam ao longo do tempo, é comum que as políticas de ILM também mudem.  Modificar políticas de ILM é um recurso essencial, permitindo que os clientes do StorageGRID se adaptem ao seu ambiente em constante mudança de forma rápida e fácil.</block>
  <block id="9446a98ad14416153cc4d45ab8b531bf" category="section-title">Desempenho</block>
  <block id="356760a65d5411f2c9f8647f90e50978" category="inline-link-macro">SG5712, SG5760, SG6060 ou SGF6024</block>
  <block id="2ec930774314e7709987603c82825f4b" category="paragraph">O StorageGRID dimensiona o desempenho adicionando mais nós de armazenamento, que podem ser VMs, bare metal ou dispositivos desenvolvidos para esse fim, como o<block ref="585d6d5337b82c3c73a6c04b53fcdd23" category="inline-link-macro-rx"></block> .  Em nossos testes, superamos os principais requisitos de desempenho do Apache Kafka com uma grade de três nós de tamanho mínimo usando o dispositivo SGF6024.  À medida que os clientes escalam seu cluster Kafka com corretores adicionais, eles podem adicionar mais nós de armazenamento para aumentar o desempenho e a capacidade.</block>
  <block id="3eee81ca69cbbee2bec24db63e4dea0d" category="section-title">Configuração do balanceador de carga e do endpoint</block>
  <block id="5b42fd120a40ecd7cc8ac5cdedde8ceb" category="paragraph">Os nós de administração no StorageGRID fornecem a interface de usuário (UI) do Grid Manager e o endpoint da API REST para visualizar, configurar e gerenciar seu sistema StorageGRID , bem como logs de auditoria para rastrear a atividade do sistema.  Para fornecer um ponto de extremidade S3 de alta disponibilidade para o armazenamento em camadas do Confluent Kafka, implementamos o balanceador de carga StorageGRID , que é executado como um serviço em nós de administração e nós de gateway.  Além disso, o balanceador de carga também gerencia o tráfego local e se comunica com o GSLB (Global Server Load Balancing) para ajudar na recuperação de desastres.</block>
  <block id="95ae2f11a98975eca88411c818226d25" category="paragraph">Para aprimorar ainda mais a configuração do endpoint, o StorageGRID fornece políticas de classificação de tráfego incorporadas ao nó de administração, permite monitorar o tráfego da carga de trabalho e aplica vários limites de qualidade de serviço (QoS) às suas cargas de trabalho.  As políticas de classificação de tráfego são aplicadas aos endpoints no serviço StorageGRID Load Balancer para nós de gateway e nós de administração.  Essas políticas podem ajudar na modelagem e monitoramento do tráfego.</block>
  <block id="dca5165744ce2dbf5825f022349ee941" category="section-title">Classificação de tráfego no StorageGRID</block>
  <block id="588db6e460515c5268204303c93a770b" category="paragraph">O StorageGRID tem funcionalidade de QoS integrada.  As políticas de classificação de tráfego podem ajudar a monitorar diferentes tipos de tráfego S3 provenientes de um aplicativo cliente.  Você pode então criar e aplicar políticas para colocar limites nesse tráfego com base na largura de banda de entrada/saída, no número de solicitações simultâneas de leitura/gravação ou na taxa de solicitações de leitura/gravação.</block>
  <block id="75dab812558989436263375877a82fb6" category="paragraph">Apache Kafka é uma implementação de framework de um barramento de software que utiliza processamento de fluxo escrito em Java e Scala.  O objetivo é fornecer uma plataforma unificada, de alto rendimento e baixa latência para lidar com feeds de dados em tempo real.  O Kafka pode se conectar a um sistema externo para exportação e importação de dados por meio do Kafka Connect e fornece fluxos do Kafka, uma biblioteca de processamento de fluxo Java.  O Kafka usa um protocolo binário baseado em TCP que é otimizado para eficiência e depende de uma abstração de "conjunto de mensagens" que agrupa mensagens naturalmente para reduzir a sobrecarga da viagem de ida e volta da rede.  Isso permite operações de disco sequenciais maiores, pacotes de rede maiores e blocos de memória contíguos, permitindo assim que o Kafka transforme um fluxo contínuo de gravações de mensagens aleatórias em gravações lineares.  A figura a seguir descreve o fluxo de dados básico do Apache Kafka.</block>
  <block id="3c061e9fbf92872063da256279195fbb" category="paragraph"><block ref="3c061e9fbf92872063da256279195fbb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c50889322e9d7d913a4218be06b94d9d" category="paragraph">O Kafka armazena mensagens de valor-chave que vêm de um número arbitrário de processos chamados produtores.  Os dados podem ser particionados em diferentes partições dentro de diferentes tópicos.  Dentro de uma partição, as mensagens são estritamente ordenadas por seus deslocamentos (a posição de uma mensagem dentro de uma partição) e indexadas e armazenadas junto com um registro de data e hora.  Outros processos chamados consumidores podem ler mensagens de partições.  Para processamento de fluxo, o Kafka oferece a API Streams, que permite escrever aplicativos Java que consomem dados do Kafka e gravam os resultados de volta no Kafka.  O Apache Kafka também funciona com sistemas de processamento de fluxo externo, como Apache Apex, Apache Flink, Apache Spark, Apache Storm e Apache NiFi.</block>
  <block id="0f13dfad626acfc5a84f5c6d8127cb93" category="paragraph">O Kafka é executado em um cluster de um ou mais servidores (chamados brokers), e as partições de todos os tópicos são distribuídas entre os nós do cluster.  Além disso, as partições são replicadas para vários corretores.  Essa arquitetura permite que o Kafka entregue grandes fluxos de mensagens de forma tolerante a falhas e permitiu que ele substituísse alguns dos sistemas de mensagens convencionais, como Java Message Service (JMS), Advanced Message Queuing Protocol (AMQP) e assim por diante.  Desde a versão 0.11.0.0, o Kafka oferece gravações transacionais, que fornecem exatamente um processamento de fluxo usando a API Streams.</block>
  <block id="a05ab89a0e70d8932f92ff5626b80205" category="paragraph">O Kafka suporta dois tipos de tópicos: regulares e compactados.  Tópicos regulares podem ser configurados com um tempo de retenção ou um limite de espaço.  Se houver registros mais antigos que o tempo de retenção especificado ou se o limite de espaço for excedido para uma partição, o Kafka poderá excluir dados antigos para liberar espaço de armazenamento.  Por padrão, os tópicos são configurados com um tempo de retenção de 7 dias, mas também é possível armazenar dados indefinidamente.  Para tópicos compactados, os registros não expiram com base em limites de tempo ou espaço.  Em vez disso, o Kafka trata mensagens posteriores como atualizações de mensagens mais antigas com a mesma chave e garante nunca excluir a mensagem mais recente por chave.  Os usuários podem excluir mensagens completamente escrevendo uma mensagem de exclusão com o valor nulo para uma chave específica.</block>
  <block id="67510baee28b6897f23f317ea0eec6cd" category="paragraph">Existem cinco APIs principais no Kafka:</block>
  <block id="43437be1fd3e6788160e377194164ab4" category="list-text">*API do produtor.*  Permite que um aplicativo publique fluxos de registros.</block>
  <block id="d4814db3c767fa7cb8ef858faeb32012" category="list-text">*API do consumidor.*  Permite que um aplicativo assine tópicos e processe fluxos de registros.</block>
  <block id="8e4e76f717f8e282710dbe0549551bbc" category="list-text">*API do conector.*  Executa as APIs reutilizáveis de produtor e consumidor que podem vincular os tópicos aos aplicativos existentes.</block>
  <block id="32a74767220f0fd870d75199524522d5" category="list-text">*API de fluxos.*  Esta API converte os fluxos de entrada em saída e produz o resultado.</block>
  <block id="4bb47a81bc800e1fb57bdde2d0945599" category="list-text">*API de administração.*  Usado para gerenciar tópicos, corretores e outros objetos do Kafka.</block>
  <block id="610121f784783393f66b6624cf93dafb" category="paragraph">As APIs de consumidor e produtor são baseadas no protocolo de mensagens Kafka e oferecem uma implementação de referência para clientes consumidores e produtores Kafka em Java.  O protocolo de mensagens subjacente é um protocolo binário que os desenvolvedores podem usar para escrever seus próprios clientes consumidores ou produtores em qualquer linguagem de programação.  Isso desbloqueia o Kafka do ecossistema da Máquina Virtual Java (JVM).  Uma lista de clientes não Java disponíveis é mantida no wiki do Apache Kafka.</block>
  <block id="3b85a5b4b78ed5de8ac5389862ce3d3f" category="section-title">Casos de uso do Apache Kafka</block>
  <block id="21f595a264810e4537696c1280efad57" category="paragraph">O Apache Kafka é mais popular para mensagens, rastreamento de atividades de sites, métricas, agregação de logs, processamento de fluxo, fornecimento de eventos e registro de confirmações.</block>
  <block id="60f50b920903b4049f776062aa5e6cdc" category="list-text">O Kafka tem melhor produtividade, particionamento integrado, replicação e tolerância a falhas, o que o torna uma boa solução para aplicativos de processamento de mensagens em larga escala.</block>
  <block id="0ae69072c472e595412163a07084932c" category="list-text">O Kafka pode reconstruir as atividades de um usuário (visualizações de páginas, pesquisas) em um pipeline de rastreamento como um conjunto de feeds de publicação e assinatura em tempo real.</block>
  <block id="6d9673a2fe148c529c3b2051cfe93896" category="list-text">O Kafka é frequentemente usado para dados de monitoramento operacional.  Isso envolve agregar estatísticas de aplicativos distribuídos para produzir feeds centralizados de dados operacionais.</block>
  <block id="8b8951c427cfdc3f095bb9d556dce00e" category="list-text">Muitas pessoas usam o Kafka como um substituto para uma solução de agregação de logs.  A agregação de log normalmente coleta arquivos de log físicos de servidores e os coloca em um local central (por exemplo, um servidor de arquivos ou HDFS) para processamento.  O Kafka abstrai detalhes de arquivos e fornece uma abstração mais limpa de dados de log ou evento como um fluxo de mensagens.  Isso permite um processamento de menor latência e suporte mais fácil para múltiplas fontes de dados e consumo de dados distribuídos.</block>
  <block id="e9b95314420c3704f19bfa0e922f51d1" category="list-text">Muitos usuários do Kafka processam dados em pipelines de processamento que consistem em vários estágios, nos quais dados de entrada brutos são consumidos de tópicos do Kafka e então agregados, enriquecidos ou transformados em novos tópicos para consumo posterior ou processamento de acompanhamento.  Por exemplo, um pipeline de processamento para recomendar artigos de notícias pode rastrear o conteúdo do artigo de feeds RSS e publicá-lo em um tópico "artigos".  O processamento posterior pode normalizar ou desduplicar esse conteúdo e publicar o conteúdo do artigo limpo em um novo tópico, e um estágio de processamento final pode tentar recomendar esse conteúdo aos usuários.  Esses pipelines de processamento criam gráficos de fluxos de dados em tempo real com base em tópicos individuais.</block>
  <block id="f2bf506d0e67708783f1bc5c0b518527" category="list-text">O sourcing de eventos é um estilo de design de aplicativo no qual as alterações de estado são registradas como uma sequência de registros ordenada por tempo.  O suporte do Kafka para grandes volumes de dados de log armazenados o torna um excelente backend para um aplicativo criado nesse estilo.</block>
  <block id="6a4fef92874e37e1418ff91ed4fda9cd" category="list-text">O Kafka pode servir como um tipo de log de confirmação externo para um sistema distribuído.  O log ajuda a replicar dados entre nós e atua como um mecanismo de ressincronização para nós com falha restaurarem seus dados.  O recurso de compactação de log no Kafka ajuda a dar suporte a esse caso de uso.</block>
  <block id="ca010f92402f8d9066224231329f1128" category="paragraph">A Confluent Platform é uma plataforma pronta para empresas que complementa o Kafka com recursos avançados projetados para ajudar a acelerar o desenvolvimento e a conectividade de aplicativos, permitir transformações por meio do processamento de fluxo, simplificar as operações empresariais em escala e atender a requisitos arquitetônicos rigorosos.  Desenvolvido pelos criadores originais do Apache Kafka, o Confluent expande os benefícios do Kafka com recursos de nível empresarial, ao mesmo tempo em que elimina o fardo do gerenciamento ou monitoramento do Kafka.  Hoje, mais de 80% das empresas da Fortune 100 são alimentadas por tecnologia de streaming de dados, e a maioria delas usa Confluent.</block>
  <block id="6b41836f6be8bfff401751859b6f5561" category="paragraph">A Confluent Platform permite que você se concentre em como extrair valor comercial dos seus dados em vez de se preocupar com a mecânica subjacente, como a forma como os dados estão sendo transportados ou integrados entre sistemas distintos.  Especificamente, a Confluent Platform simplifica a conexão de fontes de dados ao Kafka, a criação de aplicativos de streaming, bem como a proteção, o monitoramento e o gerenciamento da sua infraestrutura Kafka.  Hoje, a Confluent Platform é usada para uma ampla gama de casos de uso em vários setores, desde serviços financeiros, varejo omnicanal e carros autônomos até detecção de fraudes, microsserviços e IoT.</block>
  <block id="774f9746d58ac38abf733a92e4720365" category="paragraph">A figura a seguir mostra os componentes da plataforma Confluent Kafka.</block>
  <block id="4f93c36b7d83350cef38a27356c0d5c9" category="paragraph"><block ref="4f93c36b7d83350cef38a27356c0d5c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95577831087dbd899deb60b296f64a9c" category="section-title">Visão geral da tecnologia de streaming de eventos da Confluent</block>
  <block id="f6d3df755e538ab85e1dffe4e2ef9966" category="paragraph">No centro da Plataforma Confluent está<block ref="67718c59f00d7d04e4868dff5b37db2b" category="inline-link-rx"></block> , a plataforma de streaming distribuída de código aberto mais popular.  Os principais recursos do Kafka são os seguintes:</block>
  <block id="8da3f3354457b244e53f1423a77e8944" category="section-title">Visão geral dos recursos empresariais da plataforma Confluent</block>
  <block id="c7d070206c9b11b02bee9b591736971c" category="list-text">*Centro de Controle Confluente.*  Um sistema baseado em GUI para gerenciar e monitorar o Kafka.  Ele permite que você gerencie facilmente o Kafka Connect e crie, edite e gerencie conexões com outros sistemas.</block>
  <block id="5488a6660d4f7d32995b983624c2e915" category="list-text">*Conectores confluentes para Kafka.*  Os conectores usam a API do Kafka Connect para conectar o Kafka a outros sistemas, como bancos de dados, armazenamentos de chave-valor, índices de pesquisa e sistemas de arquivos.  O Confluent Hub tem conectores para download para as fontes e coletores de dados mais populares, incluindo versões totalmente testadas e suportadas desses conectores com a Confluent Platform.  Mais detalhes podem ser encontrados<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block> .</block>
  <block id="b47dc18271c0f29d64ce1f45f12a053c" category="list-text">*Aglomerados autobalanceados.*  Fornece balanceamento de carga automatizado, detecção de falhas e autocorreção.  Ele fornece suporte para adicionar ou desativar corretores conforme necessário, sem ajuste manual.</block>
  <block id="1e5c2c1a7b1c3f9809e2b97438773325" category="list-text">*Balanceador automático de dados Confluent.*  Monitora seu cluster quanto ao número de corretores, ao tamanho das partições, ao número de partições e ao número de líderes dentro do cluster.  Ele permite que você transfira dados para criar uma carga de trabalho uniforme em seu cluster, ao mesmo tempo em que reequilibra o tráfego para minimizar o efeito nas cargas de trabalho de produção durante o rebalanceamento.</block>
  <block id="e2e44d09263d2131a3697ad71cadb51b" category="doc">NVA-1157-DEPLOY: carga de trabalho do Apache Spark com solução de armazenamento NetApp</block>
  <block id="ddf79baf38c476a90774aad122f73cb5" category="paragraph">NVA-1157-DEPLOY descreve a validação de desempenho e funcionalidade do Apache Spark SQL em sistemas de armazenamento NetApp NFS AFF .  Ele analisa a configuração, a arquitetura e os testes de desempenho com base em vários cenários, bem como recomendações para usar o Spark com o software de gerenciamento de dados NetApp ONTAP .  Ele também abrange resultados de testes baseados em apenas um conjunto de discos (JBOD) em comparação com o controlador de armazenamento NetApp AFF A800 .</block>
  <block id="39234cd00ad225afa457b33c5b2c5957" category="paragraph"><block ref="39234cd00ad225afa457b33c5b2c5957" category="inline-link-macro-rx"></block></block>
  <block id="6a67053961e2b9d7e16bf757a5bea347" category="doc">Análise de dados moderna - Diferentes soluções para diferentes estratégias de análise</block>
  <block id="139dc952e7e6df2bb7d8000f47a42232" category="paragraph">Este white paper descreve as estratégias de soluções modernas de análise de dados da NetApp .  Ele inclui detalhes sobre os resultados de negócios, desafios do cliente, tendências tecnológicas, arquitetura legada da concorrência, fluxos de trabalho modernos, casos de uso, setores, nuvem, parceiros de tecnologia, movimentadores de dados, NetApp Active IQ Digital Advisor (também conhecido como Digital Advisor), NetApp DataOps Toolkit, Hadoop para Spark, armazenamento definido por software com NetApp Trident Protect, contêineres, gerenciamento de dados corporativos, arquivamento e hierarquização para atingir os objetivos de IA e análise e como a NetApp e os clientes estão modernizando juntos sua arquitetura de dados.</block>
  <block id="9a13b1875b1cf906383834093477aa0b" category="paragraph"><block ref="9a13b1875b1cf906383834093477aa0b" category="inline-link-macro-rx"></block></block>
  <block id="b5062caa115b4047ecd2ef0d7177923b" category="paragraph">As seguintes referências foram utilizadas neste TR:</block>
  <block id="7a5b516d0c7b523466aabf4d65c5920e" category="list-text">Arquitetura e componentes do Apache Spark</block>
  <block id="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link"><block ref="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link-rx"></block></block>
  <block id="e37c2ea27f7286c4bd6a5fda415b8de8" category="paragraph"><block ref="e37c2ea27f7286c4bd6a5fda415b8de8" category="inline-link-rx"></block></block>
  <block id="63e2d6091a94e7952a98f50aab0149ce" category="list-text">Casos de uso do Apache Spark</block>
  <block id="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link"><block ref="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link-rx"></block></block>
  <block id="7bc4162d3088ec5f539bb8bccd911d30" category="paragraph"><block ref="7bc4162d3088ec5f539bb8bccd911d30" category="inline-link-rx"></block></block>
  <block id="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link"><block ref="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link-rx"></block></block>
  <block id="4f2faa20c7d825b4d0501e1086305aac" category="paragraph"><block ref="4f2faa20c7d825b4d0501e1086305aac" category="inline-link-rx"></block></block>
  <block id="221c3eff38f8ab54d359694f9da63c6e" category="list-text">BERTO</block>
  <block id="94f39b7b282094c13473d8b26a45d1f1" category="inline-link"><block ref="94f39b7b282094c13473d8b26a45d1f1" category="inline-link-rx"></block></block>
  <block id="aff4ff24147d7c4a2645c7781e081f7f" category="paragraph"><block ref="aff4ff24147d7c4a2645c7781e081f7f" category="inline-link-rx"></block></block>
  <block id="b507f78e88e67a8302f19d731bc75b06" category="list-text">Rede profunda e cruzada para previsões de cliques em anúncios</block>
  <block id="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link"><block ref="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link-rx"></block></block>
  <block id="ae454d032cd3c53237c03ee439566905" category="paragraph"><block ref="ae454d032cd3c53237c03ee439566905" category="inline-link-rx"></block></block>
  <block id="54452390cac5f65f3bcec580ba079531" category="list-text">FlexGroup</block>
  <block id="63e6562f5c9bc7c86f115b960762e586" category="paragraph"><block ref="63e6562f5c9bc7c86f115b960762e586" category="inline-link-rx"></block></block>
  <block id="becd6832ca6f3b6680d480b5802d1435" category="list-text">Transmissão ETL</block>
  <block id="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link"><block ref="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link-rx"></block></block>
  <block id="8d325f57229e685a7ad47c71dd567604" category="paragraph"><block ref="8d325f57229e685a7ad47c71dd567604" category="inline-link-rx"></block></block>
  <block id="31a31ad34b829349beab62dc154bb53c" category="list-text">Soluções NetApp E-Series para Hadoop</block>
  <block id="7cc9f35180bb40054e46d3046347f4fd" category="inline-link"><block ref="7cc9f35180bb40054e46d3046347f4fd" category="inline-link-rx"></block></block>
  <block id="ea07fc98557e1b8c5b675972fe1621da" category="paragraph"><block ref="ea07fc98557e1b8c5b675972fe1621da" category="inline-link-rx"></block></block>
  <block id="3f7d09efe0b4d4a65add41ac272194fd" category="list-text">Soluções modernas de análise de dados da NetApp</block>
  <block id="105db1e1e5e90ed75dc22390638d6b74" category="inline-link-macro">Soluções de análise de dados</block>
  <block id="a1acc25bb8d463a22c069a9ae3d7a581" category="paragraph"><block ref="a1acc25bb8d463a22c069a9ae3d7a581" category="inline-link-macro-rx"></block></block>
  <block id="794cb725c5631ad99b5b7c000307f0df" category="list-text">SnapMirror</block>
  <block id="c932e562e101240deed6e4be0656dfd6" category="inline-link"><block ref="c932e562e101240deed6e4be0656dfd6" category="inline-link-rx"></block></block>
  <block id="750daab11890513d7529766b651ae531" category="paragraph"><block ref="750daab11890513d7529766b651ae531" category="inline-link-rx"></block></block>
  <block id="a7ac1d2e69b9bbb9a2accb2ec30a1d69" category="list-text">XCP</block>
  <block id="e7d54d48522774aa8774f3733414d084" category="inline-link"><block ref="f575d0e12f7a285daadcaf60a35e305e" category="inline-link-rx"></block></block>
  <block id="a0b810672fcf48d5064bdbf73f520d55" category="paragraph"><block ref="d41dfcb87efb2171f45941c801c9f5cc" category="inline-link-rx"></block></block>
  <block id="1ae50adfec05c416d0398e26bea5fc01" category="list-text">BlueXP Copiar e Sincronizar</block>
  <block id="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link"><block ref="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link-rx"></block></block>
  <block id="b8cfbcc5c9748a8f12142a1b9aae0e67" category="paragraph"><block ref="b8cfbcc5c9748a8f12142a1b9aae0e67" category="inline-link-rx"></block></block>
  <block id="ce9b5cd96205262213c417b501e9ed55" category="list-text">Kit de ferramentas DataOps</block>
  <block id="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link"><block ref="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link-rx"></block></block>
  <block id="20a0f3ab42054c3aa4add8c8901b4aa9" category="paragraph"><block ref="20a0f3ab42054c3aa4add8c8901b4aa9" category="inline-link-rx"></block></block>
  <block id="fd79b6614eaf33c0131b98cf6d33aef4" category="summary">Esta página descreve os principais casos de uso e arquiteturas de IA, ML e DL com mais detalhes.</block>
  <block id="029e93fe56123e362c90a853d36c91c9" category="doc">Principais casos de uso e arquiteturas de IA, ML e DL</block>
  <block id="38fe3ee7a8452539638ebb43094bf303" category="paragraph">Os principais casos de uso e metodologia de IA, ML e DL podem ser divididos nas seguintes seções:</block>
  <block id="28ab286fd15a84ffcfa82ffe262b2d07" category="section-title">Pipelines Spark NLP e inferência distribuída TensorFlow</block>
  <block id="b66d8859b0ca8adab0c5459ef44ed90c" category="paragraph">A lista a seguir contém as bibliotecas de PNL de código aberto mais populares que foram adotadas pela comunidade de ciência de dados em diferentes níveis de desenvolvimento:</block>
  <block id="357d19386660ae0694f2fa195678b61a" category="inline-link">Kit de ferramentas de linguagem natural (NLTK)</block>
  <block id="b7c0dd146600af70e881dce2c233cdb9" category="list-text"><block ref="202d1986e5208977bf54b6b767767c39" category="inline-link-rx"></block> . O kit de ferramentas completo para todas as técnicas de PNL.  Ela vem sendo mantida desde o início dos anos 2000.</block>
  <block id="76e3c26aea345cd63928dae30c7683b8" category="inline-link">TextBlob</block>
  <block id="9733a294c2e8cbac3f50f2b1c6165ac9" category="list-text"><block ref="29dbbb204c6bb7c5433e577a001773ba" category="inline-link-rx"></block> . Uma API Python de ferramentas de PNL fácil de usar, construída sobre NLTK e Pattern.</block>
  <block id="b8dc45aaa0db9ddabebf51171beed13a" category="inline-link">Stanford Core NLP</block>
  <block id="e566a3c30415cf2003b1ae965e897b0c" category="list-text"><block ref="3aea58940b1efe70ecaf2254ccc89f1e" category="inline-link-rx"></block> . Serviços e pacotes de PNL em Java desenvolvidos pelo Stanford NLP Group.</block>
  <block id="7013def92af3dd7db98d1285170b5c5a" category="inline-link">Gensim</block>
  <block id="f669b3f1322541dcae0edc94f45435ac" category="list-text"><block ref="7b679f834cae0cff7425a8dc62e2ec2e" category="inline-link-rx"></block> . O Topic Modelling for Humans começou como uma coleção de scripts Python para o projeto da Biblioteca Matemática Digital Tcheca.</block>
  <block id="2840ef6b507856e3306a32ffe28a8886" category="inline-link">SpaCy</block>
  <block id="418cc23cee80079d8aa2ccd37169bfc0" category="list-text"><block ref="bc5121a0541ff390725a7d480b19b87f" category="inline-link-rx"></block> . Fluxos de trabalho de PNL industrial de ponta a ponta com Python e Cython com aceleração de GPU para transformadores.</block>
  <block id="e0b205fce51b69be7136044a22a371ab" category="inline-link">Texto rápido</block>
  <block id="c3ad48f357ddb1f4eb538b483e904fbe" category="list-text"><block ref="53fd0bea11d98e3b7893bc4fbf501c85" category="inline-link-rx"></block> . Uma biblioteca de PNL gratuita, leve e de código aberto para aprendizado de incorporação de palavras e classificação de frases, criada pelo laboratório de pesquisa de IA (FAIR) do Facebook.</block>
  <block id="12680128425c827ef65d76f354329e97" category="inline-link">Spark ML</block>
  <block id="16cbab2d9cd08ef0822a3f68f3792982" category="paragraph">O Spark NLP é uma solução única e unificada para todas as tarefas e requisitos de PNL que permite software de PNL escalável, de alto desempenho e alta precisão para casos de uso de produção real.  Ela aproveita a aprendizagem por transferência e implementa os algoritmos e modelos mais modernos em pesquisas e em todos os setores.  Devido à falta de suporte total do Spark para as bibliotecas acima, o Spark NLP foi construído sobre<block ref="3b3cfa486b6d50798f20e9b1ded08f31" category="inline-link-rx"></block> para aproveitar o mecanismo de processamento de dados distribuídos na memória de uso geral do Spark como uma biblioteca de PNL de nível empresarial para fluxos de trabalho de produção de missão crítica.  Seus anotadores utilizam algoritmos baseados em regras, aprendizado de máquina e TensorFlow para impulsionar implementações de aprendizado profundo.  Isso abrange tarefas comuns de PNL, incluindo, mas não se limitando a tokenização, lematização, definição de radicais, marcação de classes gramaticais, reconhecimento de entidades nomeadas, verificação ortográfica e análise de sentimentos.</block>
  <block id="5f29df192bff436cf72d454f30a968c1" category="paragraph">Representações de codificador bidirecional de transformadores (BERT) é uma técnica de aprendizado de máquina baseada em transformadores para PNL.  Popularizou o conceito de pré-treinamento e ajuste fino.  A arquitetura do transformador no BERT originou-se da tradução automática, que modela dependências de longo prazo melhor do que modelos de linguagem baseados em Redes Neurais Recorrentes (RNN).  Ele também introduziu a tarefa de Modelagem de Linguagem Mascarada (MLM), onde 15% aleatórios de todos os tokens são mascarados e o modelo os prevê, permitindo verdadeira bidirecionalidade.</block>
  <block id="f12fa7d8a39cc8394ad5dfb1afe14bee" category="inline-link">Reuters TRC2</block>
  <block id="3795ebdf5b8232c65a11ceced659b1d5" category="inline-link">Banco de Frases Financeiro</block>
  <block id="189f0cc22e5920c5fbe48e7f7a384fa4" category="inline-link">Explicar Documento DL</block>
  <block id="75396b8f8501a234110f5c2b41e8f2c1" category="paragraph">A análise do sentimento financeiro é desafiadora devido à linguagem especializada e à falta de dados rotulados nesse domínio.  FinBERT, um modelo de linguagem baseado em BERT pré-treinado, foi adaptado ao domínio em<block ref="a21d1b93ad8a312fcc9c56c81567ecca" category="inline-link-rx"></block> , um corpus financeiro e ajustado com dados rotulados (<block ref="14fa31c8eadcc29b01046706cfe3add5" category="inline-link-rx"></block> ) para classificação de sentimento financeiro.  Pesquisadores extraíram 4.500 frases de artigos de notícias com termos financeiros.  Em seguida, 16 especialistas e estudantes de mestrado com formação em finanças rotularam as frases como positivas, neutras e negativas.  Construímos um fluxo de trabalho Spark de ponta a ponta para analisar o sentimento das transcrições de teleconferências sobre os lucros das 10 maiores empresas da NASDAQ de 2016 a 2020 usando FinBERT e dois outros pipelines pré-treinados,<block ref="520f5e4ba9970dad735654cb1f0d1138" category="inline-link-rx"></block> ) do Spark NLP.</block>
  <block id="026dcbbbfad27f6209a41e9dab2f3aed" category="paragraph">O mecanismo de aprendizado profundo subjacente ao Spark NLP é o TensorFlow, uma plataforma de ponta a ponta e de código aberto para aprendizado de máquina que permite a construção fácil de modelos, produção robusta de ML em qualquer lugar e experimentação poderosa para pesquisa.  Portanto, ao executar nossos pipelines no Spark<block ref="cbfea9758df7100c6471e30d3f36d3e1" prefix=" " category="inline-code"></block> modo, estávamos essencialmente executando o TensorFlow distribuído com paralelismo de dados e modelos em um nó mestre e vários nós de trabalho, bem como armazenamento conectado à rede montado no cluster.</block>
  <block id="159bdf3f5d37e56033c6c1736f86b085" category="section-title">Treinamento distribuído Horovod</block>
  <block id="7a2c7ce5896a9e74083af4e2048bb5a8" category="inline-link">Solução NetApp E-Series para Hadoop</block>
  <block id="bd3eac2bb98f840c3e8ec0d92eb9a66f" category="paragraph">A validação principal do Hadoop para desempenho relacionado ao MapReduce é realizada com TeraGen, TeraSort, TeraValidate e DFSIO (leitura e gravação).  Os resultados da validação do TeraGen e do TeraSort são apresentados em<block ref="c276ecb51e19896948b1464a39a504e4" category="inline-link-rx"></block> e na seção "Storage Tiering" para AFF.</block>
  <block id="2c41734dc7928bdea8c2eab845ad7074" category="inline-link">Hovorod no Spark</block>
  <block id="7509c08cb8b336b99de5f0cd33f545fd" category="paragraph">Com base nas solicitações dos clientes, consideramos o treinamento distribuído com Spark um dos mais importantes entre os vários casos de uso.  Neste documento, utilizamos o<block ref="e46884ff7ae14dc4a4c2907aa0145199" category="inline-link-rx"></block> para validar o desempenho do Spark com soluções NetApp locais, nativas da nuvem e de nuvem híbrida usando controladores de armazenamento NetApp All Flash FAS (AFF), Azure NetApp Files e StorageGRID.</block>
  <block id="57b5eacba6da62ec21ea18f95421ef6b" category="paragraph">O pacote Horovod no Spark fornece um wrapper conveniente em torno do Horovod que simplifica a execução de cargas de trabalho de treinamento distribuídas em clusters Spark, permitindo um loop de design de modelo preciso no qual o processamento de dados, o treinamento do modelo e a avaliação do modelo são todos feitos no Spark, onde residem os dados de treinamento e inferência.</block>
  <block id="e556cc2b256f6dd2bbe1cdfdb528c858" category="inline-link">Vendas da loja Kaggle Rossmann</block>
  <block id="f2280eb8ac361218b35f9fc97d4027b4" category="paragraph">Há duas APIs para executar o Horovod no Spark: uma API Estimator de alto nível e uma API Run de nível inferior.  Embora ambos usem o mesmo mecanismo subjacente para iniciar o Horovod nos executores do Spark, a API Estimator abstrai o processamento de dados, o loop de treinamento do modelo, o ponto de verificação do modelo, a coleta de métricas e o treinamento distribuído.  Usamos Horovod Spark Estimators, TensorFlow e Keras para uma preparação de dados de ponta a ponta e um fluxo de trabalho de treinamento distribuído com base no<block ref="d30b6f4a07a765f48b43dd15bf3bc8ea" category="inline-link-rx"></block> concorrência.</block>
  <block id="85cbe9ee50d80a624a5aacb533195f44" category="paragraph">O roteiro<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block> pode ser encontrado na seção<block ref="b6cb6fe53e443d0379ed59c804a7a30d" category="inline-link-macro-rx"></block> Ele contém três partes:</block>
  <block id="1e0ac520c0a0627793f8b0ca3703e8e1" category="list-text">A primeira parte executa várias etapas de pré-processamento de dados em um conjunto inicial de arquivos CSV fornecidos pelo Kaggle e coletados pela comunidade.  Os dados de entrada são separados em um conjunto de treinamento com um<block ref="13148717f8faa9037f37d28971dfc219" prefix=" " category="inline-code"></block> subconjunto e um conjunto de dados de teste.</block>
  <block id="80ee77d4db5b8f731e911e7c47803afa" category="list-text">A segunda parte define um modelo de Rede Neural Profunda (DNN) de Keras com função de ativação sigmoide logarítmica e um otimizador de Adam, e realiza o treinamento distribuído do modelo usando Horovod no Spark.</block>
  <block id="6c32e5a10a8b9f7e225e92b30c4eb494" category="list-text">A terceira parte realiza a previsão no conjunto de dados de teste usando o melhor modelo que minimiza o erro absoluto médio geral do conjunto de validação.  Em seguida, ele cria um arquivo CSV de saída.</block>
  <block id="091fa9121c047db1dd48c3e2ab5f3c91" category="inline-link-macro">Aprendizado de máquina</block>
  <block id="4f57ef43a107778b9d34e7c8fabafb09" category="paragraph">Veja a seção<block ref="c54562cdac0f1ff9f8a09a53f27a34da" category="inline-link-macro-rx"></block> para vários resultados de comparação de tempo de execução.</block>
  <block id="840da3122eba37f84480a8dc769a8cc3" category="section-title">Aprendizado profundo multi-trabalhador usando Keras para previsão de CTR</block>
  <block id="d003b4f5bf1fc42082f5817cb6e961dc" category="paragraph">Com os avanços recentes em plataformas e aplicativos de ML, muita atenção agora está voltada para o aprendizado em escala.  A taxa de cliques (CTR) é definida como o número médio de cliques por cem impressões de anúncios on-line (expresso como uma porcentagem).  Ela é amplamente adotada como uma métrica-chave em vários setores e casos de uso, incluindo marketing digital, varejo, comércio eletrônico e provedores de serviços.  Para obter mais detalhes sobre as aplicações do CTR e os resultados do desempenho do treinamento distribuído, consulte o<block ref="7cd04747490b9545ba139688b057ed31" category="inline-link-macro-rx"></block> seção.</block>
  <block id="45c832c8d01426bfb65d74b7c547ad0c" category="inline-link">Conjunto de dados de registros de cliques de terabytes da Criteo</block>
  <block id="be1115ec919e48805da898209ea2c15a" category="paragraph">Neste relatório técnico, usamos uma variação do<block ref="1a19f40e7660b78c77663f74c89e1e7b" category="inline-link-rx"></block> (consulte TR-4904) para aprendizado profundo distribuído por vários trabalhadores usando Keras para criar um fluxo de trabalho Spark com modelos Deep and Cross Network (DCN), comparando seu desempenho em termos de função de erro de perda de log com um modelo de regressão logística Spark ML de base.  O DCN captura eficientemente interações de recursos eficazes de graus limitados, aprende interações altamente não lineares, não requer engenharia de recursos manual ou pesquisa exaustiva e tem baixo custo computacional.</block>
  <block id="71b755d753dcdba2aeca91b65c167330" category="paragraph">Os dados para sistemas de recomendação em escala da web são, em sua maioria, discretos e categóricos, o que leva a um espaço de recursos grande e esparso, o que é desafiador para a exploração de recursos.  Isso limitou a maioria dos sistemas de larga escala a modelos lineares, como a regressão logística.  No entanto, identificar características frequentemente preditivas e, ao mesmo tempo, explorar características cruzadas raras ou invisíveis é a chave para fazer boas previsões.  Os modelos lineares são simples, interpretáveis e fáceis de escalar, mas são limitados em seu poder expressivo.</block>
  <block id="b5353aa08a1306ca5da9e3faacc66b15" category="paragraph">Por outro lado, recursos transversais demonstraram ser significativos na melhoria da expressividade dos modelos.  Infelizmente, muitas vezes é necessária engenharia de recursos manual ou pesquisa exaustiva para identificar tais recursos.  Generalizar para interações de recursos invisíveis costuma ser difícil.  Usar uma rede neural cruzada como a DCN evita a engenharia de recursos específicos da tarefa ao aplicar explicitamente o cruzamento de recursos de forma automática.  A rede cruzada consiste em múltiplas camadas, onde o maior grau de interações é provavelmente determinado pela profundidade da camada.  Cada camada produz interações de ordem superior com base nas existentes e mantém as interações das camadas anteriores.</block>
  <block id="70725839e7d887ef6f8c815f325d4592" category="paragraph">Uma rede neural profunda (DNN) tem a promessa de capturar interações muito complexas entre recursos.  Entretanto, comparado ao DCN, ele requer quase uma ordem de magnitude a mais de parâmetros, não é capaz de formar recursos cruzados explicitamente e pode falhar em aprender eficientemente alguns tipos de interações de recursos.  A rede cruzada é eficiente em termos de memória e fácil de implementar.  O treinamento conjunto dos componentes cruzados e DNN captura com eficiência interações de recursos preditivos e oferece desempenho de última geração no conjunto de dados CTR da Criteo.</block>
  <block id="2c9e5f067c0c14c56aa757d792108648" category="inline-link">DeepCTR</block>
  <block id="c024a57f5a6b531b69123f5c78627fb9" category="paragraph">Um modelo DCN começa com uma camada de incorporação e empilhamento, seguida por uma rede cruzada e uma rede profunda em paralelo.  Estes, por sua vez, são seguidos por uma camada de combinação final que combina as saídas das duas redes.  Seus dados de entrada podem ser um vetor com recursos esparsos e densos.  No Spark, as bibliotecas contêm o tipo<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block> .  Portanto, é importante que os usuários diferenciem os dois e tenham cuidado ao chamar suas respectivas funções e métodos.  Em sistemas de recomendação em escala web, como a previsão de CTR, as entradas são principalmente características categóricas, por exemplo<block ref="f296a99dd35f7e3e83183f98a62982bf" prefix=" " category="inline-code"></block> .  Tais características são frequentemente codificadas como vetores one-hot, por exemplo,<block ref="05b38799fb2e84c83a72d68e1cb6ff67" prefix=" " category="inline-code"></block> .  Codificação one-hot (OHE) com<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block> é útil ao lidar com conjuntos de dados do mundo real com vocabulários em constante mudança e crescimento.  Nós modificamos exemplos em<block ref="0be922124247f224cab64b030781eed7" category="inline-link-rx"></block> para processar vocabulários grandes, criando vetores de incorporação na camada de incorporação e empilhamento do nosso DCN.</block>
  <block id="565d2d07d9c220babb78adab27c2243a" category="inline-link">Conjunto de dados de anúncios gráficos da Criteo</block>
  <block id="75253ebc28edb897ef33f95dd995dd58" category="paragraph">O<block ref="8cb83117ecfa6e6678785dbda34d1999" category="inline-link-rx"></block> prevê a taxa de cliques dos anúncios.  Ele tem 13 características inteiras e 26 características categóricas, nas quais cada categoria tem uma alta cardinalidade.  Para este conjunto de dados, uma melhoria de 0,001 na perda logarítmica é praticamente significativa devido ao grande tamanho de entrada.  Uma pequena melhoria na precisão da previsão para uma grande base de usuários pode potencialmente levar a um grande aumento na receita de uma empresa.  O conjunto de dados contém 11 GB de registros de usuários de um período de 7 dias, o que equivale a cerca de 41 milhões de registros.  Nós usamos Spark<block ref="26ef62452ce5167b94d9bf8e4552df44" prefix=" " category="inline-code"></block> dividir aleatoriamente os dados para treinamento (80%), validação cruzada (10%) e os 10% restantes para teste.</block>
  <block id="e871e132ed2e9c6d6213da57972adec1" category="paragraph">O DCN foi implementado no TensorFlow com Keras.  Há quatro componentes principais na implementação do processo de treinamento de modelo com DCN:</block>
  <block id="18aca2eb061782e34fcc772d780e4327" category="list-text">*Processamento e incorporação de dados.*  Os recursos de valor real são normalizados pela aplicação de uma transformação logarítmica.  Para recursos categóricos, incorporamos os recursos em vetores densos de dimensão 6×(cardinalidade da categoria)1/4.  Concatenar todos os embeddings resulta em um vetor de dimensão 1026.</block>
  <block id="190befa8188b0e07126d23d7488e79e7" category="list-text">*Otimização.*  Aplicamos otimização estocástica de minilote com o otimizador Adam.  O tamanho do lote foi definido como 512.  A normalização em lote foi aplicada à rede profunda e a norma de corte de gradiente foi definida em 100.</block>
  <block id="023b8b252258fa415118862dec994bbf" category="list-text">*Regularização.*  Usamos a parada antecipada, pois a regularização ou o abandono da L2 não se mostraram eficazes.</block>
  <block id="5f7ce3c44b690052b88504fd4c0ff7bb" category="list-text">*Hiperparâmetros.*  Relatamos resultados com base em uma pesquisa de grade sobre o número de camadas ocultas, o tamanho da camada oculta, a taxa de aprendizado inicial e o número de camadas cruzadas.  O número de camadas ocultas variou de 2 a 5, com tamanhos de camadas ocultas variando de 32 a 1024.  Para DCN, o número de camadas cruzadas foi de 1 a 6.  A taxa de aprendizagem inicial foi ajustada de 0,0001 para 0,001 com incrementos de 0,0001.  Todos os experimentos aplicaram parada antecipada na etapa de treinamento 150.000, além da qual o overfitting começou a ocorrer.</block>
  <block id="a5203fd5d2ee4a156e177b2b5b5ecb45" category="inline-link">DeepFM</block>
  <block id="43d5f147547ecf24ebc038feb06a8312" category="inline-link">AutoInt</block>
  <block id="79249d5f44965bf593f3105190bac784" category="inline-link">DCN v2</block>
  <block id="edddedbe12bade5d0d47c6600aa7fc40" category="paragraph">Além do DCN, também testamos outros modelos populares de aprendizado profundo para previsão de CTR, incluindo<block ref="256b68047e4850e72fc6a1a263d88e86" category="inline-link-rx"></block> ,<block ref="a61c3ddacc920697ed1145d7ed359d25" category="inline-link-rx"></block> , e<block ref="8b59d0e884bf752e43135b866516c089" category="inline-link-rx"></block> .</block>
  <block id="408be753ce98edae615db82036085d63" category="section-title">Arquiteturas usadas para validação</block>
  <block id="2150013c97241fde077622292dd996b4" category="paragraph">Para esta validação, usamos quatro nós de trabalho e um nó mestre com um par AFF-A800 HA.  Todos os membros do cluster estavam conectados por meio de switches de rede de 10 GbE.</block>
  <block id="de404d7688ac5c78348bfea711a12792" category="paragraph">Para esta validação da solução NetApp Spark, usamos três controladores de armazenamento diferentes: o E5760, o E5724 e o AFF-A800.  Os controladores de armazenamento da série E foram conectados a cinco nós de dados com conexões SAS de 12 Gbps.  O controlador de armazenamento AFF HA-pair fornece volumes NFS exportados por meio de conexões de 10 GbE para nós de trabalho do Hadoop.  Os membros do cluster Hadoop foram conectados por meio de conexões de 10 GbE nas soluções Hadoop E-Series, AFF e StorageGRID .</block>
  <block id="f3952bdea9a512245a3b2e368bdd17a4" category="inline-image-macro">Arquiteturas usadas para validação.</block>
  <block id="dbb9fda021247ba28b40c95fcf20d529" category="paragraph"><block ref="dbb9fda021247ba28b40c95fcf20d529" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dce4db89f623baec1071c07c6784f4b1" category="summary">Um data center empresarial moderno é uma nuvem híbrida que conecta vários ambientes de infraestrutura distribuída por meio de um plano de gerenciamento de dados contínuo com um modelo operacional consistente, no local e/ou em várias nuvens públicas.  Para aproveitar ao máximo uma nuvem híbrida, você precisa ser capaz de mover dados facilmente entre seus ambientes locais e de várias nuvens, sem a necessidade de conversões de dados ou refatoração de aplicativos.</block>
  <block id="e27d277adca53504bfe79d8a5e7c2084" category="doc">Solução de nuvem híbrida</block>
  <block id="9cf7905c60934870d86a546076b272e4" category="paragraph">Os clientes indicaram que iniciam sua jornada para a nuvem híbrida movendo o armazenamento secundário para a nuvem para casos de uso como proteção de dados ou movendo cargas de trabalho menos críticas aos negócios, como desenvolvimento de aplicativos e DevOps para a nuvem.  Eles então passam para cargas de trabalho mais críticas.  Hospedagem de conteúdo e web, DevOps e desenvolvimento de aplicativos, bancos de dados, análises e aplicativos em contêineres estão entre as cargas de trabalho de nuvem híbrida mais populares.  A complexidade, o custo e os riscos dos projetos de IA empresarial historicamente dificultaram a adoção da IA do estágio experimental até a produção.</block>
  <block id="38ddba87301d0e027f020fd24b8a5ade" category="paragraph">Com uma solução de nuvem híbrida da NetApp , os clientes se beneficiam de ferramentas integradas de segurança, governança de dados e conformidade com um único painel de controle para gerenciamento de dados e fluxo de trabalho em ambientes distribuídos, ao mesmo tempo em que otimizam o custo total de propriedade com base em seu consumo.  A figura a seguir é um exemplo de solução de um parceiro de serviço de nuvem encarregado de fornecer conectividade multinuvem para dados de análise de big data dos clientes.</block>
  <block id="10ebc90118ac5ab60f289bf34b75d978" category="inline-image-macro">Exemplo de solução de um parceiro de serviço em nuvem.</block>
  <block id="f6eb8b15960b6dcbfd7e927644b45d94" category="paragraph"><block ref="f6eb8b15960b6dcbfd7e927644b45d94" category="inline-image-macro-rx" type="image"></block></block>
  <block id="207f35bf95973770d860aeee0abe32a2" category="paragraph">Neste cenário, os dados de IoT recebidos na AWS de diferentes fontes são armazenados em um local central no NetApp Private Storage (NPS).  O armazenamento NPS é conectado a clusters Spark ou Hadoop localizados na AWS e no Azure, permitindo que aplicativos de análise de big data sejam executados em várias nuvens acessando os mesmos dados.  Os principais requisitos e desafios para este caso de uso incluem o seguinte:</block>
  <block id="bf871745f8e53cd8c13aca4c2ae67522" category="list-text">Os dados devem ser recebidos de diferentes fontes, como ambientes locais e de nuvem, por meio de diferentes sensores e hubs.</block>
  <block id="cb1726ae6d68d40c3bc9861c2b26a1a0" category="list-text">A solução deve ser eficiente e econômica.</block>
  <block id="6dc7db5e9c1da14f7d61e2a7f4428219" category="list-text">O principal desafio é criar uma solução econômica e eficiente que ofereça serviços de análise híbridos entre diferentes ambientes locais e na nuvem.</block>
  <block id="cc4772ffa75dd53e0fb87df4b15528cd" category="paragraph">Nossa solução de proteção de dados e conectividade multinuvem resolve o problema de ter aplicativos de análise de nuvem em vários hiperescaladores.  Conforme mostrado na figura acima, os dados dos sensores são transmitidos e ingeridos no cluster do AWS Spark por meio do Kafka.  Os dados são armazenados em um compartilhamento NFS que reside no NPS, que está localizado fora do provedor de nuvem, dentro de um data center da Equinix.</block>
  <block id="88971c24837a2734fa58ba8805336328" category="paragraph">Como o NetApp NPS está conectado ao Amazon AWS e ao Microsoft Azure por meio de conexões Direct Connect e Express Route, respectivamente, os clientes podem aproveitar o In-Place Analytics Module para acessar os dados dos clusters de análise da Amazon e da AWS.  Consequentemente, como tanto o armazenamento local quanto o NPS executam software ONTAP ,<block ref="fcca72a796080b3a5e2b7b1394bd00ad" category="inline-link-rx"></block> pode espelhar os dados do NPS no cluster local, fornecendo análises de nuvem híbrida no local e em várias nuvens.</block>
  <block id="bc35f58684dbedfb73dd7ff64a4bd5a8" category="paragraph">Para obter o melhor desempenho, a NetApp normalmente recomenda o uso de várias interfaces de rede e conexão direta ou rotas expressas para acessar os dados de instâncias de nuvem.  Temos outras soluções de movimentação de dados, incluindo<block ref="0adb843c17d646acd72646e9688dde2b" category="inline-link-rx"></block> e<block ref="079cab06c3947ff50532e4e825fc7b2c" category="inline-link-rx"></block> para ajudar os clientes a criar clusters Spark de nuvem híbrida, seguros, econômicos e com reconhecimento de aplicativos.</block>
  <block id="cfb5f1c014066f18d7979fa1d35a934d" category="paragraph">Os três scripts Python a seguir correspondem aos três principais casos de uso testados.  O primeiro é<block ref="b01d528ada3b5a6e0e9094642b727562" prefix=" " category="inline-code"></block> .</block>
  <block id="d3abf6f12cafa2cc1b795b31cd547c75" category="paragraph">O segundo script é<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block> .</block>
  <block id="6e9120b39f924b2eed528e3bcdd009ac" category="paragraph">O terceiro script é<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block> .</block>
  <block id="90f0f970ed32524c528ba2778079d485" category="summary">A NetApp tem três portfólios de armazenamento: FAS/ AFF, E-Series e Cloud Volumes ONTAP.  Validamos o AFF e o E-Series com sistema de armazenamento ONTAP para soluções Hadoop com Apache Spark.  A estrutura de dados alimentada pela NetApp integra serviços e aplicativos de gerenciamento de dados (blocos de construção) para acesso, controle, proteção e segurança de dados.</block>
  <block id="12a9f57585cd6b3b985dd451bf552845" category="doc">Visão geral das soluções NetApp Spark</block>
  <block id="c7516072fbed3396e6f4c39a5f2356a6" category="paragraph">A NetApp tem três portfólios de armazenamento: FAS/ AFF, E-Series e Cloud Volumes ONTAP.  Validamos o AFF e o E-Series com sistema de armazenamento ONTAP para soluções Hadoop com Apache Spark.</block>
  <block id="710b54a5dd637d8e21574c4fb3eea545" category="inline-image-macro">A estrutura de dados fornece serviços e aplicativos de gerenciamento de dados.</block>
  <block id="6370a459d17d7eda9502b6008ad71b4a" category="paragraph"><block ref="6370a459d17d7eda9502b6008ad71b4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829a597c83ae2b02e991f062bb891ace" category="list-text">* Acesso direto ao NetApp NFS.*  Fornece os clusters Hadoop e Spark mais recentes com acesso direto aos volumes NetApp NFS sem requisitos adicionais de software ou driver.</block>
  <block id="d075304bce816c2722d405cac9bf4877" category="list-text">* Tecnologia NetApp SnapMirror .*  Fornece recursos de proteção de dados entre instâncias locais e ONTAP Cloud ou NPS.</block>
  <block id="bd162abba0390e6a6e2e2581d449bf77" category="paragraph">A figura a seguir descreve a solução Spark com armazenamento NetApp .</block>
  <block id="0ec1ecf37e474c5f4116ab4ae95e84d9" category="inline-image-macro">Solução Spark com armazenamento NetApp .</block>
  <block id="2c73cc344c9ea7b4fbe0e5179bb17d5a" category="paragraph"><block ref="2c73cc344c9ea7b4fbe0e5179bb17d5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e58a24b49fbb76272d712aaabf465bf7" category="paragraph">A solução ONTAP Spark usa o protocolo de acesso direto NetApp NFS para análises no local e fluxos de trabalho de IA, ML e DL usando acesso a dados de produção existentes.  Os dados de produção disponíveis para os nós do Hadoop são exportados para executar tarefas analíticas e de IA, ML e DL no local.  Você pode acessar dados para processar em nós do Hadoop com acesso direto ao NetApp NFS ou sem ele.  No Spark com o autônomo ou<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> gerenciador de cluster, você pode configurar um volume NFS usando<block ref="806400a5eefaa4811c63e2b45a736984" prefix=" " category="inline-code"></block> .  Validamos três casos de uso com diferentes conjuntos de dados.  Os detalhes dessas validações são apresentados na seção "Resultados dos testes".  (referência externa)</block>
  <block id="955ae639ea2500f38215e8263610b119" category="paragraph">A figura a seguir descreve o posicionamento do armazenamento do NetApp Apache Spark/Hadoop.</block>
  <block id="78157b6c5aece6e0b7b7ea998dce3a8a" category="inline-image-macro">Posicionamento de armazenamento do NetApp Apache Spark/Hadoop.</block>
  <block id="8e32cf48ce4f12a61f456b3ec41a7e21" category="paragraph"><block ref="8e32cf48ce4f12a61f456b3ec41a7e21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cf3adbf38f17f8e0c86c8531fc379b7" category="paragraph">Identificamos os recursos exclusivos da solução E-Series Spark, da solução AFF/ FAS ONTAP Spark e da solução StorageGRID Spark, e realizamos validação e testes detalhados.  Com base em nossas observações, a NetApp recomenda a solução E-Series para instalações greenfield e novas implantações escaláveis e a solução AFF/ FAS para análises no local, cargas de trabalho de IA, ML e DL usando dados NFS existentes, e StorageGRID para IA, ML e DL e análises de dados modernas quando o armazenamento de objetos for necessário.</block>
  <block id="675ed5324aa6eda280e015498c583161" category="inline-image-macro">Soluções NetApp recomendadas para Spark.</block>
  <block id="32530ebcaeef5cc30a605229e26ea933" category="paragraph"><block ref="32530ebcaeef5cc30a605229e26ea933" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa7b20f32446fa30f765cd0b1ca93739" category="paragraph">Um data lake é um repositório de armazenamento para grandes conjuntos de dados em formato nativo que pode ser usado para tarefas de análise, IA, ML e DL.  Criamos um repositório de data lake para as soluções Spark E-Series, AFF/ FAS e StorageGRID SG6060.  O sistema E-Series fornece acesso HDFS ao cluster Hadoop Spark, enquanto os dados de produção existentes são acessados por meio do protocolo de acesso direto NFS ao cluster Hadoop.  Para conjuntos de dados que residem no armazenamento de objetos, o NetApp StorageGRID fornece acesso seguro S3 e S3a.</block>
  <block id="881214767967db331c99550277ceb793" category="summary">Esta página descreve a arquitetura do Splunk, incluindo definições principais, implantações distribuídas do Splunk, Splunk SmartStore, fluxo de dados, requisitos de hardware e software, requisitos de sites únicos e múltiplos e assim por diante.</block>
  <block id="1e6ade59f7284c0bca28eaeeeeed0a30" category="doc">Arquitetura Splunk</block>
  <block id="3924240363e47a4a292119abc4a993a1" category="paragraph">Esta seção descreve a arquitetura do Splunk, incluindo definições principais, implantações distribuídas do Splunk, Splunk SmartStore, fluxo de dados, requisitos de hardware e software, requisitos de sites únicos e múltiplos e assim por diante.</block>
  <block id="a8449bda57f23b9282f766113987bdf2" category="section-title">Definições principais</block>
  <block id="56eee8e9cc278d0a414a6d5697a4675f" category="paragraph">As próximas duas tabelas listam os componentes Splunk e NetApp usados na implantação distribuída do Splunk.</block>
  <block id="5078bea36734bcaa4a0c1e3a0e6e4606" category="paragraph">Esta tabela lista os componentes de hardware do Splunk para a configuração distribuída do Splunk Enterprise.</block>
  <block id="5e536c35aec296fa99efa02703d1eb07" category="cell">Componente Splunk</block>
  <block id="eaeb30f9f18e0c50b178676f3eaef45f" category="cell">Tarefa</block>
  <block id="84f200201a8fe699d8d701c940bade8e" category="cell">Indexador</block>
  <block id="a5aa1df4c3c47c407c84c66303cf0ece" category="cell">Repositório para dados do Splunk Enterprise</block>
  <block id="872c8a2437dfbfa5be0882eabc86bcd3" category="cell">Despachante universal</block>
  <block id="66d25b75f626d8f6c535a4b4d25c9906" category="cell">Responsável por ingerir dados e encaminhá-los aos indexadores</block>
  <block id="c91b59f2eae5ebf309d600609f87a36f" category="cell">Cabeçalho de pesquisa</block>
  <block id="5873147385b9bd833ffd9a046374c97b" category="cell">O front-end do usuário usado para pesquisar dados em indexadores</block>
  <block id="a6230a0628a31d41191b4ef7800745ed" category="cell">Mestre do cluster</block>
  <block id="e4ae9d4eb2313305a17cde160f405a17" category="cell">Gerencia a instalação de indexadores e cabeçalhos de pesquisa do Splunk</block>
  <block id="805ac84d9852820feaf2e2b643a07efb" category="cell">Console de monitoramento</block>
  <block id="5cf5006c1d7fdc954614a4e4185a2c62" category="cell">Ferramenta de monitoramento centralizada usada em toda a implantação</block>
  <block id="fdccec582408614d1e2f7428910b1c8f" category="cell">Mestre de licença</block>
  <block id="7c3b9b8892864eb6fa5cb2a32b85cc93" category="cell">O mestre de licenças lida com o licenciamento do Splunk Enterprise</block>
  <block id="06262b5ad14fe5851defa5b0b70c86c6" category="cell">Servidor de implantação</block>
  <block id="ebe1fa5d8a359a6db13876ab1142fa50" category="cell">Atualiza configurações e distribui aplicativos para o componente de processamento</block>
  <block id="4fabea287d13a082b71f046f9d8be91d" category="cell">Componente de armazenamento</block>
  <block id="8bf5bd6530ea430a8edac8a795165179" category="cell">NetApp AFF</block>
  <block id="b1edd0b37872fd00feb3bb2738987b41" category="cell">Armazenamento all-flash usado para gerenciar dados de nível ativo.  Também conhecido como armazenamento local.</block>
  <block id="518d90155e7eb8bf96c6b7852ba519a6" category="cell">Armazenamento de objetos S3 usado para gerenciar dados da camada quente.  Usado pelo SmartStore para mover dados entre as camadas quente e morna.  Também conhecido como armazenamento remoto.</block>
  <block id="310a27e25811a8eca9b6e5edd921a267" category="paragraph">Esta tabela lista os componentes na arquitetura de armazenamento do Splunk.</block>
  <block id="40f14800d20c9cecbec85dbb2cf35592" category="cell">Componente responsável</block>
  <block id="a5847d984bf6ac525e00b95b93be4e94" category="cell">Loja Inteligente</block>
  <block id="6b64d740ca8627e515d54827d95bc7cb" category="cell">Fornece aos indexadores a capacidade de hierarquizar dados do armazenamento local para o armazenamento de objetos.</block>
  <block id="2f9304fe9b427489507405bef9a0bb9f" category="cell">Splunk</block>
  <block id="4194726ee334e1085d93e002837b73f0" category="cell">Quente</block>
  <block id="cc42c7d2fb33f9ccc06f2e23486a9b0e" category="cell">O ponto de aterrissagem onde os encaminhadores universais colocam os dados recém-gravados.  O armazenamento é gravável e os dados são pesquisáveis.  Essa camada de dados normalmente é composta de SSDs ou HDDs rápidos.</block>
  <block id="253b40ae359ba25b56231803430c4873" category="cell">ONTAP</block>
  <block id="f156996831cd546988bf05451ede7b02" category="cell">Gerenciador de Cache</block>
  <block id="52520fc1f4cef574661d086d8efcb1f8" category="cell">Gerencia o cache local de dados indexados, busca dados importantes do armazenamento remoto quando ocorre uma pesquisa e remove os dados usados com menos frequência do cache.</block>
  <block id="18297117d3d251afceed9ecbe797c849" category="cell">Esquentar</block>
  <block id="810be2ef6ffed5e543f948bf5984d544" category="cell">Os dados são transferidos logicamente para o bucket e renomeados primeiro para a camada quente a partir da camada quente.  Os dados dentro desta camada são protegidos e, assim como na camada ativa, podem ser compostos de SSDs ou HDDs de maior capacidade.  Backups incrementais e completos são suportados usando soluções comuns de proteção de dados.</block>
  <block id="7cf9c58117f9052c5d5a43b3add7f6a4" category="section-title">Implantações distribuídas do Splunk</block>
  <block id="11c2b5859cb0c1d37b40f8df716542e2" category="paragraph">Para dar suporte a ambientes maiores nos quais os dados se originam em muitas máquinas, você precisa processar grandes volumes de dados.  Se muitos usuários precisarem pesquisar os dados, você poderá dimensionar a implantação distribuindo instâncias do Splunk Enterprise em várias máquinas.  Isso é conhecido como implantação distribuída.</block>
  <block id="113f0bd975880424e2c87874233b2afb" category="paragraph">Em uma implantação distribuída típica, cada instância do Splunk Enterprise executa uma tarefa especializada e reside em uma das três camadas de processamento correspondentes às principais funções de processamento.</block>
  <block id="ac31b29e5bbd68654aeb200e66227fb8" category="paragraph">A tabela a seguir lista os níveis de processamento do Splunk Enterprise.</block>
  <block id="9483f17a69bd0b52dbc44f9106718634" category="cell">Nível</block>
  <block id="2cb05e4bb7830be982f0922fed86b4cd" category="cell">Componente</block>
  <block id="b5a7adde1af5c87d7fd797b6245c2a39" category="cell">Descrição</block>
  <block id="7d38267cdf833b2983d3487954ebf88e" category="cell">Entrada de dados</block>
  <block id="2d361d5fe6d74b7550e0aa35d94342ec" category="cell">Despachante</block>
  <block id="b2eebf5023a2a2ba3b35711069723656" category="cell">Um encaminhador consome dados e depois os encaminha para um grupo de indexadores.</block>
  <block id="521d4edc7c22d5f63bc5912ff2afa61a" category="cell">Indexação</block>
  <block id="65265b43bef75c5bacc53c21e38eb8fc" category="cell">Um indexador indexa dados de entrada que normalmente recebe de um grupo de encaminhadores.  O indexador transforma os dados em eventos e armazena os eventos em um índice.  O indexador também pesquisa os dados indexados em resposta às solicitações de pesquisa de um cabeçalho de pesquisa.</block>
  <block id="ff5b0dc94726e93d5db5cf7922183f2b" category="cell">Gerenciamento de pesquisa</block>
  <block id="d4c174b1ebc77694020097497547d218" category="cell">Um cabeçalho de pesquisa serve como um recurso central para pesquisa.  Os cabeçalhos de pesquisa em um cluster são intercambiáveis e têm acesso às mesmas pesquisas, painéis, objetos de conhecimento e assim por diante, de qualquer membro do cluster de cabeçalhos de pesquisa.</block>
  <block id="86f51d8f8fa8928e0f6ddba31139676e" category="paragraph">A tabela a seguir lista os componentes importantes usados em um ambiente distribuído do Splunk Enterprise.</block>
  <block id="dee8af298acfc4c4bcb9fda657125917" category="cell">Responsabilidade</block>
  <block id="3b656ff8459bec2d80d19d367bd71d19" category="cell">Mestre do cluster de índice</block>
  <block id="407a3e34682f31b649e8cbd865fdf50c" category="cell">Coordena atividades e atualizações de um cluster de indexadores</block>
  <block id="dad2f7ca532f008e8192d418406da758" category="cell">Gestão de índices</block>
  <block id="85ba71585b2b8c323c8eb899fa033227" category="cell">Cluster de índice</block>
  <block id="f13c7b75bef35de7c42cc0569f76e366" category="cell">Grupo de indexadores Splunk Enterprise configurados para replicar dados entre si</block>
  <block id="f8b32f50f478eb80dca360b13aa78e92" category="cell">Implantador de cabeça de pesquisa</block>
  <block id="9f45bd6fe25c3f5597af0f46bfdb20db" category="cell">Lida com a implantação e atualizações no mestre do cluster</block>
  <block id="bc2eef462c1a0c8b778b607c304ba877" category="cell">Gerenciamento de cabeçalho de pesquisa</block>
  <block id="58f4a17edb05ffec840bf2b176bf6eca" category="cell">Cluster de cabeçalho de pesquisa</block>
  <block id="70f36c7a653c3724df8921edce177b22" category="cell">Grupo de cabeças de pesquisa que serve como um recurso central para pesquisa</block>
  <block id="2ddcaa7e88a6ad9c095422ca4e601d85" category="cell">Balanceadores de carga</block>
  <block id="fe613dab61d63209235cf49513b00d8a" category="cell">Usado por componentes agrupados para lidar com a demanda crescente de cabeçalhos de pesquisa, indexadores e destino S3 para distribuir a carga entre os componentes agrupados.</block>
  <block id="184f98cf6a6dd19d0815179e63be4298" category="cell">Gerenciamento de carga para componentes em cluster</block>
  <block id="e32d50596edede1bfe3978d8b7b5c5ac" category="paragraph">Veja os seguintes benefícios das implantações distribuídas do Splunk Enterprise:</block>
  <block id="9431943c093a5cc181eccd505ca50f4c" category="list-text">Acesse fontes de dados diversas ou dispersas</block>
  <block id="e825b2fa62f5af51541982cc503c8825" category="list-text">Fornece funcionalidade para lidar com as necessidades de dados de empresas de qualquer tamanho e complexidade</block>
  <block id="c63fa16ec4ed3d9b3803c2d1e1548fe6" category="list-text">Obtenha alta disponibilidade e garanta a recuperação de desastres com replicação de dados e implantação em vários locais</block>
  <block id="fb289ff7f529e1f2477823c61e7d9c8f" category="section-title">Loja Inteligente Splunk</block>
  <block id="e2475a05ae25f0e8f31932cc309db3f1" category="paragraph">O SmartStore é um recurso de indexador que permite que armazenamentos de objetos remotos, como o Amazon S3, armazenem dados indexados.  À medida que o volume de dados de uma implantação aumenta, a demanda por armazenamento geralmente supera a demanda por recursos de computação.  O SmartStore permite que você gerencie o armazenamento do indexador e os recursos de computação de forma econômica, dimensionando esses recursos separadamente.</block>
  <block id="4b253fe4960ecb87fdd7a6c05a125003" category="paragraph">O SmartStore introduz uma camada de armazenamento remoto e um gerenciador de cache.  Esses recursos permitem que os dados residam localmente em indexadores ou na camada de armazenamento remoto.  O gerenciador de cache gerencia a movimentação de dados entre o indexador e a camada de armazenamento remoto, que é configurada no indexador.</block>
  <block id="98941a2e255442c92447b445a4a6bc6e" category="paragraph">Com o SmartStore, você pode reduzir o espaço de armazenamento do indexador ao mínimo e escolher recursos de computação otimizados para E/S.  A maioria dos dados reside no armazenamento remoto.  O indexador mantém um cache local que contém uma quantidade mínima de dados: buckets ativos, cópias de buckets ativos que participam de pesquisas ativas ou recentes e metadados de buckets.</block>
  <block id="2d153b33a50f3343c2aeb68789ee8e26" category="section-title">Fluxo de dados do Splunk SmartStore</block>
  <block id="3306b50d7dd22a0698c2245e7cd06bee" category="paragraph">Quando dados provenientes de várias fontes chegam aos indexadores, eles são indexados e salvos localmente em um hot bucket.  O indexador também replica os dados do hot bucket para indexadores de destino.  Até agora, o fluxo de dados é idêntico ao fluxo de dados para índices não SmartStore.</block>
  <block id="ad1e15c21ba7587e1631977abe48ab09" category="paragraph">Quando o balde quente rola para morno, o fluxo de dados diverge.  O indexador de origem copia o bucket quente para o armazenamento de objetos remoto (camada de armazenamento remoto), deixando a cópia existente em seu cache, porque as pesquisas tendem a ser executadas em dados indexados recentemente.  No entanto, os indexadores de destino excluem suas cópias porque o armazenamento remoto fornece alta disponibilidade sem manter várias cópias locais.  A cópia mestre do bucket agora reside no armazenamento remoto.</block>
  <block id="3d39641a906c56e9e12b0f019f23bc1d" category="paragraph">A imagem a seguir mostra o fluxo de dados do Splunk SmartStore.</block>
  <block id="d7a63eb40866a66e8bb1fc64387b113e" category="paragraph"><block ref="d7a63eb40866a66e8bb1fc64387b113e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fa16046e839496393e84b6a20e9604e" category="paragraph">O gerenciador de cache no indexador é central para o fluxo de dados do SmartStore.  Ele busca cópias de buckets do armazenamento remoto conforme necessário para lidar com solicitações de pesquisa.  Ele também remove cópias mais antigas ou menos pesquisadas de buckets do cache, porque a probabilidade de elas participarem de pesquisas diminui com o tempo.</block>
  <block id="b36837abd403dcb47f93edcd619c14de" category="paragraph">O trabalho do gerenciador de cache é otimizar o uso do cache disponível e, ao mesmo tempo, garantir que as pesquisas tenham acesso imediato aos buckets necessários.</block>
  <block id="4b2ba4c21a026c9139cf1484818f31c0" category="paragraph">A tabela abaixo lista os componentes de software necessários para implementar a solução.  Os componentes de software usados em qualquer implementação da solução podem variar de acordo com os requisitos do cliente.</block>
  <block id="aa76f43f5e0552119cc8d5313c67296e" category="cell">Família de produtos</block>
  <block id="df644ae155e79abf54175bd15d75f363" category="cell">Nome do produto</block>
  <block id="892b5a336dfe285f2d5c04ccd3d6c465" category="cell">Versão do produto</block>
  <block id="696c660ff8d9323e55146a6dbd4e4088" category="cell">Sistema operacional</block>
  <block id="1b3e6de2b0fe97c3177ea5a4ad142554" category="cell">Armazenamento de objetos StorageGRID</block>
  <block id="36552b079970ffb2dd1314115af76c4b" category="cell">11,6</block>
  <block id="274b68192b056e268f128ff63bfcd4a4" category="cell">n / D</block>
  <block id="aa1fc3398e84bda331b47203c1e53ad5" category="cell">CentOS</block>
  <block id="d6422a625045167156b3c0d85ca23ebf" category="cell">8,1</block>
  <block id="66985170e641a7e20698bfec3c1d889f" category="cell">CentOS 7.x</block>
  <block id="5dba46907e72d7502229329d2aafd8a2" category="cell">Splunk Enterprise</block>
  <block id="9d8d169ace12276d008f0d0b88b61261" category="cell">Splunk Enterprise com SmartStore</block>
  <block id="75809dde56e3fe2c2fb740f1b55807ac" category="cell">8.0.3</block>
  <block id="3192356dc19e9b4ec43ba340bad657ee" category="section-title">Requisitos de local único e múltiplo</block>
  <block id="98b8bd4f9670277f1f0e59a574019582" category="paragraph">Em um ambiente Enterprise Splunk (implantações médias e grandes) onde os dados se originam em muitas máquinas e onde muitos usuários precisam pesquisar os dados, você pode dimensionar sua implantação distribuindo instâncias do Splunk Enterprise em sites únicos e múltiplos.</block>
  <block id="22e1b76cf9acbfd35603b013eefcb079" category="paragraph">A tabela a seguir lista os componentes usados em um ambiente distribuído do Splunk Enterprise.</block>
  <block id="ee5ff25e83985cc8f46c04780442d06b" category="cell">Grupo de indexadores Splunk Enterprise configurados para replicar os dados uns dos outros</block>
  <block id="4e21e57c1860bf98fe3d0af8068f827d" category="cell">Balanceadores de carga</block>
  <block id="03d7fbb295d0abb68bf4d3ce22d6d448" category="cell">Gerenciamento de carga para componentes em cluster</block>
  <block id="a0ebc1066e0250b1b42f1a66ae974836" category="paragraph">Esta figura descreve um exemplo de uma implantação distribuída em um único local.</block>
  <block id="d929fa57a2db2b79fca2a0c134995344" category="paragraph"><block ref="d929fa57a2db2b79fca2a0c134995344" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf99a89b389bc74dc1a403695b28d6cd" category="paragraph">Esta figura descreve um exemplo de uma implantação distribuída em vários locais.</block>
  <block id="aa56e29281a1be8656361637c931faec" category="paragraph"><block ref="aa56e29281a1be8656361637c931faec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80d955d16c5178cc40e347dfe675a443" category="paragraph">As tabelas a seguir listam o número mínimo de componentes de hardware necessários para implementar a solução.  Os componentes de hardware usados em implementações específicas da solução podem variar de acordo com os requisitos do cliente.</block>
  <block id="f690a37fe0f7a5932c9eee9dc887f7c7" category="admonition">Independentemente de você ter implantado o Splunk SmartStore e o StorageGRID em um único site ou em vários sites, todos os sistemas são gerenciados pelo StorageGRID GRID Manager em um único painel de controle.  Veja a seção "Gerenciamento simples com o Grid Manager" para mais detalhes.</block>
  <block id="1605af3a62fa950fe8374a69086fdc94" category="paragraph">Esta tabela lista o hardware usado para um único site.</block>
  <block id="380dbc8d9d2c8a17f6ebb0b2c62d3e85" category="cell">Disco</block>
  <block id="b3e1f4c67ee07a73dcdaff1cf34f2640" category="cell">Capacidade utilizável</block>
  <block id="3b0649c72650c313a357338dcdfb64ec" category="cell">Observação</block>
  <block id="1c594a38f9aafa3a439c25bc55815b40" category="cell">StorageGRID SG1000</block>
  <block id="b179d20c2d3e6e91708b69931e8fcf32" category="cell">Nó de administração e balanceador de carga</block>
  <block id="48f09b085e666c51e35dbe89367de826" category="cell">StorageGRID SG6060</block>
  <block id="ab570142c34522356bdf33666f6532a3" category="cell">x48, 8 TB (HDD NL-SAS)</block>
  <block id="1792805a48a4da5ef5a78aa014da1f84" category="cell">1PB</block>
  <block id="ecefe4d01bf4079d1e2833e9a7de2db7" category="cell">Armazenamento remoto</block>
  <block id="9327a762e04913fc832ee2b182848716" category="paragraph">Esta tabela lista o hardware usado para uma configuração multisite (por site).</block>
  <block id="41cac74c281e47bb6feb1ef8db664ce4" category="cell">Nó de administração e balanceador de carga</block>
  <block id="aadc7d80b20e9c743c2920297937f9fd" category="section-title">Balanceador de carga NetApp StorageGRID : SG1000</block>
  <block id="b3f51763a6ba0ae7fe6d83095cb24299" category="paragraph">O armazenamento de objetos requer o uso de um balanceador de carga para apresentar o namespace de armazenamento em nuvem.  O StorageGRID oferece suporte a balanceadores de carga de terceiros de fornecedores líderes como F5 e Citrix, mas muitos clientes escolhem o balanceador StorageGRID de nível empresarial pela simplicidade, resiliência e alto desempenho.  O balanceador de carga StorageGRID está disponível como uma VM, contêiner ou dispositivo desenvolvido especificamente.</block>
  <block id="01f9bf7333b91ead20b7d1ac12ba4bca" category="paragraph">O StorageGRID SG1000 facilita o uso de grupos de alta disponibilidade (HA) e balanceamento de carga inteligente para conexões de caminho de dados S3.  Nenhum outro sistema de armazenamento de objetos no local fornece um balanceador de carga personalizado.</block>
  <block id="2f1a2bc20d9d0cddf636827860bdeb21" category="paragraph">O aparelho SG1000 oferece os seguintes recursos:</block>
  <block id="fee5222c1281869dd7c4e3e4b7225065" category="list-text">Um balanceador de carga e, opcionalmente, funções de nó de administração para um sistema StorageGRID</block>
  <block id="7ea5a035cfe0609861da7628e7dedc64" category="list-text">O instalador do dispositivo StorageGRID para simplificar a implantação e a configuração do nó</block>
  <block id="224d05cfece712836874ae47446c6d1b" category="list-text">Configuração simplificada de endpoints S3 e SSL</block>
  <block id="59bf11863992b10be7d53c81c21a0220" category="list-text">Largura de banda dedicada (em vez de compartilhar um balanceador de carga de terceiros com outros aplicativos)</block>
  <block id="1436fddc15afc971733cc42610be3718" category="list-text">Até 4 x 100 Gbps de largura de banda Ethernet agregada</block>
  <block id="4ff66456ad21f2aa88ad918b2a19287d" category="paragraph">A imagem a seguir mostra o dispositivo SG1000 Gateway Services.</block>
  <block id="605bc0a01cfe9da48adf3da49367bbdc" category="paragraph"><block ref="605bc0a01cfe9da48adf3da49367bbdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40b11d9d6e72b8f3d6f6cd150ea6d5b3" category="paragraph">O dispositivo StorageGRID SG6060 inclui um controlador de computação (SG6060) e uma prateleira de controlador de armazenamento (E-Series E2860) que contém dois controladores de armazenamento e 60 unidades.  Este aparelho oferece os seguintes recursos:</block>
  <block id="5d61368716b8937ccfa3ae30bdeb3add" category="list-text">Aumente até 400 PB em um único namespace.</block>
  <block id="b08da7d555d413c82fa9476b78a3d1b4" category="list-text">Até 4x 25 Gbps de largura de banda Ethernet agregada.</block>
  <block id="3b384482ee0276a75964f52aab736cac" category="list-text">Inclui o StorageGRID Appliance Installer para simplificar a implantação e a configuração dos nós.</block>
  <block id="3d6b68fb6989ac04a76612b7d50b5046" category="list-text">Cada dispositivo SG6060 pode ter uma ou duas prateleiras de expansão adicionais para um total de 180 unidades.</block>
  <block id="470503fbecc72cbe91b61c6e9b999cbe" category="list-text">Dois controladores E-Series E2800 (configuração duplex) para fornecer suporte a failover de controlador de armazenamento.</block>
  <block id="920a659800fa3289516e73f0b8d0cd70" category="list-text">Prateleira com cinco gavetas que comporta sessenta unidades de 3,5 polegadas (duas unidades de estado sólido e 58 unidades NL-SAS).</block>
  <block id="d60b006794c926c67e95ce7f49fffbed" category="paragraph">A imagem a seguir mostra o dispositivo SG6060.</block>
  <block id="cf84ce9e448fb9e498568b901279526a" category="paragraph"><block ref="cf84ce9e448fb9e498568b901279526a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad24897680a673883f3a8e9467ea3271" category="section-title">Design Splunk</block>
  <block id="c2d7b4acc3efe890969906f2a0be4bea" category="paragraph">A tabela a seguir lista a configuração do Splunk para um único site.</block>
  <block id="95dd022b7af0f9fcfb9ed21236830169" category="cell">Núcleos</block>
  <block id="17bc10091293fdc562a6db69940ee924" category="cell">SO</block>
  <block id="5132d0e71971db5ca9827d470220eae9" category="cell">16 núcleos</block>
  <block id="f4e3903ba78addf6fadac4a2d7285203" category="cell">32 GB de RAM</block>
  <block id="3988099dd7392a8b60a290ca560ac95d" category="cell">CentOS 8.1</block>
  <block id="aa7f73db0dcc93a83403f1afb650efdd" category="cell">Gerencia os dados do usuário</block>
  <block id="d3d9446802a44259755d38e6d163e820" category="cell">10</block>
  <block id="86e7f660faa5812369ca3195a6ab944a" category="cell">O front-end do usuário pesquisa dados em indexadores</block>
  <block id="eccbc87e4b5ce2fe28308fd9f2a7baf3" category="cell">3</block>
  <block id="e14f0b3b9201c717d9cae1db6969fb64" category="cell">Lida com atualizações para clusters de cabeçalhos de pesquisa</block>
  <block id="0ac993c5a472613a0cd368ccfefd6009" category="cell">Gerencia a instalação e os indexadores do Splunk</block>
  <block id="a91966f90c29f7d9420d2fd902f4aac2" category="cell">Console de monitoramento e mestre de licenças</block>
  <block id="0cb149f6f77c10496cf7645357f9fd17" category="cell">Executa monitoramento centralizado de toda a implantação do Splunk e gerencia licenças do Splunk</block>
  <block id="9bc779a08fe3e6d54c4355c4ee8c4a95" category="paragraph">As tabelas a seguir descrevem a configuração do Splunk para configurações multisite.</block>
  <block id="9605b47d211de50422182b81685da619" category="paragraph">Esta tabela lista a configuração do Splunk para uma configuração multisite (site A).</block>
  <block id="d9de1b6846e3235226dba66773043a15" category="cell">Responsável por ingerir dados e encaminhá-los aos indexadores.</block>
  <block id="76132c1712ff61ff02378720304f6529" category="cell">Executa o monitoramento centralizado de toda a implantação do Splunk e gerencia as licenças do Splunk.</block>
  <block id="2d3db4a7f27e8f892b40be60e8c003b4" category="paragraph">Esta tabela lista a configuração do Splunk para uma configuração multisite (site B).</block>
  <block id="89586ffe0445b81e878d1032f66f2e12" category="summary">O Splunk Enterprise é a solução SIEM líder de mercado que impulsiona resultados para equipes de segurança, TI e DevOps.</block>
  <block id="4d39837f3e2d893412540b1652c97cbe" category="paragraph">O Splunk Enterprise é a solução SIEM líder de mercado que impulsiona resultados para equipes de segurança, TI e DevOps.  O uso do Splunk aumentou consideravelmente nas organizações de nossos clientes.  Portanto, há uma necessidade de adicionar mais fontes de dados e, ao mesmo tempo, reter os dados por um período mais longo, sobrecarregando assim a infraestrutura do Splunk.</block>
  <block id="25c2a1fd1c8874a3e0526920fe7f440d" category="paragraph">A combinação do Splunk SmartStore e do NetApp StorageGRID foi projetada para fornecer uma arquitetura escalável para que as organizações alcancem melhor desempenho de ingestão com o armazenamento de objetos SmartStore e StorageGRID e maior escalabilidade para um ambiente Splunk em várias regiões geográficas.</block>
  <block id="fbf1f1e6f0848252d39ef48e7e18146f" category="inline-link">Recursos de documentação do NetApp StorageGRID</block>
  <block id="a246b965362984dc941c948da019cebe" category="list-text"><block ref="a246b965362984dc941c948da019cebe" category="inline-link-rx"></block></block>
  <block id="1deabb4a384507a50ad75f7c30954fe6" category="list-text"><block ref="1deabb4a384507a50ad75f7c30954fe6" category="inline-link-rx"></block></block>
  <block id="e145cc414457b4a232fb0b63ce9f44ab" category="inline-link">Documentação do Splunk Enterprise</block>
  <block id="04e37c317ba66f65142c3479329cc2e3" category="list-text"><block ref="04e37c317ba66f65142c3479329cc2e3" category="inline-link-rx"></block></block>
  <block id="14c366ebe94ed0bdf5d5eecad5a08411" category="inline-link">Splunk Enterprise Sobre SmartStore</block>
  <block id="fefd29a254418e70038ff08010d7066e" category="list-text"><block ref="fefd29a254418e70038ff08010d7066e" category="inline-link-rx"></block></block>
  <block id="b437e6537685614b8004334bad18e424" category="inline-link">Manual de implantação distribuída do Splunk Enterprise</block>
  <block id="12c4d056a98e583e653fc125f9f3338d" category="list-text"><block ref="12c4d056a98e583e653fc125f9f3338d" category="inline-link-rx"></block></block>
  <block id="d043516086780b04d9c8b38186019be3" category="inline-link">Splunk Enterprise Gerenciando Indexadores e Clusters de Indexadores</block>
  <block id="634ac9166526f20af850f5021155d4c5" category="list-text"><block ref="634ac9166526f20af850f5021155d4c5" category="inline-link-rx"></block></block>
  <block id="c7ebb883721f7d9264fd6ef2ae03fc71" category="summary">Este relatório técnico descreve os benefícios que a NetApp oferece a uma solução Splunk SmartStore, ao mesmo tempo em que demonstra uma estrutura para projetar e dimensionar o Splunk SmartStore em seu ambiente.  O resultado é uma solução simples, escalável e resiliente que oferece um TCO atraente.</block>
  <block id="766d1a96c4f198ecfe92484b980e9b31" category="doc">TR-4869: NetApp StorageGRID com Splunk SmartStore</block>
  <block id="fa4442e299e1aa350a002220ee278abc" category="paragraph">O Splunk Enterprise é a solução líder de mercado em Gerenciamento de Informações e Eventos de Segurança (SIEM) que impulsiona resultados entre as equipes de Segurança, TI e DevOps.</block>
  <block id="3b878279a04dc47d60932cb294d96259" category="section-title">Visão geral</block>
  <block id="78298f39c2d5411f080a61b3abeb845f" category="paragraph">Os volumes de dados continuam a crescer em taxas exponenciais, criando enormes oportunidades para empresas que podem aproveitar esse vasto recurso.  O Splunk Enterprise continua a ganhar adoção em uma variedade maior de casos de uso.  À medida que os casos de uso aumentam, também aumenta a quantidade de dados que o Splunk Enterprise ingere e processa.  A arquitetura tradicional do Splunk Enterprise é um design de escalonamento distribuído que fornece excelente acesso e disponibilidade de dados.  No entanto, as empresas que usam essa arquitetura enfrentam custos crescentes associados ao dimensionamento para atender ao rápido crescimento do volume de dados.</block>
  <block id="6a7254f4c4c618a79510973c24f6b258" category="paragraph">O Splunk SmartStore com NetApp StorageGRID resolve esse desafio ao fornecer um novo modelo de implantação no qual a computação e o armazenamento são dissociados.  Esta solução também desbloqueia escala e elasticidade inigualáveis para ambientes Splunk Enterprise, permitindo que os clientes escalem entre sites únicos e múltiplos, ao mesmo tempo em que reduz custos ao permitir que a computação e o armazenamento sejam escalonados de forma independente e adicionando níveis inteligentes ao armazenamento de objetos S3 baseado em nuvem com boa relação custo-benefício.</block>
  <block id="f8ff71716eed4ad221efc3e0d60beaf6" category="paragraph">A solução otimiza a quantidade de dados no armazenamento local, mantendo o desempenho da pesquisa, permitindo que a computação e o armazenamento sejam dimensionados sob demanda.  O SmartStore avalia automaticamente os padrões de acesso a dados para determinar quais dados precisam ser acessíveis para análises em tempo real e quais dados devem residir no armazenamento de objetos S3 de menor custo.</block>
  <block id="5c56ae45ba2fb5c42451dffdb2e64b55" category="paragraph">Este relatório técnico descreve os benefícios que a NetApp oferece a uma solução Splunk SmartStore, ao mesmo tempo em que demonstra uma estrutura para projetar e dimensionar o Splunk SmartStore em seu ambiente.  O resultado é uma solução simples, escalável e resiliente que oferece um TCO atraente.  O StorageGRID fornece armazenamento de objetos baseado em API/protocolo S3 escalonável e econômico, também conhecido como armazenamento remoto, permitindo que as organizações escalem sua solução Splunk a um custo menor e, ao mesmo tempo, aumentem a resiliência.</block>
  <block id="9841b81741e6066deac80b48e24f10fd" category="admonition">Splunk SmartStore se refere ao armazenamento de objetos como armazenamentos remotos ou camadas de armazenamento remoto.</block>
  <block id="4c1ead791cca9ec5a7b94356255ce5ef" category="section-title">Sobre o NetApp StorageGRID</block>
  <block id="57f13ae6637bd7ac5af4d0b1c4342cf7" category="paragraph">O NetApp StorageGRID é uma solução de armazenamento de objetos definida por software para grandes arquivos, repositórios de mídia e armazenamentos de dados da Web.  Com o StorageGRID, a NetApp aproveita duas décadas de experiência no fornecimento de soluções de gerenciamento de dados e inovação líderes do setor, ao mesmo tempo em que ajuda organizações a gerenciar e maximizar o valor de suas informações no local e em implantações de nuvem pública, privada ou híbrida.</block>
  <block id="6281e52aec6aad8556d89bbf44d95436" category="paragraph">O StorageGRID fornece armazenamento seguro e durável para dados não estruturados em escala.  Políticas integradas de gerenciamento de ciclo de vida orientadas por metadados otimizam onde seus dados ficam ao longo de sua vida útil.  O conteúdo é colocado no local certo, na hora certa e no nível de armazenamento certo para reduzir custos.  O namespace único permite que os dados sejam acessados por meio de uma única chamada, independentemente da localização geográfica do armazenamento StorageGRID .  Os clientes podem implantar e gerenciar várias instâncias do StorageGRID entre datacenters e na infraestrutura de nuvem.</block>
  <block id="d0a72d49cbe69b32b6e889db2e1429c9" category="paragraph">Um sistema StorageGRID é composto de nós redundantes, heterogêneos e distribuídos globalmente que podem ser integrados a aplicativos clientes existentes e de próxima geração.</block>
  <block id="a8bc435c89c3235d62a12e0fb3c5c909" category="paragraph"><block ref="a8bc435c89c3235d62a12e0fb3c5c909" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4077a77339f68c64c1e50f20961e468f" category="paragraph">A IDC MarketScape nomeou recentemente a NetApp como líder no relatório mais recente, IDC MarketScape: Worldwide Object-Based Storage 2019 Vendor Assessment.  Com quase 20 anos de implantações de produção nos setores mais exigentes, a StorageGRID é líder reconhecida em dados não estruturados.</block>
  <block id="a2146cca70b8afc5500f690b84357813" category="paragraph">Com o StorageGRID, você pode conseguir o seguinte:</block>
  <block id="0d29e2d2977160f50fc59018cd24d6ee" category="list-text">Implante várias instâncias do StorageGRID para acessar dados de qualquer local entre data centers e a nuvem por meio de um único namespace que pode ser facilmente dimensionado para centenas de petabytes.</block>
  <block id="770d656b5273d26168b61ba6ede38cfd" category="list-text">Forneça flexibilidade para implantar e gerenciar centralmente em todas as infraestruturas.</block>
  <block id="5926e6b363cbfe237a46219c7f92fe02" category="list-text">Ofereça durabilidade incomparável com quinze noves de durabilidade aproveitando a codificação de apagamento em camadas (EC).</block>
  <block id="77a48d0beb74ba75ef47c32ed1115a01" category="list-text">Habilite mais recursos de multinuvem híbrida com integrações validadas no Amazon S3 Glacier e no Azure Blob.</block>
  <block id="ffa0a5ca524779112b69eb9e53aacf31" category="list-text">Cumpra as obrigações regulatórias e facilite a conformidade por meio da retenção de dados à prova de violação, sem APIs proprietárias ou dependência de fornecedores.</block>
  <block id="6e9d67cdb6f2e5564ae28e0389bcc679" category="inline-link">Página inicial do NetApp StorageGRID</block>
  <block id="206008935f811359069d9b35cb5c874e" category="paragraph">Para obter mais informações sobre como o StorageGRID pode ajudá-lo a resolver seus problemas mais complexos de gerenciamento de dados não estruturados, consulte o<block ref="56ef38793a035acc851dabaa0c795287" category="inline-link-rx"></block> .</block>
  <block id="04bfb82e5f80fda36ff56ad540caaa63" category="section-title">Sobre o Splunk Enterprise</block>
  <block id="a643f0cfa3f1b40b8f79f3609f0aa84f" category="paragraph">O Splunk Enterprise é uma plataforma para transformar dados em ações.  Dados gerados por várias fontes, como arquivos de log, sites, dispositivos, sensores e aplicativos, são enviados e analisados pelos indexadores do Splunk, permitindo que você obtenha insights valiosos dos dados.  Ele pode identificar violações de dados, apontar tendências de clientes e produtos, encontrar oportunidades para otimizar a infraestrutura ou criar insights acionáveis em uma ampla variedade de casos de uso.</block>
  <block id="6118f726dd6c9b9e82e01638e958e5c8" category="section-title">Sobre a Splunk SmartStore</block>
  <block id="9ce6098334cce9db7edb3314ee645a2e" category="paragraph">O Splunk SmartStore expande os benefícios da arquitetura Splunk ao mesmo tempo em que simplifica sua capacidade de escalabilidade de forma econômica.  A dissociação dos recursos de computação e armazenamento resulta em nós indexadores otimizados para E/S com necessidades de armazenamento significativamente reduzidas porque eles armazenam apenas um subconjunto de dados como cache.  Você não precisa adicionar computação ou armazenamento extra quando apenas um desses recursos for necessário, o que permite uma economia de custos significativa.  Você pode usar o armazenamento de objetos baseado em S3, econômico e facilmente escalável, o que simplifica ainda mais o ambiente, reduz custos e permite que você mantenha um conjunto de dados maior.</block>
  <block id="fde880b7e5def5ccc70e3e98ba15b442" category="paragraph">O Splunk SmartStore oferece valor significativo às organizações, incluindo o seguinte:</block>
  <block id="16fc7d5921f88ca7b8070e1913a6fb74" category="list-text">Redução do custo de armazenamento movendo dados quentes para o armazenamento de objetos S3 otimizado em termos de custo</block>
  <block id="9ce78e75b3ecebf85fe0d43f2cf80505" category="list-text">Escalabilidade perfeita por meio da dissociação de armazenamento e computação</block>
  <block id="1dd6f3d1f3ac2a43dc2e69386b1b15ca" category="list-text">Simplificando a continuidade dos negócios aproveitando o armazenamento nativo da nuvem resiliente</block>
  <block id="bdcc72fc1bad1a939182ad2bde321f1e" category="summary">Esta página descreve o desempenho do Splunk SmartStore em um controlador NetApp StorageGRID .</block>
  <block id="b646ed758d0eaa12ba9fab12788f9ad4" category="doc">Desempenho do SmartStore de site único</block>
  <block id="b72db8dc34d5e01f398d66c9de42c11f" category="paragraph">Esta seção descreve o desempenho do Splunk SmartStore em um controlador NetApp StorageGRID .  O Splunk SmartStore move dados quentes para armazenamento remoto, que neste caso é o armazenamento de objetos StorageGRID na validação de desempenho.</block>
  <block id="dd1e8d1bd57ca578a4ba44e789957d0f" category="paragraph"><block ref="dd1e8d1bd57ca578a4ba44e789957d0f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="32b74ac1eb4eb0530a3f976e96e3120d" category="paragraph">Usamos o EF600 para armazenamento hot/cache e o StorageGRID 6060 para armazenamento remoto.  Usamos a seguinte arquitetura para a validação de desempenho.  Usamos dois cabeçotes de pesquisa, quatro encaminhadores pesados para encaminhar os dados aos indexadores, sete geradores de eventos Splunk (Eventgens) para gerar os dados em tempo real e 18 indexadores para armazenar os dados.</block>
  <block id="b127bd17913b4ab46912efd5b9a74269" category="paragraph"><block ref="b127bd17913b4ab46912efd5b9a74269" category="inline-image-macro-rx" type="image"></block></block>
  <block id="254f642527b45bc260048e30704edb39" category="section-title">Configuração</block>
  <block id="45940e86de61b51821b0ec7959b3d551" category="paragraph">Esta tabela lista o hardware usado para a validação de desempenho do SmartStorage.</block>
  <block id="2fda610cb12c654fe037d4130498d5ae" category="cell">Forwarder pesado</block>
  <block id="6d53d218eec402993fef5394aef9acdf" category="cell">16 núcleos</block>
  <block id="d3dd61dd737f0e824caf9d717bc1a59d" category="cell">TRENÓ 15 SP2</block>
  <block id="6f4922f45568161a8cdf4ad2299f6d23" category="cell">18</block>
  <block id="21dd53b3176e5a03137d603514a60ece" category="cell">O front-end do usuário pesquisa dados em indexadores</block>
  <block id="c247e74124395bc7279d790ac384786e" category="section-title">Validação de desempenho da loja remota SmartStore</block>
  <block id="30cf0ca744869370aafb6cfecdd7b4c6" category="paragraph">Nesta validação de desempenho, configuramos o cache do SmartStore no armazenamento local em todos os indexadores para 10 dias de dados.  Nós habilitamos o<block ref="6255199182bd8af7ba33e8a06e144dc4" prefix=" " category="inline-code"></block> (tamanho do bucket de 750 MB) no gerenciador de cluster do Splunk e enviou as alterações para todos os indexadores.  Para medir o desempenho de upload, ingerimos 10 TB por dia durante 10 dias e transferimos todos os hot buckets para aquecer ao mesmo tempo e capturamos o pico e a média de transferência por instância e em toda a implantação no painel do SmartStore Monitoring Console.</block>
  <block id="4fc95542b54fee8da424a2e0ab281aeb" category="paragraph">Esta imagem mostra os dados ingeridos em um dia.</block>
  <block id="1c106a39adeca49606809938222599d3" category="paragraph"><block ref="1c106a39adeca49606809938222599d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b72140907b2e824ba4a35a2f01bac4e6" category="paragraph">Executamos o seguinte comando do mestre do cluster (o nome do índice é<block ref="b6f5a7e4d9c3de59289306e2636a7438" prefix=" " category="inline-code"></block> ).  Em seguida, capturamos o pico e a média de transferência de upload por instância e em toda a implantação por meio dos painéis do SmartStore Monitoring Console.</block>
  <block id="94a0389fcc3ce42eea7a3f351f5d39b5" category="admonition">O mestre do cluster tem autenticação sem senha para todos os indexadores (rtp-idx0001…rtp-idx0018).</block>
  <block id="d27688c7ebc58e3f620120997e317180" category="paragraph">Para medir o desempenho do download, removemos todos os dados do cache executando a CLI evict duas vezes usando o seguinte comando.</block>
  <block id="4faf8abcf7e17175784cdc9d58df1608" category="admonition">Executamos o seguinte comando no mestre do cluster e executamos a pesquisa no cabeçalho de pesquisa sobre 10 dias de dados do armazenamento remoto do StorageGRID.  Em seguida, capturamos o pico e a média de transferência de upload por instância e em toda a implantação por meio dos painéis do SmartStore Monitoring Console.</block>
  <block id="995931f06acb79ea5ac83df17d692a1d" category="paragraph">As configurações do indexador foram enviadas do mestre do cluster SmartStore.  O mestre do cluster tinha a seguinte configuração para o indexador.</block>
  <block id="514109dd07ed0bb93081e9e36291b879" category="paragraph">Executamos a seguinte consulta de pesquisa no cabeçalho de pesquisa para coletar a matriz de desempenho.</block>
  <block id="71e6150ea19aef0f2e67a79bd131fca8" category="paragraph"><block ref="71e6150ea19aef0f2e67a79bd131fca8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67e03c2395d7a876b5160fefc76f9bb9" category="paragraph">Coletamos as informações de desempenho do mestre do cluster.  O desempenho máximo foi de 61,34 GBps.</block>
  <block id="c5e60940f195879f09af22af10f55027" category="paragraph"><block ref="c5e60940f195879f09af22af10f55027" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2850e7edd48f5666ab4f82242ddb37d2" category="paragraph">O desempenho médio foi de aproximadamente 29 GBps.</block>
  <block id="a8eebaef6e6889ddddfe09cfa523009c" category="paragraph"><block ref="a8eebaef6e6889ddddfe09cfa523009c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="283456e93c96a11ef44a18693dd6c886" category="section-title">Desempenho do StorageGRID</block>
  <block id="f5451e9a153b2f625ec0bc944af01be5" category="inline-link">Eventgen</block>
  <block id="764a1901ab00adf1e8e26712bf39c23a" category="paragraph">O desempenho do SmartStore é baseado na busca de padrões e sequências de caracteres específicos em grandes quantidades de dados.  Nesta validação, os eventos são gerados usando<block ref="6cec2d19baf7e588a52847e567dab457" category="inline-link-rx"></block> em um índice Splunk específico (eventgen-test) por meio do cabeçalho de pesquisa, e a solicitação vai para o StorageGRID para a maioria das consultas.  A imagem a seguir mostra os acertos e erros dos dados da consulta.  Os dados de acertos são do disco local e os dados de erros são do controlador StorageGRID .</block>
  <block id="3b8a6855a0eb4beaf2c787f34a2428d7" category="admonition">A cor verde mostra os dados de acertos e a cor laranja mostra os dados de erros.</block>
  <block id="5776938ffab0b4f2730d8923c004d57e" category="paragraph"><block ref="5776938ffab0b4f2730d8923c004d57e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6fa8244cc2900d6f36b3144c7e748ac" category="paragraph">Quando a consulta é executada para a pesquisa no StorageGRID, o tempo para a taxa de recuperação do S3 do StorageGRID é mostrado na imagem a seguir.</block>
  <block id="7393ba7bdc5067b2c80450122c8a2f0d" category="paragraph"><block ref="7393ba7bdc5067b2c80450122c8a2f0d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e3fd399eb98a5a8fae1dc144ff614f3" category="section-title">Uso de hardware do StorageGRID</block>
  <block id="8e8a6c088425467c00be94a9d15d015b" category="paragraph">A instância StorageGRID tem um balanceador de carga e três controladores StorageGRID .  A utilização da CPU para todos os três controladores é de 75% a 100%.</block>
  <block id="69851341d968a4444c52d6c167608079" category="paragraph"><block ref="69851341d968a4444c52d6c167608079" category="inline-image-macro-rx" type="image"></block></block>
  <block id="140097f96ea2b213b6f37f9d71009a5e" category="section-title">SmartStore com controlador de armazenamento NetApp - benefícios para o cliente</block>
  <block id="7f18772207b4ab40d0e7574fc68b95b6" category="list-text">*Desvinculando computação e armazenamento.*  O Splunk SmartStore separa computação e armazenamento, o que ajuda você a dimensioná-los de forma independente.</block>
  <block id="4e1a3208fe0742415bc087d082943293" category="list-text">*Dados sob demanda.*  O SmartStore aproxima os dados da computação sob demanda e fornece elasticidade de computação e armazenamento e eficiência de custos para obter maior retenção de dados em escala.</block>
  <block id="f3295a31a8b7a9b5d76cb1a1e7f67f28" category="list-text">*Compatível com API AWS S3.*  O SmartStore usa a API AWS S3 para se comunicar com o armazenamento de restauração, que é um armazenamento de objetos compatível com AWS S3 e API S3, como o StorageGRID.</block>
  <block id="4fda7aba03882818928ff7bc3a03f0e5" category="list-text">*Reduz a necessidade de armazenamento e o custo.*  O SmartStore reduz os requisitos de armazenamento para dados antigos (quentes/frios).  Ele só precisa de uma única cópia de dados porque o armazenamento NetApp fornece proteção de dados e cuida de falhas e alta disponibilidade.</block>
  <block id="c27703d92f7f2316dfa63670f02dd6b6" category="list-text">*Falha de hardware.*  A falha do nó em uma implantação do SmartStore não torna os dados inacessíveis e tem uma recuperação do indexador muito mais rápida em caso de falha de hardware ou desequilíbrio de dados.</block>
  <block id="ed20f2e9df3c744293f044d87722ce0f" category="list-text">Cache com reconhecimento de dados e aplicativos.</block>
  <block id="f57d44dedead861d1eef7e912b9cbd86" category="list-text">Adicione e remova indexadores e configure e desmonte clusters sob demanda.</block>
  <block id="98613866f09e0e2416018bef4be916d3" category="list-text">A camada de armazenamento não está mais vinculada ao hardware.</block>
  <block id="c1d2fce5798cdc81a1393206b0332f8a" category="summary">A solução permite adicionar recursos de computação, armazenamento ativo ou S3 para atender à crescente demanda em termos de número de usuários ou taxa de ingestão em implantações de sites únicos e múltiplos.</block>
  <block id="4932435adc5992fde32a04e44fd251b8" category="doc">Benefícios desta solução</block>
  <block id="bf89e1232480b95d07f648df24c3695b" category="list-text">*Desempenho.*  A combinação do Splunk SmartStore e do NetApp StorageGRID proporciona migração rápida de dados entre buckets ativos e buckets mornos usando armazenamento de objetos.  O StorageGRID acelera o processo de migração ao fornecer desempenho rápido para grandes cargas de trabalho de objetos.</block>
  <block id="e0be1ad556d6601e63eb8f1b6208c55e" category="list-text">*Pronto para vários locais.*  A arquitetura distribuída do StorageGRID permite que o Splunk SmartStore estenda implantações em sites únicos e múltiplos por meio de um único namespace global onde os dados podem ser acessados de qualquer site, independentemente de onde estejam.</block>
  <block id="9efd709ebdaac869f02b49e17fe9e92b" category="list-text">*Escalabilidade aprimorada.*  Dimensione os recursos de armazenamento independentemente dos recursos de computação para atender às necessidades e demandas em evolução no seu ambiente Splunk, proporcionando assim um melhor TCO.</block>
  <block id="52fb1ca9da3811c1cb86cd4347f98a64" category="list-text">*Capacidade.*  Atenda aos volumes de rápido crescimento na implantação do Splunk com o StorageGRID dimensionando um único namespace para mais de 560 PB.</block>
  <block id="ff501c8a6a8c7b1ee7a3c656b6f4055a" category="list-text">*Disponibilidade de dados.*  Otimize a disponibilidade, o desempenho, a distribuição geográfica, a retenção, a proteção e os custos de armazenamento de dados com políticas orientadas por metadados que podem se ajustar dinamicamente conforme o valor comercial dos seus dados evolui.</block>
  <block id="bf1b0e32d877d343f0b3bc9ba43cb688" category="inline-link">diretrizes fornecidas pela Splunk</block>
  <block id="3c5d06925a5d5bceedd74c82d3d38c04" category="paragraph">Aumente o desempenho com o cache SmartStore, que é um componente do indexador que lida com a transferência de cópias de bucket entre armazenamento local (quente) e remoto (morno).  O dimensionamento do Splunk para esta solução é baseado em<block ref="d615ab802f29a9ee4a18e420480d049f" category="inline-link-rx"></block> .  A solução permite adicionar recursos de computação, armazenamento ativo ou S3 para atender à crescente demanda em termos de número de usuários ou taxa de ingestão em implantações de sites únicos e múltiplos.</block>
  <block id="39e4c49e9af8047395aa4031e5c5f3a9" category="summary">Esta página descreve os componentes usados para concluir esta solução, incluindo NetApp StorageGRID, Splunk Enterprise e Splunk SmartStore.</block>
  <block id="c0c4b60d27032c028c91440e9d3be949" category="doc">Visão geral da solução</block>
  <block id="5ab9d0d9b506bd4b5bf294baccd4ef0a" category="paragraph">O NetApp StorageGRID é uma plataforma de armazenamento de objetos de alto desempenho e econômica.  Ele oferece gerenciamento de dados globais inteligente e orientado por políticas usando uma arquitetura de grade distribuída baseada em nós.  Ele simplifica o gerenciamento de petabytes de dados não estruturados e bilhões de objetos por meio de seu onipresente namespace de objetos globais combinado com recursos sofisticados de gerenciamento de dados.  O acesso a objetos de chamada única se estende por todos os sites e simplifica arquiteturas de alta disponibilidade, ao mesmo tempo em que garante acesso contínuo a objetos, independentemente de interrupções no site ou na infraestrutura.</block>
  <block id="d67c579ad5ceca0ec4f8fe6a86f203cf" category="paragraph">A multilocação permite que vários aplicativos de dados não estruturados corporativos e de nuvem sejam atendidos com segurança na mesma grade, aumentando o ROI e os casos de uso do StorageGRID.  Vários níveis de serviço podem ser criados com políticas de ciclo de vida de objetos orientadas por metadados, otimizando durabilidade, proteção, desempenho e localidade em várias geografias.  Os usuários podem ajustar políticas e realinhar o cenário de dados sem interrupções conforme suas necessidades mudam.</block>
  <block id="0d2b0fb2b312d872db772396e149b541" category="paragraph">O SmartStore utiliza o StorageGRID como camada de armazenamento remoto e permite que os clientes implantem vários sites distribuídos geograficamente para disponibilidade e durabilidade robustas, apresentados como um único namespace de objeto.  Isso permite que o Splunk SmartStore aproveite o alto desempenho do StorageGRID , a capacidade densa e a capacidade de escalar para centenas de nós em vários sites físicos usando uma única URL para interagir com os objetos.  Essa URL única também permite que a expansão, as atualizações e os reparos do armazenamento não causem interrupções, mesmo além de um único local.  O mecanismo de política de gerenciamento de dados exclusivo do StorageGRID fornece níveis otimizados de desempenho, durabilidade e aderência aos requisitos de localidade de dados.</block>
  <block id="f9ed96cf2d028d3cfa9c658c6ec5ae72" category="paragraph">A Splunk, líder na coleta e análise de dados gerados por máquina, ajuda a simplificar e modernizar a TI por meio de seus recursos de análise operacional.  Ele também se expande para análises de negócios, segurança e casos de uso de IoT.  O armazenamento é um facilitador essencial para uma implantação bem-sucedida do software Splunk.</block>
  <block id="1812fb837f2c63812e909b4457b0fa17" category="paragraph">Dados gerados por máquina são o tipo de big data que mais cresce.  O formato é imprevisível e vem de muitas fontes diferentes, geralmente em altas taxas e em grandes volumes.  Essas características de carga de trabalho são frequentemente chamadas de exaustão digital.  O Splunk SmartStore ajuda a dar sentido a esses dados e fornece níveis de dados inteligentes para posicionamento otimizado de dados quentes e mornos no nível de armazenamento mais econômico.</block>
  <block id="bd069a1be23f237559be08ae79727806" category="paragraph">O Splunk SmartStore é um recurso de indexador que usa armazenamento de objetos (também conhecido como armazenamento remoto ou camadas de armazenamento remoto), como o StorageGRID, para armazenar dados ativos usando o protocolo S3.</block>
  <block id="9e5e9e455aa469c6579c4cde82cf69fc" category="paragraph">À medida que o volume de dados de uma implantação aumenta, a demanda por armazenamento geralmente supera a demanda por recursos de computador.  O SmartStore permite que você gerencie seus recursos de armazenamento e computação do indexador de forma econômica, dimensionando a computação e o armazenamento separadamente.</block>
  <block id="1ab3873a2fa155a27933ac3e2b4ae709" category="paragraph">O SmartStore introduz uma camada de armazenamento remoto, usando o protocolo S3, e um gerenciador de cache.  Esses recursos permitem que os dados residam localmente em indexadores ou em armazenamento remoto.  O gerenciador de cache, que reside no indexador, gerencia a movimentação de dados entre o indexador e a camada de armazenamento remoto.  Os dados são armazenados em buckets (quente e morno) junto com metadados do bucket.</block>
  <block id="85a6e51e1b2fd3e4be531f269e108f39" category="paragraph">Com o SmartStore, você pode reduzir o espaço de armazenamento do indexador ao mínimo e escolher recursos de computação otimizados para E/S, porque a maioria dos dados reside na camada de armazenamento remoto.  O indexador mantém um cache local, representando a quantidade mínima de dados necessária para retornar os resultados solicitados e previstos.  O cache local contém buckets ativos, cópias de buckets ativos que participam de pesquisas ativas ou recentes e metadados de buckets.</block>
  <block id="8cc78103debf2dcfe53620b96565dad4" category="paragraph">O Splunk SmartStore com StorageGRID permite que os clientes escalem incrementalmente o ambiente com armazenamento remoto de alto desempenho e baixo custo, ao mesmo tempo em que fornece um alto grau de elasticidade à solução geral.  Isso permite que os clientes adicionem quaisquer componentes (armazenamento ativo e/ou armazenamento S3 morno) em qualquer quantidade e a qualquer momento, independentemente de precisarem de mais indexadores, alterar a retenção de dados ou aumentar a taxa de ingestão sem nenhuma interrupção.</block>
  <block id="d919f51e7020fabd237372f4c163a60e" category="summary">O StorageGRID tem uma ampla variedade de recursos que os usuários podem aproveitar e personalizar para seu ambiente em constante mudança.</block>
  <block id="0fc3cf31004e01f169ca3af4ef687576" category="doc">Recursos flexíveis do StorageGRID para Splunk SmartStore</block>
  <block id="d7ec4db6b0e9313773163a8a2404946e" category="paragraph">O StorageGRID tem uma ampla variedade de recursos que os usuários podem aproveitar e personalizar para seu ambiente em constante mudança.  Da implantação ao dimensionamento do seu Splunk SmartStore, seu ambiente exige rápida adoção de mudanças e não deve causar interrupções no Splunk.  As políticas flexíveis de gerenciamento de dados (ILM) e os classificadores de tráfego (QoS) do StorageGRID permitem que você planeje e se adapte ao seu ambiente.</block>
  <block id="5b552d68210e15d5ed4e4d186264b453" category="paragraph">O Grid Manager é uma interface gráfica baseada em navegador que permite configurar, gerenciar e monitorar seu sistema StorageGRID em locais distribuídos globalmente em um único painel, conforme mostrado na imagem a seguir.</block>
  <block id="b426e35a4f24b1452cf4688598a7429c" category="paragraph"><block ref="b426e35a4f24b1452cf4688598a7429c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52d198c85ec187eb3bbff17442a01baa" category="paragraph">Execute as seguintes tarefas com a interface do Grid Manager:</block>
  <block id="356e4420bfe7b6226984261d66ec9e0b" category="section-title">Aplicativo NetApp StorageGRID para Splunk</block>
  <block id="d4503ceebebf47c506c3003f760662a2" category="paragraph">O aplicativo NetApp StorageGRID para Splunk é um aplicativo específico para o Splunk Enterprise.  Este aplicativo funciona em conjunto com o complemento NetApp StorageGRID para Splunk.  Ele fornece visibilidade sobre a integridade do StorageGRID , informações de uso da conta, detalhes de auditoria de segurança, uso e monitoramento de recursos e assim por diante.</block>
  <block id="c7b8ad57a7270e26eba0ed9da1fa0b6c" category="paragraph">A imagem a seguir mostra o aplicativo StorageGRID para Splunk.</block>
  <block id="33e8e06b4bbde24cf3f439a1bd66cf19" category="paragraph"><block ref="33e8e06b4bbde24cf3f439a1bd66cf19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7e07b036910adce42ba90efc47f818e" category="section-title">Políticas de ILM</block>
  <block id="2121ccc9450b2df939a6752c3559486a" category="paragraph">O StorageGRID tem políticas flexíveis de gerenciamento de dados que incluem manter várias cópias de seus objetos e usar esquemas de EC (codificação de eliminação) como 2+1 e 4+2 (e muitos outros) para armazenar seus objetos, dependendo de requisitos específicos de desempenho e proteção de dados.  Como as cargas de trabalho e os requisitos mudam ao longo do tempo, é comum que as políticas de ILM também mudem.  Modificar políticas de ILM é um recurso essencial, permitindo que os clientes do StorageGRID se adaptem ao seu ambiente em constante mudança de forma rápida e fácil.</block>
  <block id="3f7d13681fac5c1ca00c53ae2a27efaa" category="paragraph">O StorageGRID aumenta o desempenho adicionando mais nós, que podem ser VMs, bare metal ou dispositivos específicos, como SG5712, SG5760, SG6060 ou SGF6024.  Em nossos testes, superamos os principais requisitos de desempenho do SmartStore com uma grade de três nós de tamanho mínimo usando o dispositivo SG6060.  À medida que os clientes escalam sua infraestrutura Splunk com indexadores adicionais, eles podem adicionar mais nós de armazenamento para aumentar o desempenho e a capacidade.</block>
  <block id="8a0453356d4720c8c5a67e5e2a16b419" category="section-title">Configuração do balanceador de carga e endpoint</block>
  <block id="08de46c3a8d44cfa799d969abfa407eb" category="paragraph">Os nós de administração no StorageGRID fornecem a interface de usuário (UI) do Grid Manager e o endpoint da API REST para visualizar, configurar e gerenciar seu sistema StorageGRID , bem como logs de auditoria para rastrear a atividade do sistema.  Para fornecer um ponto de extremidade S3 de alta disponibilidade para armazenamento remoto do Splunk SmartStore, implementamos o balanceador de carga StorageGRID , que é executado como um serviço em nós de administração e nós de gateway.  Além disso, o balanceador de carga também gerencia o tráfego local e se comunica com o GSLB (Global Server Load Balancing) para ajudar na recuperação de desastres.</block>
  <block id="d2134190f6b031237d4b1523c86c29a2" category="paragraph">Para aprimorar ainda mais a configuração do endpoint, o StorageGRID fornece políticas de classificação de tráfego incorporadas ao nó de administração, permite que você monitore o tráfego da sua carga de trabalho e aplique vários limites de qualidade de serviço (QoS) às suas cargas de trabalho.  As políticas de classificação de tráfego são aplicadas aos endpoints no serviço StorageGRID Load Balancer para nós de gateway e nós de administração.  Essas políticas podem ajudar a limitar e monitorar o tráfego.</block>
  <block id="9fa345c6a2f967ec80e8b940a9d2a1c3" category="summary">À medida que os clientes percebem o poder e a facilidade de usar a análise de dados do Splunk, eles naturalmente querem indexar uma quantidade cada vez maior de dados.  À medida que a quantidade de dados cresce, também cresce a infraestrutura de computação e armazenamento necessária para atendê-los.</block>
  <block id="f9a3e09b74e61e83c0352f2953dcdc87" category="doc">Hierarquização inteligente e economia de custos</block>
  <block id="e09913e41f1a0082ec190482abfeff57" category="paragraph">À medida que os clientes percebem o poder e a facilidade de usar a análise de dados do Splunk, eles naturalmente querem indexar uma quantidade cada vez maior de dados.  À medida que a quantidade de dados cresce, também cresce a infraestrutura de computação e armazenamento necessária para atendê-los.  Como dados mais antigos são referenciados com menos frequência, comprometer a mesma quantidade de recursos de computação e consumir armazenamento primário caro se torna cada vez mais ineficiente.  Para operar em escala, os clientes se beneficiam da movimentação de dados quentes para uma camada mais econômica, liberando computação e armazenamento primário para dados quentes.</block>
  <block id="f7300ec91634b8cd535c45fd11ee503f" category="paragraph">O Splunk SmartStore com StorageGRID oferece às organizações uma solução escalável, de alto desempenho e econômica.  Como o SmartStore reconhece dados, ele avalia automaticamente os padrões de acesso a dados para determinar quais dados precisam ser acessíveis para análises em tempo real (dados ativos) e quais dados devem residir em armazenamento de longo prazo de menor custo (dados quentes).  O SmartStore usa a API AWS S3 padrão do setor de forma dinâmica e inteligente, colocando dados no armazenamento S3 fornecido pelo StorageGRID.  A arquitetura de escalonamento flexível do StorageGRID permite que a camada de dados quentes cresça de forma econômica, conforme necessário.  A arquitetura baseada em nós do StorageGRID garante que os requisitos de desempenho e custo sejam atendidos de forma otimizada.</block>
  <block id="d75fb5ef86bb0625c22c38dd2229c627" category="paragraph">A imagem a seguir ilustra a divisão em camadas do Splunk e do StorageGRID .</block>
  <block id="f710071dfe9306034297e2bbb442d8bc" category="paragraph"><block ref="f710071dfe9306034297e2bbb442d8bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6821c40fa59a17fa0f78dbb9e556be5" category="paragraph">A combinação líder do setor do Splunk SmartStore com o NetApp StorageGRID oferece os benefícios da arquitetura desacoplada por meio de uma solução full-stack.</block>
  <block id="404af9ebdf8554a92ea8d3dde06945b4" category="doc">TR-4623: NetApp E-Series E5700 e Splunk Enterprise</block>
  <block id="1dcb8fb2d6ad519f4a7ecd244f9c7c76" category="paragraph">Mitch Blackburn, NetApp</block>
  <block id="8c121c8c1e758ef244a52184e2d48c66" category="paragraph">TR-4623 descreve a arquitetura integrada do NetApp E-Series e do design do Splunk.  Otimizado para equilíbrio de armazenamento de nós, confiabilidade, desempenho, capacidade de armazenamento e densidade, este design emprega o modelo de nó de índice clusterizado do Splunk, com maior escalabilidade e menor TCO.  Desacoplar o armazenamento da computação oferece a capacidade de dimensionar cada um separadamente, economizando o custo de provisionamento excessivo de um ou outro.  Além disso, este documento resume os resultados dos testes de desempenho obtidos de uma ferramenta de simulação de eventos de log de máquina Splunk.</block>
  <block id="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="paragraph"><block ref="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="inline-link-macro-rx"></block></block>
  <block id="f1739b1d5d1c44e562a8500d3b80579f" category="summary">Recursos de IA da NetApp que permitem o gerenciamento e a movimentação de dados perfeitos no pipeline de IA para treinamento, reciclagem, ajuste fino, inferência e monitoramento de modelos de IA generativos.</block>
  <block id="36cc0281ec7abcd20091f5d39b995cc4" category="doc">IA generativa e valor NetApp</block>
  <block id="6dbc3469d4924aa631238769172515d8" category="paragraph">A demanda por inteligência artificial generativa (IA) está gerando disrupção em todos os setores, aumentando a criatividade empresarial e a inovação de produtos.</block>
  <block id="40ed4c797a14998a489b495cd8c9a5e0" category="paragraph">Muitas organizações estão usando IA generativa para criar novos recursos de produtos, melhorar a produtividade da engenharia e prototipar aplicativos com tecnologia de IA que oferecem melhores resultados e experiências ao consumidor.  A IA generativa, como os Transformadores Pré-treinados Generativos (GPT), usa redes neurais para criar novos conteúdos, tão diversos quanto texto, áudio e vídeo.  Dada a escala extrema e os enormes conjuntos de dados envolvidos com grandes modelos de linguagem (LLMs), é crucial arquitetar uma infraestrutura de IA robusta que aproveite os recursos atraentes de armazenamento de dados das opções de implantação local, híbrida e multinuvem e reduza os riscos associados à mobilidade de dados, proteção de dados e governança antes que as empresas possam projetar soluções de IA.  Este artigo descreve essas considerações e os recursos correspondentes do NetApp AI que permitem o gerenciamento e a movimentação de dados perfeitos no pipeline de dados de IA para treinamento, retreinamento, ajuste fino e inferência de modelos de IA generativos.</block>
  <block id="a573d92b77d430af7e424879baf78e94" category="section-title">Sumário executivo</block>
  <block id="3fed37bedb6b36d52c0c5b3aa0089bfe" category="paragraph">Mais recentemente, após o lançamento do ChatGPT, um spin-off do GPT-3 em novembro de 2022, novas ferramentas de IA usadas para gerar texto, código, imagem ou até mesmo proteínas terapêuticas em resposta a solicitações do usuário ganharam fama significativa.  Isso indica que os usuários podem fazer uma solicitação usando linguagem natural e a IA interpretará e gerará texto, como artigos de notícias ou descrições de produtos que refletem a solicitação do usuário ou produzem código, música, fala, efeitos visuais e ativos 3D usando algoritmos treinados em dados já existentes.  Como resultado, frases como Difusão Estável, Alucinações, Engenharia Rápida e Alinhamento de Valores estão surgindo rapidamente no design de sistemas de IA.  Esses modelos de aprendizado de máquina (ML) autossupervisionados ou semissupervisionados estão se tornando amplamente disponíveis como modelos básicos pré-treinados (FM) por meio de provedores de serviços de nuvem e outros fornecedores de IA, que estão sendo adotados por vários estabelecimentos comerciais em todos os setores para uma ampla gama de tarefas de PNL (processamento de linguagem natural) posteriores.  Conforme afirmam empresas de análise de pesquisa como a McKinsey: "O impacto da IA generativa na produtividade pode agregar trilhões de dólares em valor à economia global".  Enquanto as empresas estão reinventando a IA como parceira de pensamento dos humanos e os FMs estão ampliando simultaneamente o que empresas e instituições podem fazer com IA generativa, as oportunidades para gerenciar grandes volumes de dados continuarão a crescer.  Este documento apresenta informações introdutórias sobre IA generativa e os conceitos de design em relação aos recursos da NetApp que agregam valor aos clientes da NetApp , tanto em ambientes locais quanto híbridos ou multinuvem.</block>
  <block id="8bcfe22a3d7c5edf904444893704a8de" category="paragraph">*Então, o que os clientes ganham ao usar o NetApp em seus ambientes de IA?*  A NetApp ajuda as organizações a lidar com as complexidades criadas pelo rápido crescimento de dados e nuvem, gerenciamento de várias nuvens e adoção de tecnologias de última geração, como IA.  A NetApp combinou vários recursos em software de gerenciamento de dados inteligente e infraestrutura de armazenamento que foram bem equilibrados com alto desempenho otimizado para cargas de trabalho de IA.  Soluções de IA generativas, como LLMs, precisam ler e processar seus conjuntos de dados de origem do armazenamento para a memória diversas vezes para promover a inteligência.  A NetApp é líder em tecnologias de mobilidade de dados, governança de dados e segurança de dados em todo o ecossistema da ponta ao núcleo e à nuvem, atendendo clientes empresariais que criam soluções de IA em escala.  A NetApp, com uma forte rede de parceiros, tem ajudado diretores de dados, engenheiros de IA, arquitetos corporativos e cientistas de dados no design de um pipeline de dados de fluxo livre para preparação de dados, proteção de dados e responsabilidades de gerenciamento estratégico de dados de treinamento e inferência de modelos de IA, otimizando o desempenho e a escalabilidade do ciclo de vida de IA/ML.  As tecnologias e os recursos de dados da NetApp , como o NetApp ONTAP AI para pipeline de dados de aprendizado profundo, o NetApp SnapMirror para transportar dados de forma integrada e eficiente entre endpoints de armazenamento e o NetApp FlexCache para renderização em tempo real quando o fluxo de dados muda de lote para tempo real e a engenharia de dados acontece em tempo real, agregam valor à implantação de modelos de IA generativa em tempo real.  À medida que empresas de todos os tipos adotam novas ferramentas de IA, elas enfrentam desafios de dados, da borda ao data center e à nuvem, que exigem soluções de IA escaláveis, responsáveis e explicáveis.  Como autoridade em dados em nuvem híbrida e múltipla, a NetApp está comprometida em construir uma rede de parceiros e soluções conjuntas que podem ajudar em todos os aspectos da construção de um pipeline de dados e data lakes para treinamento de modelos de IA generativos (pré-treinamento), ajuste fino, inferência baseada em contexto e monitoramento de decaimento de modelo de LLMs.</block>
  <block id="ba4c46fa4f06702b4667d0b3a6b2bdfe" category="section-title">O que é IA Generativa?</block>
  <block id="11703c9edbc2bf714a8c4be38891fc77" category="paragraph">A IA generativa está mudando a maneira como criamos conteúdo, geramos novos conceitos de design e exploramos novas composições.  Ele ilustra estruturas de redes neurais como Rede Adversarial Generativa (GAN), Autocodificadores Variacionais (VAE) e Transformadores Pré-Treinados Generativos (GPT), que podem gerar novos conteúdos como texto, código, imagens, áudio, vídeo e dados sintéticos.  Modelos baseados em transformadores, como o Chat-GPT da OpenAI, o Bard do Google, o BLOOM da Hugging Face e o LLaMA da Meta surgiram como a tecnologia fundamental que sustenta muitos avanços em grandes modelos de linguagem.  Da mesma forma, o Dall-E da OpenAI, o CM3leon da Meta e o Imagen do Google são exemplos de modelos de difusão de texto para imagem que oferecem aos clientes um grau sem precedentes de fotorrealismo para criar imagens novas e complexas do zero ou editar imagens existentes para gerar imagens de alta qualidade com reconhecimento de contexto usando aumento de conjunto de dados e síntese de texto para imagem, vinculando semântica textual e visual.  Artistas digitais estão começando a aplicar uma combinação de tecnologias de renderização como NeRF (Neural Radiance Field) com IA generativa para converter imagens 2D estáticas em cenas 3D imersivas.  Em geral, os LLMs são amplamente caracterizados por quatro parâmetros: (1) Tamanho do modelo (normalmente em bilhões de parâmetros); (2) Tamanho do conjunto de dados de treinamento; (3) Custo do treinamento e (4) Desempenho do modelo após o treinamento.  Os LLMs também se enquadram principalmente em três arquiteturas de transformadores.  (i) Modelos somente com codificador.  Ex.: BERT (Google, 2018); (ii) Modelos codificador-decodificador Ex.: BART (Meta, 2020) e (iii) Modelos somente decodificador.  Por exemplo, LLaMA (Meta, 2023), PaLM-E (Google, 2023).  Dependendo dos requisitos do negócio, independentemente da arquitetura que uma empresa escolher, o número de parâmetros do modelo (N) e o número de tokens (D) no conjunto de dados de treinamento geralmente determinam o custo base do treinamento (pré-treinamento) ou do ajuste fino de um LLM.</block>
  <block id="d1ddcb04dcb447b3f05fa54e9ab492d0" category="section-title">Casos de uso empresarial e tarefas de PNL posteriores</block>
  <block id="a4a7c510156562fb9841dd055348b753" category="paragraph">Empresas de todos os setores estão descobrindo cada vez mais o potencial da IA para extrair e produzir novas formas de valor de dados existentes para operações comerciais, vendas, marketing e serviços jurídicos.  De acordo com a inteligência de mercado da IDC (International Data Corporation) sobre casos de uso e investimentos globais em IA generativa, a gestão do conhecimento no desenvolvimento de software e design de produtos será a mais impactada, seguida pela criação de histórias para marketing e geração de código para desenvolvedores.  Na área da saúde, organizações de pesquisa clínica estão inovando na medicina.  Modelos pré-treinados como o ProteinBERT incorporam anotações de Gene Ontology (GO) para projetar rapidamente estruturas de proteínas para medicamentos, representando um marco significativo na descoberta de medicamentos, bioinformática e biologia molecular.  Empresas de biotecnologia iniciaram testes em humanos para medicamentos descobertos por IA generativa, que visam tratar doenças como fibrose pulmonar (FPI), uma doença pulmonar que causa cicatrizes irreversíveis no tecido pulmonar.</block>
  <block id="8e5aaca094938e3b1a2e08f48f3db558" category="paragraph">Figura 1: Casos de uso que impulsionam a IA generativa</block>
  <block id="8d04a6a1813e89b5849d40e5113b0902" category="paragraph"><block ref="8d04a6a1813e89b5849d40e5113b0902" category="inline-image-macro-rx" type="image"></block></block>
  <block id="605e4f6997ac64a7de35f4e8a02721e9" category="paragraph">O aumento na adoção da automação impulsionado pela IA generativa também está mudando a oferta e a demanda de atividades de trabalho para muitas ocupações.  De acordo com a McKinsey, o mercado de trabalho dos EUA (diagrama abaixo) passou por uma rápida transição, que pode continuar apenas quando se considera o impacto da IA.</block>
  <block id="844d4a4d01e4441540857f7a302f6239" category="paragraph">Fonte: McKinsey &amp; Company</block>
  <block id="14509aeb117a81412dfa4dc27107f735" category="inline-image-macro">Figura 2: Fonte: McKinsey &amp;amp; Company</block>
  <block id="f86a1cf79787f9ca7a0bc2698a14baa8" category="paragraph"><block ref="1cdd0679074896d7373f66c66dc8dda4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="072f966c176c14e4a8ac1b32dff891bc" category="section-title">Papel do armazenamento na IA generativa</block>
  <block id="6a352eac97ff84fb6680bea0e3f1582b" category="inline-link-macro">512 MB</block>
  <block id="23f951a15f217f2ce467c5d52e3a74a2" category="paragraph">Os LLMs dependem amplamente de aprendizado profundo, GPUs e computação.  Entretanto, quando o buffer da GPU fica cheio, os dados precisam ser gravados rapidamente no armazenamento.  Embora alguns modelos de IA sejam pequenos o suficiente para serem executados na memória, os LLMs exigem alto IOPS e armazenamento de alto rendimento para fornecer acesso rápido a grandes conjuntos de dados, especialmente se envolver bilhões de tokens ou milhões de imagens.  Para um requisito típico de memória de GPU de um LLM, a memória necessária para treinar um modelo com 1 bilhão de parâmetros pode chegar a 80 GB com precisão total de 32 bits.  Nesse caso, o LLaMA 2 da Meta, uma família de LLMs que varia em escala de 7 bilhões a 70 bilhões de parâmetros, pode exigir 70x80, aproximadamente 5.600 GB ou 5,6 TB de RAM de GPU.  Além disso, a quantidade de memória necessária é diretamente proporcional ao número máximo de tokens que você deseja gerar.  Por exemplo, se você deseja gerar saídas de até 512 tokens (cerca de 380 palavras), você precisa<block ref="8b6a924b2b2c8b02d5e56762d0384bc1" category="inline-link-macro-rx"></block> .  Pode parecer insignificante, mas, se você quiser executar lotes maiores, isso começa a somar.  Portanto, torna-se muito caro para organizações treinar ou ajustar LLMs na memória, tornando o armazenamento uma base fundamental para a IA generativa.</block>
  <block id="b0b4b15d26d559735ca79c547ebcf9b6" category="section-title">Três abordagens principais para LLMs</block>
  <block id="29ff458fbe275b29aaf5e7dbd636eed4" category="inline-link-macro">Harvard Business Review</block>
  <block id="b026e17fa592b49ccc86f0f9b718b03b" category="paragraph">Para a maioria das empresas, com base nas tendências atuais, a abordagem para implantar LLMs pode ser condensada em três cenários básicos.  Conforme descrito em um recente<block ref="9b642d86ef84545807d431905b86239d" category="inline-link-macro-rx"></block> Artigo: (1) Treinamento (pré-treinamento) de um LLM do zero – caro e requer habilidades especializadas em IA/ML; (2) Ajuste fino de um modelo de base com dados empresariais – complexo, mas viável; (3) Uso de geração aumentada de recuperação (RAG) para consultar repositórios de documentos, APIs e bancos de dados vetoriais que contêm dados da empresa.  Cada um deles tem compensações entre esforço, velocidade de iteração, custo-benefício e precisão do modelo em suas implementações, usadas para resolver diferentes tipos de problemas (diagrama abaixo).</block>
  <block id="c35884049dd0467b68f884a60d4920ea" category="paragraph">Figura 3: Tipos de problemas</block>
  <block id="2ee3234ece3d669efe95dc1a84c67a06" category="paragraph"><block ref="2ee3234ece3d669efe95dc1a84c67a06" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff76a02d3da4ad3236fe1704ce7b2a4c" category="section-title">Modelos de Fundação</block>
  <block id="212ec66e09b7b19d2e397c5c04e8543d" category="paragraph">Um modelo de fundação (FM), também conhecido como modelo base, é um grande modelo de IA (LLM) treinado em grandes quantidades de dados não rotulados, usando autossupervisão em escala, geralmente adaptado para uma ampla gama de tarefas de PNL posteriores.  Como os dados de treinamento não são rotulados por humanos, o modelo emerge em vez de ser codificado explicitamente.  Isso significa que o modelo pode gerar histórias ou uma narrativa própria sem ser explicitamente programado para isso.  Portanto, uma característica importante da FM é a homogeneização, o que significa que o mesmo método é usado em muitos domínios.  No entanto, com técnicas de personalização e ajuste fino, os FMs integrados aos produtos que aparecem hoje em dia não são bons apenas para gerar texto, texto para imagens e texto para código, mas também para explicar tarefas específicas de domínio ou depurar código.  Por exemplo, FMs como o Codex da OpenAI ou o Code Llama da Meta podem gerar código em várias linguagens de programação com base em descrições em linguagem natural de uma tarefa de programação.  Esses modelos são proficientes em mais de uma dúzia de linguagens de programação, incluindo Python, C#, JavaScript, Perl, Ruby e SQL.  Eles entendem a intenção do usuário e geram código específico que realiza a tarefa desejada, útil para desenvolvimento de software, otimização de código e automação de tarefas de programação.</block>
  <block id="09505640cb74de4ed6c0043b4fd83b62" category="section-title">Ajuste fino, especificidade de domínio e retreinamento</block>
  <block id="d70061bb0ac24d99b6a01f537dfc5836" category="inline-link-macro">Lhama de Meta 2</block>
  <block id="3983fea9bc2f220141201994aa6cf9de" category="paragraph">Uma das práticas comuns na implantação do LLM após a preparação e o pré-processamento de dados é selecionar um modelo pré-treinado que foi treinado em um conjunto de dados grande e diversificado.  No contexto de ajuste fino, isso pode ser um modelo de linguagem grande de código aberto, como<block ref="40c631914d673c775e5813606a4c652a" category="inline-link-macro-rx"></block> treinado em 70 bilhões de parâmetros e 2 trilhões de tokens.  Depois que o modelo pré-treinado for selecionado, o próximo passo é ajustá-lo nos dados específicos do domínio.  Isso envolve ajustar os parâmetros do modelo e treiná-lo com os novos dados para se adaptar a um domínio e tarefa específicos.  Por exemplo, a BloombergGPT, uma LLM proprietária treinada em uma ampla gama de dados financeiros que atendem ao setor financeiro.  Modelos específicos de domínio projetados e treinados para uma tarefa específica geralmente têm maior precisão e desempenho dentro de seu escopo, mas baixa transferibilidade entre outras tarefas ou domínios.  Quando o ambiente de negócios e os dados mudam ao longo de um período, a precisão da previsão do FM pode começar a diminuir quando comparada ao seu desempenho durante os testes.  É nesse momento que o retreinamento ou ajuste fino do modelo se torna crucial.  O retreinamento de modelo em IA/ML tradicional refere-se à atualização de um modelo de ML implantado com novos dados, geralmente realizado para eliminar dois tipos de desvios que ocorrem.  (1) Desvio de conceito – quando a ligação entre as variáveis de entrada e as variáveis de destino muda ao longo do tempo, uma vez que a descrição do que queremos prever muda, o modelo pode produzir previsões imprecisas.  (2) Desvio de dados – ocorre quando as características dos dados de entrada mudam, como mudanças nos hábitos ou comportamento do cliente ao longo do tempo e, portanto, a incapacidade do modelo de responder a tais mudanças.  De forma semelhante, a reciclagem se aplica a FMs/LLMs, porém pode ser muito mais custosa (em milhões de dólares), portanto, não é algo que a maioria das organizações consideraria.  Está sob pesquisa ativa, ainda emergindo no campo do LLMOps.  Então, em vez de retreinar, quando ocorre decadência do modelo em FMs ajustados, as empresas podem optar por fazer um novo ajuste fino (muito mais barato) com um conjunto de dados mais novo.  Para uma perspectiva de custo, listamos abaixo um exemplo de uma tabela de preços de modelo do Azure-OpenAI Services.  Para cada categoria de tarefa, os clientes podem ajustar e avaliar modelos em conjuntos de dados específicos.</block>
  <block id="95d06c21390dc25827c0fd489dc141e4" category="paragraph">Fonte: Microsoft Azure</block>
  <block id="56307bc010f6f11cf695a4f4a8868ec2" category="paragraph"><block ref="56307bc010f6f11cf695a4f4a8868ec2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="157d80dbb8ad88a26dfd59594b88e11c" category="section-title">Engenharia rápida e inferência</block>
  <block id="e48b39374db0f3e4c1479cb81f7ebd58" category="paragraph">Engenharia rápida refere-se aos métodos eficazes de como se comunicar com LLMs para executar tarefas desejadas sem atualizar os pesos do modelo.  Tão importante quanto o treinamento e o ajuste fino do modelo de IA para aplicações de PNL, a inferência é igualmente importante, onde os modelos treinados respondem às solicitações do usuário.  Os requisitos do sistema para inferência geralmente dependem muito mais do desempenho de leitura do sistema de armazenamento de IA que alimenta dados de LLMs para as GPUs, pois ele precisa ser capaz de aplicar bilhões de parâmetros de modelo armazenados para produzir a melhor resposta.</block>
  <block id="71451daa1205b079e03924f700485fb7" category="section-title">LLMOps, Monitoramento de Modelos e Vectorstores</block>
  <block id="37dc13dd8c23bd5e417bad0376cb8642" category="paragraph">Assim como as operações de aprendizado de máquina tradicionais (MLOps), as operações de modelos de grande linguagem (LLMOps) também exigem a colaboração de cientistas de dados e engenheiros de DevOps com ferramentas e práticas recomendadas para o gerenciamento de LLMs em ambientes de produção.  No entanto, o fluxo de trabalho e a pilha de tecnologia para LLMs podem variar de algumas maneiras.  Por exemplo, pipelines LLM criados usando estruturas como LangChain encadeiam diversas chamadas de API LLM para endpoints de incorporação externos, como vectorstores ou bancos de dados de vetores.  O uso de um endpoint de incorporação e um vectorstore para conectores downstream (como um banco de dados vetorial) representa um desenvolvimento significativo na forma como os dados são armazenados e acessados.  Ao contrário dos modelos tradicionais de ML que são desenvolvidos do zero, os LLMs geralmente dependem da aprendizagem por transferência, pois esses modelos começam com FMs que são ajustados com novos dados para melhorar o desempenho em um domínio mais específico.  Portanto, é crucial que o LLMOps forneça recursos de gerenciamento de risco e monitoramento de decaimento do modelo.</block>
  <block id="e1e7449571fe3b65d3a1e689bc700cbc" category="section-title">Riscos e Ética na era da IA Generativa</block>
  <block id="c12a37efb07149af3ee94636c74b80c5" category="paragraph">"ChatGPT – É inteligente, mas ainda fala bobagens." – MIT Tech Review.  Lixo que entra e lixo que sai sempre foi um caso desafiador na computação.  A única diferença com a IA generativa é que ela se destaca em tornar o lixo altamente confiável, levando a resultados imprecisos.  Os LLMs tendem a inventar fatos para se adequar à narrativa que estão construindo.  Portanto, as empresas que veem a IA generativa como uma grande oportunidade para reduzir seus custos com equivalentes de IA precisam detectar falsificações profundas com eficiência, reduzir vieses e diminuir riscos para manter os sistemas honestos e éticos.  Um pipeline de dados de fluxo livre com uma infraestrutura de IA robusta que ofereça suporte à mobilidade de dados, qualidade de dados, governança de dados e proteção de dados por meio de criptografia de ponta a ponta e proteções de IA é essencial no design de modelos de IA generativos responsáveis e explicáveis.</block>
  <block id="b1c01c916bfeda43bbe010599a3756ef" category="section-title">Cenário do cliente e NetApp</block>
  <block id="d475afb6eaf5d8966136580d55f5a688" category="paragraph">Figura 3: Fluxo de trabalho do modelo de aprendizado de máquina/linguagem grande</block>
  <block id="1d5b6314b7c490b3ba00c157c5d73c98" category="paragraph"><block ref="1d5b6314b7c490b3ba00c157c5d73c98" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9dd90f4ead88ee59ec52f11bac2d164b" category="paragraph">*Estamos treinando ou ajustando?*  A questão de (a) treinar um modelo LLM do zero, ajustar um FM pré-treinado ou usar o RAG para recuperar dados de repositórios de documentos fora de um modelo de base e aumentar os prompts e (b) aproveitar LLMs de código aberto (por exemplo, Llama 2) ou FMs proprietários (por exemplo, ChatGPT, Bard, AWS Bedrock) é uma decisão estratégica para as organizações.  Cada abordagem tem um equilíbrio entre custo-benefício, gravidade dos dados, operações, precisão do modelo e gerenciamento de LLMs.</block>
  <block id="8c8696e5c9dd013fefe41f5a257ecba6" category="paragraph">A NetApp , como empresa, adota a IA internamente em sua cultura de trabalho e em sua abordagem aos esforços de design e engenharia de produtos.  Por exemplo, a proteção autônoma contra ransomware da NetApp é criada usando IA e aprendizado de máquina.  Ele fornece detecção antecipada de anomalias no sistema de arquivos para ajudar a identificar ameaças antes que elas afetem as operações.  Em segundo lugar, a NetApp usa IA preditiva para suas operações comerciais, como previsão de vendas e estoque, e chatbots para auxiliar os clientes em serviços de suporte a produtos de call center, especificações técnicas, garantia, manuais de serviço e muito mais.  Em terceiro lugar, a NetApp agrega valor ao cliente para o pipeline de dados de IA e o fluxo de trabalho de ML/LLM por meio de produtos e soluções que atendem clientes que criam soluções de IA preditivas, como previsão de demanda, imagens médicas, análise de sentimentos e soluções de IA generativas, como GANs para detecção de anomalias em imagens industriais no setor de manufatura e combate à lavagem de dinheiro e detecção de fraudes em serviços bancários e financeiros com produtos e recursos da NetApp , como NetApp ONTAP AI, NetApp SnapMirror e NetApp FlexCache.</block>
  <block id="1e79e12b94e448f7c2f614e8ab2794ba" category="section-title">Recursos do NetApp</block>
  <block id="14560cdfa11223c1b6b5ae41321de6d4" category="paragraph">A movimentação e o gerenciamento de dados em aplicativos de IA generativa, como chatbot, geração de código, geração de imagens ou expressão de modelo de genoma, podem abranger a borda, o data center privado e o ecossistema multicloud híbrido.  Por exemplo, um bot de IA em tempo real que ajuda um passageiro a atualizar sua passagem aérea para a classe executiva a partir de um aplicativo de usuário final exposto por meio de APIs de modelos pré-treinados, como o ChatGPT, não consegue realizar essa tarefa sozinho, pois as informações do passageiro não estão disponíveis publicamente na internet.  A API requer acesso às informações pessoais do passageiro e às informações da passagem da companhia aérea, que podem existir em um ecossistema híbrido ou multinuvem.  Um cenário semelhante pode se aplicar a cientistas que compartilham uma molécula de medicamento e dados de pacientes por meio de um aplicativo de usuário final que usa LLMs para realizar testes clínicos em descobertas de medicamentos envolvendo instituições de pesquisa biomédica de um para muitos.  Dados confidenciais que são passados para FMs ou LLMs podem incluir PII, informações financeiras, informações de saúde, dados biométricos, dados de localização, dados de comunicação, comportamento online e informações legais.  Em um evento de renderização em tempo real, execução rápida e inferência de borda, há movimentação de dados do aplicativo do usuário final para endpoints de armazenamento por meio de modelos LLM proprietários ou de código aberto para um data center local ou plataformas de nuvem pública.  Em todos esses cenários, a mobilidade e a proteção de dados são cruciais para as operações de IA envolvendo LLMs que dependem de grandes conjuntos de dados de treinamento e movimentação desses dados.</block>
  <block id="2bf2b67b54f29152ea5e8649dd4b7327" category="paragraph">Figura 4: Pipeline de dados de IA generativa - LLM</block>
  <block id="206f6329180f9a8251d5f78b853663ab" category="inline-image-macro">Figura 4: Pipeline de dados generativos de IA-LLM</block>
  <block id="47b42e2c6c693df656a00ec63e39dde3" category="paragraph"><block ref="47b42e2c6c693df656a00ec63e39dde3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc004144b88d4fadbbf7623c57d2c805" category="paragraph">O portfólio de infraestrutura de armazenamento, dados e serviços de nuvem da NetApp é alimentado por software de gerenciamento de dados inteligente.</block>
  <block id="7d5e80d61d854ee2e646efedf9f5e72d" category="paragraph">*Preparação de dados*: O primeiro pilar da pilha de tecnologia do LLM permanece praticamente intocado pela pilha de ML tradicional mais antiga.  O pré-processamento de dados no pipeline de IA é necessário para normalizar e limpar os dados antes do treinamento ou ajuste fino.  Esta etapa inclui conectores para ingerir dados onde quer que eles residam na forma de uma camada do Amazon S3 ou em sistemas de armazenamento locais, como um armazenamento de arquivos ou um armazenamento de objetos como o NetApp StorageGRID.</block>
  <block id="b63aea4b58eede8ed8da27c8b36c34dc" category="paragraph">* NetApp ONTAP* é a tecnologia fundamental que sustenta as soluções de armazenamento crítico da NetApp no data center e na nuvem.  O ONTAP inclui vários recursos e capacidades de gerenciamento e proteção de dados, incluindo proteção automática contra ransomware contra ataques cibernéticos, recursos integrados de transporte de dados e capacidades de eficiência de armazenamento para uma variedade de arquiteturas, desde locais, híbridas, multiclouds em NAS, SAN, objetos e situações de armazenamento definido por software (SDS) de implantações de LLM.</block>
  <block id="77b83e7426a1ca8eea17df3ff3a421f7" category="paragraph">* NetApp ONTAP AI* para treinamento de modelos de aprendizado profundo.  O NetApp ONTAP oferece suporte ao NVIDIA GPU Direct Storage com o uso de NFS sobre RDMA para clientes NetApp com cluster de armazenamento ONTAP e nós de computação NVIDIA DGX.  Ele oferece um desempenho econômico para ler e processar conjuntos de dados de origem do armazenamento para a memória diversas vezes para promover a inteligência, permitindo que as organizações tenham acesso a treinamento, ajuste fino e dimensionamento para LLMs.</block>
  <block id="420e9d37fdcde42065e69c7f6d925ab3" category="paragraph">* NetApp FlexCache* é um recurso de cache remoto que simplifica a distribuição de arquivos e armazena em cache apenas os dados lidos ativamente.  Isso pode ser útil para treinamento, reciclagem e ajuste fino de LLM, agregando valor aos clientes com requisitos de negócios, como renderização em tempo real e inferência de LLM.</block>
  <block id="0aef0293018a6f953acd79d5d6fb52ae" category="paragraph">* NetApp SnapMirror* é um recurso ONTAP que replica instantâneos de volume entre quaisquer dois sistemas ONTAP .  Esse recurso transfere dados de ponta de forma otimizada para seu data center local ou para a nuvem.  O SnapMirror pode ser usado para mover dados de forma segura e eficiente entre nuvens locais e hiperescaláveis, quando os clientes desejam desenvolver IA generativa em nuvens com RAG contendo dados empresariais.  Ele transfere com eficiência apenas as alterações, economizando largura de banda e acelerando a replicação, trazendo, assim, recursos essenciais de mobilidade de dados durante as operações de treinamento, retreinamento e ajuste fino de FMs ou LLMs.</block>
  <block id="67e47ad6c891ade32e226f1b046d1168" category="paragraph">* O NetApp SnapLock* traz capacidade de disco imutável em sistemas de armazenamento baseados em ONTAP para controle de versão de conjuntos de dados.  A arquitetura microcore foi projetada para proteger os dados do cliente com o mecanismo FPolicy Zero Trust.  A NetApp garante que os dados do cliente estejam disponíveis resistindo a ataques de negação de serviço (DoS) quando um invasor interage com um LLM de uma forma que consome muitos recursos.</block>
  <block id="6fb00f321c345f8a92148aec8d1359f9" category="paragraph">* O NetApp Cloud Data Sense* ajuda a identificar, mapear e classificar informações pessoais presentes em conjuntos de dados empresariais, promulgar políticas, atender a requisitos de privacidade no local ou na nuvem, ajudar a melhorar a postura de segurança e cumprir regulamentações.</block>
  <block id="8bca7c4074d7b3156f8b66e3ad7a5be8" category="paragraph">* Classificação NetApp BlueXP*, fornecida pelo Cloud Data Sense.  Os clientes podem escanear, analisar, categorizar e agir automaticamente sobre dados em todo o acervo de dados, detectar riscos de segurança, otimizar o armazenamento e acelerar implantações na nuvem.  Ele combina serviços de armazenamento e dados por meio de seu plano de controle unificado. Os clientes podem usar instâncias de GPU para computação e ambientes multicloud híbridos para camadas de armazenamento a frio e para arquivos e backups.</block>
  <block id="528fb7334ec5453cef67bca12d29f735" category="paragraph">* Dualidade arquivo-objeto do NetApp *.  O NetApp ONTAP permite acesso de protocolo duplo para NFS e S3.  Com esta solução, os clientes podem acessar dados NFS de notebooks Amazon AWS SageMaker por meio de buckets S3 do NetApp Cloud Volumes ONTAP.  Isso oferece flexibilidade aos clientes que precisam de acesso fácil a fontes de dados heterogêneas com a capacidade de compartilhar dados do NFS e do S3.  Por exemplo, ajuste fino de FMs como os modelos de geração de texto Llama 2 da Meta no SageMaker com acesso a buckets de arquivo-objeto.</block>
  <block id="a2e08866ca50b890089d6b77f640d7b5" category="paragraph">O serviço * NetApp Cloud Sync* oferece uma maneira simples e segura de migrar dados para qualquer destino, na nuvem ou no local.  O Cloud Sync transfere e sincroniza dados perfeitamente entre armazenamento local ou em nuvem, NAS e armazenamentos de objetos.</block>
  <block id="e53b3c8e83c8d94be048ce5801830a49" category="paragraph">* NetApp XCP* é um software cliente que permite migrações de dados rápidas e confiáveis de qualquer para NetApp e de NetApp para NetApp .  O XCP também oferece a capacidade de mover dados em massa de forma eficiente dos sistemas de arquivos Hadoop HDFS para o ONTAP NFS, S3 ou StorageGRID, e a análise de arquivos do XCP fornece visibilidade do sistema de arquivos.</block>
  <block id="d0d48e5a8fe903e906882461b57dcfd3" category="paragraph">* NetApp DataOps Toolkit* é uma biblioteca Python que simplifica para cientistas de dados, DevOps e engenheiros de dados a execução de diversas tarefas de gerenciamento de dados, como provisionamento, clonagem ou criação de snapshots quase instantâneos de um volume de dados ou espaço de trabalho do JupyterLab, apoiados por armazenamento NetApp de alto desempenho escalável.</block>
  <block id="97d451a12ea524d66984cc35758777b4" category="paragraph">*Segurança do produto da NetApp*.  Os LLMs podem inadvertidamente revelar dados confidenciais em suas respostas, o que é uma preocupação para os CISOs que estudam as vulnerabilidades associadas a aplicativos de IA que utilizam LLMs.  Conforme descrito pelo OWASP (Open Worldwide Application Security Project), problemas de segurança como envenenamento de dados, vazamento de dados, negação de serviço e injeções imediatas em LLMs podem impactar empresas, desde a exposição de dados até o acesso não autorizado por invasores.  Os requisitos de armazenamento de dados devem incluir verificações de integridade e instantâneos imutáveis para dados estruturados, semiestruturados e não estruturados.  NetApp Snapshots e SnapLock estão sendo usados para controle de versão de conjuntos de dados.  Ele traz controle de acesso rigoroso baseado em funções (RBAC), bem como protocolos seguros e criptografia padrão do setor para proteger dados em repouso e em trânsito.  O Cloud Insights e o Cloud Data Sense juntos oferecem recursos para ajudar você a identificar forensemente a origem da ameaça e priorizar quais dados restaurar.</block>
  <block id="0364ee2a32c23b9f35e29f68c79d63e1" category="section-title">* ONTAP AI com DGX BasePOD*</block>
  <block id="c6f1dc673303b79fafb5e05f0c7a97cb" category="paragraph">A arquitetura de referência de IA do NetApp ONTAP com NVIDIA DGX BasePOD é uma arquitetura escalável para cargas de trabalho de aprendizado de máquina (ML) e inteligência artificial (IA).  Para a fase crítica de treinamento dos LLMs, os dados normalmente são copiados do armazenamento de dados para o cluster de treinamento em intervalos regulares.  Os servidores usados nesta fase usam GPUs para paralelizar cálculos, criando um enorme apetite por dados.  Atender às necessidades de largura de banda de E/S bruta é crucial para manter alta utilização da GPU.</block>
  <block id="9a05494b8b259619e21e3e78c47f4dc5" category="section-title">* ONTAP AI com NVIDIA AI Enterprise*</block>
  <block id="65590ec18b850984cfb8bbe6ba35fe7d" category="paragraph">O NVIDIA AI Enterprise é um conjunto completo e nativo em nuvem de software de IA e análise de dados que é otimizado, certificado e suportado pela NVIDIA para ser executado no VMware vSphere com sistemas certificados pela NVIDIA.  Este software facilita a implantação, o gerenciamento e o dimensionamento simples e rápidos de cargas de trabalho de IA no ambiente de nuvem híbrida moderno.  O NVIDIA AI Enterprise, com tecnologia NetApp e VMware, oferece carga de trabalho de IA de nível empresarial e gerenciamento de dados em um pacote simplificado e familiar.</block>
  <block id="1ad177c0b9d841f941eb7d5322dc9b52" category="section-title">*Plataformas em Nuvem 1P*</block>
  <block id="0e877c6cfb49f5bbdc17c6d204b4b7cb" category="paragraph">As ofertas de armazenamento em nuvem totalmente gerenciadas estão disponíveis nativamente no Microsoft Azure como Azure NetApp Files (ANF), na AWS como Amazon FSx for NetApp ONTAP (FSx ONTAP) e no Google como Google Cloud NetApp Volumes (GNCV).  1P é um sistema de arquivos gerenciado e de alto desempenho que permite aos clientes executar cargas de trabalho de IA de alta disponibilidade com segurança de dados aprimorada em nuvens públicas, para ajustar LLMs/FMs com plataformas de ML nativas da nuvem, como AWS SageMaker, Azure-OpenAI Services e Vertex AI do Google.</block>
  <block id="64992f0c01704aa99d3bd851b7673bf7" category="section-title">Conjunto de soluções para parceiros da NetApp</block>
  <block id="0e3151175898c0a6687552a854a08b00" category="paragraph">Além de seus principais produtos de dados, tecnologias e recursos, a NetApp também colabora estreitamente com uma rede robusta de parceiros de IA para agregar valor aos clientes.</block>
  <block id="5c682f526a6d29391ad4d45cd7c7cae9" category="paragraph">* Os Guardrails da NVIDIA * em sistemas de IA servem como salvaguardas para garantir o uso ético e responsável das tecnologias de IA.  Os desenvolvedores de IA podem escolher definir o comportamento de aplicativos com tecnologia LLM em tópicos específicos e impedi-los de se envolver em discussões sobre tópicos indesejados.  Guardrails, um kit de ferramentas de código aberto, oferece a capacidade de conectar um LLM a outros serviços de forma integrada e segura para criar sistemas de conversação LLM confiáveis, seguros e protegidos.</block>
  <block id="0b46f95333d136197f1bb757634ebae2" category="paragraph">*Domino Data Lab* fornece ferramentas versáteis e de nível empresarial para criar e produzir IA generativa - rápida, segura e econômica, onde quer que você esteja em sua jornada de IA.  Com a plataforma Enterprise MLOps da Domino's, os cientistas de dados podem usar as ferramentas preferidas e todos os seus dados, treinar e implantar modelos facilmente em qualquer lugar e gerenciar riscos e custos de forma eficaz — tudo a partir de um único centro de controle.</block>
  <block id="20350fb42ff163b07d9d4a2636b4a555" category="paragraph">*Modzy para Edge AI*.  A NetApp e a Modzy fizeram uma parceria para fornecer IA em escala para qualquer tipo de dado, incluindo imagens, áudio, texto e tabelas.  Modzy é uma plataforma MLOps para implantação, integração e execução de modelos de IA, oferecendo aos cientistas de dados recursos de monitoramento de modelos, detecção de desvios e explicabilidade, com uma solução integrada para inferência LLM perfeita.</block>
  <block id="50841f507614d3540c25e7671dc0cdc0" category="paragraph">A *Run:AI* e a NetApp fizeram uma parceria para demonstrar os recursos exclusivos da solução NetApp ONTAP AI com a plataforma de gerenciamento de cluster Run:AI para simplificar a orquestração de cargas de trabalho de IA.  Ele divide e une automaticamente os recursos da GPU, projetados para dimensionar seus pipelines de processamento de dados para centenas de máquinas com estruturas de integração integradas para Spark, Ray, Dask e Rapids.</block>
  <block id="7f8ef2f7d9a73eb64e35d815049ddd46" category="paragraph">A IA generativa pode produzir resultados eficazes somente quando o modelo é treinado em grandes quantidades de dados de qualidade.  Embora os LLMs tenham alcançado marcos notáveis, é fundamental reconhecer suas limitações, desafios de design e riscos associados à mobilidade e à qualidade dos dados.  Os LLMs dependem de conjuntos de dados de treinamento grandes e díspares de fontes de dados heterogêneas.  Resultados imprecisos ou tendenciosos gerados pelos modelos podem colocar empresas e consumidores em risco.  Esses riscos podem corresponder a restrições para LLMs que surgem potencialmente de desafios de gerenciamento de dados associados à qualidade de dados, segurança de dados e mobilidade de dados.  A NetApp ajuda as organizações a lidar com as complexidades criadas pelo rápido crescimento de dados, mobilidade de dados, gerenciamento de várias nuvens e adoção de IA.  A infraestrutura de IA em escala e o gerenciamento eficiente de dados são cruciais para definir o sucesso de aplicações de IA como a IA generativa.  É essencial que os clientes cubram todos os cenários de implantação sem comprometer a capacidade de expansão conforme necessário pelas empresas, mantendo a eficiência de custos, a governança de dados e as práticas éticas de IA sob controle.  A NetApp trabalha constantemente para ajudar os clientes a simplificar e acelerar suas implantações de IA.</block>
  <block id="cea78864209b835e9b37cbe0a2cb862e" category="doc">NVA-1172-DESIGN: NetApp AIPod com Lenovo para NVIDIA OVX</block>
  <block id="cd270e0e169361bb079873f1cb21e6b5" category="paragraph">Bobby Oommen, Abhinav Singh, Roney Daniel, NetApp</block>
  <block id="999a2bd7b329bd7fe4178352281b558b" category="paragraph">Esta arquitetura de referência combina servidores OVX Lenovo ThinkSystem certificados pela NVIDIA, equipados com GPUs NVIDIA L40S, com redes NVIDIA Spectrum para fornecer uma solução de infraestrutura ideal para otimizar e implantar LLMs (modelos de grande linguagem).  A intenção deste documento é fornecer orientações relacionadas ao armazenamento para uma configuração OVX.  Esta plataforma é adequada para diversas cargas de trabalho de IA generativa, incluindo RAG (Retrieval Augmented Generation), ajuste fino e treinamento de modelos leves.</block>
  <block id="688a655aa25fa96dbcd977348cc95acc" category="inline-link-macro">NVA-1172-DESIGN: Guia de design do NetApp AIPod com Lenovo para NVIDIA OVX</block>
  <block id="07ba0b8aab1e2887d9dc0f7f9d5dad4f" category="paragraph"><block ref="07ba0b8aab1e2887d9dc0f7f9d5dad4f" category="inline-link-macro-rx"></block></block>
  <block id="82b67ae3d50932b0d818b7c3a23b3428" category="summary">NetApp AIPod com sistemas NVIDIA DGX - Arquitetura</block>
  <block id="92527686d5dc11342676e296e31b0b51" category="doc">NVA-1173 NetApp AIPod com sistemas NVIDIA DGX H100 - Arquitetura da solução</block>
  <block id="34fc6f8c7d10337be1b911dd98627e40" category="paragraph">Esta seção se concentra na arquitetura do NetApp AIPod com sistemas NVIDIA DGX.</block>
  <block id="b10a3a95ab83cbad7acc457e6bc13a1b" category="section-title">NetApp AIPod com sistemas DGX</block>
  <block id="990e00b86cef2bb25d2e346df6e7adfe" category="paragraph">Esta arquitetura de referência utiliza malhas separadas para interconexão de cluster de computação e acesso ao armazenamento, com conectividade InfiniBand (IB) de 400 Gb/s entre nós de computação.  O desenho abaixo mostra a topologia geral da solução do NetApp AIPod com sistemas DGX H100.</block>
  <block id="5d065d1080de5349462d7a342f622bf3" category="paragraph">_Topologia da solução NetApp AIpod_</block>
  <block id="552dcf63ade7f6a706107c5da1f5a2a6" category="paragraph"><block ref="552dcf63ade7f6a706107c5da1f5a2a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19c939070c0b6ebbb52e1e0119b15301" category="section-title">Projeto de rede</block>
  <block id="57f55a30c80dbf621eb119c782a8b3c5" category="paragraph">Nessa configuração, a estrutura do cluster de computação usa um par de switches IB QM9700 de 400 Gb/s, que são conectados entre si para alta disponibilidade.  Cada sistema DGX H100 é conectado aos switches usando oito conexões, com portas pares conectadas a um switch e portas ímpares conectadas ao outro switch.</block>
  <block id="8ee4ef799026973266981f7c555ea058" category="paragraph">Para acesso ao sistema de armazenamento, gerenciamento em banda e acesso do cliente, um par de switches Ethernet SN4600 é usado.  Os switches são conectados com links entre switches e configurados com várias VLANs para isolar os vários tipos de tráfego.  O roteamento L3 básico é habilitado entre VLANs específicas para permitir múltiplos caminhos entre interfaces de cliente e armazenamento no mesmo switch, bem como entre switches para alta disponibilidade.  Para implantações maiores, a rede Ethernet pode ser expandida para uma configuração folha-espinha adicionando pares de switches adicionais para switches espinha e folhas adicionais, conforme necessário.</block>
  <block id="082b01f67d64181611dc998408a2b121" category="inline-link-macro">detalhes de implantação</block>
  <block id="41b55cdcb36636c126a5ef6c6e873a08" category="paragraph">Além da interconexão de computadores e das redes Ethernet de alta velocidade, todos os dispositivos físicos também são conectados a um ou mais switches Ethernet SN2201 para gerenciamento fora de banda.  Por favor, veja o<block ref="11e89a956fe8616ed611e595e22cdb97" category="inline-link-macro-rx"></block> página para obter mais informações sobre configuração de rede.</block>
  <block id="9eaf2c6f65cf6ad700b387972ddc345e" category="section-title">Visão geral do acesso ao armazenamento para sistemas DGX H100</block>
  <block id="b1cdc2ac23891a1bf0e697359ffeeef6" category="paragraph">Cada sistema DGX H100 é provisionado com dois adaptadores ConnectX-7 de porta dupla para gerenciamento e tráfego de armazenamento e, para esta solução, ambas as portas em cada placa são conectadas ao mesmo switch.  Uma porta de cada placa é então configurada em um vínculo LACP MLAG com uma porta conectada a cada switch, e VLANs para gerenciamento em banda, acesso de cliente e acesso de armazenamento em nível de usuário são hospedadas nesse vínculo.</block>
  <block id="891c72a31ed1199769c3f62cab11e7b4" category="paragraph">A outra porta em cada placa é usada para conectividade com os sistemas de armazenamento AFF A90 e pode ser usada em diversas configurações, dependendo dos requisitos de carga de trabalho.  Para configurações que usam NFS sobre RDMA para oferecer suporte ao NVIDIA Magnum IO GPUDirect Storage, as portas são usadas individualmente com endereços IP em VLANs separadas.  Para implantações que não exigem RDMA, as interfaces de armazenamento também podem ser configuradas com vinculação LACP para fornecer alta disponibilidade e largura de banda adicional.  Com ou sem RDMA, os clientes podem montar o sistema de armazenamento usando NFS v4.1 pNFS e entroncamento de sessão para permitir acesso paralelo a todos os nós de armazenamento no cluster.  Por favor, veja o<block ref="11e89a956fe8616ed611e595e22cdb97" category="inline-link-macro-rx"></block> página para obter mais informações sobre a configuração do cliente.</block>
  <block id="c95998835114a4e50f348f8c5e5686ed" category="inline-link-macro">Documentação do NVIDIA BasePOD</block>
  <block id="8660b0a825d671d8855117ae496d3af6" category="paragraph">Para mais detalhes sobre a conectividade do sistema DGX H100, consulte o<block ref="784f66b69fd9a6fd2983e969e5202b40" category="inline-link-macro-rx"></block> .</block>
  <block id="42dc99c097c1b9b9af75ba060788e1f1" category="section-title">Projeto do sistema de armazenamento</block>
  <block id="61b2fad5f824784462363e1b366833fa" category="paragraph">Cada sistema de armazenamento AFF A90 é conectado usando seis portas 200 GbE de cada controlador.  Quatro portas de cada controlador são usadas para acesso a dados de carga de trabalho dos sistemas DGX, e duas portas de cada controlador são configuradas como um grupo de interface LACP para dar suporte ao acesso dos servidores do plano de gerenciamento para artefatos de gerenciamento de cluster e diretórios pessoais do usuário.  Todo o acesso aos dados do sistema de armazenamento é fornecido por meio do NFS, com uma máquina virtual de armazenamento (SVM) dedicada ao acesso à carga de trabalho de IA e uma SVM separada dedicada aos usos de gerenciamento de cluster.</block>
  <block id="6c9aef89eae0fd771909b15623e452df" category="paragraph">O SVM de gerenciamento requer apenas um único LIF, que é hospedado nos grupos de interface de 2 portas configurados em cada controlador.  Outros volumes FlexGroup são provisionados no SVM de gerenciamento para abrigar artefatos de gerenciamento de cluster, como imagens de nós de cluster, dados históricos de monitoramento do sistema e diretórios pessoais do usuário final.  O desenho abaixo mostra a configuração lógica do sistema de armazenamento.</block>
  <block id="995db3e6bdfdd81bd5e1b6a98b33e5b7" category="paragraph">_Configuração lógica do cluster de armazenamento NetApp A90_</block>
  <block id="1e7a613d4d1ae838806eb303b8f25492" category="paragraph"><block ref="1e7a613d4d1ae838806eb303b8f25492" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6420553f17ebdab39fa9a1825d57651" category="section-title">Servidores de plano de gerenciamento</block>
  <block id="e6391a8600a62f5346ec27d437d43626" category="paragraph">Esta arquitetura de referência também inclui cinco servidores baseados em CPU para uso no plano de gerenciamento.  Dois desses sistemas são usados como nós principais do NVIDIA Base Command Manager para implantação e gerenciamento de cluster.  Os outros três sistemas são usados para fornecer serviços de cluster adicionais, como nós mestres do Kubernetes ou nós de login para implantações que utilizam o Slurm para agendamento de tarefas.  Implantações que utilizam o Kubernetes podem aproveitar o driver NetApp Trident CSI para fornecer provisionamento automatizado e serviços de dados com armazenamento persistente para cargas de trabalho de gerenciamento e IA no sistema de armazenamento AFF A900 .</block>
  <block id="108f9bbf932c304dff7d03edbf186c18" category="paragraph">Cada servidor é fisicamente conectado aos switches IB e Ethernet para permitir a implantação e o gerenciamento do cluster, e configurado com montagens NFS no sistema de armazenamento por meio do SVM de gerenciamento para armazenamento de artefatos de gerenciamento do cluster, conforme descrito anteriormente.</block>
  <block id="19a97f58216292f6ce34aa1a3ad9e96e" category="summary">NetApp AIPod com sistemas NVIDIA DGX - Onde encontrar informações adicionais</block>
  <block id="43e1c1d93ec30f643ac7004cd6fafc47" category="doc">NVA-1173 NetApp AIPod com sistemas NVIDIA DGX - Conclusão e informações adicionais</block>
  <block id="7c3d91801a54614f755a9f2897ee42f3" category="paragraph">Esta seção inclui referências para informações adicionais sobre o NetApp AIPod com sistemas NVIDIA DGX.</block>
  <block id="bcde7144e6a13836183bd03e403987ef" category="paragraph">A arquitetura DGX BasePOD é uma plataforma de aprendizado profundo de última geração que requer recursos igualmente avançados de armazenamento e gerenciamento de dados.  Ao combinar o DGX BasePOD com os sistemas NetApp AFF , a arquitetura do NetApp AIPod com sistemas DGX pode ser implementada em quase qualquer escala.  Combinado com a integração de nuvem superior e os recursos definidos por software do NetApp ONTAP, o AFF permite uma gama completa de pipelines de dados que abrangem a borda, o núcleo e a nuvem para projetos de DL bem-sucedidos.</block>
  <block id="092bf78f9c97ba171b8232ddff585392" category="section-title">Informações adicionais</block>
  <block id="68e34599e7058d633da08de84c55032d" category="paragraph">Para saber mais sobre as informações descritas neste documento, consulte os seguintes documentos e/ou sites:</block>
  <block id="f85150beb9ce598095b212b1de60815f" category="list-text">Software de gerenciamento de dados NetApp ONTAP — biblioteca de informações ONTAP</block>
  <block id="5f60faf04d2b972aa0cf8c369cfc6a26" category="inline-link"><block ref="5f60faf04d2b972aa0cf8c369cfc6a26" category="inline-link-rx"></block></block>
  <block id="d99ede023f079413a479e349dcb54616" category="paragraph"><block ref="d99ede023f079413a479e349dcb54616" category="inline-link-rx"></block></block>
  <block id="b8667e5a766c0335e106bdd9b4ea825f" category="list-text">Sistemas de armazenamento NetApp AFF A90</block>
  <block id="8a5df1408a92dc0ef3181cd15cbc989e" category="inline-link"><block ref="8a5df1408a92dc0ef3181cd15cbc989e" category="inline-link-rx"></block></block>
  <block id="22ef65e375f266c2889509f939e1ac83" category="paragraph"><block ref="22ef65e375f266c2889509f939e1ac83" category="inline-link-rx"></block></block>
  <block id="29b91fda4bb7baae0176d0ca5870634a" category="list-text">Informações sobre NetApp ONTAP RDMA-</block>
  <block id="0f4b138acdd63a2f36e4aeb66ce027c5" category="inline-link-macro"><block ref="0f4b138acdd63a2f36e4aeb66ce027c5" category="inline-link-rx"></block></block>
  <block id="c08c09703d9322a16ef4a93b82ff897e" category="paragraph"><block ref="c08c09703d9322a16ef4a93b82ff897e" category="inline-link-macro-rx"></block></block>
  <block id="e71e852dc96d4d0e2da95de923a6f8ff" category="list-text">NetApp Trident</block>
  <block id="3daf8b3b7ee9b11922ef3d82e81e3a2c" category="paragraph"><block ref="3daf8b3b7ee9b11922ef3d82e81e3a2c" category="inline-link-macro-rx"></block></block>
  <block id="4613e07c94020e7ba8189d048f9d61c1" category="list-text">Blog de armazenamento GPUDirect da NetApp</block>
  <block id="cf8832fa60205a911c1036fb274f649e" category="inline-link"><block ref="cf8832fa60205a911c1036fb274f649e" category="inline-link-rx"></block></block>
  <block id="0f1f9907ba0a6f040f1fa28d77e74fb8" category="paragraph"><block ref="0f1f9907ba0a6f040f1fa28d77e74fb8" category="inline-link-rx"></block></block>
  <block id="64dc43320ec1a44c390fafb5e2408f4b" category="list-text">NVIDIA DGX BasePOD</block>
  <block id="6ff1278864800ae134fcd2dda1a5e0e9" category="inline-link"><block ref="6ff1278864800ae134fcd2dda1a5e0e9" category="inline-link-rx"></block></block>
  <block id="0c2cd58ffa7f091c420ae61854a0a8db" category="paragraph"><block ref="0c2cd58ffa7f091c420ae61854a0a8db" category="inline-link-rx"></block></block>
  <block id="e3d6e4bdd7281f2c5d652f6f01825970" category="list-text">Sistemas NVIDIA DGX H100</block>
  <block id="f3d1cd3a647a52b1157c812ae2d90248" category="inline-link"><block ref="f3d1cd3a647a52b1157c812ae2d90248" category="inline-link-rx"></block></block>
  <block id="f4e11a54d0110771220fa05425235763" category="paragraph"><block ref="f4e11a54d0110771220fa05425235763" category="inline-link-rx"></block></block>
  <block id="d90238071267e4279a25de2c6945b227" category="list-text">Rede NVIDIA</block>
  <block id="51c8257f6c8ba308b83f9f13b405dad0" category="inline-link"><block ref="51c8257f6c8ba308b83f9f13b405dad0" category="inline-link-rx"></block></block>
  <block id="a19d7568aa9c7e4c1f3bf3e831367115" category="paragraph"><block ref="a19d7568aa9c7e4c1f3bf3e831367115" category="inline-link-rx"></block></block>
  <block id="a96fecd8b3666b7b60c0bc0a24db79b2" category="list-text">Armazenamento NVIDIA Magnum IO-GPUDirect</block>
  <block id="74079d06fd0015403a15f89699e6bcba" category="inline-link"><block ref="74079d06fd0015403a15f89699e6bcba" category="inline-link-rx"></block></block>
  <block id="110c88150ddcbc728071b2fcd7848bd2" category="paragraph"><block ref="110c88150ddcbc728071b2fcd7848bd2" category="inline-link-rx"></block></block>
  <block id="c7bef72157cc39b6eb7c391a393a20d2" category="list-text">Comando básico da NVIDIA</block>
  <block id="bbae10fb46fb1d3604fe601d556f4187" category="inline-link"><block ref="bbae10fb46fb1d3604fe601d556f4187" category="inline-link-rx"></block></block>
  <block id="936c47b696a994feb0ad33a2addb1168" category="paragraph"><block ref="936c47b696a994feb0ad33a2addb1168" category="inline-link-rx"></block></block>
  <block id="b4675c30af15f661c8112c2853f97970" category="list-text">Gerenciador de comando básico da NVIDIA</block>
  <block id="5cb8e16a3e555ee938b528aaeb45b703" category="inline-link"><block ref="5cb8e16a3e555ee938b528aaeb45b703" category="inline-link-rx"></block></block>
  <block id="6b36fdb81918af4b96afe2ba587a8ae1" category="paragraph"><block ref="6b36fdb81918af4b96afe2ba587a8ae1" category="inline-link-rx"></block></block>
  <block id="51ab86189ca8b1d1a08ac2970d39f90c" category="list-text">NVIDIA AI Enterprise</block>
  <block id="42c9b161f86365b647172182503d9520" category="inline-link"><block ref="42c9b161f86365b647172182503d9520" category="inline-link-rx"></block></block>
  <block id="f5802e2c53799babc0ac27f6cb392604" category="paragraph"><block ref="f5802e2c53799babc0ac27f6cb392604" category="inline-link-rx"></block></block>
  <block id="9132ee4ebfc1bcccf9be22b87e818413" category="paragraph">Este documento é um trabalho das equipes de engenharia da NetApp Solutions e da ONTAP : David Arnette, Olga Kornievskaia, Dustin Fischer, Srikanth Kaligotla, Mohit Kumar e Raghuram Sudhaakar.  Os autores também gostariam de agradecer à NVIDIA e à equipe de engenharia do NVIDIA DGX BasePOD pelo suporte contínuo.</block>
  <block id="7c4d674fe3a4532c3ffe553151378a3f" category="summary">NetApp AIPod com sistemas NVIDIA DGX - Implantação</block>
  <block id="302db59f0ad2458d76aedcc8a6fdd7be" category="doc">NVA-1173 NetApp AIPod com sistemas NVIDIA DGX - Detalhes da implantação</block>
  <block id="c584dd3e1383c7899a434fb7b8e1a341" category="paragraph">Esta seção descreve os detalhes de implantação usados durante a validação desta solução.  Os endereços IP usados são exemplos e devem ser modificados com base no ambiente de implantação.  Para obter mais informações sobre comandos específicos usados na implementação desta configuração, consulte a documentação apropriada do produto.</block>
  <block id="b5f0a1ca7b5559b93159bcc11b7b99e9" category="paragraph">O diagrama abaixo mostra informações detalhadas de rede e conectividade para 1 sistema DGX H100 e 1 par HA de controladores AFF A90 .  As orientações de implantação nas seções a seguir são baseadas nos detalhes deste diagrama.</block>
  <block id="a1ce9904a2cc7e8a6e1267980553c732" category="paragraph">_Configuração de rede NetApp AIpod_</block>
  <block id="c4e9bce0ddaf289da0094c0a0560c136" category="paragraph"><block ref="c4e9bce0ddaf289da0094c0a0560c136" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea12591fa7a8663c28086764fc393d35" category="paragraph">A tabela a seguir mostra exemplos de atribuições de cabeamento para até 16 sistemas DGX e 2 pares AFF A90 HA.</block>
  <block id="4919e7d6c7a8481619e206520f937aaf" category="cell">Switch e porta</block>
  <block id="e0ac20adce6ffee48c7151b070aa5737" category="cell">Dispositivo</block>
  <block id="e85450f6454a8b84aa3dd8ab4cfe658c" category="cell">Porta do dispositivo</block>
  <block id="bdbd5451b62f5c0739cd0300b29d0db1" category="cell">portas switch1 1-16</block>
  <block id="b6bf51e15f6d9d931c3ef52dcf7c2e74" category="cell">DGX-H100-01 a -16</block>
  <block id="4d866d6d7dc3628895dbedb26f1bdf96" category="cell">enp170s0f0np0, slot1 porta 1</block>
  <block id="6438dabe67e09d4e0ec2e3d17d7074f9" category="cell">portas switch1 17-32</block>
  <block id="744d517d131df3b9ae1b4bdbdf70b282" category="cell">enp170s0f1np1, slot1 porta 2</block>
  <block id="2914cd4a87277c08ac1f71cafd311de5" category="cell">portas switch1 33-36</block>
  <block id="b08a34f62ae5d3df1c59356cb996a50a" category="cell">AFF-A90-01 a -04</block>
  <block id="3d163afca230cdca293d07b9bce1004f" category="cell">porta e6a</block>
  <block id="09a5a99bfdac461078765cf577fa36c1" category="cell">portas switch1 37-40</block>
  <block id="67d1565f0da7861ffc787acf0cc159af" category="cell">porta e11a</block>
  <block id="d350694943ec1acbb17fb85d69fd2aa9" category="cell">portas switch1 41-44</block>
  <block id="44b26214a7c3f5ffe5ec1db0aa3e4f98" category="cell">porta e2a</block>
  <block id="9e444fba13b3dd8f65bd7deb1b742747" category="cell">portas switch1 57-64</block>
  <block id="7a744922ca20208077a50d69271d15fd" category="cell">ISL para switch2</block>
  <block id="68813ae3b3a11b5b786ffe4305c5d542" category="cell">portas 57-64</block>
  <block id="9b878f628cccd99408682b50785b3598" category="cell">switch2 portas 1-16</block>
  <block id="3cdeea9afe6ab2952bd32f14b371d0c3" category="cell">enp41s0f0np0, slot 2 porta 1</block>
  <block id="6a11ad764d8b60d242c533b565b99142" category="cell">switch2 portas 17-32</block>
  <block id="e26d3524de049d551125c01b1d65729e" category="cell">enp41s0f1np1, slot 2 porta 2</block>
  <block id="59ba8265a302f2fb97997075c8f27f6d" category="cell">switch2 portas 33-36</block>
  <block id="9df3af84859046bac07e13013fce0466" category="cell">porta e6b</block>
  <block id="d9a9acdd71cb92eb03299a9702a84577" category="cell">switch2 portas 37-40</block>
  <block id="0b9b24c59934606f5e10f1c15b3a86cb" category="cell">porta e11b</block>
  <block id="2f4b59b7b40dec7ee6362e6017960380" category="cell">switch2 portas 41-44</block>
  <block id="2c635d05e781d03137efe254ee8f86a1" category="cell">porta e2b</block>
  <block id="67a367a7d31cdd640df71104820055c4" category="cell">switch2 portas 57-64</block>
  <block id="ed38d5a59568aa5dd0a40c94574cf056" category="cell">ISL para switch1</block>
  <block id="c470336f17afce51494a7db95c91de92" category="paragraph">A tabela a seguir mostra as versões de software para os vários componentes usados nesta validação.</block>
  <block id="40ddf58fef213ff0d6433ef322edfe2e" category="cell">Versão do software</block>
  <block id="b1c079bf2940033fab8f8dffbf4a5ff2" category="cell">Switches NVIDIA SN4600</block>
  <block id="90db213df8a0c782abe8388881fce336" category="cell">Cumulus Linux v5.9.1</block>
  <block id="18cf8e6ece8a122dba390f844981b900" category="cell">Sistema NVIDIA DGX</block>
  <block id="cfba00e4a4b4df8f6a7ebf83cfd81c4c" category="cell">DGX OS v6.2.1 (Ubuntu 22.04 LTS)</block>
  <block id="857ecbf3846b57d505e2a1b49da67f65" category="cell">Mellanox OFED</block>
  <block id="38aa87e1c845f13e459d6a71f7049cac" category="cell">24,01</block>
  <block id="3eb4233634d4c27ee1a1ddf72619b98d" category="cell">NetApp AFF A90</block>
  <block id="6944cefb93932417ed3a50959c66a9c5" category="cell">NetApp ONTAP 9.14.1</block>
  <block id="93fb68f81a2ad999b6aae02d586c4ef4" category="section-title">Configuração de rede de armazenamento</block>
  <block id="84814a12bbb8397e0a8f1357446c94e5" category="inline-link-macro">Documentação do NVIDIA Cumulus Linux</block>
  <block id="5d27fc003227b21f0392098a85eb18c2" category="paragraph">Esta seção descreve os principais detalhes para a configuração da rede de armazenamento Ethernet.  Para obter informações sobre como configurar a rede de computação InfiniBand, consulte o<block ref="784f66b69fd9a6fd2983e969e5202b40" category="inline-link-macro-rx"></block> .  Para mais detalhes sobre a configuração do switch, consulte o<block ref="5e4d481e02111d80d9871bbc3802a082" category="inline-link-macro-rx"></block> .</block>
  <block id="57719be20908b73e68d37637555b97d6" category="paragraph">As etapas básicas usadas para configurar os switches SN4600 são descritas abaixo.  Este processo pressupõe que o cabeamento e a configuração básica do switch (gerenciamento de endereço IP, licenciamento, etc.) estejam concluídos.</block>
  <block id="e55cea47183e18fc2e2e86a5dcee8ec7" category="list-text">Configurar o vínculo ISL entre os switches para habilitar agregação multi-link (MLAG) e tráfego de failover</block>
  <block id="72a998485758ede34cc727692eda3bd2" category="list-text">Esta validação utilizou 8 links para fornecer largura de banda mais do que suficiente para a configuração de armazenamento em teste</block>
  <block id="3051c0af523b2627a57ce2bf1e587655" category="list-text">Para obter instruções específicas sobre como habilitar o MLAG, consulte a documentação do Cumulus Linux.</block>
  <block id="8ae9a0f6054b5fb4a974e1f0d735ff8d" category="list-text">Configurar LACP MLAG para cada par de portas de cliente e portas de armazenamento em ambos os switches</block>
  <block id="3c81bce81a92df032d58d66eb88265b0" category="list-text">porta swp17 em cada switch para DGX-H100-01 (enp170s0f1np1 e enp41s0f1np1), porta swp18 para DGX-H100-02, etc (bond1-16)</block>
  <block id="563a9dfd999aa71e1b86c22188243c2b" category="list-text">porta swp41 em cada switch para AFF-A90-01 (e2a e e2b), porta swp42 para AFF-A90-02, etc (bond17-20)</block>
  <block id="44f6b0b1ffb3c7d26ff370ef2db934bb" category="list-text">nv define interface bondX membro do vínculo swpX</block>
  <block id="e88a9fc1fac9e835ce4f94863fa6c017" category="list-text">nv define interface bondx vínculo mlag id X</block>
  <block id="53e5d1cb8672703c6d9c6468088afa1a" category="list-text">Adicione todas as portas e ligações MLAG ao domínio de ponte padrão</block>
  <block id="e196c3365de079c5ab9127511e0dd99c" category="list-text">nv definir int swp1-16,33-40 domínio de ponte br_default</block>
  <block id="807ec963a7ac91bb05d484cf2aedb28c" category="list-text">nv definir int bond1-20 domínio de ponte br_default</block>
  <block id="812bc6c1e22132212f3bd611d2be624b" category="list-text">Habilitar RoCE em cada switch</block>
  <block id="5b474542c656a524ee80214d547f357f" category="list-text">nv define o modo roce sem perdas</block>
  <block id="e1ddeeabdb3c578a39e7f7457c83adcb" category="list-text">Configurar VLANs - 2 para portas de cliente, 2 para portas de armazenamento, 1 para gerenciamento, 1 para switch L3 para switch</block>
  <block id="e8c935d4b4d1ac2ba8e60a311d4dd3e3" category="list-text">interruptor 1-</block>
  <block id="d0dbd46c5b3822649194130f76e47a74" category="list-text">VLAN 3 para roteamento de switch L3 para switch em caso de falha da placa de rede do cliente</block>
  <block id="4d0ddcd703c2db59dd2b93a0864f348e" category="list-text">VLAN 101 para porta de armazenamento 1 em cada sistema DGX (enp170s0f0np0, slot1 porta 1)</block>
  <block id="988d3fe9d9a9c24bdfaf0d1e8c04c718" category="list-text">VLAN 102 para porta e6a e e11a em cada controlador de armazenamento AFF A90</block>
  <block id="8534bf29bf68cf0b3a4ef8fc1c8367ef" category="list-text">VLAN 301 para gerenciamento usando as interfaces MLAG para cada sistema DGX e controlador de armazenamento</block>
  <block id="decdf257b13a488f92fa3c1f3c758e26" category="list-text">interruptor 2-</block>
  <block id="9d406d38f0c9d262294560c3ffe601e6" category="list-text">VLAN 201 para porta de armazenamento 2 em cada sistema DGX (enp41s0f0np0, slot2 porta 1)</block>
  <block id="ad80d15b1164d5cda913549da61e6aa3" category="list-text">VLAN 202 para porta e6b e e11b em cada controlador de armazenamento AFF A90</block>
  <block id="09417c9a09b9c4ceb39f1b21b0c805ce" category="list-text">Atribua portas físicas a cada VLAN conforme apropriado, por exemplo, portas de cliente em VLANs de cliente e portas de armazenamento em VLANs de armazenamento</block>
  <block id="30add6fef18e27847f71d245bce4adf2" category="list-text">nv set int &lt;swpX&gt; domínio de ponte br_default acesso &lt;id da VLAN&gt;</block>
  <block id="8c088863d87c4744d16775f50bd22826" category="list-text">As portas MLAG devem permanecer como portas de tronco para habilitar múltiplas VLANs nas interfaces vinculadas, conforme necessário.</block>
  <block id="dc7dbdf7949b0253d64542d3a6648b53" category="list-text">Configurar interfaces virtuais de switch (SVI) em cada VLAN para atuar como um gateway e habilitar o roteamento L3</block>
  <block id="bbc11fb8434953cf5f8a56090594c94e" category="list-text">nv definir endereço IP int vlan3 100.127.0.0/31</block>
  <block id="56a4338a8bbb720e395dea767276043e" category="list-text">nv definir int vlan101 endereço IP 100.127.101.1/24</block>
  <block id="c88e27e83683371775c79ed4db025a42" category="list-text">nv definir int vlan102 endereço IP 100.127.102.1/24</block>
  <block id="c8e18763efa8332ade09b61ec6c43e79" category="list-text">nv definir endereço IP int vlan3 100.127.0.1/31</block>
  <block id="d39015045c0b670844a63ea89a0558e1" category="list-text">nv definir int vlan201 endereço IP 100.127.201.1/24</block>
  <block id="72caedfc84ea977b468f72cc81db5b0f" category="list-text">nv definir endereço IP int vlan202 100.127.202.1/24</block>
  <block id="4d86d7ad33785bddc3f3227d7cfe8c00" category="list-text">Criar rotas estáticas</block>
  <block id="957e71bdd90bad3e445176749a6e839a" category="list-text">Rotas estáticas são criadas automaticamente para sub-redes no mesmo switch</block>
  <block id="ba77f5caf647fd0155f2edd382f4c005" category="list-text">Rotas estáticas adicionais são necessárias para o roteamento de switch para switch no caso de falha de link do cliente</block>
  <block id="cb6543cc4fa221dc0cadbcce30a3d708" category="list-text">nv define vrf roteador padrão estático 100.127.128.0/17 via 100.127.0.1</block>
  <block id="3616a5e3448d387e297a217363fcd491" category="list-text">nv define vrf roteador padrão estático 100.127.0.0/17 via 100.127.0.0</block>
  <block id="2139fe384d5ae165545994dff01961d9" category="section-title">Configuração do sistema de armazenamento</block>
  <block id="eb75aeb3b4b2b9734ba3e52f5483f0b2" category="inline-link-macro">Documentação do ONTAP</block>
  <block id="6c077f840844078f56944a0699577ff6" category="paragraph">Esta seção descreve os principais detalhes para a configuração do sistema de armazenamento A90 para esta solução.  Para mais detalhes sobre a configuração dos sistemas ONTAP , consulte o<block ref="c9be69f343f12523b36264fad0c62551" category="inline-link-macro-rx"></block> .  O diagrama abaixo mostra a configuração lógica do sistema de armazenamento.</block>
  <block id="a2720bc0a2d05de970087a0c7fad9311" category="paragraph">As etapas básicas usadas para configurar o sistema de armazenamento são descritas abaixo.  Este processo pressupõe que a instalação básica do cluster de armazenamento tenha sido concluída.</block>
  <block id="a65ed1368170b15ddddd6ee0b2408084" category="list-text">Configurar 1 agregado em cada controlador com todas as partições disponíveis menos 1 sobressalente</block>
  <block id="104afbbbf990a88bdaee0bb7222c4b8e" category="list-text">aggr create -node &lt;nó&gt; -aggregate &lt;nó&gt;_data01 -diskcount &lt;47&gt;</block>
  <block id="40531cd604f58d3ba347b865243c7e48" category="list-text">Configurar ifgrps em cada controlador</block>
  <block id="f72dfa57e15677b92e70b5a144e0b5f9" category="list-text">porta de rede ifgrp create -node &lt;nó&gt; -ifgrp a1a -mode multimode_lacp -distr-function porta</block>
  <block id="55be7178bd14f4153f1b019457ede4a9" category="list-text">porta de rede ifgrp add-port -node &lt;nó&gt; -ifgrp &lt;ifgrp&gt; -ports &lt;nó&gt;:e2a,&lt;nó&gt;:e2b</block>
  <block id="b13faeadb39006cbcc1d3c2e50344bf1" category="list-text">Configurar porta VLAN de gerenciamento no ifgrp em cada controlador</block>
  <block id="e6e28ccd055fb443d6dd14a9a6eb7d1a" category="list-text">porta de rede vlan criar -nó aff-a90-01 -porta a1a -vlan-id 31</block>
  <block id="f740c9ebcb9caacb0b5d819655c488ed" category="list-text">porta de rede vlan criar -nó aff-a90-02 -porta a1a -vlan-id 31</block>
  <block id="5d71abf584a26ed36de342533bc6b11f" category="list-text">porta de rede vlan criar -nó aff-a90-03 -porta a1a -vlan-id 31</block>
  <block id="21e3a0fbbbf79005355b371bbcdd44e6" category="list-text">porta de rede vlan criar -nó aff-a90-04 -porta a1a -vlan-id 31</block>
  <block id="cd002818e71e3e15ea7d845a92b82053" category="list-text">Criar domínios de transmissão</block>
  <block id="060c8e724635c9585153496e36c5fe64" category="list-text">domínio de transmissão criar -domínio de transmissão vlan21 -mtu 9000 -portas aff-a90-01:e6a,aff-a90-01:e11a,aff-a90-02:e6a,aff-a90-02:e11a,aff-a90-03:e6a,aff-a90-03:e11a,aff-a90-04:e6a,aff-a90-04:e11a</block>
  <block id="f0375c78fd286627e0ea2e893298127b" category="list-text">domínio de transmissão criar -domínio de transmissão vlan22 -mtu 9000 -portas aaff-a90-01:e6b,aff-a90-01:e11b,aff-a90-02:e6b,aff-a90-02:e11b,aff-a90-03:e6b,aff-a90-03:e11b,aff-a90-04:e6b,aff-a90-04:e11b</block>
  <block id="46bd5a85171233df8aad89e1ea34eca2" category="list-text">domínio de transmissão criar -domínio de transmissão vlan31 -mtu 9000 -portas aff-a90-01:a1a-31,aff-a90-02:a1a-31,aff-a90-03:a1a-31,aff-a90-04:a1a-31</block>
  <block id="623ea6b05fb05729ffd64b3aecd6e969" category="list-text">Criar SVM de gerenciamento *</block>
  <block id="5619023db11b9124790191d573fd6c9a" category="list-text">Configurar SVM de gerenciamento</block>
  <block id="a085de8c20c0316efb0b620d42f96f5d" category="list-text">criar LIF</block>
  <block id="f2a8aff28094374e836aba88837e4ecd" category="list-text">net int create -vserver basepod-mgmt -lif vlan31-01 -home-node aff-a90-01 -home-port a1a-31 -address 192.168.31.X -netmask 255.255.255.0</block>
  <block id="025643e2f4f3d8255f6a74703e817f10" category="list-text">criar volumes FlexGroup</block>
  <block id="ff251de7d10dfd4d224adb00c9771d80" category="list-text">vol create -vserver basepod-mgmt -volume home -size 10T -auto-provision-as flexgroup -junction-path /home</block>
  <block id="7eadd281ac9fa05f29dd10931c800b73" category="list-text">vol create -vserver basepod-mgmt -volume cm -size 10T -auto-provision-as flexgroup -junction-path /cm</block>
  <block id="4daa96de5bcd998457adea84b3b0d3f2" category="list-text">criar política de exportação</block>
  <block id="0224cbf10aded53062d1c33a00ed3f00" category="list-text">regra de política de exportação criar -vserver basepod-mgmt -policy default -client-match 192.168.31.0/24 -rorule sys -rwrule sys -superuser sys</block>
  <block id="d5c522a3ee4c4fb65fcbe94d031d0a08" category="list-text">Criar dados SVM *</block>
  <block id="6310e0b69ca3cd6447bec629307180b7" category="list-text">Configurar dados SVM</block>
  <block id="8aa04063c0eff21564b4943f7c5bd0af" category="list-text">configurar SVM para suporte RDMA</block>
  <block id="f67ee8861066661a87085502a485f642" category="list-text">vserver nfs modify -vserver basepod-data -rdma habilitado</block>
  <block id="f29cc71670e3362a894e54ea9924917c" category="list-text">criar LIFs</block>
  <block id="3df4cfdffe24b83cba807ded784fb107" category="list-text">net int create -vserver basepod-data -lif c1-6a-lif1 -home-node aff-a90-01 -home-port e6a -address 100.127.102.101 -netmask 255.255.255.0</block>
  <block id="26a6d29a1530006b710e49ad940bc64a" category="list-text">net int create -vserver basepod-data -lif c1-6a-lif2 -home-node aff-a90-01 -home-port e6a -address 100.127.102.102 -netmask 255.255.255.0</block>
  <block id="985d0d4d212dc0238d9f101fee0a3418" category="list-text">net int create -vserver basepod-data -lif c1-6b-lif1 -home-node aff-a90-01 -home-port e6b -address 100.127.202.101 -netmask 255.255.255.0</block>
  <block id="07f93d0815d9e298cb8b02049c677706" category="list-text">net int create -vserver basepod-data -lif c1-6b-lif2 -home-node aff-a90-01 -home-port e6b -address 100.127.202.102 -netmask 255.255.255.0</block>
  <block id="2d977106413211171eefeeb51af2bdf7" category="list-text">net int create -vserver basepod-data -lif c1-11a-lif1 -home-node aff-a90-01 -home-port e11a -address 100.127.102.103 -netmask 255.255.255.0</block>
  <block id="10d75b950d2d9634a2804a1ed92f0df7" category="list-text">net int create -vserver basepod-data -lif c1-11a-lif2 -home-node aff-a90-01 -home-port e11a -address 100.127.102.104 -netmask 255.255.255.0</block>
  <block id="7e3ec60a178738ba9ac6680a6bf6340d" category="list-text">net int create -vserver basepod-data -lif c1-11b-lif1 -home-node aff-a90-01 -home-port e11b -address 100.127.202.103 -netmask 255.255.255.0</block>
  <block id="b14efeaf4c17d63f2e6011dc35f5722c" category="list-text">net int create -vserver basepod-data -lif c1-11b-lif2 -home-node aff-a90-01 -home-port e11b -address 100.127.202.104 -netmask 255.255.255.0</block>
  <block id="74c24c93e98c023e9fe31988005f6735" category="list-text">net int create -vserver basepod-data -lif c2-6a-lif1 -home-node aff-a90-02 -home-port e6a -address 100.127.102.105 -netmask 255.255.255.0</block>
  <block id="d00b578414c1bb9f219c72ef1262d701" category="list-text">net int create -vserver basepod-data -lif c2-6a-lif2 -home-node aff-a90-02 -home-port e6a -address 100.127.102.106 -netmask 255.255.255.0</block>
  <block id="c49b52997695ebd048410b0b8f9f19f2" category="list-text">net int create -vserver basepod-data -lif c2-6b-lif1 -home-node aff-a90-02 -home-port e6b -address 100.127.202.105 -netmask 255.255.255.0</block>
  <block id="912c10c91d670dee279852756245a063" category="list-text">net int create -vserver basepod-data -lif c2-6b-lif2 -home-node aff-a90-02 -home-port e6b -address 100.127.202.106 -netmask 255.255.255.0</block>
  <block id="031724ef6867c2ff3771e70c8520b1d0" category="list-text">net int create -vserver basepod-data -lif c2-11a-lif1 -home-node aff-a90-02 -home-port e11a -address 100.127.102.107 -netmask 255.255.255.0</block>
  <block id="8b417c98283cde9dc265541e2455e2f5" category="list-text">net int create -vserver basepod-data -lif c2-11a-lif2 -home-node aff-a90-02 -home-port e11a -address 100.127.102.108 -netmask 255.255.255.0</block>
  <block id="f129b43cd7a26c7049c4340ac4ef86e1" category="list-text">net int create -vserver basepod-data -lif c2-11b-lif1 -home-node aff-a90-02 -home-port e11b -address 100.127.202.107 -netmask 255.255.255.0</block>
  <block id="5a6d6f4dbbb1d6f8f5558b1c36f5e671" category="list-text">net int create -vserver basepod-data -lif c2-11b-lif2 -home-node aff-a90-02 -home-port e11b -address 100.127.202.108 -netmask 255.255.255.0</block>
  <block id="057f5c63653dacba830db83ad6ad78ee" category="list-text">Configurar LIFs para acesso RDMA</block>
  <block id="ea7a0f026442b56683f1e50cb21a0d06" category="list-text">Para implantações com o ONTAP 9.15.1, a configuração do RoCE QoS para informações físicas requer comandos de nível de sistema operacional que não estão disponíveis na CLI do ONTAP .  Entre em contato com o Suporte da NetApp para obter assistência com a configuração de portas para suporte ao RoCE.  NFS sobre RDMA funciona sem problemas</block>
  <block id="2e94a4ea05164067f4cb6f27639c8b7a" category="list-text">A partir do ONTAP 9.16.1, as interfaces físicas serão configuradas automaticamente com as configurações apropriadas para suporte RoCE de ponta a ponta.</block>
  <block id="95f5fd496607048d9a2d17c6c6577aa2" category="list-text">net int modificar -vserver basepod-data -lif * -rdma-protocols roce</block>
  <block id="29789a25d415e0f3b5d8cef38626fadc" category="list-text">Configurar parâmetros NFS no SVM de dados</block>
  <block id="37013073e580c7f2ed500849958f49cd" category="list-text">nfs modify -vserver basepod-data -v4.1 habilitado -v4.1-pnfs habilitado -v4.1-trunking habilitado -tcp-max-transfer-size 262144</block>
  <block id="8f7c2b974d2b68275b99738f2db92da7" category="list-text">Criar volumes FlexGroup</block>
  <block id="375a2038f90b0da452502ee281313fdd" category="list-text">vol create -vserver basepod-data -volume data -size 100T -auto-provision-as flexgroup -junction-path /data</block>
  <block id="48e79d83943623a53289accfc05a7108" category="list-text">Criar política de exportação</block>
  <block id="f36c67518ab2b84b8b81ef59c8d30976" category="list-text">regra de política de exportação criar -vserver basepod-data -policy default -client-match 100.127.101.0/24 -rorule sys -rwrule sys -superuser sys</block>
  <block id="738b25d5c96222859fa0d9f34e585e1d" category="list-text">regra de política de exportação criar -vserver basepod-data -policy default -client-match 100.127.201.0/24 -rorule sys -rwrule sys -superuser sys</block>
  <block id="14f424e270715fb6e8bf7277cb075650" category="list-text">criar rotas</block>
  <block id="086c700f168ee8ad618b80e189d3ab75" category="list-text">rota adicionar -vserver basepod_data -destino 100.127.0.0/17 -gateway 100.127.102.1 métrica 20</block>
  <block id="e6bf4bcbe9f12d429928fe014e660008" category="list-text">rota adicionar -vserver basepod_data -destino 100.127.0.0/17 -gateway 100.127.202.1 métrica 30</block>
  <block id="35dc59e7fce425d44a0f407fcd227c43" category="list-text">rota adicionar -vserver basepod_data -destino 100.127.128.0/17 -gateway 100.127.202.1 métrica 20</block>
  <block id="50a387548848ab61afe342aa18b992c7" category="list-text">rota adicionar -vserver basepod_data -destino 100.127.128.0/17 -gateway 100.127.102.1 métrica 30</block>
  <block id="dc8a99ae9ee0b79d432c8eac1124edb5" category="section-title">Configuração DGX H100 para acesso ao armazenamento RoCE</block>
  <block id="206274d0712987318a4f897f7e6ae75c" category="inline-link-macro">Documentação do BCM</block>
  <block id="0448e5984ca30c8aeeb162534801fe92" category="paragraph">Esta seção descreve os principais detalhes para a configuração dos sistemas DGX H100.  Muitos desses itens de configuração podem ser incluídos na imagem do sistema operacional implantada nos sistemas DGX ou implementados pelo Base Command Manager no momento da inicialização.  Eles estão listados aqui para referência, para mais informações sobre como configurar nós e imagens de software no BCM, consulte o<block ref="21b53d84e45529faee31545df8020d3b" category="inline-link-macro-rx"></block> .</block>
  <block id="12211cca460b22741ca0d08e3f60fb0c" category="list-text">Instalar pacotes adicionais</block>
  <block id="0df162aa5e7703fc2c2a77a7d1d5a1fe" category="list-text">ipmitool</block>
  <block id="e08cb560fa0fac340ce6e958daaf5e4d" category="list-text">python3-pip</block>
  <block id="8cd5d0cdb86cde9f0dc88352811817ec" category="list-text">Instalar pacotes Python</block>
  <block id="32760a760ea625ddb856e92f3b089802" category="list-text">paramiko</block>
  <block id="f02113237a5a5fff03e34c9eeeb46640" category="list-text">matplotlib</block>
  <block id="9b162ba267ba83b0a5f5cb6cdbe972dd" category="list-text">Reconfigure o dpkg após a instalação do pacote</block>
  <block id="a8bc68a93f8c901b4a33e27af2f21da0" category="list-text">dpkg --configure -a</block>
  <block id="0243e3d81be4d79f622d517c103c3ae0" category="list-text">Instalar MOFED</block>
  <block id="08c24ffe86544b752cd2764895595237" category="list-text">Definir valores mst para ajuste de desempenho</block>
  <block id="d5bedef65a3750cb3c0a2b86f80a11e4" category="list-text">mstconfig -y -d &lt;aa:00.0,29:00.0&gt; definir CONFIGURAÇÕES_PCI_AVANÇADAS=1 NÚMERO_DE_VFS=0 LEITURA_MÁXIMA_DE_SAÍDA_ACC=44</block>
  <block id="bdacbd6c214d3cc42e1d1f8305ef92c9" category="list-text">Redefinir os adaptadores após modificar as configurações</block>
  <block id="9af48ffdb9436775e220fda80ded47ad" category="list-text">mlxfwreset -d &lt;aa:00.0,29:00.0&gt; -y redefinir</block>
  <block id="c7cb0d4934d36b9bb0816b3a5c49f0b1" category="list-text">Definir MaxReadReq em dispositivos PCI</block>
  <block id="1a252b6a7629ccb0f15527f8ca5f627c" category="list-text">setpci -s &lt;aa:00.0,29:00.0&gt; 68.W=5957</block>
  <block id="29aaf92306610006fe7ce7d8c90411ca" category="list-text">Definir tamanho do buffer de anel RX e TX</block>
  <block id="3d789bdc86cf1d51f9b23d11b808ddd5" category="list-text">ethtool -G &lt;enp170s0f0np0,enp41s0f0np0&gt; rx 8192 tx 8192</block>
  <block id="a0340fb71fb195f79ce47dabe6242f8e" category="list-text">Definir PFC e DSCP usando mlnx_qos</block>
  <block id="6537005ab5e42cbee146ce9b17d892d8" category="list-text">mlnx_qos -i &lt;enp170s0f0np0,enp41s0f0np0&gt; --pfc 0,0,0,1,0,0,0,0 --trust=dscp --cable_len=3</block>
  <block id="a277efb29c974f8ae6d1925383335b05" category="list-text">Definir ToS para tráfego RoCE em portas de rede</block>
  <block id="8c1e8c1481d777723e305f147f16012d" category="list-text">eco 106 &gt; /sys/classe/infiniband/&lt;mlx5_7,mlx5_1&gt;/tc/1/classe_de_trafego</block>
  <block id="05dae9ad2cfb95dc1f78bc696aa0d6a4" category="list-text">Configure cada NIC de armazenamento com um endereço IP na sub-rede apropriada</block>
  <block id="fa2bddc64b24b8cd13f0be734ce934ca" category="list-text">100.127.101.0/24 para armazenamento NIC 1</block>
  <block id="945382c87aa13867b8b36da66c8ae8fc" category="list-text">100.127.201.0/24 para armazenamento NIC 2</block>
  <block id="ed769c091c9112ad2d1a5c89de5c0c65" category="list-text">Configurar portas de rede em banda para vinculação LACP (enp170s0f1np1, enp41s0f1np1)</block>
  <block id="af487da74a6eeea9aa52d90c5c8cd04d" category="list-text">configurar rotas estáticas para caminhos primários e secundários para cada sub-rede de armazenamento</block>
  <block id="593c13037333a6722527c42d1d0b156c" category="list-text">rota adicionar –net 100.127.0.0/17 gw 100.127.101.1 métrica 20</block>
  <block id="8656e83d4d88a713f09d848f3cc09702" category="list-text">rota adicionar –net 100.127.0.0/17 gw 100.127.201.1 métrica 30</block>
  <block id="85f6d08b3d54f8d8785ef6f36f7c61c3" category="list-text">rota adicionar –net 100.127.128.0/17 gw 100.127.201.1 métrica 20</block>
  <block id="d70120de1b67fd20affa2557aca990ef" category="list-text">rota adicionar –net 100.127.128.0/17 gw 100.127.101.1 métrica 30</block>
  <block id="7fc2f78e0bd34dcefec071f2a70514c2" category="list-text">Montagem /volume inicial</block>
  <block id="9ff7402ee00f4969ccc4395a7241c47c" category="list-text">mount -o vers=3,nconnect=16,rsize=262144,wsize=262144 192.168.31.X:/home /home</block>
  <block id="152cd866abad6e43429948eb4715b973" category="list-text">Montagem /volume de dados</block>
  <block id="1cd39f0089800bb9511317cc53d73557" category="list-text">As seguintes opções de montagem foram usadas ao montar o volume de dados-</block>
  <block id="bcd39ebb3417a185678d6de2189af4b9" category="list-text">vers=4.1 # habilita pNFS para acesso paralelo a múltiplos nós de armazenamento</block>
  <block id="5cd472c72f4b3a3c75cbdb77edc30528" category="list-text">proto=rdma # define o protocolo de transferência para RDMA em vez do TCP padrão</block>
  <block id="f8553c0c0cde0245d779c37090c093a7" category="list-text">max_connect=16 # habilita o entroncamento de sessão NFS para agregar largura de banda da porta de armazenamento</block>
  <block id="f8a3438d5712d48a22100c8109ea556e" category="list-text">write=eager # melhora o desempenho de gravação de gravações armazenadas em buffer</block>
  <block id="42fdb382646439a01d661ce9d2127a1c" category="list-text">rsize=262144,wsize=262144 # define o tamanho da transferência de E/S para 256k</block>
  <block id="7f86b6f2a05fc6e5c5931f73e9af29fd" category="summary">NetApp AIPod com sistemas NVIDIA DGX - Componentes de hardware</block>
  <block id="7c451f18f811f88a48907bf86377cdd8" category="doc">NVA-1173 NetApp AIPod com sistemas NVIDIA DGX - Componentes de hardware</block>
  <block id="bd6e083031bf15817a67b63cc58a211c" category="paragraph">Esta seção se concentra nos componentes de hardware do NetApp AIPod com sistemas NVIDIA DGX.</block>
  <block id="68674fa5fbd6fb83969183d07d48b8cd" category="section-title">Sistemas de armazenamento NetApp AFF</block>
  <block id="3b6d33ce139758ecf9b0b83f9ecce001" category="paragraph">Os sistemas de armazenamento de última geração da NetApp AFF permitem que os departamentos de TI atendam aos requisitos de armazenamento empresarial com desempenho líder do setor, flexibilidade superior, integração com a nuvem e o melhor gerenciamento de dados da categoria.  Projetados especificamente para flash, os sistemas AFF ajudam a acelerar, gerenciar e proteger dados essenciais aos negócios.</block>
  <block id="d1d40f451fb75b4e7160785e64a75da3" category="section-title">Sistemas de armazenamento AFF A90</block>
  <block id="df7df1dd54ea101ca8a417ee258e2693" category="paragraph">O NetApp AFF A90, equipado com o software de gerenciamento de dados NetApp ONTAP, oferece proteção de dados integrada, recursos anti-ransomware opcionais e o alto desempenho e resiliência necessários para dar suporte às cargas de trabalho empresariais mais críticas.  Ele elimina interrupções em operações de missão crítica, minimiza o ajuste de desempenho e protege seus dados contra ataques de ransomware.  Oferece: • Desempenho líder do setor • Segurança de dados incomparável • Atualizações simplificadas e não disruptivas</block>
  <block id="6bd43dd4b56bb5bfe362d48a0d5219e0" category="paragraph">_Sistema de armazenamento NetApp AFF A90</block>
  <block id="df3fd00dc667f05e52f1e05b8dedfd55" category="paragraph"><block ref="df3fd00dc667f05e52f1e05b8dedfd55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1863aa82dcf92831635aa05e975d399d" category="section-title">Desempenho líder do setor</block>
  <block id="a261fc6acbe5e140d750bc3f1dd8c7a7" category="paragraph">O AFF A90 gerencia facilmente cargas de trabalho de última geração, como aprendizado profundo, IA e análises de alta velocidade, bem como bancos de dados empresariais tradicionais, como Oracle, SAP HANA, Microsoft SQL Server e aplicativos virtualizados.  Ele mantém aplicativos essenciais aos negócios em execução na velocidade máxima com até 2,4 milhões de IOPS por par de HA e latência de até 100 µs, além de aumentar o desempenho em até 50% em relação aos modelos anteriores da NetApp .  Com NFS sobre RDMA, pNFS e Session Trunking, os clientes podem atingir o alto nível de desempenho de rede necessário para aplicativos de última geração usando a infraestrutura de rede de data center existente.  Os clientes também podem escalar e crescer com suporte multiprotocolo unificado para SAN, NAS e armazenamento de objetos e oferecer flexibilidade máxima com software de gerenciamento de dados ONTAP unificado e único, para dados no local ou na nuvem.  Além disso, a saúde do sistema pode ser otimizada com análises preditivas baseadas em IA fornecidas pelo Active IQ e Cloud Insights.</block>
  <block id="773efff7a0bbe1582ceff936530b5ae3" category="section-title">Segurança de dados sem comprometimento</block>
  <block id="b867e6aa9b3e46766f55ab250eb69715" category="paragraph">Os sistemas AFF A90 contêm um conjunto completo de software de proteção de dados integrado e consistente com aplicativos da NetApp .  Ele fornece proteção de dados integrada e soluções anti-ransomware de ponta para prevenção e recuperação pós-ataque.  Arquivos maliciosos podem ser bloqueados e não podem ser gravados no disco, e anormalidades no armazenamento são facilmente monitoradas para obter insights.</block>
  <block id="f6353452ddd71a9ef0e4d8578d7dc7e3" category="section-title">Atualizações simplificadas e não disruptivas</block>
  <block id="4015e152c676ca730da1d797ef1e9993" category="paragraph">O AFF A90 está disponível como uma atualização não disruptiva no chassi para clientes A800 existentes.  A NetApp simplifica a atualização e a eliminação de interrupções em operações de missão crítica por meio de nossos recursos avançados de confiabilidade, disponibilidade, capacidade de manutenção e capacidade de gerenciamento (RASM).  Além disso, a NetApp aumenta ainda mais a eficiência operacional e simplifica as atividades diárias das equipes de TI porque o software ONTAP aplica automaticamente atualizações de firmware para todos os componentes do sistema.</block>
  <block id="13ab18b8510a80a65aefbf9a56e3b3d3" category="paragraph">Para as maiores implantações, os sistemas AFF A1K oferecem as mais altas opções de desempenho e capacidade, enquanto outros sistemas de armazenamento NetApp , como o AFF A70 e o AFF C800, oferecem opções para implantações menores com custos mais baixos.</block>
  <block id="3ebd416d1b3232ef4125025ab8f437a9" category="paragraph">O NVIDIA DGX BasePOD é uma solução integrada que consiste em componentes de hardware e software NVIDIA , soluções MLOps e armazenamento de terceiros.  Aproveitando as melhores práticas de design de sistemas escaláveis com produtos NVIDIA e soluções de parceiros validadas, os clientes podem implementar uma plataforma eficiente e gerenciável para desenvolvimento de IA.  A Figura 1 destaca os vários componentes do NVIDIA DGX BasePOD.</block>
  <block id="76d810a9cb0440f2de2c7104493e266f" category="paragraph">_Solução NVIDIA DGX BasePOD_</block>
  <block id="559d10ed60e21f546209442a6aade09d" category="paragraph"><block ref="559d10ed60e21f546209442a6aade09d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0a5f31a2eea3b274409614f4eb63433c" category="section-title">Sistemas NVIDIA DGX H100</block>
  <block id="2cdfa62855978fa129d36e4602f41e0b" category="paragraph">O sistema NVIDIA DGX H100™ é a potência da IA que é acelerada pelo desempenho inovador da GPU NVIDIA H100 Tensor Core.</block>
  <block id="4a8da04b1b7a51ad2e9c77e221e0d9d9" category="paragraph">_Sistema NVIDIA DGX H100_</block>
  <block id="b9ab32cd1976da02bb3c074578d491c3" category="paragraph"><block ref="b9ab32cd1976da02bb3c074578d491c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93b775e18b65e433d85d83ad863c1797" category="paragraph">As principais especificações do sistema DGX H100 são: • Oito GPUs NVIDIA H100.  • 80 GB de memória GPU por GPU, para um total de 640 GB.  • Quatro chips NVIDIA NVSwitch.  • Processadores Intel Xeon Platinum 8480 duplos de 56 núcleos com suporte a PCIe 5.0.  • 2 TB de memória de sistema DDR5.  • Quatro portas OSFP atendendo oito adaptadores NVIDIA ConnectX-7 (InfiniBand/Ethernet) de porta única e dois adaptadores NVIDIA ConnectX-7 (InfiniBand/Ethernet) de porta dupla.  • Duas unidades M.2 NVMe de 1,92 TB para DGX OS, oito unidades U.2 NVMe de 3,84 TB para armazenamento/cache.  • Potência máxima de 10,2 kW.  As portas traseiras da bandeja da CPU DGX H100 são mostradas abaixo.  Quatro das portas OSFP atendem oito adaptadores ConnectX-7 para a estrutura de computação InfiniBand.  Cada par de adaptadores ConnectX-7 de porta dupla fornece caminhos paralelos para as estruturas de armazenamento e gerenciamento.  A porta fora de banda é usada para acesso BMC .</block>
  <block id="1811b955f76e78d806cc9f89eca9365d" category="paragraph">_Painel traseiro NVIDIA DGX H100_</block>
  <block id="7d94d25261d22723cf1dcbc550472562" category="paragraph"><block ref="7d94d25261d22723cf1dcbc550472562" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e64325a640583a5afbe8ce27e88608e" category="section-title">Switch NVIDIA Quantum-2 QM9700</block>
  <block id="96e834f144fffd019191dee8b2e3fa9e" category="paragraph">_Switch NVIDIA Quantum-2 QM9700 InfiniBand_</block>
  <block id="02e6cd41035da9c303b4223fcb954c57" category="paragraph"><block ref="02e6cd41035da9c303b4223fcb954c57" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58e83b10341e2ec3a48b164715b6ba34" category="paragraph">Os switches NVIDIA Quantum-2 QM9700 com conectividade InfiniBand de 400 Gb/s alimentam a malha computacional nas configurações NVIDIA Quantum-2 InfiniBand BasePOD.  Os adaptadores de porta única ConnectX-7 são usados para a estrutura de computação InfiniBand.  Cada sistema NVIDIA DGX tem conexões duplas com cada switch QM9700, fornecendo vários caminhos de alta largura de banda e baixa latência entre os sistemas.</block>
  <block id="88f086b3f05858ad120601108f0821a7" category="section-title">Comutador NVIDIA Spectrum-3 SN4600</block>
  <block id="69dc0a65b1f9cc56bf9d1b38913e279e" category="paragraph">_Switch NVIDIA Spectrum-3 SN4600_</block>
  <block id="a5317e31cdc481b4371010e9f47b541d" category="paragraph"><block ref="a5317e31cdc481b4371010e9f47b541d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df2b71117642b0bdbf87a4e9d643c47e" category="paragraph">Os switches NVIDIA Spectrum®-3 SN4600 oferecem 128 portas no total (64 por switch) para fornecer conectividade redundante para gerenciamento em banda do DGX BasePOD.  O switch NVIDIA SN4600 pode fornecer velocidades entre 1 GbE e 200 GbE.  Para dispositivos de armazenamento conectados via Ethernet, os switches NVIDIA SN4600 também são usados.  As portas nos adaptadores NVIDIA DGX Dual-Port ConnectX-7 são usadas para gerenciamento em banda e conectividade de armazenamento.</block>
  <block id="9bc83d36ebb307eef9521860d72d6a83" category="section-title">Comutador NVIDIA Spectrum SN2201</block>
  <block id="0a58d2e4f07c9b74c7b9f0f643df366e" category="paragraph">_Switch NVIDIA Spectrum SN2201_</block>
  <block id="63573ea3854985f600f8cc8c44aa5bea" category="paragraph"><block ref="63573ea3854985f600f8cc8c44aa5bea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6714f3120a26d6eb7222fbbd52715a6c" category="paragraph">Os switches NVIDIA Spectrum SN2201 oferecem 48 portas para fornecer conectividade para gerenciamento fora de banda.  O gerenciamento fora de banda fornece conectividade de gerenciamento consolidada para todos os componentes no DGX BasePOD.</block>
  <block id="82e5da407cc33e26189f053503aa2bf6" category="section-title">Adaptador NVIDIA ConnectX-7</block>
  <block id="74baf984365e15a6f92345e68021621a" category="paragraph">_Adaptador NVIDIA ConnectX-7_</block>
  <block id="062446821e85b6d2c053705d69b2c037" category="paragraph"><block ref="062446821e85b6d2c053705d69b2c037" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1f31835004684d86091e359c9a240e92" category="paragraph">O adaptador NVIDIA ConnectX-7 pode fornecer 25/50/100/200/400G de taxa de transferência.  Os sistemas NVIDIA DGX usam adaptadores ConnectX-7 de porta única e dupla para fornecer flexibilidade em implantações DGX BasePOD com InfiniBand e Ethernet de 400 Gb/s.</block>
  <block id="9f68b039fbd3ecc8729ee9a4be7903ea" category="summary">O NetApp AIPod com sistemas NVIDIA DGX é uma arquitetura de referência pronta para empresas baseada no NVIDIA BasePOD para aprendizado profundo e inteligência artificial usando sistemas de armazenamento NetApp ONTAP AFF e sistemas de rede e DGX NVIDIA .</block>
  <block id="9b07efa8439fb4859742ace8bb15c070" category="doc">NVA-1173 NetApp AIPod com sistemas NVIDIA DGX - Introdução</block>
  <block id="03a5dba0ba7f06a853319a59ab10f1db" category="inline-image-macro">200,200,Erro: Imagem gráfica ausente</block>
  <block id="540456658a35dff79ec59aa1338d398e" category="paragraph"><block ref="540456658a35dff79ec59aa1338d398e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="217432d0ec5a422d97fdd8082983c438" category="paragraph">Engenharia de Soluções NetApp</block>
  <block id="617f17b8f2c8c0557ec9f79c918464eb" category="paragraph">O NetApp&amp;#8482; AIPod com sistemas NVIDIA DGX&amp;#8482; e sistemas de armazenamento conectados à nuvem NetApp simplificam as implantações de infraestrutura para cargas de trabalho de aprendizado de máquina (ML) e inteligência artificial (IA) eliminando a complexidade do design e as suposições.  Com base no design do NVIDIA DGX BasePOD para oferecer desempenho de computação excepcional para cargas de trabalho de última geração, o AIPod com sistemas NVIDIA DGX adiciona sistemas de armazenamento NetApp AFF que permitem aos clientes começar pequenos e crescer sem interrupções, ao mesmo tempo em que gerenciam dados de forma inteligente da borda ao núcleo, à nuvem e vice-versa.  O NetApp AIPod faz parte do portfólio maior de soluções de IA da NetApp , mostrado na figura abaixo.</block>
  <block id="194ff09c8e869017b4ffe91887dde829" category="paragraph">_Portfólio de soluções de IA da NetApp_</block>
  <block id="629225e0ba0d0325f35ee6fcfd7ebf4e" category="paragraph"><block ref="629225e0ba0d0325f35ee6fcfd7ebf4e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff9a398ccda9f0fc1e44521cf40ca977" category="paragraph">Este documento descreve os principais componentes da arquitetura de referência do AIPod , informações de conectividade e configuração do sistema, resultados de testes de validação e orientação de dimensionamento da solução.  Este documento é destinado a engenheiros de soluções da NetApp e parceiros e tomadores de decisões estratégicas de clientes interessados em implantar uma infraestrutura de alto desempenho para cargas de trabalho de ML/DL e análise.</block>
  <block id="77f2324c2483df30f029d522599f882e" category="summary">NetApp AIPod com sistemas NVIDIA DGX - Componentes de software</block>
  <block id="751547b5efb176a435e672a4015bb7e9" category="doc">NVA-1173 NetApp AIPod com sistemas NVIDIA DGX - Componentes de software</block>
  <block id="c3d68fb38e0db372152f5a3a84fed148" category="paragraph">Esta seção se concentra nos componentes de software do NetApp AIPod com sistemas NVIDIA DGX.</block>
  <block id="5475410ded0787143601d2206a245532" category="section-title">Software NVIDIA</block>
  <block id="96a0475a5e6d02d46b5b8d7f1327a530" category="paragraph">O NVIDIA Base Command&amp;#8482; capacita cada DGX BasePOD, permitindo que as organizações aproveitem o melhor da inovação de software da NVIDIA .  As empresas podem liberar todo o potencial de seus investimentos com uma plataforma comprovada que inclui orquestração de nível empresarial e gerenciamento de cluster, bibliotecas que aceleram a computação, o armazenamento e a infraestrutura de rede, além de um sistema operacional (SO) otimizado para cargas de trabalho de IA.</block>
  <block id="f30878d7bf93bf61a8d0a25e397a8583" category="paragraph">_Solução NVIDIA BaseCommand_</block>
  <block id="26997aefe36f4fb8a168ede0ec7189e1" category="paragraph"><block ref="26997aefe36f4fb8a168ede0ec7189e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9052758d35faeab8995feefc50d729ed" category="section-title">Nuvem de GPU NVIDIA (NGC)</block>
  <block id="5cbbb9592d14a268aacbc5ecd838a166" category="paragraph">O NVIDIA NGC fornece software para atender às necessidades de cientistas de dados, desenvolvedores e pesquisadores com vários níveis de experiência em IA.  O software hospedado no NGC passa por varreduras em relação a um conjunto agregado de vulnerabilidades e exposições comuns (CVEs), criptografia e chaves privadas.  Ele foi testado e projetado para ser escalonado para várias GPUs e, em muitos casos, para vários nós, garantindo que os usuários maximizem seus investimentos em sistemas DGX.</block>
  <block id="d19c3b09db45ed579ed1aa2895637b7d" category="paragraph">_Nuvem de GPU NVIDIA_</block>
  <block id="c46997ba8e7fdf0cb96f12b451129203" category="paragraph"><block ref="c46997ba8e7fdf0cb96f12b451129203" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b4d69ee10ecec0ac3d21aba6691dc53" category="paragraph">NVIDIA AI Enterprise é a plataforma de software completa que coloca a IA generativa ao alcance de todas as empresas, fornecendo o tempo de execução mais rápido e eficiente para modelos básicos de IA generativa otimizados para execução na plataforma NVIDIA DGX.  Com segurança, estabilidade e capacidade de gerenciamento de nível de produção, ele simplifica o desenvolvimento de soluções de IA generativas.  O NVIDIA AI Enterprise está incluído no DGX BasePOD para que desenvolvedores corporativos acessem modelos pré-treinados, estruturas otimizadas, microsserviços, bibliotecas aceleradas e suporte empresarial.</block>
  <block id="9aeccfb63defa46cb78ffa3611d362c6" category="section-title">Software NetApp</block>
  <block id="f45c2aa2e74e3412ee9883eb28b7549e" category="paragraph">ONTAP 9, a última geração de software de gerenciamento de armazenamento da NetApp, permite que as empresas modernizem a infraestrutura e façam a transição para um data center pronto para a nuvem.  Aproveitando os recursos de gerenciamento de dados líderes do setor, o ONTAP permite o gerenciamento e a proteção de dados com um único conjunto de ferramentas, independentemente de onde os dados residam.  Você também pode mover dados livremente para onde for necessário: na borda, no núcleo ou na nuvem.  O ONTAP 9 inclui vários recursos que simplificam o gerenciamento de dados, aceleram e protegem dados críticos e permitem recursos de infraestrutura de última geração em arquiteturas de nuvem híbrida.</block>
  <block id="28e23b5888c04e1859e75c594c6cec26" category="section-title">Acelere e proteja os dados</block>
  <block id="d9cd75773d759d63134b34db3490eab3" category="paragraph">O ONTAP oferece níveis superiores de desempenho e proteção de dados e estende esses recursos das seguintes maneiras:</block>
  <block id="7c282a19ff405710e49738f9d0a03a85" category="list-text">Desempenho e menor latência.  O ONTAP oferece o maior rendimento possível com a menor latência possível, incluindo suporte para NVIDIA GPUDirect Storage (GDS) usando NFS sobre RDMA, NFS paralelo (pNFS) e entroncamento de sessão NFS.</block>
  <block id="b2d0aaf645ff5747fbe1e0aec0cf528c" category="list-text">Proteção de dados.  O ONTAP oferece recursos integrados de proteção de dados e a mais forte garantia anti-ransomware do setor, com gerenciamento comum em todas as plataformas.</block>
  <block id="892dd840b39835d7da795bbd29f99987" category="list-text">Criptografia de volume NetApp (NVE).  O ONTAP oferece criptografia nativa em nível de volume com suporte para gerenciamento de chaves externo e integrado.</block>
  <block id="651928f77d87184265ec1be1ab0b8aff" category="list-text">Multilocação de armazenamento e autenticação multifator.  O ONTAP permite o compartilhamento de recursos de infraestrutura com os mais altos níveis de segurança.</block>
  <block id="f1586460cef11d0abaaf5270f37f18d7" category="section-title">Simplifique o gerenciamento de dados</block>
  <block id="47b2e74e56111387efd2ff8314d1154c" category="paragraph">O gerenciamento de dados é crucial para as operações de TI corporativas e cientistas de dados, para que recursos apropriados sejam usados para aplicativos de IA e treinamento de conjuntos de dados de IA/ML.  As seguintes informações adicionais sobre as tecnologias NetApp estão fora do escopo desta validação, mas podem ser relevantes dependendo da sua implantação.</block>
  <block id="31c0318dee8b7049a328f752c457824f" category="paragraph">O software de gerenciamento de dados ONTAP inclui os seguintes recursos para otimizar e simplificar as operações e reduzir seu custo total de operação:</block>
  <block id="621721e0b0144695aabce4090fa40eed" category="list-text">Snapshots e clones permitem colaboração, experimentação paralela e governança de dados aprimorada para fluxos de trabalho de ML/DL.</block>
  <block id="b1932ff070760d4f32c0a3701982558d" category="list-text">O SnapMirror permite a movimentação contínua de dados em ambientes de nuvem híbrida e multisite, entregando dados onde e quando são necessários.</block>
  <block id="258ce6748736436345d3a4ade7bfcd47" category="list-text">Compactação de dados em linha e desduplicação expandida.  A compactação de dados reduz o desperdício de espaço dentro dos blocos de armazenamento e a desduplicação aumenta significativamente a capacidade efetiva.  Isso se aplica a dados armazenados localmente e dados em camadas na nuvem.</block>
  <block id="e0243dd3e4c9bff6b7a18cab1c1e37c8" category="list-text">Qualidade de serviço mínima, máxima e adaptável (AQoS).  Controles granulares de qualidade de serviço (QoS) ajudam a manter os níveis de desempenho para aplicativos críticos em ambientes altamente compartilhados.</block>
  <block id="74959a361bdb223dafbb94226dd84e3e" category="list-text">Os NetApp FlexGroups permitem a distribuição de dados entre todos os nós no cluster de armazenamento, fornecendo grande capacidade e maior desempenho para conjuntos de dados extremamente grandes.</block>
  <block id="c3528a5e48bbe189e76cf8d737aa5961" category="inline-link">TR-4598: Melhores práticas do FabricPool</block>
  <block id="adc171e1d8b6a0bed3a98762139c9875" category="list-text">NetApp FabricPool.  Fornece hierarquização automática de dados frios para opções de armazenamento em nuvem pública e privada, incluindo Amazon Web Services (AWS), Azure e solução de armazenamento NetApp StorageGRID .  Para obter mais informações sobre FabricPool, consulte<block ref="234c921b7066bc1bdd676ae1a510e5c5" category="inline-link-rx"></block> .</block>
  <block id="eec4aeb85db42cd9055b9aba24052c7e" category="list-text">NetApp FlexCache.  Fornece recursos de cache de volume remoto que simplificam a distribuição de arquivos, reduzem a latência da WAN e diminuem os custos de largura de banda da WAN.  O FlexCache permite o desenvolvimento distribuído de produtos em vários sites, bem como acesso acelerado a conjuntos de dados corporativos de locais remotos.</block>
  <block id="685f280ead44650493627d9ac47818e1" category="section-title">Infraestrutura à prova do futuro</block>
  <block id="836ed833c0dea3b588f04d16ca3f850d" category="paragraph">O ONTAP ajuda a atender às necessidades empresariais exigentes e em constante mudança com os seguintes recursos:</block>
  <block id="483e92f76323d9d7b2d7f2ec6d4c0590" category="list-text">Escalabilidade perfeita e operações não disruptivas.  O ONTAP oferece suporte à adição on-line de capacidade aos controladores existentes e à expansão de clusters.  Os clientes podem atualizar para as tecnologias mais recentes, como NVMe e 32Gb FC, sem migrações de dados dispendiosas ou interrupções.</block>
  <block id="96cf8f94fadb527d958ae5373082d6d7" category="list-text">Conexão em nuvem.  ONTAP é o software de gerenciamento de armazenamento mais conectado à nuvem, com opções para armazenamento definido por software (ONTAP Select) e instâncias nativas da nuvem (Google Cloud NetApp Volumes) em todas as nuvens públicas.</block>
  <block id="2a7e7bc180cc3d059089e02f091bac27" category="list-text">Integração com aplicações emergentes.  A ONTAP oferece serviços de dados de nível empresarial para plataformas e aplicativos de última geração, como veículos autônomos, cidades inteligentes e Indústria 4.0, usando a mesma infraestrutura que dá suporte aos aplicativos empresariais existentes.</block>
  <block id="2c7194a99a4f7de8ffbf3ba400a92df8" category="paragraph">O NetApp DataOps Toolkit é uma ferramenta baseada em Python que simplifica o gerenciamento de espaços de trabalho de desenvolvimento/treinamento e servidores de inferência apoiados por armazenamento NetApp de alto desempenho e escalonável.  O DataOps Toolkit pode operar como um utilitário autônomo e é ainda mais eficaz em ambientes Kubernetes, aproveitando o NetApp Trident para automatizar operações de armazenamento.  Os principais recursos incluem:</block>
  <block id="f9e55f3095ff79acd2c7f6315222ba4a" category="list-text">Provisione rapidamente novos espaços de trabalho JupyterLab de alta capacidade, apoiados por armazenamento NetApp escalável e de alto desempenho.</block>
  <block id="a9e4b1a2cc4b445907d2b986ab2f3515" category="list-text">Provisione rapidamente novas instâncias do NVIDIA Triton Inference Server com suporte de armazenamento NetApp de nível empresarial.</block>
  <block id="44ce48cceac53b351ab54ca5685fcf55" category="list-text">Clonagem quase instantânea de espaços de trabalho de alta capacidade do JupyterLab para permitir experimentação ou iteração rápida.</block>
  <block id="b47bad7e2a479b14e613be5ba1af90a0" category="list-text">Snapshots quase instantâneos de espaços de trabalho de alta capacidade do JupyterLab para backup e/ou rastreabilidade/linha de base.</block>
  <block id="afe9b022bbe49ebc232dc11679a61bb4" category="list-text">Provisionamento quase instantâneo, clonagem e snapshots de volumes de dados de alta capacidade e alto desempenho.</block>
  <block id="b242f57e51b5f507797a088899c22df7" category="paragraph">O Trident é um orquestrador de armazenamento de código aberto totalmente suportado para contêineres e distribuições Kubernetes, incluindo o Anthos. O Trident funciona com todo o portfólio de armazenamento da NetApp , incluindo o NetApp ONTAP, e também oferece suporte a conexões NFS, NVMe/TCP e iSCSI. O Trident acelera o fluxo de trabalho do DevOps permitindo que os usuários finais provisionem e gerenciem o armazenamento de seus sistemas de armazenamento NetApp sem exigir a intervenção de um administrador de armazenamento.</block>
  <block id="1efc1a71dad2451e243efa783d9aaba0" category="summary">NetApp AIPod com sistemas NVIDIA DGX - Validação de soluções e orientação de dimensionamento</block>
  <block id="1baf67b0ad3fef1cc60370bda6ebc7f9" category="doc">NVA-1173 NetApp AIPod com sistemas NVIDIA DGX - Validação de solução e orientação de dimensionamento</block>
  <block id="d2fb9fca0fa09d949a54ae42e337c891" category="paragraph">Esta seção se concentra na validação da solução e nas orientações de dimensionamento para o NetApp AIPod com sistemas NVIDIA DGX.</block>
  <block id="773a9689ba6682deeabffa6746d64105" category="section-title">Validação da Solução</block>
  <block id="364bed9cbf28e51b3a87b1cece482054" category="paragraph">A configuração de armazenamento nesta solução foi validada usando uma série de cargas de trabalho sintéticas usando a ferramenta de código aberto FIO.  Esses testes incluem padrões de E/S de leitura e gravação destinados a simular a carga de trabalho de armazenamento gerada por sistemas DGX que executam trabalhos de treinamento de aprendizado profundo.  A configuração de armazenamento foi validada usando um cluster de servidores de CPU de 2 soquetes executando as cargas de trabalho FIO simultaneamente para simular um cluster de sistemas DGX.  Cada cliente foi configurado com a mesma configuração de rede descrita anteriormente, com a adição dos seguintes detalhes.</block>
  <block id="5c553fedff3f40a2af76bb0c410b404f" category="paragraph">As seguintes opções de montagem foram usadas para esta validação:</block>
  <block id="cb8472643b1176f8340370ce5a0b204d" category="cell">versão=4.1</block>
  <block id="893b3a13ba8b6b5a60094306461bc370" category="cell">permite pNFS para acesso paralelo a vários nós de armazenamento</block>
  <block id="1df213ce94ed5cdef706c9350768f0c2" category="cell">proto=rdma</block>
  <block id="42cc89ba8e1299f3640ad771a94abfaa" category="cell">define o protocolo de transferência para RDMA em vez do TCP padrão</block>
  <block id="9b7b56ffe75ec2daff44ba8923725d27" category="cell">porta=20049</block>
  <block id="52c223170500f2f347a266328f0c4216" category="cell">especifique a porta correta para o serviço RDMA NFS</block>
  <block id="5b75616cf8bcd004a7fb0c78bcf4cb1e" category="cell">max_connect=16</block>
  <block id="82264615e17e10dec975d19de56f7e01" category="cell">permite o entroncamento de sessão NFS para agregar largura de banda da porta de armazenamento</block>
  <block id="b0b79785aa490d51befbe60046fe59a6" category="cell">escrever=ansioso</block>
  <block id="27d6ebb9c804f9228e43f1362d2ad502" category="cell">melhora o desempenho de gravação de gravações armazenadas em buffer</block>
  <block id="df2285a23b7de4affb43985a03a9b955" category="cell">rsize=262144,wsize=262144</block>
  <block id="226cf9c18b16f30e1381d76500dcd2c3" category="cell">define o tamanho da transferência de E/S para 256k</block>
  <block id="1275e87e965ab2e83ee1a3d508393bb1" category="paragraph">Além disso, os clientes foram configurados com um valor NFS max_session_slots de 1024.  Como a solução foi testada usando NFS sobre RDMA, as portas das redes de armazenamento foram configuradas com um vínculo ativo/passivo.  Os seguintes parâmetros de ligação foram usados para esta validação:</block>
  <block id="dc2f1400a2999b58888391b52366d42d" category="cell">modo=backup ativo</block>
  <block id="ceafe9fbea6d2853c0ef101fde263114" category="cell">define o vínculo para o modo ativo/passivo</block>
  <block id="0772e25cb688aaddbfcafe9a95042ae0" category="cell">primário=&lt;nome da interface&gt;</block>
  <block id="126d68b093e92a0eeafa0ea632b5dee2" category="cell">as interfaces primárias para todos os clientes foram distribuídas pelos switches</block>
  <block id="cbfd831ae9cd4bbc2c5955b278fc1464" category="cell">mii-monitor-intervalo=100</block>
  <block id="ef530a18c3e08c2e1454d98413c8995a" category="cell">especifica intervalo de monitoramento de 100 ms</block>
  <block id="4a7a0a399fdd09cc77725d4bca22c5d2" category="cell">fail-over-mac-policy=ativo</block>
  <block id="1cddea1ebc0f8a54ddb9d1b5d3701199" category="cell">especifica que o endereço MAC do link ativo é o MAC do vínculo.  Isso é necessário para a operação adequada do RDMA na interface vinculada.</block>
  <block id="13e766ae456cff38288a10e042da1460" category="paragraph">O sistema de armazenamento foi configurado conforme descrito com dois pares de HA A900 (4 controladores) com duas prateleiras de disco NS224 de 24 unidades de disco NVMe de 1,9 TB conectadas a cada par de HA.  Conforme observado na seção de arquitetura, a capacidade de armazenamento de todos os controladores foi combinada usando um volume FlexGroup , e os dados de todos os clientes foram distribuídos entre todos os controladores no cluster.</block>
  <block id="4534545218c3df22ad30ec5ab0466128" category="section-title">Orientação sobre dimensionamento de sistemas de armazenamento</block>
  <block id="e58e8ec46be51c65fb6895529b19620c" category="paragraph">A NetApp concluiu com sucesso a certificação DGX BasePOD, e os dois pares A90 HA testados podem facilmente suportar um cluster de dezesseis sistemas DGX H100.  Para implantações maiores com requisitos mais altos de desempenho de armazenamento, sistemas AFF adicionais podem ser adicionados ao cluster NetApp ONTAP , até 12 pares de HA (24 nós) em um único cluster.  Usando a tecnologia FlexGroup descrita nesta solução, um cluster de 24 nós pode fornecer mais de 79 PB e até 552 GBps de taxa de transferência em um único namespace.  Outros sistemas de armazenamento NetApp , como o AFF A400, A250 e C800, oferecem opções de menor desempenho e/ou maior capacidade para implantações menores com custos mais baixos.  Como o ONTAP 9 oferece suporte a clusters de modelos mistos, os clientes podem começar com um espaço inicial menor e adicionar mais ou maiores sistemas de armazenamento ao cluster conforme os requisitos de capacidade e desempenho aumentam.  A tabela abaixo mostra uma estimativa aproximada do número de GPUs A100 e H100 suportadas em cada modelo AFF .</block>
  <block id="d151e6348ab5291d10caeda2db802b75" category="paragraph">_Orientação de dimensionamento do sistema de armazenamento NetApp_</block>
  <block id="c61d72d95f504983715ce76fcfdfb864" category="paragraph"><block ref="c61d72d95f504983715ce76fcfdfb864" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28e8b3e83af233fe7085ba954fc6fd36" category="doc">BeeGFS no NetApp com armazenamento da série E</block>
  <block id="e8afe31a21b6aae9717484d865743dae" category="paragraph">O BeeGFS no NetApp com armazenamento da Série E é uma solução comprovada e integrada com uma infraestrutura de HPC simples, confiável, escalável e econômica que acompanha suas cargas de trabalho mais extremas.</block>
  <block id="d18d454d6ae7128c6b49bf41c9ea2cf4" category="paragraph"><block ref="d18d454d6ae7128c6b49bf41c9ea2cf4" category="inline-link-macro-rx"></block></block>
  <block id="fcf432f7f886df6aeafb1dec9357085d" category="doc">NVA-1150-DEPLOY: Guia de implantação de sistemas Quantum StorNext com NetApp E-Series</block>
  <block id="806008ac96286a2e08058ba3a3daa601" category="paragraph">Ryan Rodine, NetApp</block>
  <block id="25dbf1b5193ae9eff63687c18c19e6f5" category="paragraph">Este documento fornece detalhes sobre como implantar uma solução de sistema de arquivos paralelo StorNext com sistemas de armazenamento NetApp E-Series.  Esta solução abrange o array all-flash NetApp EF280, o array NVMe all-flash NetApp EF300, o array NVMe all-flash NetApp EF600 e o sistema híbrido NetApp E5760.  Ele oferece caracterização de desempenho com base no benchmarking Frametest, uma ferramenta amplamente utilizada para testes na indústria de mídia e entretenimento.</block>
  <block id="a06fe4c2db4f7b09c705e4e8dafb5627" category="paragraph"><block ref="a06fe4c2db4f7b09c705e4e8dafb5627" category="inline-link-macro-rx"></block></block>
  <block id="96f5c57f6fea73d6692c5f8c2703e9b9" category="doc">NVA-1150-DESIGN: Guia de design de sistemas Quantum StorNext com NetApp E-Series</block>
  <block id="5ee668b979e736471a8d46609abdc49b" category="paragraph">Este documento fornece detalhes sobre como projetar uma solução de sistema de arquivos paralelo StorNext com sistemas de armazenamento NetApp E-Series.  Esta solução abrange o array all-flash NetApp EF280, o array NVMe all-flash NetApp EF300, o array NVMe all-flash EF600 e o sistema híbrido NetApp E5760.  Ele oferece caracterização de desempenho com base no benchmarking Frametest, uma ferramenta amplamente utilizada para testes na indústria de mídia e entretenimento.</block>
  <block id="4f8b12df588cb1e82eb6d578f26c6c62" category="paragraph"><block ref="4f8b12df588cb1e82eb6d578f26c6c62" category="inline-link-macro-rx"></block></block>
  <block id="bf6adc497a862180909278cf6ed029f1" category="doc">TR-4859: Implantando a escala de espectro da IBM com armazenamento NetApp E-Series - Instalação e validação</block>
  <block id="7d8a7f37eb34080960253271b824ab2f" category="paragraph">Chris Seirer, NetApp</block>
  <block id="06bd55c4b576fd1f13eb5e25a1415bba" category="paragraph">TR-4859 descreve o processo de implantação de uma solução completa de sistema de arquivos paralelo com base na pilha de software Spectrum Scale da IBM.  O TR-4859 foi projetado para fornecer detalhes sobre como instalar o Spectrum Scale, validar a infraestrutura e gerenciar a configuração.</block>
  <block id="6a51aeb3b4e11ee4436f8ad323e23c5a" category="paragraph"><block ref="6a51aeb3b4e11ee4436f8ad323e23c5a" category="inline-link-macro-rx"></block></block>
  <block id="3026654be6be955b54735554371ee5a0" category="summary">Esta Arquitetura Verificada da NetApp descreve o design do NVIDIA DGX SuperPOD com blocos de construção NetApp BeeGFS.  Esta solução é uma plataforma de data center full-stack validada em um cluster de aceitação dedicado na NVIDIA.</block>
  <block id="85505186d8e84ecff8e7e71596423747" category="doc">NVIDIA DGX SuperPOD com NetApp - Guia de Design</block>
  <block id="49ba6c0ee9149acc4bdb6fac5165b7b0" category="paragraph">Esta Arquitetura Verificada da NetApp descreve o design do NVIDIA DGX SuperPOD com blocos de construção NetApp BeeGFS.  Esta solução é uma plataforma de data center full-stack validada em um cluster de aceitação dedicado na NVIDIA.</block>
  <block id="adb0b7d6a9d5c0af32d1c6fe9a103229" category="inline-image-macro">200.200</block>
  <block id="0a8dfa4d72d5f9b29ce5ac529286b37f" category="paragraph"><block ref="0a8dfa4d72d5f9b29ce5ac529286b37f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0a7225e9429ab905378b45f3aa288040" category="paragraph">Amine Bennani, Christian Whiteside, David Arnette e Sathish Thyagarajan, NetApp</block>
  <block id="7919e821dc18f3e88c0201e01bf6a240" category="section-title">Sumário executivo</block>
  <block id="d83b5adf97fe549e1dc83bb95e6f2cdf" category="paragraph">No cenário tecnológico de rápida evolução de hoje, a IA está revolucionando as experiências do consumidor e impulsionando a inovação em todos os setores.  No entanto, também apresenta desafios significativos para os departamentos de TI, que estão sob pressão para implantar soluções de computação de alto desempenho (HPC) capazes de lidar com as intensas demandas das cargas de trabalho de IA.  À medida que as organizações correm para aproveitar o poder da IA, cresce a urgência por uma solução que seja fácil de implantar, dimensionar e gerenciar.</block>
  <block id="2e93342ec6458064edd50d209383c787" category="paragraph">NVIDIA DGX SuperPOD é uma plataforma de infraestrutura de data center de IA fornecida como uma solução pronta para uso para TI, para dar suporte às cargas de trabalho de IA mais complexas enfrentadas pelas empresas de hoje.  No centro de qualquer modelo preciso de aprendizado profundo (DL) estão grandes volumes de dados, exigindo uma solução de armazenamento de alto rendimento que possa servir e servir novamente esses dados de forma eficiente.  A solução NetApp BeeGFS, composta por matrizes de armazenamento NetApp EF600 com o sistema de arquivos paralelo BeeGFS, permite que o NVIDIA DGX SuperPOD libere toda a sua capacidade.  A solução NetApp BeeGFS foi validada pela NVIDIA para integração e escalabilidade com a arquitetura SuperPOD.  O resultado é uma implantação e um gerenciamento simplificados de data center de IA, ao mesmo tempo em que oferece escalabilidade praticamente ilimitada para desempenho e capacidade.</block>
  <block id="77e585eeb67a682a6445c0154fd9a028" category="paragraph">A solução NetApp BeeGFS, alimentada pelos sistemas de armazenamento NetApp EF600 NVMe de alto desempenho e pelo sistema de arquivos paralelos BeeGFS escalável, oferece uma base de armazenamento robusta e eficiente para cargas de trabalho de IA exigentes.  Sua arquitetura de disco compartilhado garante alta disponibilidade, mantendo desempenho e acessibilidade consistentes, mesmo diante de desafios do sistema.  Esta solução fornece uma arquitetura escalável e flexível que pode ser personalizada para atender a diversos requisitos de armazenamento.  Os clientes podem expandir facilmente o desempenho e a capacidade de armazenamento integrando blocos de construção de armazenamento adicionais para lidar até mesmo com as cargas de trabalho mais exigentes.</block>
  <block id="1ad3f73d04f7a3d0b225d62bf707c034" category="list-text">O NVIDIA DGX SuperPOD aproveita os sistemas DGX H100 e H200 com um armazenamento compartilhado conectado externamente validado:</block>
  <block id="8dc89fa0c821b38b2ab07d3f5dd4385f" category="list-text">Cada unidade escalável (SU) DGX SuperPOD consiste em 32 sistemas DGX e é capaz de 640 petaFLOPS de desempenho de IA com precisão FP8.  A NetApp recomenda dimensionar a solução de armazenamento NetApp BeeGFS com pelo menos 2 blocos de construção para uma única configuração DGX SuperPOD.</block>
  <block id="0aa799745475dedefbc0785863494b75" category="paragraph">_Uma visão geral da solução_</block>
  <block id="0e06b8493198d6e7d8d53d9201ddd9bc" category="inline-image-macro">Figura mostrando uma visão geral de alto nível da solução NetApp BeeGFS com um NVIDIA DGX SuperPOD.</block>
  <block id="6bfc1196652f29c394bdbe8e2807a4a0" category="paragraph"><block ref="6bfc1196652f29c394bdbe8e2807a4a0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="949e06b94ff43763386683593267b5d3" category="list-text">Os blocos de construção do NetApp BeeGFS consistem em dois arrays NetApp EF600 e dois servidores x86:</block>
  <block id="53a59094fc8cf61c8ceb5488c68798f9" category="list-text">Com os arrays all-flash NetApp EF600 na base do NVIDIA DGX SuperPOD, os clientes obtêm uma base de armazenamento confiável apoiada por seis 9s de tempo de atividade.</block>
  <block id="23830778b135794055062035d895d122" category="list-text">A camada do sistema de arquivos entre os sistemas NetApp EF600 e NVIDIA DGX é o sistema de arquivos paralelo BeeGFS.  O BeeGFS foi criado pelo Centro Fraunhofer de Computação de Alto Desempenho na Alemanha para resolver os problemas dos sistemas de arquivos paralelos legados.  O resultado é um sistema de arquivos com uma arquitetura moderna de espaço de usuário que agora é desenvolvido e entregue pela ThinkParQ e usado por muitos ambientes de supercomputação.</block>
  <block id="d6dbc9a4d449d8584f1bc7766a233055" category="list-text">O suporte da NetApp para BeeGFS alinha a excelente organização de suporte da NetApp com os requisitos do cliente em termos de desempenho e tempo de atividade.  Os clientes têm acesso a recursos de suporte superiores, acesso antecipado às versões do BeeGFS e acesso a recursos empresariais selecionados do BeeGFS, como aplicação de cotas e alta disponibilidade (HA).</block>
  <block id="06723075d010c851032e77543613704f" category="list-text">A combinação dos NVIDIA SuperPOD SUs e dos blocos de construção NetApp BeeGFS fornece uma solução de IA ágil na qual a computação ou o armazenamento são dimensionados de forma fácil e contínua.</block>
  <block id="e0d00c6a1325f01dc14822163a1d43fe" category="paragraph">_Bloco de construção NetApp BeeGFS_</block>
  <block id="f2ccf42799ed738590ee8a95c9a2e5c9" category="inline-image-macro">Figura mostrando um único bloco de construção NetApp BeeGFS.</block>
  <block id="9390da63574f67fe268b45392cf0ec3e" category="paragraph"><block ref="9390da63574f67fe268b45392cf0ec3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df07b47923825d5392c14e80cea2d72a" category="section-title">Resumo do caso de uso</block>
  <block id="976894dcc596e37094668684315ccac4" category="paragraph">Esta solução se aplica aos seguintes casos de uso:</block>
  <block id="30e31e5dc6388c3434cea1711261b743" category="list-text">Inteligência Artificial (IA), incluindo aprendizado de máquina (ML), aprendizado profundo (DL), processamento de linguagem natural (NLP), compreensão de linguagem natural (NLU) e IA generativa (GenAI).</block>
  <block id="c21f50752fbbe8f54e46848c0f9ce70a" category="list-text">Treinamento de IA em média e grande escala</block>
  <block id="137c3bef49af695737b7c23000204b5c" category="list-text">Modelos de visão computacional, fala, áudio e linguagem</block>
  <block id="15ed9179636b107f0a88e83f782e6cec" category="list-text">HPC incluindo aplicações aceleradas por interface de passagem de mensagens (MPI) e outras técnicas de computação distribuída</block>
  <block id="90b7289b464ec4d544bf5a9eacbaf7f0" category="list-text">Cargas de trabalho de aplicativos caracterizadas pelo seguinte:</block>
  <block id="c9ccfce7935790c9fd0d9ccf98da5177" category="list-text">Ler ou escrever em arquivos maiores que 1 GB</block>
  <block id="680e47afa4860ce2ac4a078a0d466121" category="list-text">Leitura ou gravação no mesmo arquivo por vários clientes (dezenas, centenas e milhares)</block>
  <block id="af7aa0607b7f1d728a529edd21a52763" category="list-text">Conjuntos de dados multiterabytes ou multipetabytes</block>
  <block id="efc155766b6000aefdf459d6ff3ecd75" category="list-text">Ambientes que precisam de um único namespace de armazenamento otimizável para uma mistura de arquivos grandes e pequenos</block>
  <block id="dcbd8f687e2ef904380c2b6c942c989e" category="paragraph">Esta seção aborda os requisitos de tecnologia para a solução NVIDIA DGX SuperPOD com NetApp .</block>
  <block id="b95d6ba22cd7d0fb6a3c655d4c24d180" category="inline-link">Arquitetura de referência NVIDIA DGX H100 SuperPOD</block>
  <block id="02399dc2f4ffe6e6772456736a8522d7" category="inline-link">NVA-1164-DESIGN: BeeGFS no NetApp NVA Design</block>
  <block id="5425be0e2232456057166446265f9a88" category="paragraph">A Tabela 1 abaixo lista os componentes de hardware necessários para implementar a solução para uma única SU.  O dimensionamento da solução começa com 32 sistemas NVIDIA DGX H100 e dois ou três blocos de construção NetApp BeeGFS.  Um único bloco de construção NetApp BeeGFS consiste em dois arrays NetApp EF600 e dois servidores x86.  Os clientes podem adicionar blocos de construção adicionais conforme o tamanho da implantação aumenta.  Para mais informações, consulte o<block ref="55ded0354bf42e7e117b50dda2359a8a" category="inline-link-rx"></block> e<block ref="de7b61948f391c0bb69985cc0357d2a5" category="inline-link-rx"></block> .</block>
  <block id="5aa595c84818428979f9fa2d99bb6f83" category="cell">NVIDIA DGX H100 ou H200</block>
  <block id="6364d3f0f495b6ab9dcf8d3b5c6e0b01" category="cell">32</block>
  <block id="eef6c1a81c81a43f02e2b7749d260ef5" category="cell">Switches NVIDIA Quantum QM9700</block>
  <block id="34a2c495ed1b62db3e0fffd75420aca5" category="cell">8 folhas, 4 lombadas</block>
  <block id="be3accc5713b4d53186215779c2deeed" category="cell">Blocos de construção NetApp BeeGFS</block>
  <block id="0dbcb15fd014d19061fb2910f0a1ab0e" category="paragraph">A Tabela 2 abaixo lista os componentes de software necessários para implementar a solução.  Os componentes de software usados em qualquer implementação específica da solução podem variar com base nos requisitos do cliente.</block>
  <block id="b9e807b01f3ef86c9dfed350c8c3d49f" category="cell">Pilha de software NVIDIA DGX</block>
  <block id="32ac4a04c126e4e450b2f93ae6cfd3a7" category="cell">Sistema de arquivos paralelos ThinkParQ BeeGFS</block>
  <block id="dc140913e754c7554bc598a02951fa66" category="section-title">Verificação da solução</block>
  <block id="f95f7879d178879af0b5a728259ce9a3" category="inline-link">NVIDIA DGX SuperPOD: Arquitetura de referência NetApp EF600 e BeeGFS</block>
  <block id="24e45924f52e38078756fd5fb1d83668" category="paragraph">O NVIDIA DGX SuperPOD com NetApp foi validado em um cluster de aceitação dedicado na NVIDIA usando blocos de construção NetApp BeeGFS.  Os critérios de aceitação foram baseados em uma série de testes de aplicação, desempenho e estresse realizados pela NVIDIA. Para mais informações, consulte o<block ref="2ffc6657f5234f1aed913433d4ce09f3" category="inline-link-rx"></block> .</block>
  <block id="b7f81445ff8908f0aa2a3356e8231f05" category="paragraph">A NetApp e a NVIDIA têm um longo histórico de colaboração para fornecer um portfólio de soluções de IA ao mercado.  O NVIDIA DGX SuperPOD com o array all-flash NetApp EF600 é uma solução comprovada e validada que os clientes podem implementar com confiança.  Essa arquitetura totalmente integrada e pronta para uso elimina os riscos da implantação e coloca qualquer pessoa no caminho para vencer a corrida pela liderança em IA.</block>
  <block id="dcd86a18e8aa77675f1b2f792cb6ba5c" category="inline-link-macro">Arquitetura de referência NVIDIA DGX SuperPOD</block>
  <block id="98d56828382118fe5dcd8ef673b93afb" category="list-text"><block ref="98d56828382118fe5dcd8ef673b93afb" category="inline-link-macro-rx"></block></block>
  <block id="4fafe9ef5c2efce123913e9ac744f4d6" category="inline-link-macro">Guia de referência de design de data center NVIDIA DGX SuperPOD</block>
  <block id="473bfb82bbec433a8f08fa15c67e0c08" category="list-text"><block ref="473bfb82bbec433a8f08fa15c67e0c08" category="inline-link-macro-rx"></block></block>
  <block id="6f698ddb1773933b8e41b2ed16297ce7" category="inline-link-macro">NVIDIA DGX SuperPOD: NetApp EF600 e BeeGFS</block>
  <block id="a552f45479fc3484a4356ed78090fa76" category="list-text"><block ref="7f25f2868948e2fffc54c32cf9c33644" category="inline-link-macro-rx"></block></block>
  <block id="58415f353579ec62f4e5d8047761a3cc" category="summary">A automação orientada por IA e a computação de ponta são uma abordagem líder para ajudar organizações empresariais a alcançar a transformação digital e maximizar a eficiência operacional e a segurança.  Com a computação de ponta, os dados são processados muito mais rápido porque não precisam viajar de um data center para outro.  Portanto, o custo associado ao envio e recebimento de dados para data centers ou para a nuvem é reduzido.</block>
  <block id="7d7c5045abef00692470c8d5ed1aeebd" category="paragraph">A automação orientada por IA e a computação de ponta são uma abordagem líder para ajudar organizações empresariais a alcançar a transformação digital e maximizar a eficiência operacional e a segurança.  Com a computação de ponta, os dados são processados muito mais rápido porque não precisam viajar de um data center para outro.  Portanto, o custo associado ao envio e recebimento de dados para data centers ou para a nuvem é reduzido.  Menor latência e maior velocidade podem ser benéficas quando as empresas precisam tomar decisões quase em tempo real usando modelos de inferência de IA implantados na borda.</block>
  <block id="691e8c5d8b13259848ef2e5515d14ca9" category="paragraph">Os sistemas de armazenamento NetApp oferecem o mesmo desempenho ou melhor que o armazenamento SSD local e oferecem os seguintes benefícios para cientistas de dados, engenheiros de dados, desenvolvedores de IA/ML e tomadores de decisões de negócios ou de TI:</block>
  <block id="59ceee4c2b9743d6e9aae43f1e9ee547" category="list-text">Compartilhamento fácil de dados entre sistemas de IA, análises e outros sistemas empresariais críticos.  Esse compartilhamento de dados reduz a sobrecarga de infraestrutura, melhora o desempenho e simplifica o gerenciamento de dados em toda a empresa.</block>
  <block id="b9f30f0e1030c74a0db7ca1a1e82a22f" category="list-text">Computação e armazenamento escaláveis de forma independente para minimizar custos e melhorar o uso de recursos.</block>
  <block id="40454c2a63608aacf0433b6a47f388f4" category="list-text">Fluxos de trabalho de desenvolvimento e implantação simplificados usando cópias e clones de Snapshot integrados para espaços de trabalho de usuários instantâneos e com economia de espaço, controle de versão integrado e implantação automatizada.</block>
  <block id="0543f71645ff9108a860d92965cc1383" category="list-text">Proteção de dados de nível empresarial para recuperação de desastres e continuidade de negócios.  A solução da NetApp e da Lenovo apresentada neste documento é uma arquitetura flexível e escalável, ideal para implantações de inferência de IA de nível empresarial na borda.</block>
  <block id="84ffd62e595c9d0122e136c3b255f4df" category="section-title">Agradecimentos</block>
  <block id="68c8080de8c25b2c95e86546db2c34f4" category="list-text">JJ  Falkanger, gerente sênior, soluções de HPC e IA, Lenovo</block>
  <block id="a1be3af64bad65325413de79cbdd38ec" category="list-text">Dave Arnette, engenheiro de marketing técnico, NetApp</block>
  <block id="ab7eb4cf2e6900db95523411e2e2d968" category="list-text">Joey Parnell, líder técnico de soluções de IA da série E, NetApp</block>
  <block id="7506341ffff969b3db4120a09a3cd873" category="list-text">Cody Harryman, engenheiro de controle de qualidade, NetApp</block>
  <block id="345245c83d2b2c4c2a5eb9f2887da627" category="paragraph">Para saber mais sobre as informações descritas neste documento, consulte os seguintes documentos e/ou sites:</block>
  <block id="16d9e623379df2a050a5042b643bf4fc" category="list-text">Página de produto dos arrays NetApp AFF Série A</block>
  <block id="2eea2276b1fb61cd770f311f77c0f440" category="inline-link"><block ref="2eea2276b1fb61cd770f311f77c0f440" category="inline-link-rx"></block></block>
  <block id="3ac5561d8de2087fdd9ac49ace880bff" category="paragraph"><block ref="3ac5561d8de2087fdd9ac49ace880bff" category="inline-link-rx"></block></block>
  <block id="ac2e4973250b614c4ffed16837be9bda" category="list-text">Software de gerenciamento de dados NetApp ONTAP — biblioteca de informações ONTAP 9</block>
  <block id="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link"><block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="paragraph"><block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="5dbac8b4dac620b04fd11b54388ac506" category="list-text">TR-4727: Introdução à série NetApp EF</block>
  <block id="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link"><block ref="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link-rx"></block></block>
  <block id="5e60359f54f57375f6417990b408bc8d" category="paragraph"><block ref="5e60359f54f57375f6417990b408bc8d" category="inline-link-rx"></block></block>
  <block id="bf8eb67f3476640d74487d7395b166a8" category="list-text">Folha de dados do software NetApp E-Series SANtricity</block>
  <block id="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link"><block ref="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link-rx"></block></block>
  <block id="62cabab367af4d0d4f74456d673e91e7" category="paragraph"><block ref="62cabab367af4d0d4f74456d673e91e7" category="inline-link-rx"></block></block>
  <block id="f11b61c13d771c4795415471f8362f8c" category="list-text">Armazenamento persistente da NetApp para contêineres — NetApp Trident</block>
  <block id="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link"><block ref="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link-rx"></block></block>
  <block id="e582bd0f584c041fb70164ea1502666b" category="paragraph"><block ref="e582bd0f584c041fb70164ea1502666b" category="inline-link-rx"></block></block>
  <block id="6bd5e585bc974f029ff9c7cc8a2b68dd" category="list-text">MLPerf</block>
  <block id="856500f909a4984692886f9549398b67" category="inline-link"><block ref="856500f909a4984692886f9549398b67" category="inline-link-rx"></block></block>
  <block id="fe6e33e3be237f2a488d04432ad4b35f" category="list-text"><block ref="fe6e33e3be237f2a488d04432ad4b35f" category="inline-link-rx"></block></block>
  <block id="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link"><block ref="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link-rx"></block></block>
  <block id="3de4b3f21621e41c0738a82d4e694114" category="list-text"><block ref="3de4b3f21621e41c0738a82d4e694114" category="inline-link-rx"></block></block>
  <block id="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link"><block ref="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link-rx"></block></block>
  <block id="25b3dca46bdabc4612ba4ba5dac0f9db" category="list-text"><block ref="25b3dca46bdabc4612ba4ba5dac0f9db" category="inline-link-rx"></block></block>
  <block id="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link"><block ref="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link-rx"></block></block>
  <block id="fdad8301fde8271edff994d643d18865" category="paragraph"><block ref="fdad8301fde8271edff994d643d18865" category="inline-link-rx"></block></block>
  <block id="7749687216549469e9a78db087fbb44b" category="list-text">Benchmark do TensorFlow</block>
  <block id="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link"><block ref="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link-rx"></block></block>
  <block id="be1b7087c9993d320070b1e676c832f9" category="paragraph"><block ref="be1b7087c9993d320070b1e676c832f9" category="inline-link-rx"></block></block>
  <block id="13f9a963bd60406520ccdc128d44b54a" category="list-text">Servidor Lenovo ThinkSystem SE350 Edge</block>
  <block id="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link"><block ref="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link-rx"></block></block>
  <block id="b1a88588a48ee9492506277f8561b392" category="paragraph"><block ref="b1a88588a48ee9492506277f8561b392" category="inline-link-rx"></block></block>
  <block id="f9732caa47051768fc11729f5535891b" category="list-text">Matriz de armazenamento flash unificada Lenovo ThinkSystem DM5100F</block>
  <block id="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link"><block ref="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link-rx"></block></block>
  <block id="a4113bc79b3920d11274d7bf9cfafe10" category="paragraph"><block ref="a4113bc79b3920d11274d7bf9cfafe10" category="inline-link-rx"></block></block>
  <block id="207e9f2f3c6b5a3e8c9228ceadc806b2" category="summary">Esta seção descreve as configurações testadas, a infraestrutura de rede, o servidor SE350 e os detalhes de provisionamento de armazenamento.</block>
  <block id="32d798df7254f6703ed2262024e0e174" category="doc">Configuração de teste</block>
  <block id="a55faacbe457d923ebd296421a71b898" category="paragraph">A figura a seguir mostra a configuração do teste.  Usamos o sistema de armazenamento NetApp AFF C190 e dois servidores Lenovo ThinkSystem SE350 (cada um com um acelerador NVIDIA T4).  Esses componentes são conectados por meio de um switch de rede 10GbE.  O armazenamento de rede contém conjuntos de dados de validação/teste e modelos pré-treinados.  Os servidores fornecem capacidade computacional e o armazenamento é acessado pelo protocolo NFS.</block>
  <block id="d8c97013f1e301478b23530ad6ed1ef6" category="paragraph">Esta seção descreve as configurações testadas, a infraestrutura de rede, o servidor SE350 e os detalhes de provisionamento de armazenamento.  A tabela a seguir lista os componentes básicos para a arquitetura da solução.</block>
  <block id="d552f08a6baeb9bee58f2ca6ff5090d2" category="cell">Servidores Lenovo ThinkSystem</block>
  <block id="fe8ab8cb391be4f8cf88a9b64c3ce3cd" category="list-text">2 servidores SE350, cada um com uma placa de GPU NVIDIA T4</block>
  <block id="acd4671bd4d78c7fc0ac8cbc66a01483" category="list-text">Cada servidor contém uma CPU Intel Xeon D-2123IT com quatro núcleos físicos rodando a 2,20 GHz e 128 GB de RAM</block>
  <block id="d7d02fd9ab069a2d95dee248370100f9" category="cell">Sistema de armazenamento NetApp AFF de nível básico (par HA)</block>
  <block id="1d680806b37a387e8d84b0c21be4d816" category="list-text">Software NetApp ONTAP 9</block>
  <block id="0c1dcc458c4dd96728e0b0998cba7305" category="list-text">24 SSDs de 960 GB</block>
  <block id="a2a817ee9a8e05389f7b11bd8ce4bbdb" category="list-text">Protocolo NFS</block>
  <block id="d8e87bd5878266cd4137e82d919799eb" category="list-text">Um grupo de interface por controlador, com quatro endereços IP lógicos para pontos de montagem</block>
  <block id="e2921b0ff5efef521f662303c467e27f" category="paragraph"><block ref="e2921b0ff5efef521f662303c467e27f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208eac927f1261c6e6eaa3135a529cf3" category="paragraph">A tabela a seguir lista a configuração de armazenamento: AFF C190 com 2RU, 24 slots de unidade.</block>
  <block id="9bbf373797bf7cf7ba62c80023682e25" category="cell">Controlador</block>
  <block id="2ee34178bb8415b7d7234cd27b83aed6" category="cell">Agregar</block>
  <block id="e9db3004828d9514fafc57881dfbdbd2" category="cell">Volume FlexGroup</block>
  <block id="2e0fb97d51b96b1635dcc3ca51f74fee" category="cell">Tamanho agregado</block>
  <block id="b94c9ec583603e13b5c32d83199c7376" category="cell">Tamanho do volume</block>
  <block id="53a35f8b51acc9748a3e172a76f542a7" category="cell">Ponto de montagem do sistema operacional</block>
  <block id="6a1ab89ed912a96429c83ff1ba0f48d0" category="cell">Controller1</block>
  <block id="4d80d82716f0b771738e7fad121e059a" category="cell">Aggr1</block>
  <block id="e39298390e27007517a0cb199728188a" category="cell">/netapplenovo_AI_fg</block>
  <block id="4923ec171d721fba1d4547deefc98e8c" category="cell">8.42TiB</block>
  <block id="f13cb116755b4e8fa1af1b201025f377" category="cell">15 TB</block>
  <block id="3fe74875837b518b23813988af1e39d9" category="cell">/netapp_lenovo_fg</block>
  <block id="3877384a92be771d61972d07648b799f" category="cell">Controller2</block>
  <block id="f3913037ef38679d334aa0cf30e2b6fd" category="cell">Aggr2</block>
  <block id="6b02e3a677be18a8be3641bb43e8b220" category="paragraph">A pasta /netappLenovo_AI_fg contém os conjuntos de dados usados para validação do modelo.</block>
  <block id="e4239f67d8e47773c69a7cb4be34d949" category="paragraph">A figura abaixo mostra a configuração do teste.  Usamos o sistema de armazenamento NetApp EF280 e dois servidores Lenovo ThinkSystem SE350 (cada um com um acelerador NVIDIA T4).  Esses componentes são conectados por meio de um switch de rede 10GbE.  O armazenamento de rede contém conjuntos de dados de validação/teste e modelos pré-treinados.  Os servidores fornecem capacidade computacional e o armazenamento é acessado pelo protocolo NFS.</block>
  <block id="efb90877bc42cc445eb6e1b59c0e1b16" category="paragraph">A tabela a seguir lista a configuração de armazenamento do EF280.</block>
  <block id="0951a6690e5dc87411346792c9f941c7" category="cell">Grupo de Volume</block>
  <block id="bd7a9717d29c5ddcab1bc175eda1e298" category="cell">Volume</block>
  <block id="6c88d21af6046f64871457b825dcf1c8" category="cell">Tamanho DDP</block>
  <block id="59b02558285aa326c0e9018324ed0c4f" category="cell">Método de conexão</block>
  <block id="db320b0194c895c7ac56fedae7928e63" category="cell">DDP1</block>
  <block id="fc452c26db3c4aa6f6213b9c5d9e3abc" category="cell">Volume 1</block>
  <block id="fe066d0b9d36398d5f525d6ac7f8e8c5" category="cell">16 TB</block>
  <block id="e0d2b052ec3dbd102ff7a7f2b356ea41" category="cell">SE350-1 para iSCSI LUN 0</block>
  <block id="ef0e038a9f9b0db74b504d5521e7a0fc" category="cell">Volume 2</block>
  <block id="5b846730a13fc5ea0a76a6b7b9a69d5a" category="cell">SE350-2 para iSCSI LUN 1</block>
  <block id="7192b14affaba8b38680e0cd3749622e" category="paragraph"><block ref="7192b14affaba8b38680e0cd3749622e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00760d3595ff19f6db2da5213b1fdd58" category="summary">Este documento descreve uma arquitetura de computação e armazenamento para implantar inferência de inteligência artificial (IA) baseada em GPU em controladores de armazenamento NetApp e servidores Lenovo ThinkSystem em um ambiente de ponta que atende a cenários de aplicativos emergentes.</block>
  <block id="09f4ae28e2596e14a7568f3e12a77834" category="doc">TR-4886: Inferência de IA na Borda - NetApp com Lenovo ThinkSystem - Design de Solução</block>
  <block id="6671938f046112e34e990cb75cc642dd" category="paragraph">Sathish Thyagarajan, NetApp Miroslav Hodak, Lenovo</block>
  <block id="290612199861c31d1036b185b4e69b75" category="section-title">Resumo</block>
  <block id="ee0e2e290e4e02a3860382ef2cc42ca0" category="paragraph">Vários cenários de aplicação emergentes, como sistemas avançados de assistência ao motorista (ADAS), Indústria 4.0, cidades inteligentes e Internet das Coisas (IoT), exigem o processamento de fluxos de dados contínuos sob uma latência próxima de zero.  Este documento descreve uma arquitetura de computação e armazenamento para implantar inferência de inteligência artificial (IA) baseada em GPU em controladores de armazenamento NetApp e servidores Lenovo ThinkSystem em um ambiente de ponta que atende a esses requisitos.  Este documento também fornece dados de desempenho para o benchmark MLPerf Inference padrão do setor, avaliando várias tarefas de inferência em servidores de ponta equipados com GPUs NVIDIA T4.  Investigamos o desempenho de cenários de inferência offline, de fluxo único e multifluxo e mostramos que a arquitetura com um sistema de armazenamento em rede compartilhado e econômico tem alto desempenho e fornece um ponto central para gerenciamento de dados e modelos para vários servidores de ponta.</block>
  <block id="a27de0758c1fc778a0fb19ebcb6a8aff" category="paragraph">As empresas estão gerando cada vez mais grandes volumes de dados na borda da rede.  Para obter o máximo valor de sensores inteligentes e dados de IoT, as organizações estão buscando uma solução de streaming de eventos em tempo real que permita computação de ponta.  Portanto, trabalhos computacionalmente exigentes são cada vez mais realizados na borda, fora dos data centers.  A inferência de IA é um dos impulsionadores dessa tendência.  Os servidores de borda fornecem poder computacional suficiente para essas cargas de trabalho, especialmente ao usar aceleradores, mas o armazenamento limitado geralmente é um problema, especialmente em ambientes multisservidor.  Neste documento, mostramos como você pode implantar um sistema de armazenamento compartilhado no ambiente de ponta e como ele beneficia cargas de trabalho de inferência de IA sem impor uma penalidade de desempenho.</block>
  <block id="c22ef83c0446b759f6cd8835206adaae" category="paragraph">Este documento descreve uma arquitetura de referência para inferência de IA na borda.  Ele combina vários servidores de ponta Lenovo ThinkSystem com um sistema de armazenamento NetApp para criar uma solução fácil de implantar e gerenciar.  O objetivo é servir de guia básico para implementações práticas em diversas situações, como no chão de fábrica com diversas câmeras e sensores industriais, sistemas de ponto de venda (POS) em transações de varejo ou sistemas de direção totalmente autônoma (FSD) que identificam anomalias visuais em veículos autônomos.</block>
  <block id="36d77288dbd3663ec436c43b32682300" category="paragraph">Este documento abrange testes e validação de uma configuração de computação e armazenamento composta pelo Lenovo ThinkSystem SE350 Edge Server e um sistema de armazenamento NetApp AFF e EF-Series de nível básico.  As arquiteturas de referência fornecem uma solução eficiente e econômica para implantações de IA, ao mesmo tempo em que fornecem serviços de dados abrangentes, proteção de dados integrada, escalabilidade perfeita e armazenamento de dados conectado à nuvem com o software de gerenciamento de dados NetApp ONTAP e NetApp SANtricity .</block>
  <block id="5dd536dd8122d7ba5df3ce642e603305" category="paragraph">Este documento é destinado aos seguintes públicos:</block>
  <block id="ebb25f3a3991f2ad744d7ec643c950fe" category="list-text">Líderes empresariais e arquitetos corporativos que desejam produzir IA na ponta.</block>
  <block id="c19c4b63370004c67b540d52ae4d0ba3" category="list-text">Cientistas de dados, engenheiros de dados, pesquisadores de IA/aprendizado de máquina (ML) e desenvolvedores de sistemas de IA.</block>
  <block id="d64b2d5963d22d2d9c15222cbbe4a41c" category="list-text">Arquitetos corporativos que projetam soluções para o desenvolvimento de modelos e aplicativos de IA/ML.</block>
  <block id="563f47ae807a7a985313a5186e239a5d" category="list-text">Cientistas de dados e engenheiros de IA buscam maneiras eficientes de implantar modelos de aprendizado profundo (DL) e ML.</block>
  <block id="c1df171c3c219ea01c2724d28fa03f93" category="list-text">Gerentes de dispositivos de borda e administradores de servidores de borda responsáveis pela implantação e gerenciamento de modelos de inferência de borda.</block>
  <block id="a40893fa754ed62d5268702b023fea91" category="section-title">Arquitetura da solução</block>
  <block id="cc402abc10a0191493024c4510783afc" category="paragraph">Este servidor Lenovo ThinkSystem e a solução de armazenamento NetApp ONTAP ou NetApp SANtricity foram projetados para lidar com inferência de IA em grandes conjuntos de dados usando o poder de processamento de GPUs junto com CPUs tradicionais.  Esta validação demonstra alto desempenho e gerenciamento de dados ideal com uma arquitetura que usa um ou vários servidores de borda Lenovo SR350 interconectados com um único sistema de armazenamento NetApp AFF , conforme mostrado nas duas figuras a seguir.</block>
  <block id="f21cce3e60a01cff1e8e221c6536fe78" category="paragraph"><block ref="f21cce3e60a01cff1e8e221c6536fe78" category="inline-image-macro-rx" type="image"></block></block>
  <block id="94aa1b43a547a9dd2c4d023dbc98322b" category="paragraph"><block ref="94aa1b43a547a9dd2c4d023dbc98322b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa68c0f0557e1b1d9b151c9be9aae26a" category="paragraph">A visão geral da arquitetura lógica na figura a seguir mostra as funções dos elementos de computação e armazenamento nesta arquitetura.  Especificamente, ele mostra o seguinte:</block>
  <block id="f2e5640bc98f623bd0a257e3088ead2c" category="list-text">Dispositivos de computação de ponta que realizam inferências nos dados recebidos de câmeras, sensores e assim por diante.</block>
  <block id="ba8dee772ce5a627767af000b8bbb826" category="list-text">Um elemento de armazenamento compartilhado que atende a vários propósitos:</block>
  <block id="8a1d15a179258733a83884fac2d16e38" category="list-text">Fornece um local central para modelos de inferência e outros dados necessários para realizar a inferência.  Os servidores de computação acessam o armazenamento diretamente e usam modelos de inferência na rede sem a necessidade de copiá-los localmente.</block>
  <block id="6c20432374a9a40cfb818250edf55367" category="list-text">Modelos atualizados são enviados aqui.</block>
  <block id="4a32229da6d6fceda48d909ad92a952a" category="list-text">Arquiva dados de entrada que os servidores de borda recebem para análise posterior.  Por exemplo, se os dispositivos de borda estiverem conectados a câmeras, o elemento de armazenamento mantém os vídeos capturados pelas câmeras.</block>
  <block id="3c5974fb92ca4b40257a58c213d0f137" category="paragraph"><block ref="3c5974fb92ca4b40257a58c213d0f137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bda9643ac6601722a28f238714274da4" category="cell">vermelho</block>
  <block id="48d6215903dff56238e52e8891380c8f" category="cell">azul</block>
  <block id="95e6ac9e87f07caf580a7b83adb1526b" category="cell">Sistema de computação Lenovo</block>
  <block id="81a15d59c420e43b55830213cc8c16b9" category="cell">Sistema de armazenamento NetApp AFF</block>
  <block id="f46e4977aa2e9918471e011cafc5cbe1" category="cell">Dispositivos de borda que realizam inferências em entradas de câmeras, sensores e assim por diante.</block>
  <block id="edb1af4b83edf30ec5e56e3f4a6352f3" category="cell">Armazenamento compartilhado contendo modelos de inferência e dados de dispositivos de ponta para análise posterior.</block>
  <block id="6fa1f5494d341a20c6c746a33cbb31b3" category="paragraph">Esta solução da NetApp e da Lenovo oferece os seguintes benefícios principais:</block>
  <block id="f1bd3fc2711f634964362fb2a96445bf" category="list-text">Computação acelerada por GPU na borda.</block>
  <block id="a644cc245485a603217667e7cbdb7ef9" category="list-text">Implantação de vários servidores de borda apoiados e gerenciados a partir de um armazenamento compartilhado.</block>
  <block id="d649f2b00c65fe4953b1a7e7469c9431" category="list-text">Proteção de dados robusta para atender a objetivos de baixo ponto de recuperação (RPOs) e objetivos de tempo de recuperação (RTOs) sem perda de dados.</block>
  <block id="2d0fcf5abf2f152f10ecfbf80a62e9db" category="list-text">Gerenciamento de dados otimizado com cópias e clones do NetApp Snapshot para simplificar os fluxos de trabalho de desenvolvimento.</block>
  <block id="94d9a1cd726b8a3fed2b6beb07904959" category="section-title">Como usar esta arquitetura</block>
  <block id="9a22eb3c4ef782aa04a39e5ad3ffc8b5" category="paragraph">Este documento valida o design e o desempenho da arquitetura proposta.  No entanto, não testamos certos componentes de nível de software, como gerenciamento de contêiner, carga de trabalho ou modelo e sincronização de dados com nuvem ou data center local, porque eles são específicos para um cenário de implantação.  Aqui, existem várias escolhas.</block>
  <block id="543ca2d3d9aa63e1a63c69dd219d5f2a" category="inline-link-macro">Plano de controle de IA da NetApp</block>
  <block id="bfbeeaf5d09672568692829ade4ca556" category="paragraph">No nível de gerenciamento de contêineres, o gerenciamento de contêineres do Kubernetes é uma boa escolha e tem bom suporte em uma versão totalmente upstream (Canonical) ou em uma versão modificada adequada para implantações corporativas (Red Hat).  O<block ref="cba35aa1f9d4aeed351c50bd57559a4d" category="inline-link-macro-rx"></block> que usa o NetApp Trident e o recém-adicionado<block ref="18f9f1b3975974bec435249b1752c2d6" category="inline-link-rx"></block> fornece rastreabilidade integrada, funções de gerenciamento de dados, interfaces e ferramentas para cientistas e engenheiros de dados integrarem com o armazenamento NetApp .  O Kubeflow, o kit de ferramentas de ML para Kubernetes, fornece recursos adicionais de IA, além de suporte para controle de versão de modelo e KFServing em diversas plataformas, como TensorFlow Serving ou NVIDIA Triton Inference Server.  Outra opção é a plataforma NVIDIA EGX, que fornece gerenciamento de carga de trabalho juntamente com acesso a um catálogo de contêineres de inferência de IA habilitados para GPU.  No entanto, essas opções podem exigir esforço e experiência significativos para colocá-las em produção e podem exigir a assistência de um fornecedor de software independente (ISV) ou consultor.</block>
  <block id="1a667cf8dc2ace931f29baf9aeed69d9" category="section-title">Áreas de solução</block>
  <block id="560d585bccd63f1ccf34b07b325adbcd" category="paragraph">O principal benefício da inferência de IA e da computação de ponta é a capacidade dos dispositivos de calcular, processar e analisar dados com um alto nível de qualidade sem latência.  Há muitos exemplos de casos de uso de computação de ponta para descrever neste documento, mas aqui estão alguns dos principais:</block>
  <block id="8106f228c3a2b774c2e47d0d2ca766eb" category="section-title">Automóveis: Veículos autônomos</block>
  <block id="49f3cb6fe79fc77d0b151dcc2f7d7109" category="paragraph">A ilustração clássica da computação de ponta está nos sistemas avançados de assistência ao motorista (ADAS) em veículos autônomos (VA).  A IA em carros autônomos deve processar rapidamente uma grande quantidade de dados de câmeras e sensores para ser um motorista seguro e bem-sucedido.  Demorar muito para interpretar a comunicação entre um objeto e um humano pode significar vida ou morte. Portanto, conseguir processar esses dados o mais próximo possível do veículo é crucial.  Nesse caso, um ou mais servidores de computação de ponta manipulam a entrada de câmeras, RADAR, LiDAR e outros sensores, enquanto o armazenamento compartilhado mantém modelos de inferência e armazena dados de entrada de sensores.</block>
  <block id="e5e51dcd521792cb797e6e3c53736987" category="section-title">Assistência médica: Monitoramento de pacientes</block>
  <block id="bace962401fe7f588dcfdc4444fa9cfd" category="paragraph">Um dos maiores impactos da IA e da computação de ponta é sua capacidade de melhorar o monitoramento contínuo de pacientes com doenças crônicas, tanto em cuidados domiciliares quanto em unidades de terapia intensiva (UTIs).  Dados de dispositivos de ponta que monitoram níveis de insulina, respiração, atividade neurológica, ritmo cardíaco e funções gastrointestinais exigem análise instantânea de dados que devem ser acionados imediatamente porque há tempo limitado para agir e salvar a vida de alguém.</block>
  <block id="7e4b8a4224f71143d7bd188ceeea4acd" category="section-title">Varejo: Pagamento sem caixa</block>
  <block id="a8712e81fee7af830aa2cd6466cfb339" category="paragraph">A computação de ponta pode impulsionar IA e ML para ajudar os varejistas a reduzir o tempo de checkout e aumentar o tráfego de pedestres.  Os sistemas sem caixa oferecem suporte a vários componentes, como os seguintes:</block>
  <block id="dbc0817910529140e6894b79ec51b412" category="list-text">Autenticação e acesso.  Conectar o comprador físico a uma conta validada e permitir acesso ao espaço de varejo.</block>
  <block id="349a2650c71706ec201ef08d57dc58e7" category="list-text">Monitoramento de estoque.  Usando sensores, etiquetas RFID e sistemas de visão computacional para ajudar a confirmar a seleção ou desmarcação de itens pelos compradores.</block>
  <block id="86f5df5b4d7496a74d1d41bed2929983" category="paragraph">Aqui, cada um dos servidores de borda gerencia cada caixa de pagamento e o sistema de armazenamento compartilhado serve como um ponto central de sincronização.</block>
  <block id="498375fc1d2fd41616385f8abfd37893" category="section-title">Serviços financeiros: Segurança humana em quiosques e prevenção de fraudes</block>
  <block id="1dd0f8c70693faa846f69d76af9ffbf7" category="paragraph">As organizações bancárias estão usando IA e computação de ponta para inovar e criar experiências bancárias personalizadas.  Quiosques interativos que usam análise de dados em tempo real e inferência de IA agora permitem que caixas eletrônicos não apenas ajudem os clientes a sacar dinheiro, mas monitorem proativamente os quiosques por meio de imagens capturadas por câmeras para identificar riscos à segurança humana ou comportamento fraudulento.  Nesse cenário, servidores de computação de ponta e sistemas de armazenamento compartilhado são conectados a quiosques e câmeras interativos para ajudar os bancos a coletar e processar dados com modelos de inferência de IA.</block>
  <block id="0014200d8a9f4fe7a8b65ae923557be6" category="section-title">Manufatura: Indústria 4.0</block>
  <block id="18bfb27ab22a9db6eb932a3bfe5f51a4" category="paragraph">A quarta revolução industrial (Indústria 4.0) começou, junto com tendências emergentes como Fábrica Inteligente e impressão 3D.  Para se preparar para um futuro orientado por dados, a comunicação máquina a máquina (M2M) em larga escala e a IoT são integradas para maior automação sem a necessidade de intervenção humana.  A manufatura já é altamente automatizada e adicionar recursos de IA é uma continuação natural da tendência de longo prazo.  A IA permite automatizar operações que podem ser automatizadas com a ajuda da visão computacional e outros recursos de IA.  Você pode automatizar o controle de qualidade ou tarefas que dependem da visão humana ou da tomada de decisões para executar análises mais rápidas de materiais em linhas de montagem em fábricas para ajudar as fábricas a atender aos padrões ISO exigidos de segurança e gestão de qualidade.  Aqui, cada servidor de borda de computação é conectado a uma série de sensores que monitoram o processo de fabricação e modelos de inferência atualizados são enviados ao armazenamento compartilhado, conforme necessário.</block>
  <block id="a2df8c6c694bb6d9b42851d95a6d7814" category="section-title">Telecomunicações: Detecção de ferrugem, inspeção de torres e otimização de rede</block>
  <block id="d562d0e475687af21d44b6ea803c10a8" category="paragraph">O setor de telecomunicações usa técnicas de visão computacional e IA para processar imagens que detectam automaticamente ferrugem e identificam torres de celular que contêm corrosão e, portanto, exigem inspeção mais aprofundada.  O uso de imagens de drones e modelos de IA para identificar regiões distintas de uma torre para analisar ferrugem, rachaduras superficiais e corrosão aumentou nos últimos anos.  A demanda continua crescendo por tecnologias de IA que permitam que a infraestrutura de telecomunicações e torres de celular sejam inspecionadas com eficiência, avaliadas regularmente quanto à degradação e reparadas prontamente quando necessário.</block>
  <block id="d88e40cd850f8bd6b5e737761a1786fd" category="paragraph">Além disso, outro caso de uso emergente em telecomunicações é o uso de algoritmos de IA e ML para prever padrões de tráfego de dados, detectar dispositivos compatíveis com 5G e automatizar e aumentar o gerenciamento de energia de múltiplas entradas e saídas (MIMO).  O hardware MIMO é usado em torres de rádio para aumentar a capacidade da rede; no entanto, isso acarreta custos adicionais de energia.  Modelos de ML para "modo de espera MIMO" implantados em estações de rádio podem prever o uso eficiente de rádios e ajudar a reduzir os custos de consumo de energia para operadoras de redes móveis (MNOs).  As soluções de inferência de IA e computação de ponta ajudam as MNOs a reduzir a quantidade de dados transmitidos de um lado para o outro entre os data centers, diminuir seu TCO, otimizar as operações de rede e melhorar o desempenho geral para os usuários finais.</block>
  <block id="228af426af79aabaa0b969d8cee05002" category="summary">Este documento segue o código e as regras do MLPerf Inference v0.7, do MLPerf Inference v1.1.  Executamos benchmarks projetados para inferência na borda, conforme definido nas tabelas apresentadas nesta seção.</block>
  <block id="b3e6ac4f3c523ea5a90f4f79ca3e585d" category="doc">Plano de teste</block>
  <block id="c13367945d5d4c91047b3b50234aa7ab" category="inline-link">código</block>
  <block id="a4f86f7bfc24194b276c22e0ef158197" category="inline-link">regras</block>
  <block id="eb190159f20d63d1c7687ecafd03fc73" category="paragraph">Este documento segue o MLPerf Inference v0.7<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block> , Inferência MLPerf v1.1<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block> , e<block ref="efc21f34f290528320a21a8cc99ffcfc" category="inline-link-rx"></block> .  Executamos benchmarks MLPerf projetados para inferência na borda, conforme definido na tabela a seguir.</block>
  <block id="deec4ff19974f12ed781cb9a59064214" category="cell">Área</block>
  <block id="a559b87068921eec05086ce5485e9784" category="cell">Modelo</block>
  <block id="239658e016e3d5d06ae719d280a79fec" category="cell">Conjunto de dados</block>
  <block id="e110cde47b67924ec0ef64500e8cb067" category="cell">Tamanho QSL</block>
  <block id="571094bb27864b600d8e6b561a137a55" category="cell">Qualidade</block>
  <block id="77f086368f7402e03b21bb823cda2eb3" category="cell">Restrição de latência multistream</block>
  <block id="99a0628d9f7179c032e0cf59efbc0fad" category="cell">Visão</block>
  <block id="c84e3388f5bc3e4ce028dc81625bf819" category="cell">Classificação de imagens</block>
  <block id="4cf67db3abdf54de6064fce40cf27398" category="cell">Resnet50v1.5</block>
  <block id="05e96e35d2778a07f18ff8b414821ee8" category="cell">ImageNet (224x224)</block>
  <block id="021bbc7ee20b71134d53e20206bd6feb" category="cell">1024</block>
  <block id="79267804a18aa7217c234994e26bb5c7" category="cell">99% do FP32</block>
  <block id="c2010c9d1312ce345a2313d3acb5c6d5" category="cell">50 ms</block>
  <block id="5d9387d7bf46f8c6854a5caafd6cfbf3" category="cell">Detecção de objetos (grandes)</block>
  <block id="7dd82182395c2720676a1e82b781ef04" category="cell">SSD- ResNet34</block>
  <block id="0505dc2363120e454308e12e47f6d354" category="cell">COCO (1200x1200)</block>
  <block id="ea5d2f1c4608232e07d3aa3d998e5135" category="cell">64</block>
  <block id="f336aeb0ea3de7c70100c292338460e3" category="cell">66 ms</block>
  <block id="a3e1c35debe58b3684abba30911eb0f9" category="cell">Detecção de objetos (pequenos)</block>
  <block id="d05a0b1a6c857a559314f24c10825416" category="cell">SSD- MobileNetsv1</block>
  <block id="f471fd17e298022a58bcbd05aa25a819" category="cell">COCO (300x300)</block>
  <block id="f718499c1c8cef6730f9fd03c8125cab" category="cell">256</block>
  <block id="ed076605284997250d9cc771eedbfc61" category="cell">Segmentação de imagens médicas</block>
  <block id="b8ffefa5ddac895023e8ab6fe1b55b45" category="cell">3D UNET</block>
  <block id="5ea5e4840c21271f42762e8b9271527a" category="cell">BraTS 2019 (224x224x160)</block>
  <block id="c74d97b01eae257e44aa9d5bade97baf" category="cell">16</block>
  <block id="8322d3768dee2653e9cc15c955ee60a8" category="cell">99% e 99,9% do FP32</block>
  <block id="04a83927cfa1af6ae14f94e90aab9ebb" category="cell">Discurso</block>
  <block id="ade9e8d743e7e78d87c5c5603b0aa4ae" category="cell">Conversão de fala em texto</block>
  <block id="69ee0ff6f427bb2dfd286a55bbc181ea" category="cell">RNNT</block>
  <block id="d3c7d61f6e8ea0b76fd8b65e5115b28b" category="cell">Librispeech dev-clean</block>
  <block id="84b20b1f5a0d103f5710bb67a043cd78" category="cell">2513</block>
  <block id="4994a8ffeba4ac3140beb89e8d41f174" category="cell">Linguagem</block>
  <block id="f8672b43ad1f9d3531557d69b6da380c" category="cell">Processamento de linguagem</block>
  <block id="f50c0cca078c7426bed1eb196911c809" category="cell">Esquadrão v1.1</block>
  <block id="d56da061d55e2175bd67901d5f0948be" category="cell">10833</block>
  <block id="816720c0b642aa1eef01c4f9108f54c5" category="paragraph">A tabela a seguir apresenta cenários de benchmark do Edge.</block>
  <block id="85051346c766b4444af7bfaaa0c189f5" category="cell">Cenários</block>
  <block id="4bb9c2b62dbc9558da74af948130693b" category="cell">Classificação de imagens</block>
  <block id="d5348bf8d0ff8e72043bdbb08aef9767" category="cell">Transmissão única, offline, multitransmissão</block>
  <block id="468acb809a41b49bb7fcdf7425dcd7ee" category="cell">Transmissão única, offline</block>
  <block id="3d1aa46be43bf2f29633e829d42082af" category="cell">Conversão de fala em texto</block>
  <block id="7966e67de4ba20fb5412257b4023f4d1" category="paragraph">Realizamos esses benchmarks usando a arquitetura de armazenamento em rede desenvolvida nesta validação e comparamos os resultados com aqueles de execuções locais nos servidores de borda enviados anteriormente ao MLPerf.  A comparação serve para determinar quanto impacto o armazenamento compartilhado tem no desempenho da inferência.</block>
  <block id="b481424c052310e67a9b67a931165509" category="summary">Esta seção descreve os procedimentos de teste usados para validar esta solução.</block>
  <block id="3562305aa864cd56d3e2840eb5071caa" category="doc">Procedimento de teste</block>
  <block id="1b0981f820949c10d68daad3fdf03976" category="section-title">Configuração do sistema operacional e inferência de IA</block>
  <block id="fe03e7fb4a8d3a1afb24c94c4c88d32f" category="paragraph">Para o AFF C190, usamos o Ubuntu 18.04 com drivers NVIDIA e docker com suporte para GPUs NVIDIA e usamos o MLPerf<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block> disponível como parte do envio da Lenovo para o MLPerf Inference v0.7.</block>
  <block id="504812acf44740b8f536a0d166375734" category="paragraph">Para o EF280, usamos o Ubuntu 20.04 com drivers NVIDIA e docker com suporte para GPUs NVIDIA e MLPerf<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block> disponível como parte do envio da Lenovo para o MLPerf Inference v1.1.</block>
  <block id="fbd2228a821a8ab1948d4a8c3121fb0e" category="paragraph">Para configurar a inferência de IA, siga estas etapas:</block>
  <block id="9177ba75c6dc50d818c52360f10e2fe1" category="list-text">Baixe os conjuntos de dados que exigem registro, o conjunto de validação ImageNet 2012, o conjunto de dados Criteo Terabyte e o conjunto de treinamento BraTS 2019 e, em seguida, descompacte os arquivos.</block>
  <block id="12dda17fb1d76556387dceb2e85a9290" category="list-text">Crie um diretório de trabalho com pelo menos 1 TB e defina a variável de ambiente<block ref="597c05a331d3bca9b42845049a851c94" prefix=" " category="inline-code"></block> referindo-se ao diretório.</block>
  <block id="342ecacc441a9548b60eae46065039f8" category="paragraph">Você deve compartilhar esse diretório no armazenamento compartilhado para o caso de uso de armazenamento de rede ou no disco local ao testar com dados locais.</block>
  <block id="7c5f7553ff57e0548889000668d1cf39" category="list-text">Execute a criação<block ref="ba8a3d8e03d727387e03ca6ef842d4c5" prefix=" " category="inline-code"></block> comando, que cria e inicia o contêiner docker para as tarefas de inferência necessárias.</block>
  <block id="9cfc451dfe052c5c3835b0355375b1b7" category="admonition">Os comandos a seguir são todos executados de dentro do contêiner docker em execução:</block>
  <block id="b25e1e6ba392fe4c0e0da7617a67fa4d" category="list-text">Baixe modelos de IA pré-treinados para tarefas de inferência MLPerf:<block ref="b59a4beb5c95f2e0e1fed56d89e16cf0" prefix=" " category="inline-code"></block></block>
  <block id="ed43016366915f1fc65fe332de60965f" category="list-text">Baixe conjuntos de dados adicionais que podem ser baixados gratuitamente:<block ref="fd0245b042cdcee1ab8bd760c8b4bfbc" prefix=" " category="inline-code"></block></block>
  <block id="41165a10471c0644aef30b976f113946" category="list-text">Pré-processar os dados: fazer<block ref="03275934d57d2ecfe9e68f7023f456ce" prefix=" " category="inline-code"></block></block>
  <block id="f0bacb5df46d2e8bed3d6d0d863fce01" category="list-text">Correr:<block ref="be647e69451a82a2f326980291e0f781" prefix=" " category="inline-code"></block> .</block>
  <block id="189eed4566c6894d64b4d4f8bc9df94c" category="list-text">Crie mecanismos de inferência otimizados para GPU em servidores de computação:<block ref="37496efe33254cb883b0705fde55fcc1" prefix=" " category="inline-code"></block></block>
  <block id="4efea18a74f8c5a6fa0f4b239ff2d734" category="list-text">Para executar cargas de trabalho de inferência, execute o seguinte (um comando):</block>
  <block id="9ce2624cb32bec75a2ad4e276fa594f6" category="section-title">Execuções de inferência de IA</block>
  <block id="2a71d3fa50a14f6fa9c62d9fe3935d5d" category="paragraph">Três tipos de execuções foram executadas:</block>
  <block id="3a4a320ee019614122e99baebf056b86" category="list-text">Inferência de IA de servidor único usando armazenamento local</block>
  <block id="adf25fe660bba733a104887732393fdd" category="list-text">Inferência de IA de servidor único usando armazenamento de rede</block>
  <block id="34e4c32e4097a70208139be85d5dc892" category="list-text">Inferência de IA multiservidor usando armazenamento de rede</block>
  <block id="8708911de20cfce9bafb315fd0cde0a2" category="summary">Uma infinidade de testes foram executados para avaliar o desempenho da arquitetura proposta.  Há seis cargas de trabalho diferentes (classificação de imagens, detecção de objetos [pequenos], detecção de objetos [grandes], imagens médicas, conversão de fala em texto e processamento de linguagem natural [PLN]), que você pode executar em três cenários diferentes: offline, fluxo único e multifluxo.</block>
  <block id="3274a50ba9f0d3c0adefdfa11c5094be" category="doc">Resultados dos testes</block>
  <block id="a274daca2deace9b89099b24f248715c" category="paragraph">Uma infinidade de testes foram executados para avaliar o desempenho da arquitetura proposta.</block>
  <block id="37bf74d7f686cd395d40af1cc2ed7c55" category="paragraph">Há seis cargas de trabalho diferentes (classificação de imagens, detecção de objetos [pequenos], detecção de objetos [grandes], imagens médicas, conversão de fala em texto e processamento de linguagem natural [PLN]), que você pode executar em três cenários diferentes: offline, fluxo único e multifluxo.</block>
  <block id="aaabb57453387e4d8fdae92cdf5d558b" category="admonition">O último cenário é implementado apenas para classificação de imagens e detecção de objetos.</block>
  <block id="e7b8f9d880e5e20f44e5277ba99d101b" category="paragraph">Isso resulta em 15 cargas de trabalho possíveis, todas testadas em três configurações diferentes:</block>
  <block id="6beb824a1e58582d2c0c733600244087" category="list-text">Servidor único/armazenamento local</block>
  <block id="0ce03975d1039901bae5d17f67b2ac39" category="list-text">Servidor único/armazenamento em rede</block>
  <block id="ffac1c611ceb8a0bd6268359872e3e68" category="list-text">Armazenamento multi-servidor/rede</block>
  <block id="f5b98cda08f17c4b221c6ef2fbf7217f" category="paragraph">Os resultados são descritos nas seções a seguir.</block>
  <block id="18d566b8a783b6684a78fc2924714180" category="section-title">Inferência de IA em cenário offline para AFF</block>
  <block id="0aee493b887954641c1ba2e779adcf85" category="paragraph">Neste cenário, todos os dados estavam disponíveis no servidor e o tempo necessário para processar todas as amostras foi medido.  Relatamos larguras de banda em amostras por segundo como resultados dos testes.  Quando mais de um servidor de computação foi usado, relatamos a largura de banda total somada em todos os servidores.  Os resultados para todos os três casos de uso são mostrados na figura abaixo.  Para o caso de dois servidores, relatamos a largura de banda combinada de ambos os servidores.</block>
  <block id="50c1d1baa999e0997ecc5b2fb7ce848c" category="paragraph"><block ref="50c1d1baa999e0997ecc5b2fb7ce848c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0d89c8c627ec0463d3f82a6cbbc04bd" category="paragraph">Os resultados mostram que o armazenamento em rede não afeta negativamente o desempenho — a alteração é mínima e, para algumas tarefas, nenhuma é encontrada.  Ao adicionar o segundo servidor, a largura de banda total dobra exatamente ou, na pior das hipóteses, a alteração é inferior a 1%.</block>
  <block id="d0be2e7e62dc4b0bdbb35ded9b6d842e" category="section-title">Inferência de IA em um cenário de fluxo único para AFF</block>
  <block id="fbbf5a4ee90b9175f00f7c8cab5a0670" category="paragraph">Este benchmark mede a latência.  Para o caso de múltiplos servidores computacionais, relatamos a latência média.  Os resultados para o conjunto de tarefas são apresentados na figura abaixo.  Para o caso de dois servidores, relatamos a latência média de ambos os servidores.</block>
  <block id="e3a127ece515b351ac983cdc09f48eb3" category="paragraph"><block ref="e3a127ece515b351ac983cdc09f48eb3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ef9ced66e0746938556409b4c473052" category="paragraph">Os resultados, mais uma vez, mostram que o armazenamento em rede é suficiente para lidar com as tarefas.  A diferença entre armazenamento local e de rede no caso de um servidor é mínima ou nenhuma.  Da mesma forma, quando dois servidores usam o mesmo armazenamento, a latência em ambos os servidores permanece a mesma ou muda em uma quantidade muito pequena.</block>
  <block id="64a84459b695510c92164965941ad8f1" category="section-title">Inferência de IA em cenário multistream para AFF</block>
  <block id="22ca0fa830d8fd46fe137f6748374c21" category="paragraph">Nesse caso, o resultado é o número de fluxos que o sistema pode manipular, satisfazendo a restrição de QoS.  Portanto, o resultado é sempre um número inteiro.  Para mais de um servidor, relatamos o número total de fluxos somados em todos os servidores.  Nem todas as cargas de trabalho suportam esse cenário, mas executamos aquelas que o fazem. Os resultados dos nossos testes estão resumidos na figura abaixo.  Para o caso de dois servidores, relatamos o número combinado de fluxos de ambos os servidores.</block>
  <block id="79bd7075b14462178ff1e836cefd5d04" category="paragraph"><block ref="79bd7075b14462178ff1e836cefd5d04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3eefb9cc4232b7df67a3c63566ae707" category="paragraph">Os resultados mostram o desempenho perfeito da configuração: o armazenamento local e de rede fornecem os mesmos resultados e adicionar o segundo servidor dobra o número de fluxos que a configuração proposta pode manipular.</block>
  <block id="4ecb5ff41d7f3bd6f1c92bc183f1cb32" category="section-title">Resultados dos testes para EF</block>
  <block id="ee7c693721c881b091fdb1adf8a37707" category="paragraph">Uma infinidade de testes foram executados para avaliar o desempenho da arquitetura proposta.  Há seis cargas de trabalho diferentes (classificação de imagens, detecção de objetos [pequenos], detecção de objetos [grandes], imagens médicas, conversão de fala em texto e processamento de linguagem natural [PLN]), que foram executadas em dois cenários diferentes: offline e fluxo único.  Os resultados são descritos nas seções a seguir.</block>
  <block id="010bb9776a194ae73e567f4812c8be99" category="section-title">Inferência de IA em cenário offline para EF</block>
  <block id="f4fc0d2711e472dedfd5d2952191989c" category="paragraph">Neste cenário, todos os dados estavam disponíveis no servidor e o tempo necessário para processar todas as amostras foi medido.  Relatamos larguras de banda em amostras por segundo como resultados dos testes.  Para execuções de nó único, relatamos a média de ambos os servidores, enquanto para execuções de dois servidores, relatamos a largura de banda total somada em todos os servidores.  Os resultados para os casos de uso são mostrados na figura abaixo.</block>
  <block id="063dd3a1aadafc5ef1c52be7451bda1d" category="paragraph"><block ref="063dd3a1aadafc5ef1c52be7451bda1d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb71ae4a7513a21f0771b9aa65aeef9c" category="section-title">Inferência de IA em um cenário de fluxo único para EF</block>
  <block id="ca0aa5c3a448e511d9334d94174b8b85" category="paragraph">Este benchmark mede a latência.  Para todos os casos, relatamos a latência média em todos os servidores envolvidos nas execuções.  Os resultados para o conjunto de tarefas são fornecidos.</block>
  <block id="bcd5a75126c6cafd37838b2f3c6e138b" category="paragraph"><block ref="bcd5a75126c6cafd37838b2f3c6e138b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f02eaec2bc90de6689765cffde92e809" category="paragraph">Os resultados mostram novamente que o armazenamento de rede é suficiente para lidar com as tarefas.  A diferença entre o armazenamento local e o de rede no caso de um servidor é mínima ou nenhuma.  Da mesma forma, quando dois servidores usam o mesmo armazenamento, a latência em ambos os servidores permanece a mesma ou muda em uma quantidade muito pequena.</block>
  <block id="354967c7509f48d7d8a6d2845803bfbc" category="summary">Você pode ajustar a configuração usada para a validação para se adequar a outros casos de uso.</block>
  <block id="c4236be1a211aab0c15476d08b3e7e0c" category="doc">Opções de dimensionamento de arquitetura</block>
  <block id="9d8c4ebebb4b789e6ec48dda7ac54406" category="section-title">Servidor de computação</block>
  <block id="1b3bfec82c01730e4379631c5f74db2d" category="paragraph">Usamos uma CPU Intel Xeon D-2123IT, que é o nível mais baixo de CPU suportado no SE350, com quatro núcleos físicos e TDP de 60 W.  Embora o servidor não suporte a substituição de CPUs, ele pode ser encomendado com uma CPU mais potente.  A CPU mais suportada é o Intel Xeon D-2183IT com 16 núcleos, 100 W e rodando a 2,20 GHz.  Isso aumenta consideravelmente a capacidade computacional da CPU.  Embora a CPU não tenha sido um gargalo para executar as cargas de trabalho de inferência em si, ela ajuda no processamento de dados e outras tarefas relacionadas à inferência.  Atualmente, a NVIDIA T4 é a única GPU disponível para casos de uso de ponta; portanto, atualmente, não há possibilidade de atualizar ou fazer downgrade da GPU.</block>
  <block id="928fe421f0c735b90f3b3ec353741235" category="section-title">Armazenamento compartilhado</block>
  <block id="ba49c21e7aa335a8ea452042c02f306a" category="paragraph">Para testes e validação, o sistema NetApp AFF C190 , que tem capacidade máxima de armazenamento de 50,5 TB, uma taxa de transferência de 4,4 GBps para leituras sequenciais e 230 mil IOPS para pequenas leituras aleatórias, foi usado para os fins deste documento e comprovadamente é adequado para cargas de trabalho de inferência de ponta.</block>
  <block id="44114b1635cead15f56735bad0467251" category="inline-link">NetApp EF300</block>
  <block id="043774815e3806ded716086e0c8c3d03" category="paragraph">No entanto, se você precisar de mais capacidade de armazenamento ou velocidades de rede mais rápidas, use os sistemas de armazenamento NetApp AFF A220 ou NetApp AFF A250 .  Além disso, o sistema NetApp EF280, que tem capacidade máxima de 1,5 PB e largura de banda de 10 GBps, também foi utilizado para fins de validação desta solução.  Se você preferir mais capacidade de armazenamento com maior largura de banda,<block ref="ab4f2e0c1e56faa457a7a1f93253a647" category="inline-link-rx"></block> pode ser usado.</block>
  <block id="6c2749dd86f49cdb85fde6976a317e4b" category="summary">Esta seção descreve a base tecnológica para esta solução de IA.</block>
  <block id="b2412d3528eff2c1e191154bf1ecfd60" category="section-title">Sistemas NetApp AFF</block>
  <block id="b7bec75e06d57a8576b1ec632131ea53" category="paragraph">Os sistemas de armazenamento NetApp AFF de última geração permitem implantações de inferência de IA na borda para atender aos requisitos de armazenamento empresarial com desempenho líder do setor, flexibilidade superior, integração em nuvem e o melhor gerenciamento de dados da categoria.  Projetados especificamente para flash, os sistemas NetApp AFF ajudam a acelerar, gerenciar e proteger dados essenciais aos negócios.</block>
  <block id="45f242ad7738d4805c03311378260bbf" category="list-text">Os sistemas de armazenamento NetApp AFF de nível básico são baseados em hardware FAS2750 e mídia flash SSD</block>
  <block id="d308392edcd4d2f839897b51e24cf6f6" category="list-text">Dois controladores em configuração HA</block>
  <block id="b2ed189fbf328f509ec4ca77960d3e1a" category="paragraph"><block ref="b2ed189fbf328f509ec4ca77960d3e1a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6b0a1e5585dc8095dd546c5930f1a6c" category="paragraph">Os sistemas de armazenamento AFF C190 de nível básico da NetApp oferecem suporte aos seguintes recursos:</block>
  <block id="42087aa1683ece2ea30ab7fa45862cd6" category="list-text">Uma contagem máxima de unidades de 24 SSDs de 960 GB</block>
  <block id="d7123d8583ed65e3090da25ea5aee965" category="list-text">Duas configurações possíveis:</block>
  <block id="35b9fc01c3820062d5969f142bdc5ce5" category="list-text">Ethernet (10GbE): 4 portas 10GBASE-T (RJ-45)</block>
  <block id="f5e2ae88aead451be011eb9f8abfdd6e" category="list-text">Unificado (16 Gb FC ou 10 GbE): 4 portas de adaptador de destino unificado 2 (UTA2)</block>
  <block id="1e927fd215e516034d85785b393b0efb" category="list-text">Capacidade efetiva máxima de 50,5 TB</block>
  <block id="aa9cba7f7b6d2ff8fb2251620a584dcd" category="admonition">Para cargas de trabalho NAS, um único sistema AFF C190 de nível básico oferece suporte a uma taxa de transferência de 4,4 GBps para leituras sequenciais e 230 mil IOPS para pequenas leituras aleatórias em latências de 1 ms ou menos.</block>
  <block id="1672d070f346948fb25e819b40bb3ade" category="section-title">NetApp AFF A220</block>
  <block id="ac7bdd389786fda32ee572c48eef4838" category="paragraph">A NetApp também oferece outros sistemas de armazenamento de nível básico que fornecem maior desempenho e escalabilidade para implantações em larga escala.  Para cargas de trabalho NAS, um único sistema AFF A220 de nível básico suporta:</block>
  <block id="732568c5581337c7341011c38721e2db" category="list-text">Taxa de transferência de 6,2 GBps para leituras sequenciais</block>
  <block id="4900f6d90a4169888690f2c04f3c6603" category="list-text">375K IOPS para pequenas leituras aleatórias em latências de 1 ms ou menos</block>
  <block id="fbcd9d84b2d7be8631cbf7226884f17a" category="list-text">Contagem máxima de unidades de 144 SSDs de 960 GB, 3,8 TB ou 7,6 TB</block>
  <block id="db527e605a2eacc627448a70b8a745db" category="list-text">O AFF A220 pode ser dimensionado para mais de 1 PB de capacidade efetiva</block>
  <block id="25297dbc8df2aecff2fa2e9e47638d35" category="section-title">NetApp AFF A250</block>
  <block id="cac36335022421f12e1c8e999ffeb1af" category="list-text">A capacidade efetiva máxima é de 35 PB com escala máxima de 2 a 24 nós (12 pares de HA)</block>
  <block id="62a23a7791227c5f5e3d068e70759128" category="list-text">Oferece aumento de desempenho ≥ 45% em relação ao AFF A220</block>
  <block id="dc7ac33362f108fc7f4b7d8eb0e2cf4e" category="list-text">440k IOPS de leituras aleatórias a 1 ms</block>
  <block id="0f4615fb8d6105bcb2cbce504f8f091c" category="list-text">Desenvolvido com base na versão mais recente do NetApp ONTAP : ONTAP 9.8</block>
  <block id="440a976974d702d027543e058c1fffc0" category="list-text">Aproveita dois Ethernet de 25 Gb para HA e interconexão de cluster</block>
  <block id="4dc1c0d5a0f0257d8d9e183bc226ab45" category="section-title">Sistemas NetApp E-Series EF</block>
  <block id="f5e23a285b378cde99c2d7fb43586c1b" category="paragraph">A série EF é uma família de matrizes de armazenamento SAN all-flash de nível básico e médio que podem acelerar o acesso aos seus dados e ajudar você a extrair valor deles mais rapidamente com o software NetApp SANtricity .  Esses sistemas oferecem armazenamento flash SAS e NVMe e fornecem IOPS acessíveis a extremos, tempos de resposta abaixo de 100 microssegundos e largura de banda de até 44 GBps, tornando-os ideais para cargas de trabalho mistas e aplicativos exigentes, como inferência de IA e computação de alto desempenho (HPC).</block>
  <block id="96e4797e3006bef737785f8627faae06" category="paragraph">A figura a seguir mostra o sistema de armazenamento NetApp EF280.</block>
  <block id="94bb9af4c6eb62dbf44f691e2565e77e" category="paragraph"><block ref="94bb9af4c6eb62dbf44f691e2565e77e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6f17b7c2ad64f8977585fc43d702abf" category="section-title">NetApp EF280</block>
  <block id="2d6477e98cb834485323c97da975c640" category="list-text">Suporte para FC de 32 Gb/16 Gb, iSCSI de 25 Gb/10 Gb e SAS de 12 Gb</block>
  <block id="d637a0904677ae775d98b9ce0beda3d6" category="list-text">A capacidade efetiva máxima é de 96 unidades totalizando 1,5 PB</block>
  <block id="6f409cb54d8cb27deac8a918fe03f3cc" category="list-text">Taxa de transferência de 10 GBps (leituras sequenciais)</block>
  <block id="7c61b8793dbe5a66cbf144bdabcf76cd" category="list-text">300 mil IOPs (leituras aleatórias)</block>
  <block id="4c5a963973ae3026e92baab2ef522c6c" category="list-text">O NetApp EF280 é o array all-flash (AFA) de menor custo do portfólio da NetApp</block>
  <block id="f1330bea5ad6aa446aa17d0a324bb579" category="list-text">24 unidades SSD NVMe para uma capacidade total de 367 TB</block>
  <block id="6768e0b9e957297070e3822e98a4b8f9" category="list-text">Opções de expansão totalizando 240x HDDs NL-SAS, 96x SSDs SAS ou uma combinação</block>
  <block id="0fa40de31cbd933cc9a954d82204feb9" category="list-text">100 Gb NVMe/IB, NVMe/RoCE, iSER/IB e SRP/IB</block>
  <block id="aee7a4e3788dbbff7166952ed0e2d2c9" category="list-text">32 Gb NVME/FC, FCP</block>
  <block id="c4b9deb88d9cf1b1a2160cb28a2c41ca" category="list-text">iSCSI de 25 Gb</block>
  <block id="03597240f9b0b4a23f3ffdf6e159d6ca" category="list-text">20 GBps (leituras sequenciais)</block>
  <block id="ffe3b3adfe232ee25f1914e7e7d266c4" category="list-text">670 mil IOPs (leituras aleatórias)</block>
  <block id="7105ea3513c2bdae1a0d63a9f0703579" category="inline-link">Folha de dados dos arrays all-flash EF600, F300, EF570 e EF280 da NetApp NetApp -Series</block>
  <block id="6e69804b180359b12a32a56c17c0641e" category="admonition">Para mais informações, consulte o<block ref="5f5484869dc0c271e2b062d172d38bee" category="inline-link-rx"></block> .</block>
  <block id="a5119a6bd0f4d733e0f1f4c10f9d063b" category="section-title">NetApp ONTAP 9</block>
  <block id="b407d5a86fd662f03d5a1615963e0827" category="paragraph">ONTAP 9.8.1, a última geração de software de gerenciamento de armazenamento da NetApp, permite que as empresas modernizem a infraestrutura e façam a transição para um data center pronto para a nuvem.  Aproveitando os recursos de gerenciamento de dados líderes do setor, o ONTAP permite o gerenciamento e a proteção de dados com um único conjunto de ferramentas, independentemente de onde os dados residam.  Você também pode mover dados livremente para onde for necessário: na borda, no núcleo ou na nuvem.  O ONTAP 9.8.1 inclui vários recursos que simplificam o gerenciamento de dados, aceleram e protegem dados críticos e permitem recursos de infraestrutura de última geração em arquiteturas de nuvem híbrida.</block>
  <block id="2e2b24551fd50942c6da57d4f8efdfae" category="paragraph">O gerenciamento de dados é crucial para as operações de TI da empresa, para que recursos apropriados sejam usados para aplicativos e conjuntos de dados.  O ONTAP inclui os seguintes recursos para agilizar e simplificar as operações e reduzir o custo total da operação:</block>
  <block id="4934cd09a8e487be128d2b6321ee3279" category="list-text">*Compactação de dados em linha e desduplicação expandida.*  A compactação de dados reduz o desperdício de espaço dentro dos blocos de armazenamento e a desduplicação aumenta significativamente a capacidade efetiva.  Isso se aplica a dados armazenados localmente e dados em camadas na nuvem.</block>
  <block id="0ddc097c124782f16e8a0a1b014fc2bb" category="list-text">*Qualidade de serviço mínima, máxima e adaptável (AQoS).*  Controles granulares de qualidade de serviço (QoS) ajudam a manter os níveis de desempenho para aplicativos críticos em ambientes altamente compartilhados.</block>
  <block id="0c720f269a89477f24f77f6f027719cc" category="inline-link-macro">TR-4598</block>
  <block id="7920a2957aeb5c70e8ee2fa43c94e741" category="list-text">* NetApp FabricPool.*  Este recurso fornece hierarquização automática de dados frios para opções de armazenamento em nuvem pública e privada, incluindo Amazon Web Services (AWS), Azure e solução de armazenamento NetApp StorageGRID .  Para obter mais informações sobre FabricPool, consulte<block ref="38e4393e170a142db2e52760317ecb7f" category="inline-link-macro-rx"></block> .</block>
  <block id="85e643b872d0d98ec2251220de803a1f" category="paragraph">O ONTAP 9 oferece níveis superiores de desempenho e proteção de dados e estende esses recursos das seguintes maneiras:</block>
  <block id="bfb9fa643243eb975ccd9d158cf97800" category="list-text">*Desempenho e menor latência.*  ONTAP oferece o maior rendimento possível com a menor latência possível.</block>
  <block id="ef9770ee572f97c59254dc0d022afda8" category="list-text">*Proteção de dados.*  O ONTAP fornece recursos integrados de proteção de dados com gerenciamento comum em todas as plataformas.</block>
  <block id="86a12b3dbbf039b371f714a515919535" category="list-text">* Criptografia de volume NetApp (NVE).*  O ONTAP oferece criptografia nativa em nível de volume com suporte para gerenciamento de chaves externo e integrado.</block>
  <block id="b3023c0a4db125fc22f0d6056c6e379d" category="list-text">*Autenticação multilocação e multifator.*  O ONTAP permite o compartilhamento de recursos de infraestrutura com os mais altos níveis de segurança.</block>
  <block id="f9eaef0b2cf89b234c431c18aec36bf3" category="paragraph">O ONTAP 9 ajuda a atender às necessidades empresariais exigentes e em constante mudança com os seguintes recursos:</block>
  <block id="9e98379ad83b5c60933a3437c7fb61c7" category="list-text">*Escalonamento perfeito e operações não disruptivas.*  O ONTAP oferece suporte à adição não disruptiva de capacidade aos controladores existentes e aos clusters escaláveis.  Os clientes podem atualizar para as tecnologias mais recentes, como NVMe e 32Gb FC, sem migrações de dados dispendiosas ou interrupções.</block>
  <block id="7d97721ced74a2279b6645f506722980" category="list-text">*Conexão com a nuvem.*  ONTAP é o software de gerenciamento de armazenamento mais conectado à nuvem, com opções para armazenamento definido por software (ONTAP Select) e instâncias nativas da nuvem (Google Cloud NetApp Volumes) em todas as nuvens públicas.</block>
  <block id="b5dc6026803056308b6bf7007af32a2b" category="list-text">*Integração com aplicações emergentes.*  A ONTAP oferece serviços de dados de nível empresarial para plataformas e aplicativos de última geração, como veículos autônomos, cidades inteligentes e Indústria 4.0, usando a mesma infraestrutura que dá suporte aos aplicativos empresariais existentes.</block>
  <block id="e4872d9c30e978d9408425f0e08882c5" category="section-title">NetApp SANtricity</block>
  <block id="965539211ad2d7bc981e7e954db08850" category="inline-link">Folha de dados do software NetApp E-Series SANtricity</block>
  <block id="568549d316f6f749a07012e522e0bca3" category="paragraph">O NetApp SANtricity foi projetado para oferecer desempenho, confiabilidade e simplicidade líderes do setor para arrays híbridos flash da série E e all-flash da série EF.  Obtenha o máximo desempenho e utilização de seus conjuntos de flash híbrido da série E e de flash total da série EF para aplicações de carga de trabalho pesada, incluindo análise de dados, vigilância por vídeo e backup e recuperação.  Com o SANtricity, ajustes de configuração, manutenção, expansão de capacidade e outras tarefas podem ser concluídas enquanto o armazenamento permanece online.  O SANtricity também oferece proteção de dados superior, monitoramento proativo e segurança certificada, tudo acessível por meio da interface do System Manager fácil de usar e integrada.  Para saber mais, consulte o<block ref="64769f0652e98a060ba5d2cd17320298" category="inline-link-rx"></block> .</block>
  <block id="c4cf91172f1e96366d0dfa38c1167df9" category="section-title">Desempenho otimizado</block>
  <block id="3d615c3559b8d33749ea23cf3a34b759" category="paragraph">O software SANtricity otimizado para desempenho fornece dados — com altos IOPs, alto rendimento e baixa latência — para todos os seus aplicativos de análise de dados, vigilância por vídeo e backup.  Acelere o desempenho de aplicativos de alto IOPS e baixa latência, além de aplicativos de alta largura de banda e alto rendimento.</block>
  <block id="8238dd9365065265be82d79d4dd38a98" category="section-title">Maximize o tempo de atividade</block>
  <block id="28ed557ae8b4ff60f83da71465cbcb9b" category="paragraph">Conclua todas as suas tarefas de gerenciamento enquanto o armazenamento permanece online.  Ajuste configurações, realize manutenção ou expanda a capacidade sem interromper E/S.  Obtenha a melhor confiabilidade da categoria com recursos automatizados, configuração on-line, tecnologia de última geração de pools de discos dinâmicos (DPP) e muito mais.</block>
  <block id="2b34e4806834294a7dd611ad1d7d0308" category="section-title">Fique tranquilo</block>
  <block id="7847b3892c0f355acdb3fe824654e209" category="paragraph">O software SANtricity oferece proteção de dados superior, monitoramento proativo e segurança certificada, tudo por meio da interface do System Manager fácil de usar e pronta para uso.  Simplifique as tarefas de gerenciamento de armazenamento.  Obtenha a flexibilidade necessária para o ajuste avançado de todos os sistemas de armazenamento da Série E.  Gerencie seu sistema NetApp E-Series a qualquer hora e em qualquer lugar.  Nossa interface web pronta para uso simplifica seu fluxo de trabalho de gerenciamento.</block>
  <block id="10f0fa4079121b371145e16713fdbb44" category="inline-link">Trident</block>
  <block id="2758085534b10a85f702f6a61737eefb" category="paragraph"><block ref="d14308042ff124582c531f74c03d90f3" category="inline-link-rx"></block>da NetApp é um orquestrador de armazenamento dinâmico de código aberto para Docker e Kubernetes que simplifica a criação, o gerenciamento e o consumo de armazenamento persistente.  O Trident, um aplicativo nativo do Kubernetes, é executado diretamente em um cluster do Kubernetes.  O Trident permite que os clientes implantem facilmente imagens de contêiner DL no armazenamento NetApp e fornece uma experiência de nível empresarial para implantações de contêineres de IA.  Usuários do Kubernetes (como desenvolvedores de ML e cientistas de dados) podem criar, gerenciar e automatizar a orquestração e a clonagem para aproveitar os recursos avançados de gerenciamento de dados da NetApp , fornecidos pela tecnologia NetApp .</block>
  <block id="9b6334cb865bfb3ae702677852339a38" category="paragraph"><block ref="9f25cf06e22037e38bb7442b4d301b6c" category="inline-link-rx"></block>é um serviço da NetApp para sincronização de dados rápida e segura.  Se você precisa transferir arquivos entre compartilhamentos de arquivos NFS ou SMB locais, NetApp StorageGRID, NetApp ONTAP S3, Google Cloud NetApp Volumes, Azure NetApp Files, Amazon Simple Storage Service (Amazon S3), Amazon Elastic File System (Amazon EFS), Azure Blob, Google Cloud Storage ou IBM Cloud Object Storage, o BlueXP Copy and Sync move os arquivos para onde você precisa de forma rápida e segura.  Após seus dados serem transferidos, eles estarão totalmente disponíveis para uso tanto na origem quanto no destino.  O BlueXP Copy and Sync sincroniza continuamente os dados, com base na sua programação predefinida, movendo apenas os deltas, minimizando assim o tempo e o dinheiro gastos na replicação de dados.  O BlueXP Copy and Sync é uma ferramenta de software como serviço (SaaS) extremamente simples de configurar e usar.  As transferências de dados acionadas pelo BlueXP Copy and Sync são realizadas por corretores de dados.  Você pode implantar os corretores de dados BlueXP Copy and Sync na AWS, Azure, Google Cloud Platform ou no local.</block>
  <block id="8eb0c6a27656d04de6abfc6d24a1a8d5" category="paragraph">Os servidores Lenovo ThinkSystem apresentam hardware, software e serviços inovadores que resolvem os desafios atuais dos clientes e oferecem uma abordagem de design modular, evolutiva e adequada para enfrentar os desafios de amanhã.  Esses servidores capitalizam as melhores tecnologias padrão do setor, aliadas às inovações diferenciadas da Lenovo para fornecer a maior flexibilidade possível em servidores x86.</block>
  <block id="493e1540ce727fb5f465fff015aa4733" category="paragraph">As principais vantagens da implantação de servidores Lenovo ThinkSystem incluem:</block>
  <block id="b7c6c5eb82b90f69eddd06060626e5e3" category="list-text">Projetos modulares e altamente escaláveis para crescer junto com seu negócio</block>
  <block id="c2599c559a0be54b242b8aa3c67325c8" category="list-text">Resiliência líder do setor para economizar horas de inatividade não programada e dispendiosa</block>
  <block id="c57cb88fcbeb47afa8496b8fc32cbf03" category="list-text">Tecnologias de flash rápido para latências mais baixas, tempos de resposta mais rápidos e gerenciamento de dados mais inteligente em tempo real</block>
  <block id="6d72d9a0181555ca86c9562861e47058" category="paragraph">Na área de IA, a Lenovo está adotando uma abordagem prática para ajudar as empresas a entender e adotar os benefícios do ML e da IA para suas cargas de trabalho.  Os clientes da Lenovo podem explorar e avaliar as ofertas de IA da Lenovo nos Centros de Inovação de IA da Lenovo para entender completamente o valor para seu caso de uso específico.  Para melhorar o tempo de retorno do investimento, essa abordagem centrada no cliente oferece aos clientes uma prova de conceito para plataformas de desenvolvimento de soluções prontas para uso e otimizadas para IA.</block>
  <block id="6bf0f92a7340921305982a91f7277085" category="paragraph">A computação de ponta permite que dados de dispositivos IoT sejam analisados na borda da rede antes de serem enviados ao data center ou à nuvem.  O Lenovo ThinkSystem SE350, conforme mostrado na figura abaixo, foi projetado para atender aos requisitos exclusivos de implantação na borda, com foco em flexibilidade, conectividade, segurança e capacidade de gerenciamento remoto em um formato compacto, robusto e ambientalmente seguro.</block>
  <block id="72dd0df190a1bdc8d3043fafdba7122b" category="paragraph">Equipado com o processador Intel Xeon D e a flexibilidade para oferecer suporte à aceleração de cargas de trabalho de IA de ponta, o SE350 foi desenvolvido especificamente para enfrentar o desafio de implantações de servidores em uma variedade de ambientes fora do data center.</block>
  <block id="c45cd4236e9fecc47291c206c4aac70a" category="paragraph"><block ref="c45cd4236e9fecc47291c206c4aac70a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="16bb0d66e42a8bb99cbefc63c53bcfdc" category="paragraph"><block ref="16bb0d66e42a8bb99cbefc63c53bcfdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45c08b3aee1d5fb5dc3447ec1271a853" category="inline-link">Inferência MLPerf v0.7</block>
  <block id="f6922096e43c9e99d2be9d521357ff1c" category="paragraph">O MLPerf é o conjunto de benchmark líder do setor para avaliar o desempenho da IA.  Ele abrange muitas áreas de IA aplicada, incluindo classificação de imagens, detecção de objetos, imagens médicas e processamento de linguagem natural (PLN).  Nesta validação, usamos cargas de trabalho do Inference v0.7, que é a iteração mais recente do MLPerf Inference na conclusão desta validação.  O<block ref="1303efdddf9d8dbc0de31c402aa4ef22" category="inline-link-rx"></block> O pacote inclui quatro novos benchmarks para sistemas de data center e edge:</block>
  <block id="c781a146774780843a929b97004ba720" category="list-text">*BERTO.*  Representação de codificador bidirecional de transformadores (BERT) ajustada para resposta a perguntas usando o conjunto de dados SQuAD.</block>
  <block id="cb93b50c2b2216543a9eee4d9a38b38c" category="list-text">*DLRM.*  O Modelo de Recomendação de Aprendizado Profundo (DLRM) é um modelo de personalização e recomendação treinado para otimizar as taxas de cliques (CTR).</block>
  <block id="16139bb6e8da8fe8f8aaf1e5fb8bde0d" category="list-text">*Rede U 3D.*  A arquitetura 3D U-Net é treinada no conjunto de dados de segmentação de tumores cerebrais (BraTS).</block>
  <block id="5691eec0e5e0ea401478ea67b8168d64" category="list-text">*RNN-T.* O Recurrent Neural Network Transducer (RNN-T) é um modelo de reconhecimento automático de fala (ASR) treinado em um subconjunto do LibriSpeech.  Os resultados e o código da inferência do MLPerf estão disponíveis publicamente e são lançados sob a licença Apache.  O MLPerf Inference tem uma divisão Edge, que suporta os seguintes cenários:</block>
  <block id="e772865569495cb43ba25be1d6eed756" category="list-text">*Fluxo único.*  Este cenário imita sistemas onde a capacidade de resposta é um fator crítico, como consultas de IA offline realizadas em smartphones.  Consultas individuais são enviadas ao sistema e os tempos de resposta são registrados.  A latência do 90º percentil de todas as respostas é relatada como resultado.</block>
  <block id="f9cf7025c2d80af397a9b960974631e2" category="list-text">*Multitransmissão.*  Este benchmark é para sistemas que processam entradas de vários sensores.  Durante o teste, as consultas são enviadas em um intervalo de tempo fixo.  Uma restrição de QoS (latência máxima permitida) é imposta.  O teste relata o número de fluxos que o sistema pode processar enquanto atende à restrição de QoS.</block>
  <block id="78a9abbe3c771a5882830fc8e2a73a8f" category="list-text">*Off-line.*  Este é o cenário mais simples que abrange aplicações de processamento em lote e a métrica é a taxa de transferência em amostras por segundo.  Todos os dados ficam disponíveis para o sistema e o benchmark mede o tempo necessário para processar todas as amostras.</block>
  <block id="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link"><block ref="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link-rx"></block></block>
  <block id="13176cbb826705821e77b735791d29d4" category="paragraph">A Lenovo publicou pontuações de inferência MLPerf para SE350 com T4, o servidor usado neste documento.  Veja os resultados em<block ref="8efc95b379113ebfb6f66010213223ce" category="inline-link-rx"></block> na seção "Edge, Divisão Fechada" na entrada nº 0.7-145.</block>
  <block id="686ebb62ce1be84dcfae0007fb84562d" category="summary">A configuração usada para a validação pode ser ajustada para se adequar a outros casos de uso.</block>
  <block id="bf46169695d75ff844d955af09f33e75" category="doc">Ajustes de arquitetura</block>
  <block id="1cf27bd587c6c632877c322cf42c0d97" category="paragraph">A configuração usada para esta validação pode ser ajustada para se adequar a outros casos de uso.</block>
  <block id="a752efb5fb2512dc99b2045f032779f7" category="section-title">Ajustes de CPU</block>
  <block id="122acc941b98ef5a11208d23ed0a8090" category="paragraph">Usamos um processador Skylake Intel Xeon Platinum 8360Y para esta validação, conforme recomendado pela Lenovo.  Esperamos que a CPU Cascade Lake equivalente, um processador Intel Xeon Gold 6330, ofereça desempenho semelhante porque essa carga de trabalho não é limitada pela CPU.</block>
  <block id="3cc37c167d58a1828b00c13cc6018ae8" category="section-title">Aumento da capacidade de armazenamento</block>
  <block id="f40ff1aaa4f2e4ccd4189adfb3584e29" category="paragraph">Com base nas suas necessidades de capacidade de armazenamento, você pode aumentar o armazenamento compartilhado (volume NFS) sob demanda, desde que tenha prateleiras de disco e modelos de controlador adicionais.  Você pode fazer isso pela CLI ou pela interface web do NetApp do controlador de armazenamento como usuário administrador.</block>
  <block id="15977ebfd8c3685ca2d8911f74efcc2d" category="summary">Esta solução da NetApp e da Lenovo é uma arquitetura de escalonamento flexível, ideal para entrada em IA empresarial de nível médio.  O armazenamento NetApp oferece o mesmo desempenho ou melhor que o armazenamento SSD local e oferece os seguintes benefícios para cientistas de dados, engenheiros de dados e tomadores de decisões de TI.</block>
  <block id="994c1f46e0860094a86d2a822416646b" category="paragraph">A solução da NetApp e da Lenovo validada aqui é uma arquitetura de escalonamento flexível, ideal para entrada em IA empresarial de nível médio.</block>
  <block id="bcbfcce438abee9a9a41cb7e588eb4de" category="paragraph">O armazenamento NetApp oferece o mesmo desempenho ou melhor que o armazenamento SSD local e oferece os seguintes benefícios para cientistas de dados, engenheiros de dados e tomadores de decisões de TI:</block>
  <block id="6127562591a3f60f8ac270d3967754dd" category="list-text">Computação e armazenamento escaláveis de forma independente para minimizar custos e melhorar a utilização de recursos.</block>
  <block id="74902bcc2ed17395305301b925afee3f" category="list-text">Fluxos de trabalho de desenvolvimento e implantação simplificados usando snapshots e clones integrados para espaços de trabalho de usuários instantâneos e com economia de espaço, controle de versão integrado e implantação automatizada.</block>
  <block id="42e2aaa2f651d8ad800a51f65a258f1e" category="list-text">Proteção de dados de nível empresarial para recuperação de desastres e continuidade dos negócios.</block>
  <block id="2ea563f362255807faae7242f06c9881" category="list-text">Karthikeyan Nagalingam, engenheiro técnico de marketing, NetApp</block>
  <block id="cccf21ceeae034a9e54b62eb00d9b6b3" category="list-text">Jarrett Upton, Administrador, Sistemas de Laboratório de IA, Lenovo</block>
  <block id="fdc944d7a0de8d8e3dfff03c6a0e03c6" category="list-text">Página do produto NetApp All Flash Arrays</block>
  <block id="d875955d78b62e4aff0847425410f79a" category="inline-link"><block ref="d875955d78b62e4aff0847425410f79a" category="inline-link-rx"></block></block>
  <block id="45f6f9585c85146b389a4f896653a5f9" category="paragraph"><block ref="45f6f9585c85146b389a4f896653a5f9" category="inline-link-rx"></block></block>
  <block id="ec5282877903d9d2aceb3db45b21da54" category="list-text">Página NetApp AFF A400</block>
  <block id="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link"><block ref="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link-rx"></block></block>
  <block id="04438df627d0343d17b2f6f307b489ed" category="paragraph"><block ref="04438df627d0343d17b2f6f307b489ed" category="inline-link-rx"></block></block>
  <block id="9d92155996555576a58d20e697fc2bd6" category="list-text">Página do produto do software de gerenciamento de dados NetApp ONTAP</block>
  <block id="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link"><block ref="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link-rx"></block></block>
  <block id="2f08744b4a39af375744e1fc4a15b53a" category="paragraph"><block ref="2f08744b4a39af375744e1fc4a15b53a" category="inline-link-rx"></block></block>
  <block id="45913847e0b47b72b60766711f7a8c21" category="inline-link"><block ref="45913847e0b47b72b60766711f7a8c21" category="inline-link-rx"></block></block>
  <block id="229469a202dbd3052c7b165bd55eda87" category="paragraph"><block ref="229469a202dbd3052c7b165bd55eda87" category="inline-link-rx"></block></block>
  <block id="dedba6b3261804ab1e5c2b75051c62ac" category="list-text">NVIDIA SMI (nvidia-smi)</block>
  <block id="f5800a0bf7fbf711d11868c2913c218f" category="inline-link"><block ref="f5800a0bf7fbf711d11868c2913c218f" category="inline-link-rx"></block></block>
  <block id="41299b529a1014318d5e7776b9f92ad1" category="paragraph"><block ref="41299b529a1014318d5e7776b9f92ad1" category="inline-link-rx"></block></block>
  <block id="bd7c9d63c88eb380170362e93db6ba46" category="summary">Esta seção descreve as configurações testadas, a infraestrutura de rede, o servidor SR670 V2 e os detalhes de provisionamento de armazenamento.</block>
  <block id="a1052c50691421535c201fa50690a1ca" category="paragraph">Esta seção descreve as configurações testadas, a infraestrutura de rede, o servidor SR670 V2 e os detalhes de provisionamento de armazenamento da NetApp .</block>
  <block id="7c8d74d4c719b2f2e30a143bb98717ad" category="paragraph">Usamos os componentes da solução listados na tabela a seguir para esta validação.</block>
  <block id="35c99b744e4464f42b9b61595c1a1e79" category="list-text">Dois servidores SR670 V2, cada um com oito placas GPU NVIDIA A100 de 80 GB</block>
  <block id="222a9edda77d8676279c651c1b06d653" category="list-text">Cada servidor contém 2 CPUs Intel Xeon Platinum 8360Y (28 núcleos físicos) e 1 TB de RAM</block>
  <block id="e18f1a9d73bf89b2b1245e5af1a99cf4" category="cell">Linux (Ubuntu – 20.04 com CUDA 11.8)</block>
  <block id="2113187ee3a9451b60e960fdea11bbac" category="cell">Sistema de armazenamento NetApp AFF (par HA)</block>
  <block id="73b4d2da39f967445be9b79a6016c84c" category="list-text">Software NetApp ONTAP 9.10.1</block>
  <block id="4028b206981977bc3aea334fd55f4cb9" category="list-text">1 grupo de interface (ifgrp) por controlador, com quatro endereços IP lógicos para pontos de montagem</block>
  <block id="82693066c3bae0719e01ba8060494172" category="paragraph">Nesta validação, usamos o ResNet v2.0 com o conjunto de base ImageNet conforme especificado pelo MLPerf v2.0.  O conjunto de dados é armazenado em um sistema de armazenamento NetApp AFF com o protocolo NFS.  Os SR670s foram conectados ao sistema de armazenamento NetApp AFF A400 por meio de um switch de 100 GbE.</block>
  <block id="e4869dda2a4e140bc138f43895626550" category="paragraph">ImageNet é um conjunto de dados de imagens frequentemente usado.  Ele contém quase 1,3 milhão de imagens, totalizando 144 GB.  O tamanho médio da imagem é 108 KB.</block>
  <block id="3961f6874ee29dab2f4982bc3e0a1be5" category="paragraph">A figura a seguir descreve a topologia de rede da configuração testada.</block>
  <block id="d015822ec6fd4a7fc9867768f5a27898" category="inline-image-macro">Este gráfico descreve a camada de computação, um Lenovo ThinkSystem SR670 V2, a camada de rede, um switch Lenovo Ethernet, e a camada de armazenamento, um controlador de armazenamento NetApp AFF A400 .  Todas as conexões de rede estão incluídas.</block>
  <block id="74ae44f09af988f16e87e4e2e31ef81a" category="paragraph"><block ref="74ae44f09af988f16e87e4e2e31ef81a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18866bc1d6ba54b48522f7a219e02740" category="paragraph">A tabela a seguir lista a configuração de armazenamento.</block>
  <block id="f64bc191156dac76ffce8622c16cb21d" category="cell">Tamanho agregado</block>
  <block id="6bb41960470a19d97556b9240ac0b3ff" category="cell">Tamanho do volume</block>
  <block id="abd2beb6abe5072ffab5f1aad1a8c27f" category="cell">Ponto de montagem do sistema operacional</block>
  <block id="a38b6dcf7d1d2c2957803ba9a28b472e" category="cell">/a400-100g</block>
  <block id="43f5cd38d362fc55ace2f313e6b5cf09" category="cell">9,9 TB</block>
  <block id="09808554056bf39d02319e3dbc2d6667" category="cell">19 TB</block>
  <block id="a27053e11ec415312f3dc32f4e351b67" category="admonition">A pasta /a400-100g contém o conjunto de dados usado para validação do ResNet.</block>
  <block id="1f599c1b266e901a2c8d38e266e23c6f" category="summary">Esta seção descreve os resultados detalhados do procedimento de teste.</block>
  <block id="c87fa6e515cf0976291b387e5a8ab6f6" category="doc">Procedimento de teste e resultados detalhados</block>
  <block id="b70dd619781891706b7d2f44c418a2b5" category="section-title">Treinamento de reconhecimento de imagem usando ResNet em ONTAP</block>
  <block id="bf523bb892b07c71c90bd7ea34a091a9" category="paragraph">Executamos o benchmark ResNet50 com um e dois servidores SR670 V2.  Este teste usou o contêiner MXNet 22.04-py3 NGC para executar o treinamento.</block>
  <block id="a08c4eedb9047aae68f44b82037739b0" category="paragraph">Utilizamos o seguinte procedimento de teste nesta validação:</block>
  <block id="df1a5f60f20e6aa3336812f58095e04f" category="list-text">Limpamos o cache do host antes de executar o script para garantir que os dados ainda não estivessem armazenados em cache:</block>
  <block id="ab93a65fabd2eaae21f5a6e097320730" category="list-text">Executamos o script de benchmark com o conjunto de dados ImageNet no armazenamento do servidor (armazenamento SSD local), bem como no sistema de armazenamento NetApp AFF .</block>
  <block id="9f98453c4a6eede45b87d72527b49e7e" category="list-text">Validamos o desempenho da rede e do armazenamento local usando o<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> comando.</block>
  <block id="47b048d9dcf1d84d76bddb033b842b3b" category="list-text">Para a execução de nó único, usamos o seguinte comando:</block>
  <block id="cf9a86ba8909a23b4d67d509b389a080" category="list-text">Para as execuções distribuídas, usamos o modelo de paralelismo do servidor de parâmetros.  Usamos dois servidores de parâmetros por nó e definimos o número de épocas para ser o mesmo da execução de nó único.  Fizemos isso porque o treinamento distribuído geralmente leva mais períodos devido à sincronização imperfeita entre os processos.  O número diferente de épocas pode distorcer as comparações entre casos de nó único e distribuídos.</block>
  <block id="8f74be345dbaeac65cc3a488503b2a1f" category="section-title">Velocidade de leitura de dados: armazenamento local versus armazenamento em rede</block>
  <block id="16d8fe364e1a7846c093983bec75e764" category="paragraph">A velocidade de leitura foi testada usando o<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> comando em um dos arquivos do conjunto de dados ImageNet.  Especificamente, executamos os seguintes comandos para dados locais e de rede:</block>
  <block id="c685a224eb9a88c5b7bd2be45fe5a128" category="paragraph">Ambos os valores são semelhantes, demonstrando que o armazenamento em rede pode fornecer dados a uma taxa semelhante ao armazenamento local.</block>
  <block id="aa613e8f689a1a64605aef401595bfd2" category="section-title">Caso de uso compartilhado: vários trabalhos independentes e simultâneos</block>
  <block id="7e4312d3e922a98bfc1dc4a84c80f12c" category="paragraph">Este teste simulou o caso de uso esperado para esta solução: treinamento de IA multitarefa e multiusuário.  Cada nó executou seu próprio treinamento enquanto usava o armazenamento de rede compartilhado.  Os resultados são exibidos na figura a seguir, que mostra que o caso da solução forneceu excelente desempenho, com todos os trabalhos sendo executados essencialmente na mesma velocidade dos trabalhos individuais.  A taxa de transferência total foi dimensionada linearmente com o número de nós.</block>
  <block id="2b9215e7cc3c2422637b6f95b0d47d97" category="inline-image-macro">Esta figura mostra as imagens agregadas por segundo.</block>
  <block id="568b99e77256e0aa65f03e3612709ffc" category="paragraph"><block ref="568b99e77256e0aa65f03e3612709ffc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45f5fcaaad259a917b031b3169cd5ad4" category="inline-image-macro">Esta figura mostra o tempo de execução em minutos.</block>
  <block id="c8a726b6eb44bab6b01c319420a7605a" category="paragraph"><block ref="c8a726b6eb44bab6b01c319420a7605a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="289b386724c768cabf5ad786a3842335" category="paragraph">Esses gráficos apresentam o tempo de execução em minutos e as imagens agregadas por segundo para nós de computação que usaram oito GPUs de cada servidor em uma rede de cliente de 100 GbE, combinando o modelo de treinamento simultâneo e o modelo de treinamento único.  O tempo médio de execução do modelo de treinamento foi de 35 minutos e 9 segundos.  Os tempos de execução individuais foram de 34 minutos e 32 segundos, 36 minutos e 21 segundos, 34 minutos e 37 segundos, 35 minutos e 25 segundos e 34 minutos e 31 segundos.  A média de imagens por segundo para o modelo de treinamento foi de 22.573, e as imagens individuais por segundo foram de 21.764; 23.438; 22.556; 22.564; e 22.547.</block>
  <block id="ce47a442fe1dc7c09bf9a3ec5ed71236" category="paragraph">Com base em nossa validação, um modelo de treinamento independente com tempo de execução de dados NetApp foi de 34 minutos e 54 segundos, com 22.231 imagens/seg.  Um modelo de treinamento independente com tempo de execução de dados locais (DAS) foi de 34 minutos e 21 segundos, com 22.102 imagens/seg.  Durante essas execuções, a utilização média da GPU foi de 96%, conforme observado no nvidia-smi.  Observe que essa média inclui a fase de testes, durante a qual as GPUs não foram usadas, enquanto a utilização da CPU foi de 40%, conforme medido pelo mpstat.  Isso demonstra que a taxa de entrega de dados é suficiente em cada caso.</block>
  <block id="1d126a9d86b70dcdbc0585754993a848" category="summary">Esta solução se concentra na arquitetura de cluster de nível básico e médio usando armazenamento NetApp e servidores Lenovo otimizados para cargas de trabalho de inteligência artificial.  Ele é destinado a equipes de pequeno e médio porte, para as quais a maioria dos trabalhos de computação são de nó único (GPU única ou múltipla) ou são distribuídos em alguns nós computacionais.  Esta não é uma limitação importante, porque a maioria dos trabalhos diários de treinamento de IA envolvem um único nó.</block>
  <block id="119a956725a313a60a3ef97db900f9fa" category="doc">TR-4810: NetApp AFF A400 com Lenovo ThinkSystem SR670 V2 para treinamento de modelos de IA e ML</block>
  <block id="db297dc3a6b72858a5039fa6507a2b34" category="paragraph">Sathish Thyagarajan, David Arnette, NetApp Mircea Troaca, Lenovo</block>
  <block id="252875fbe73a0c4ecbd42a23cc730022" category="paragraph">Esta solução apresenta uma arquitetura de cluster de médio porte usando armazenamento NetApp e servidores Lenovo otimizados para cargas de trabalho de inteligência artificial (IA).  Ele é destinado a pequenas e médias empresas para as quais a maioria dos trabalhos de computação são de nó único (GPU única ou múltipla) ou distribuídos em alguns nós computacionais.  Esta solução se alinha à maioria dos trabalhos diários de treinamento de IA de muitas empresas.</block>
  <block id="2fd79dc2b0743358191fe41cd806d103" category="paragraph">Este documento abrange testes e validação de uma configuração de computação e armazenamento composta por servidores Lenovo SR670V2 de oito GPUs, um sistema de armazenamento NetApp AFF A400 de médio porte e um switch de interconexão de 100 GbE.  Para medir o desempenho, usamos o ResNet50 com o conjunto de dados ImageNet, um tamanho de lote de 408, meia precisão, CUDA e cuDNN.  Essa arquitetura fornece uma solução eficiente e econômica para organizações de pequeno e médio porte que estão começando com iniciativas de IA e que exigem recursos de nível empresarial do armazenamento de dados conectado à nuvem NetApp ONTAP .</block>
  <block id="a186cc4a556d59a6e7b787796afd96a6" category="list-text">Cientistas de dados, engenheiros de dados, administradores de dados e desenvolvedores de sistemas de IA</block>
  <block id="9f16d751276619605acf16a23befe48e" category="list-text">Arquitetos corporativos que projetam soluções para o desenvolvimento de modelos de IA</block>
  <block id="e8982c30a351cd862612b0062923a81e" category="list-text">Cientistas e engenheiros de dados que buscam maneiras eficientes de atingir metas de desenvolvimento de aprendizado profundo (DL) e aprendizado de máquina (ML)</block>
  <block id="ca84e34dfe1115f7b462050a20377876" category="list-text">Líderes empresariais e tomadores de decisão de TO/TI que desejam atingir o tempo de comercialização mais rápido possível para iniciativas de IA</block>
  <block id="a2dac0ecb0b60ec2625d20a5003869fb" category="paragraph">Esta solução com servidores Lenovo ThinkSystem e NetApp ONTAP com armazenamento AFF foi projetada para lidar com treinamento de IA em grandes conjuntos de dados usando o poder de processamento de GPUs junto com CPUs tradicionais.  Esta validação demonstra alto desempenho e gerenciamento de dados ideal com uma arquitetura de escalonamento que usa um, dois ou quatro servidores Lenovo SR670 V2 junto com um único sistema de armazenamento NetApp AFF A400 .  A figura a seguir fornece uma visão geral da arquitetura.</block>
  <block id="9eaa73568302c6f5b850762b65b3f334" category="inline-image-macro">Esta imagem mostra um switch Ethernet cercado pelo servidor de gerenciamento, quatro SR670 V2s com oito GPUs cada e um sistema de armazenamento NetApp ONTAP .</block>
  <block id="98230d6fe5f2e966446d65810c888228" category="paragraph"><block ref="98230d6fe5f2e966446d65810c888228" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9336931f4103d973313cb8539e5c2613" category="list-text">Desempenho altamente eficiente e econômico ao executar vários trabalhos de treinamento em paralelo</block>
  <block id="81c3992924ee5cdc4cb02692dcae98b4" category="list-text">Desempenho escalável com base em diferentes números de servidores Lenovo e diferentes modelos de controladores de armazenamento NetApp</block>
  <block id="bdcea52fecbcd9741f95a6bc0dbbde0f" category="list-text">Proteção de dados robusta para atender a objetivos de ponto de recuperação (RPOs) e tempo de recuperação (RTOs) baixos sem perda de dados</block>
  <block id="98393526d67c065feb588e5665301706" category="list-text">Gerenciamento de dados otimizado com snapshots e clones para agilizar os fluxos de trabalho de desenvolvimento</block>
  <block id="f737e7cc3d8aa89c5b49c4fe701e9e40" category="summary">Nesta validação, realizamos treinamento de reconhecimento de imagem conforme especificado pelo MLPerf v2.0.  Especificamente, treinamos o modelo ResNet v2.0 com o conjunto de dados ImageNet.  A principal métrica é o tempo para atingir a precisão desejada.  Também relatamos a largura de banda de treinamento em imagens por segundo para melhor avaliar a eficiência de escala.</block>
  <block id="0f25983094bc4cf5cea830260da8ee75" category="paragraph">Nesta validação, realizamos treinamento de reconhecimento de imagem conforme especificado pelo MLPerf v2.0.  Especificamente, treinamos o modelo ResNet v2.0 com o conjunto de dados ImageNet até atingirmos uma precisão de 76,1%.  A principal métrica é o tempo para atingir a precisão desejada.  Também relatamos a largura de banda de treinamento em imagens por segundo para melhor avaliar a eficiência de escala.</block>
  <block id="ac3e6a4fbe8e02d639c2defeebeac17f" category="paragraph">O caso de teste primário avaliou vários processos de treinamento independentes (um por nó) executados simultaneamente.  Isso simula o caso de uso principal, um sistema compartilhado usado por vários cientistas de dados.  O segundo caso de teste avaliou a eficiência de expansão.</block>
  <block id="2d316c5d9e0cd748d1890ee69f57dc6c" category="summary">Esta seção resume os resultados dos testes nesta solução.</block>
  <block id="80b6b969d6707ba1b92d65466e8325f0" category="paragraph">A tabela a seguir resume os resultados de todos os testes realizados para esta solução.</block>
  <block id="f5bc14ae022ba581c26f3bdb35badef1" category="cell">Descrição do teste</block>
  <block id="34d8129946f1108a296f033dc66db266" category="cell">Resumo dos resultados</block>
  <block id="ab0d993807168c3a70cdd2952d4edfc0" category="cell">Treinamento de reconhecimento de imagem: vários trabalhos simultâneos</block>
  <block id="290ba1c81812edd0651d8e18c5895054" category="cell">Desempenho altamente eficiente.  Todos os trabalhos foram executados em velocidade máxima, mesmo quando o cluster estava totalmente utilizado.  Os sistemas de armazenamento da NetApp proporcionaram desempenho de treinamento comparável ao armazenamento SSD local, ao mesmo tempo em que permitiram fácil compartilhamento de dados entre servidores.</block>
  <block id="d58827ca3ccfccb5c83b1dc9c7e12289" category="cell">Treinamento de reconhecimento de imagem: escalonamento horizontal</block>
  <block id="afb4fda11ecde317daa521e054df2bd4" category="cell">Altamente eficiente para até quatro nós.  Nesse ponto, a expansão era menos eficiente, mas ainda viável.  Usar uma rede computacional de alta velocidade melhora a escalabilidade.  O sistema de armazenamento NetApp proporcionou desempenho de treinamento comparável ao armazenamento SSD local, ao mesmo tempo em que permitiu fácil compartilhamento de dados entre servidores.</block>
  <block id="e59b92fc604ecde201ab865ddefca7c2" category="summary">Esta seção apresenta os principais componentes desta solução com mais detalhes.</block>
  <block id="995049066ee0a46858d3a35e74f687fc" category="paragraph">Os sistemas de armazenamento NetApp AFF permitem que as empresas atendam aos requisitos de armazenamento empresarial com desempenho líder do setor, flexibilidade superior, integração com a nuvem e o melhor gerenciamento de dados da categoria.  Projetados especificamente para flash, os sistemas AFF ajudam a acelerar, gerenciar e proteger dados essenciais aos negócios.</block>
  <block id="9cdcb25bd8b8e9dd029f0c58f1c1ce14" category="inline-image-macro">Este gráfico mostra a parte frontal do controlador de armazenamento NetApp AFF A400 .</block>
  <block id="f150868d2ce410023c5087a2a86bf51e" category="paragraph"><block ref="f150868d2ce410023c5087a2a86bf51e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a4c41eb7420fce0589579f0f045df87" category="inline-image-macro">Este gráfico mostra a parte traseira do controlador de armazenamento NetApp AFF A400 .</block>
  <block id="11540913656d83142b2b0f7aed3df7e4" category="paragraph"><block ref="11540913656d83142b2b0f7aed3df7e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="32fbd740c28afd94422aeceef5424762" category="paragraph">O NetApp AFF A400 é um sistema de armazenamento flash NVMe de médio porte que inclui os seguintes recursos:</block>
  <block id="4b78ed4e994ac9de0ed2b09e38067a6a" category="list-text">Capacidade efetiva máxima: ~20PB</block>
  <block id="9b150a217729988c3dd54fdaf7b0f9b3" category="list-text">Escala máxima: 2-24 nós (12 pares de HA)</block>
  <block id="ae3b033d221455bb2825ac51bee7200e" category="list-text">Suporte a host FC de 25 GbE e 16 Gb</block>
  <block id="e16f4e2b178ce47880c3556c501efea4" category="list-text">Conectividade 100GbE RDMA sobre Ethernet convergente (RoCE) para prateleiras de armazenamento de expansão NVMe</block>
  <block id="e9038c807b352c2a4dcfd8cf1ac2cdd4" category="list-text">As portas RoCE de 100 GbE podem ser usadas para conexão de rede host se as prateleiras NVMe não estiverem conectadas</block>
  <block id="dff1410020c1b676f56ee973acea57d3" category="list-text">Prateleiras de armazenamento de expansão de conectividade SAS de 12 Gbps</block>
  <block id="565637725a05c879995851c50d41275c" category="list-text">Disponível em duas configurações:</block>
  <block id="8e707b713d26c4b020eda98a37207373" category="list-text">Ethernet: 4 portas Ethernet de 25 Gb (SFP28)</block>
  <block id="1d3c6ad9f15fc70a1cf63e449e90436a" category="list-text">Canal de fibra: 4 portas FC (SFP+) de 16 Gb</block>
  <block id="6a2a811bcec501901ab6f8f94694d1b2" category="list-text">100% de leitura aleatória de 8 KB a 0,4 ms 400 mil IOPS</block>
  <block id="d3309961dfabc3043c3ea1878752450b" category="paragraph">Os recursos do NetApp AFF A250 para implantações de IA/ML de nível básico incluem o seguinte:</block>
  <block id="68448ae40d26fce5bb74cd3bf75999c4" category="list-text">Capacidade efetiva máxima: 35PB</block>
  <block id="83fa45e9cc2def5751527547e3c57b61" category="list-text">Escala máxima: 2-24 nós (12 pares HA)</block>
  <block id="1283cfcd2651148a611c2c4b105458c3" category="list-text">Construído na versão mais recente do NetApp ONTAP ONTAP 9.8 ou posterior</block>
  <block id="f31903137775862e1157677f447b0f52" category="list-text">Duas portas Ethernet de 25 Gb para HA e interconexão de cluster</block>
  <block id="f6c48fdc99c510156e0364e03a6fbd9e" category="paragraph">A NetApp também oferece outros sistemas de armazenamento, como o AFF A800 e o AFF A700 , que fornecem maior desempenho e escalabilidade para implantações de IA/ML em larga escala.</block>
  <block id="3f0cb8a376b551c058cd6886f68bceb0" category="paragraph">ONTAP 9, a última geração de software de gerenciamento de armazenamento da NetApp, permite que as empresas modernizem a infraestrutura e façam a transição para um data center pronto para a nuvem.  Aproveitando os recursos de gerenciamento de dados líderes do setor, o ONTAP permite o gerenciamento e a proteção de dados com um único conjunto de ferramentas, independentemente de onde os dados residam.  Os dados também podem ser movidos livremente para onde forem necessários: na borda, no núcleo ou na nuvem.  O ONTAP 9 inclui vários recursos que simplificam o gerenciamento de dados, aceleram e protegem dados críticos e uma infraestrutura preparada para o futuro em arquiteturas de nuvem híbrida.</block>
  <block id="c5b25bb449b07e8b863f41dbe3b90a2a" category="list-text">*Qualidade de serviço (QoS) mínima, máxima e adaptável.*  Controles granulares de QoS ajudam a manter os níveis de desempenho para aplicativos críticos em ambientes altamente compartilhados.</block>
  <block id="ddf38f965aeb6f6b5785254e6f143a09" category="list-text">* ONTAP FabricPool.*  Esse recurso classifica automaticamente dados frios em opções de armazenamento em nuvem pública e privada, incluindo Amazon Web Services (AWS), Azure e armazenamento de objetos NetApp StorageGRID .</block>
  <block id="2a228ac6322b6d496b4cb0cf22cfbfe4" category="list-text">*Desempenho e menor latência.*  ONTAP oferece o maior rendimento possível com a menor latência possível.</block>
  <block id="493a7caad772a79b06f5d4a7dd98afcd" category="list-text">* Criptografia de volume NetApp .*  O ONTAP oferece criptografia nativa em nível de volume com suporte para gerenciamento de chaves interno e externo.</block>
  <block id="cf4d3359e3cce4324a54d8e1864d2647" category="paragraph">ONTAP 9 ajuda a atender às necessidades empresariais exigentes e em constante mudança:</block>
  <block id="99f4fd3a9ea4a861a7095bfe26937f28" category="list-text">*Escalonamento perfeito e operações não disruptivas.*  O ONTAP oferece suporte à adição não disruptiva de capacidade aos controladores existentes, bem como aos clusters escaláveis.  Os clientes podem atualizar para as tecnologias mais recentes, como NVMe e 32Gb FC, sem migrações de dados dispendiosas ou interrupções.</block>
  <block id="ba1e7aff40da44f3c5b86ba78a62e7d0" category="list-text">*Integração com aplicações emergentes.*  A ONTAP oferece serviços de dados de nível empresarial para plataformas e aplicativos de última geração, como OpenStack, Hadoop e MongoDB, usando a mesma infraestrutura que dá suporte aos aplicativos empresariais existentes.</block>
  <block id="0fdd508a09442b5caa00e47bc0563112" category="section-title">Volumes do NetApp FlexGroup</block>
  <block id="641653fdc449e0b1e30f3ee9d04182ab" category="paragraph">Os conjuntos de dados de treinamento geralmente são uma coleção de potencialmente bilhões de arquivos.  Os arquivos podem incluir texto, áudio, vídeo e outras formas de dados não estruturados que devem ser armazenados e processados para serem lidos em paralelo.  O sistema de armazenamento deve armazenar muitos arquivos pequenos e deve lê-los em paralelo para E/S sequencial e aleatória.</block>
  <block id="e6ad1152aea2aa4f79a47e3b80410fce" category="paragraph">Um volume FlexGroup (figura a seguir) é um único namespace composto de vários volumes de membros constituintes que é gerenciado e atua como um FlexVol volume NetApp FlexVol para administradores de armazenamento.  Os arquivos em um volume FlexGroup são alocados para volumes de membros individuais e não são distribuídos entre volumes ou nós.  Eles permitem os seguintes recursos:</block>
  <block id="381a99cae8c29b3b8fd64a207b811935" category="list-text">Até 20 petabytes de capacidade e baixa latência previsível para cargas de trabalho com muitos metadados</block>
  <block id="b0e05251a53a0118d23cd469db4b1903" category="list-text">Até 400 bilhões de arquivos no mesmo namespace</block>
  <block id="4eb6665794643a2afabf63f90ddbe4da" category="list-text">Operações paralelizadas em cargas de trabalho NAS em CPUs, nós, agregados e volumes FlexVol constituintes</block>
  <block id="55f5279d0b1378eee63af77d4c7ac7bd" category="inline-image-macro">Esta imagem descreve um par HA de controladores de armazenamento contendo muitos volumes com arquivos principais dentro de um FlexGroup.</block>
  <block id="27f19cee54b11d13039a99839ca83e4c" category="paragraph"><block ref="27f19cee54b11d13039a99839ca83e4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f52dbcd9b43086f1d2957e6eb89f4113" category="section-title">Portfólio Lenovo ThinkSystem</block>
  <block id="c5ac419e5467e7539d60c18be3da4b99" category="paragraph">As principais vantagens da implantação de servidores Lenovo ThinkSystem incluem o seguinte:</block>
  <block id="c19629173ec04d03fae09e96ce30b98c" category="list-text">Projetos modulares e altamente escaláveis que crescem com o seu negócio</block>
  <block id="9ac34c98220e3dd285a7cd6c8679caeb" category="paragraph">Na área de IA, a Lenovo está adotando uma abordagem prática para ajudar as empresas a entender e adotar os benefícios do ML e da IA para suas cargas de trabalho.  Os clientes da Lenovo podem explorar e avaliar as ofertas de IA da Lenovo nos Centros de Inovação de IA da Lenovo para entender completamente o valor para seu caso de uso específico.  Para melhorar o tempo de retorno do investimento, essa abordagem centrada no cliente fornece aos clientes provas de conceito para plataformas de desenvolvimento de soluções prontas para uso e otimizadas para IA.</block>
  <block id="7cbc0e3d7cff391aa0e61b487dc29df1" category="section-title">Lenovo SR670 V2</block>
  <block id="5889950b76dcc45f10977523225c92a8" category="paragraph">O servidor rack Lenovo ThinkSystem SR670 V2 oferece desempenho ideal para IA acelerada e computação de alto desempenho (HPC).  Com suporte para até oito GPUs, o SR670 V2 é adequado para requisitos de carga de trabalho computacionalmente intensiva de ML, DL e inferência.</block>
  <block id="327669874a587f6f9336f608f83d451d" category="inline-image-macro">Esta imagem mostra três configurações do SR670.  O primeiro mostra quatro GPUs SXM com oito unidades HS de 2,5 polegadas e 2 slots de E/S PCIe.  O segundo mostra quatro slots de GPU de largura dupla ou oito de largura simples e dois slots de E/S PCIe com oito unidades HS de 2,5 polegadas ou quatro de 3,5 polegadas.  O terceiro mostra oito slots de GPU de largura dupla com seis unidades EDSFF HS e dois slots de E/S PCIe.</block>
  <block id="20b8a0ab50b43efab313a63b4c461c6e" category="paragraph"><block ref="20b8a0ab50b43efab313a63b4c461c6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="85b1e2eb4bc61f3bdaea9a9f040eb3a0" category="paragraph">Com as mais recentes CPUs Intel Xeon escaláveis que oferecem suporte a GPUs de ponta (incluindo a GPU NVIDIA A100 80GB PCIe 8x), o ThinkSystem SR670 V2 oferece desempenho otimizado e acelerado para cargas de trabalho de IA e HPC.</block>
  <block id="d7ed5fdb2102567c3c051078e7c72e11" category="paragraph">Como mais cargas de trabalho usam o desempenho dos aceleradores, a demanda por densidade de GPU aumentou.  Setores como varejo, serviços financeiros, energia e saúde estão usando GPUs para extrair mais insights e impulsionar a inovação com ML, DL e técnicas de inferência.</block>
  <block id="89a846b0823ae167964c8a02382225cf" category="paragraph">O ThinkSystem SR670 V2 é uma solução otimizada de nível empresarial para implantação de cargas de trabalho aceleradas de HPC e IA na produção, maximizando o desempenho do sistema e mantendo a densidade do data center para clusters de supercomputação com plataformas de última geração.</block>
  <block id="9378d87a3787bb6ab3fe4605dd558aaf" category="paragraph">Outros recursos incluem:</block>
  <block id="fe62ffc0b0188329f10e2bfc0c560ece" category="list-text">Suporte para E/S RDMA direta de GPU, em que adaptadores de rede de alta velocidade são conectados diretamente às GPUs para maximizar o desempenho de E/S.</block>
  <block id="03e5fd8f257caa94eae847639e18b1a9" category="list-text">Suporte para armazenamento direto de GPU no qual unidades NVMe são conectadas diretamente às GPUs para maximizar o desempenho do armazenamento.</block>
  <block id="ad7857a40388167e99516cfe367478d5" category="paragraph">O MLPerf é o conjunto de benchmark líder do setor para avaliar o desempenho da IA.  Nesta validação, usamos seu benchmark de classificação de imagens com MXNet, uma das estruturas de IA mais populares.  O script de treinamento MXNet_benchmarks foi usado para conduzir o treinamento de IA.  O script contém implementações de vários modelos convencionais populares e foi projetado para ser o mais rápido possível.  Ele pode ser executado em uma única máquina ou em modo distribuído em vários hosts.</block>
  <block id="75c1d09e56fd67f885464b85c424c1a6" category="summary">Este artigo apresenta um projeto de referência validado do NetApp AIPod para Enterprise RAG com tecnologias e recursos combinados de processadores Intel Xeon 6 e soluções de gerenciamento de dados NetApp .  A solução demonstra um aplicativo ChatQnA downstream que aproveita um grande modelo de linguagem, fornecendo respostas precisas e contextualmente relevantes para usuários simultâneos.  As respostas são recuperadas do repositório de conhecimento interno de uma organização por meio de um pipeline de inferência RAG isolado.</block>
  <block id="98082f297da0ed06e10c426d26145b83" category="doc">NetApp AIPod Mini - Inferência RAG empresarial com NetApp e Intel</block>
  <block id="f7b06c1111212ddff169549b5e723f7d" category="inline-image-macro">Logotipo da Intel</block>
  <block id="0e15068b5c1105ba9f4537e00817149b" category="paragraph"><block ref="0e15068b5c1105ba9f4537e00817149b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7c6562cf6ae61e882bf5b2ce4cfcba9d" category="paragraph">Sathish Thyagarajan, Michael Oglesby, NetApp</block>
  <block id="609170132b6430c9060811e3315d482b" category="paragraph">Um número crescente de organizações está aproveitando aplicativos de geração aumentada de recuperação (RAG) e modelos de grande linguagem (LLMs) para interpretar prompts do usuário e gerar respostas para aumentar a produtividade e o valor comercial.  Esses prompts e respostas podem incluir texto, código, imagens ou até mesmo estruturas de proteínas terapêuticas recuperadas da base de conhecimento interna de uma organização, data lakes, repositórios de código e repositórios de documentos.  Este artigo aborda o design de referência da solução NetApp AIPod Mini, que inclui armazenamento NetApp AFF e servidores com processadores Intel Xeon 6.  Inclui o software de gerenciamento de dados NetApp ONTAP combinado com o Intel Advanced Matrix Extensions (Intel AMX) e o software Intel AI for Enterprise Retrieval-Augmented Generation (RAG) desenvolvido na Open Platform for Enterprise AI (OPEA).  O NetApp AIPod Mini para RAG empresarial permite que as organizações ampliem um LLM público em uma solução de inferência de IA generativa privada (GenAI).  A solução demonstra inferência RAG eficiente e econômica em escala empresarial, projetada para aumentar a confiabilidade e fornecer melhor controle sobre suas informações proprietárias.</block>
  <block id="ad17078c7a931a9c4e7e96f485d5a504" category="section-title">Validação de parceiros de armazenamento Intel</block>
  <block id="56f2eda910ca62395eb64d1a789a0edd" category="paragraph">Servidores equipados com processadores Intel Xeon 6 são desenvolvidos para lidar com cargas de trabalho exigentes de inferência de IA, usando Intel AMX para desempenho máximo.  Para permitir desempenho e escalabilidade ideais de armazenamento, a solução foi validada com sucesso usando o NetApp ONTAP, permitindo que as empresas atendam às necessidades dos aplicativos RAG.  Esta validação foi realizada em servidores com processadores Intel Xeon 6.  A Intel e a NetApp têm uma forte parceria focada em fornecer soluções de IA otimizadas, escaláveis e alinhadas aos requisitos de negócios do cliente.</block>
  <block id="679a14435daad5bf55fe65cf54175466" category="section-title">Vantagens de executar sistemas RAG com NetApp</block>
  <block id="320696921fb4cab1e55c519f97302d91" category="paragraph">As aplicações RAG envolvem a recuperação de conhecimento dos repositórios de documentos das empresas em vários tipos, como PDF, texto, CSV, Excel ou gráficos de conhecimento.  Esses dados normalmente são armazenados em soluções como armazenamento de objetos S3 ou NFS local como fonte de dados.  A NetApp é líder em tecnologias de gerenciamento de dados, mobilidade de dados, governança de dados e segurança de dados em todo o ecossistema de borda, data center e nuvem.  O gerenciamento de dados do NetApp ONTAP fornece armazenamento de nível empresarial para dar suporte a vários tipos de cargas de trabalho de IA, incluindo inferência em lote e em tempo real, e oferece alguns dos seguintes benefícios:</block>
  <block id="18fb2614ff78418dcaae1e9141862c62" category="list-text">Velocidade e escalabilidade.  Você pode manipular grandes conjuntos de dados em alta velocidade para controle de versão com a capacidade de dimensionar o desempenho e a capacidade de forma independente.</block>
  <block id="71861e9c8f9e5be0d026ab6bdf1a8a1a" category="list-text">Acesso a dados.  O suporte multiprotocolo permite que aplicativos cliente leiam dados usando os protocolos de compartilhamento de arquivos S3, NFS e SMB.  Os buckets NAS ONTAP S3 podem facilitar o acesso a dados em cenários de inferência LLM multimodal.</block>
  <block id="27a2888f3fc62ef093e756c75c45081e" category="list-text">Confiabilidade e confidencialidade.  O ONTAP fornece proteção de dados, NetApp Autonomous Ransomware Protection (ARP) integrada e provisionamento dinâmico de armazenamento, além de oferecer criptografia baseada em software e hardware para aumentar a confidencialidade e a segurança.  O ONTAP é compatível com FIPS 140-2 para todas as conexões SSL.</block>
  <block id="104d96e571b334e50365e35ae17299d9" category="paragraph">Este documento é destinado a tomadores de decisão de IA, engenheiros de dados, líderes empresariais e executivos departamentais que desejam aproveitar uma infraestrutura criada para fornecer soluções empresariais de RAG e GenAI.  Conhecimento prévio de inferência de IA, LLMs, Kubernetes e redes e seus componentes ajudará durante a fase de implementação.</block>
  <block id="63b41ad25402b4d0e25695e062bb14ad" category="section-title">Tecnologias de IA da Intel</block>
  <block id="d8f5efc84f626ba14a7b3cf5ec1b06c7" category="inline-link">Processador Xeon 6</block>
  <block id="9dc22cb886e2ea682197d9ab3292ba79" category="paragraph">Com o Xeon 6 como CPU host, os sistemas acelerados se beneficiam de alto desempenho de thread único; maior largura de banda de memória; maior confiabilidade, disponibilidade e capacidade de manutenção (RAS); e mais faixas de E/S.  O Intel AMX acelera a inferência para INT8 e BF16 e oferece suporte para modelos treinados em FP16, com até 2.048 operações de ponto flutuante por ciclo por núcleo para INT8 e 1.024 operações de ponto flutuante por ciclo por núcleo para BF16/FP16.  Para implantar uma solução RAG usando processadores Xeon 6, geralmente é recomendado um mínimo de 250 GB de RAM e 500 GB de espaço em disco.  No entanto, isso depende muito do tamanho do modelo LLM.  Para obter mais informações, consulte o site da Intel<block ref="5d6ada86cc7a762cca0505b98060c709" category="inline-link-rx"></block> resumo do produto.</block>
  <block id="c3f5f2ae46fce3305ec2b138111a93b9" category="inline-image-macro">300.300</block>
  <block id="1e2eb4a765ee46d2a2a5ec4ace0544fc" category="paragraph">Figura 1 - Servidor de computação com processadores Intel Xeon 6<block ref="791fbab5dd410f620397cbb8a7265767" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d7c9993f09f717fcec0e1d09837e1efc" category="section-title">Armazenamento NetApp AFF</block>
  <block id="969e81477626b41849d992785dfcd02d" category="paragraph">Os sistemas NetApp AFF A-Series de nível básico e médio oferecem desempenho mais potente, densidade e maior eficiência.  Os sistemas NetApp AFF A20, AFF A30 e AFF A50 fornecem armazenamento verdadeiramente unificado que suporta blocos, arquivos e objetos, com base em um único sistema operacional que pode gerenciar, proteger e mobilizar dados para aplicativos RAG com o menor custo em nuvem híbrida.</block>
  <block id="f89af68595f296408d40bf9a33b8df16" category="paragraph">Figura 2 - Sistema NetApp AFF Série A.<block ref="f19ab1d9dc0e27bd83c8759fade26d2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="958c530ea1ae0e18b942f8784148734c" category="cell">*Hardware*</block>
  <block id="ddcac68770926479de530a8b7b73319e" category="cell">*Quantidade*</block>
  <block id="9bdc480955b350f1fe8089392ad36cbe" category="cell">*Comentário*</block>
  <block id="f0ef78c28754fd06e4d1d893f113852d" category="cell">Servidor baseado em Intel Xeon 6</block>
  <block id="3e18c872662c63bcc37a4934b1161411" category="cell">Nós de inferência RAG — com processadores Intel Xeon série 6900 ou Intel Xeon série 6700 de soquete duplo e 250 GB a 3 TB de RAM com DDR5 (6400 MHz) ou MRDIMM (8800 MHz).  Servidor 2U.</block>
  <block id="e5cb14453a0aa5c9218e9b6f4a2468d1" category="cell">Servidor de plano de controle com processador Intel</block>
  <block id="f5aa1aa461d9a8bb35210fb241f42cda" category="cell">Plano de controle do Kubernetes/servidor 1U.</block>
  <block id="5a0cd1929a98cebd107b65ee74abdd78" category="cell">Escolha de switch Ethernet de 100 Gb</block>
  <block id="8bfef0f2ef10319beae9f37e53900e5a" category="cell">Switch de data center.</block>
  <block id="7a2bdeec28cc635e8de5bbcea81978e1" category="cell">NetApp AFF A20 (ou AFF A30; AFF A50)</block>
  <block id="4e42b39bc940168c6df430c647a36a11" category="cell">Capacidade máxima de armazenamento: 9,3 PB.  Observação: Rede: portas 10/25/100 GbE.</block>
  <block id="44959688d91c76b11d501b550db01844" category="paragraph">Para a validação deste projeto de referência, foram utilizados servidores com processadores Intel Xeon 6 da Supermicro (222HA-TN-OTO-37) e um switch 100GbE da Arista (7280R3A).</block>
  <block id="aa6ecfe41f4b8c352896cd6cf7bc99f7" category="section-title">Plataforma aberta para IA empresarial</block>
  <block id="6fbfd0726b7202aebde976680ced22c4" category="paragraph">A Open Platform for Enterprise AI (OPEA) é uma iniciativa de código aberto liderada pela Intel em colaboração com parceiros do ecossistema.  Ele fornece uma plataforma modular de blocos de construção componíveis, projetados para acelerar o desenvolvimento de sistemas de IA generativa de ponta, com forte foco em RAG.  O OPEA inclui uma estrutura abrangente com LLMs, armazenamentos de dados, mecanismos de prompt, projetos arquitetônicos RAG e um método de avaliação de quatro etapas que avalia sistemas de IA generativa com base em desempenho, recursos, confiabilidade e prontidão empresarial.</block>
  <block id="cbe45632fbbac4e94036260c2653169b" category="paragraph">Em sua essência, a OPEA compreende dois componentes principais:</block>
  <block id="4293e41be4afaf5127828398b7c550da" category="list-text">GenAIComps: um kit de ferramentas baseado em serviços composto por componentes de microsserviços</block>
  <block id="b93ca66f4736b98ad6d348c3b08a6806" category="list-text">GenAIExamples: soluções prontas para implantação, como ChatQnA, que demonstram casos de uso práticos</block>
  <block id="de3c6a3259d3e324c7703889f55a4dde" category="inline-link">Documentação do Projeto OPEA</block>
  <block id="95a35f38b1c8257e521a361226ddc22d" category="paragraph">Para mais detalhes, consulte o<block ref="61827ec0b891f01987001b685543f04f" category="inline-link-rx"></block></block>
  <block id="515b4067e1d91f462d68de8996b254f6" category="section-title">Intel AI para inferência empresarial com tecnologia OPEA</block>
  <block id="36a128563cdcf54e3a3e0bfe9a0952a5" category="paragraph">OPEA para Intel AI for Enterprise RAG simplifica a transformação de dados corporativos em insights práticos.  Equipado com processadores Intel Xeon, ele integra componentes de parceiros do setor para oferecer uma abordagem simplificada para implantação de soluções empresariais.  Ele se adapta perfeitamente a estruturas de orquestração comprovadas, proporcionando a flexibilidade e as opções que sua empresa precisa.</block>
  <block id="9cc188487c3944246ae7f6c5402d3c53" category="paragraph">Com base na OPEA, o Intel AI for Enterprise RAG amplia essa base com recursos importantes que melhoram a escalabilidade, a segurança e a experiência do usuário.  Esses recursos incluem capacidades de malha de serviço para integração perfeita com arquiteturas modernas baseadas em serviços, validação pronta para produção para confiabilidade de pipeline e uma interface de usuário rica em recursos para RAG como serviço, permitindo fácil gerenciamento e monitoramento de fluxos de trabalho.  Além disso, o suporte da Intel e de parceiros fornece acesso a um amplo ecossistema de soluções, combinado com Gerenciamento de Identidade e Acesso (IAM) integrado com interface de usuário e aplicativos para operações seguras e compatíveis.  Os guardrails programáveis fornecem controle detalhado sobre o comportamento do pipeline, permitindo configurações personalizadas de segurança e conformidade.</block>
  <block id="1671448a75b3c116c61a1ac925267b0b" category="inline-link">Saiba mais sobre a configuração do ONTAP S3</block>
  <block id="90c6a896851e2b2d442ba1cd9d8de55a" category="paragraph">O NetApp ONTAP é a tecnologia fundamental que sustenta as soluções críticas de armazenamento de dados da NetApp.  O ONTAP inclui vários recursos de gerenciamento e proteção de dados, como proteção automática contra ransomware contra ataques cibernéticos, recursos integrados de transporte de dados e recursos de eficiência de armazenamento.  Esses benefícios se aplicam a uma variedade de arquiteturas, desde locais até multicloud híbrida em NAS, SAN, objeto e armazenamento definido por software para implantações de LLM.  Você pode usar um servidor de armazenamento de objetos ONTAP S3 em um cluster ONTAP para implantar aplicativos RAG, aproveitando as eficiências de armazenamento e a segurança do ONTAP, fornecidas por usuários autorizados e aplicativos clientes.  Para mais informações, consulte<block ref="5ba5b9c5717eb24d2b5fdfe0fd9cfc0e" category="inline-link-rx"></block></block>
  <block id="c1b379b8a85b20135cbeae3496ac9cb9" category="inline-link">NetApp Trident no Git</block>
  <block id="05ff24c52b7f489f2df6dab1ac93a444" category="paragraph">O software NetApp Trident é um orquestrador de armazenamento de código aberto e totalmente compatível para contêineres e distribuições Kubernetes, incluindo o Red Hat OpenShift.  O Trident funciona com todo o portfólio de armazenamento da NetApp , incluindo o NetApp ONTAP , e também oferece suporte a conexões NFS e iSCSI.  Para mais informações, consulte<block ref="b09494428fb81fc17c232fdf3cd6ebfd" category="inline-link-rx"></block></block>
  <block id="7eef23b11d6e87eee968a9bef33fd707" category="cell">*Software*</block>
  <block id="45cc01ab5f209e8760027e9c30097025" category="cell">*Versão*</block>
  <block id="b968b232dc718c194c40c140b496647a" category="cell">OPEA para Intel AI para Enterprise RAG</block>
  <block id="522c33efdda0b8dc6ce90c991beb9666" category="cell">1.1.2</block>
  <block id="cec6a9b163aa2911c259a1fd129fafec" category="cell">Plataforma empresarial RAG baseada em microsserviços OPEA</block>
  <block id="7b02c13e31cd24ff2d950fc29a8f9d53" category="cell">Interface de armazenamento de contêiner (driver CSI)</block>
  <block id="a821a7b77c7f65a585f8b5e2b6679cd3" category="cell">NetApp Trident 25.02</block>
  <block id="4d437b953db79f111d6140d4d62384e4" category="cell">Permite provisionamento dinâmico, cópias do NetApp Snapshot e volumes.</block>
  <block id="3d945423f8e9496c429a5d8c65b4604f" category="cell">Ubuntu</block>
  <block id="5e3add1fd258bd782aade74ed9a9877d" category="cell">22.04.5</block>
  <block id="d63705a0c12ee1eea0e9fa2f30be636d" category="cell">SO em cluster de dois nós</block>
  <block id="d7ac58512991ed45f3abecbfbb9cddf1" category="cell">Orquestração de contêineres</block>
  <block id="307ea69c7c6931f75ee51c5349fefb05" category="cell">Kubernetes 1.31.4</block>
  <block id="382fc90b48fccde9d59f816ea9dc9b4a" category="cell">Ambiente para executar o framework RAG</block>
  <block id="6f72c11338419e7cbef5d90da27338b1" category="cell">ONTAP 9.16.1P4</block>
  <block id="345ec8aa297f872cecdbf6b3c0e32bfd" category="cell">Sistema operacional de armazenamento no AFF A20.  Possui Vscan e ARP.</block>
  <block id="77e4d80ae2f4257081e17476b146608a" category="section-title">Implantação da solução</block>
  <block id="e137b1b38be73f6e2bb5d628d2325215" category="section-title">Pilha de software</block>
  <block id="4b9b3f178d68004f22177def38ac1a0a" category="paragraph">A solução é implantada em um cluster Kubernetes que consiste em nós de aplicativos baseados em Intel Xeon.  Pelo menos três nós são necessários para implementar alta disponibilidade básica para o plano de controle do Kubernetes.  Validamos a solução usando o seguinte layout de cluster.</block>
  <block id="9a5c044d129dc6879fa0ab37fdf1da36" category="paragraph">Tabela 3 - Layout do cluster Kubernetes</block>
  <block id="6c3a6944a808a7c0bbb6788dbec54a9f" category="cell">Nó</block>
  <block id="bbbabdbe1b262f75d99d62880b953be1" category="cell">Papel</block>
  <block id="f6deba375b4908f8ab44946cb1ac15ec" category="cell">Servidores com processadores Intel Xeon 6 e 1 TB de RAM</block>
  <block id="5e13dbdc232ae09e4bcf3ca30f51de88" category="cell">Nó de aplicativo, nó do plano de controle</block>
  <block id="c8b75ba615f900ff258046bb36a7fc62" category="cell">Servidor genérico</block>
  <block id="6f8f92d5847446fe4b0ae5b71badd7cd" category="cell">Nó do plano de controle</block>
  <block id="b1ee6de34c23dd606b6401a06907e658" category="inline-image-macro">600.600</block>
  <block id="13c96942dd3c3b3bdb84e02b2a303778" category="paragraph">A figura a seguir descreve uma "visão da pilha de software" da solução.<block ref="841e6c807fed1e7947a5b7ebff264e4b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8388066510b59c8d3387373b6969a7af" category="section-title">Etapas de implantação</block>
  <block id="6c00804e5ebc94e7610086e3e0f7e581" category="section-title">Implantar dispositivo de armazenamento ONTAP</block>
  <block id="ec6e72d1c4bb7dccdc62b6caf35c95f7" category="inline-link">Documentação dos sistemas de hardware ONTAP</block>
  <block id="c5ba881390fd2c8d5f9d0fb165ad1049" category="paragraph">Implante e provisione seu dispositivo de armazenamento NetApp ONTAP .  Consulte o<block ref="8f6fc8fb2a7bb6f821a0fddf6c335b91" category="inline-link-rx"></block> para mais detalhes.</block>
  <block id="9df0c5d4eab5f45fac1c5ad20e8fdade" category="section-title">Configurar um ONTAP SVM para acesso NFS e S3</block>
  <block id="b0e271f740ae6f03e699c988b5b7c576" category="paragraph">Configure uma máquina virtual de armazenamento ONTAP (SVM) para acesso NFS e S3 em uma rede que seja acessível pelos seus nós do Kubernetes.</block>
  <block id="05ef9b22209f0e35efc9b6f875ad3c55" category="inline-link">Documentação do ONTAP .</block>
  <block id="a647bfcaa1b11c3008439f5c2a0a888f" category="paragraph">Para criar uma SVM usando o ONTAP System Manager, navegue até Armazenamento &gt; VMs de armazenamento e clique no botão + Adicionar.  Ao habilitar o acesso S3 para sua SVM, escolha a opção de usar um certificado assinado por uma CA (autoridade de certificação) externa, não um certificado gerado pelo sistema.  Você pode usar um certificado autoassinado ou um certificado assinado por uma CA publicamente confiável.  Para obter detalhes adicionais, consulte o<block ref="9162972b1d9e1d587a9c620aa7cb22be" category="inline-link-rx"></block></block>
  <block id="59ea3be65306f9546fb9ed8da06a4fc4" category="paragraph">A captura de tela a seguir descreve a criação de um SVM usando o ONTAP System Manager.  Modifique os detalhes conforme necessário com base no seu ambiente.</block>
  <block id="ba045795e96e030beb3430fdc0bcf388" category="paragraph">Figura 4 - Criação de SVM usando o ONTAP System Manager.<block ref="eddc39049915c5d642c02b97b2cbe95e" category="inline-image-macro-rx" type="image"></block> <block ref="d6e1134442a83aae943e8555fe42f14e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e98de7098944681485c37173696a48b" category="section-title">Configurar permissões do S3</block>
  <block id="9e677f1fe64f248526596041ab78f505" category="paragraph">Configure as definições de usuário/grupo do S3 para o SVM que você criou na etapa anterior.  Certifique-se de ter um usuário com acesso total a todas as operações da API do S3 para esse SVM.  Consulte a documentação do ONTAP S3 para obter detalhes.</block>
  <block id="8182eb49f0464e8a5b6d2e7b642a6da5" category="paragraph">Observação: este usuário será necessário para o serviço de ingestão de dados do aplicativo Intel AI for Enterprise RAG.  Se você criou seu SVM usando o ONTAP System Manager, o System Manager terá criado automaticamente um usuário chamado<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block> e uma política chamada<block ref="0268c876e4588f7ad98bacb113933dab" prefix=" " category="inline-code"></block> quando você criou seu SVM, mas nenhuma permissão foi atribuída a ele<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block> .</block>
  <block id="c00a2800b71457eb0e0cabb2511b615a" category="paragraph">Para editar as permissões deste usuário, navegue até Armazenamento &gt; VMs de armazenamento, clique no nome da SVM que você criou na etapa anterior, clique em Configurações e, em seguida, clique no ícone de lápis ao lado de "S3".  Para dar<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block> acesso total a todas as operações da API S3, crie um novo grupo que associe<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block> com o<block ref="0268c876e4588f7ad98bacb113933dab" prefix=" " category="inline-code"></block> política conforme ilustrado na captura de tela a seguir.</block>
  <block id="229c665cb2b8cb2576229fea9470bfe6" category="paragraph">Figura 5 - Permissões do S3.</block>
  <block id="3ce7236b065597bbadf2a14e9845558e" category="paragraph"><block ref="3ce7236b065597bbadf2a14e9845558e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7cc27c397bf2aa7589869b84e048e24c" category="section-title">Criar um bucket S3</block>
  <block id="bd31776e6efcf27fc82ed6ba0862c4fb" category="paragraph">Crie um bucket S3 dentro do SVM que você criou anteriormente.  Para criar um SVM usando o ONTAP System Manager, navegue até Armazenamento &gt; Buckets e clique no botão + Adicionar.  Para obter detalhes adicionais, consulte a documentação do ONTAP S3.</block>
  <block id="0b755fcdfc7b6b61938269f21db3f841" category="paragraph">A captura de tela a seguir descreve a criação de um bucket S3 usando o ONTAP System Manager.</block>
  <block id="9568e70889a07b151a91a53d10969aed" category="paragraph">Figura 6 - Crie um bucket S3.<block ref="06e84b109f1e09150cd4d15502f0a16d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="847d5eae44750df0abbb4d655d69c6a7" category="section-title">Configurar permissões do bucket S3</block>
  <block id="c23ccda8191e76cb192f1bd40cae534b" category="paragraph">Configure permissões para o bucket S3 que você criou na etapa anterior.  Certifique-se de que o usuário configurado na etapa anterior tenha as seguintes permissões:<block ref="82cabf6bd017130caa599103617f61df" prefix=" " category="inline-code"></block></block>
  <block id="c3bf5d608f066a6b405a40012a2fc10c" category="inline-link">Documentação do ONTAP S3</block>
  <block id="cc944a7541814572eb9767d03e306277" category="paragraph">Para editar as permissões do bucket S3 usando o ONTAP System Manager, navegue até Armazenamento &gt; Buckets, clique no nome do seu bucket, clique em Permissões e, em seguida, clique em Editar.  Consulte o<block ref="3c678e24d354397cff48df8b3cf3f717" category="inline-link-rx"></block> para obter detalhes adicionais.</block>
  <block id="0d1bf17e818c5b150c239afaa05e5f17" category="paragraph">A captura de tela a seguir descreve as permissões de bucket necessárias no ONTAP System Manager.</block>
  <block id="54bf7776c2d0b7f0ee45097aaad50403" category="paragraph">Figura 7 - Permissões do bucket S3.<block ref="cc0f8d7f1fe9cc3d53404327451495be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="000356058e153b3be211db974d645a75" category="section-title">Criar regra de compartilhamento de recursos de origem cruzada de bucket</block>
  <block id="004935665424a8d10e5e54b7140e97e1" category="paragraph">Usando a CLI do ONTAP , crie uma regra de compartilhamento de recursos de origem cruzada (CORS) para o bucket que você criou em uma etapa anterior:</block>
  <block id="51704d982c17dad72393ced89212b5ca" category="paragraph">Esta regra permite que o aplicativo web OPEA para Intel AI for Enterprise RAG interaja com o bucket de dentro de um navegador da web.</block>
  <block id="d2a899c39e099bd681cfe52af554b20c" category="section-title">Implantar servidores</block>
  <block id="fa3bc02ffb34d7c680db187aa209dddd" category="paragraph">Implante seus servidores e instale o Ubuntu 22.04 LTS em cada servidor.  Após a instalação do Ubuntu, instale os utilitários NFS em todos os servidores.  Para instalar os utilitários NFS, execute o seguinte comando:</block>
  <block id="5ed0c66dfa2ac395ad8e9830aa5964aa" category="section-title">Instalar o Kubernetes</block>
  <block id="7a21958624d0a70f3a6b70bcf03ba09a" category="inline-link">Documentação do Kubespray</block>
  <block id="eb6273ed753aae187941e09aa142f02a" category="paragraph">Instale o Kubernetes em seus servidores usando o Kubespray.  Consulte o<block ref="1d9598782a4be0d8f1003429c1865811" category="inline-link-rx"></block> para mais detalhes.</block>
  <block id="b0583213f3e2e379b7dd549fd41f909f" category="section-title">Instalar o driver Trident CSI</block>
  <block id="c17b9b6d3e5d228bcc6c08edc3438f7f" category="inline-link">Documentação de instalação do Trident</block>
  <block id="1ba254856621ddad1eb72d0beee0001c" category="paragraph">Instale o driver NetApp Trident CSI no seu cluster Kubernetes.  Consulte o<block ref="0fa543c14587a20e022922b0d6d40500" category="inline-link-rx"></block> para mais detalhes.</block>
  <block id="cca56b6e3954004aac402213ce3054e6" category="section-title">Crie um back-end Trident</block>
  <block id="f95ebb45354495c835f81296b11e95c1" category="inline-link">Documentação de back-end do Trident</block>
  <block id="31f53fbd09b24f455b372567da98766f" category="paragraph">Crie um back-end Trident para o SVM que você criou anteriormente.  Ao criar seu back-end, use o<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block> motorista.  Consulte o<block ref="4b8fa33525637fa26acc3e336d80affb" category="inline-link-rx"></block> para mais detalhes.</block>
  <block id="14f4c7abe09c4481722f1fa6563f2604" category="section-title">Criar uma classe de armazenamento</block>
  <block id="bdecb047bffb568e0e8e84eeca503f89" category="paragraph">Crie uma classe de armazenamento do Kubernetes correspondente ao back-end do Trident que você criou na etapa anterior.  Consulte a documentação da classe de armazenamento Trident para obter detalhes.</block>
  <block id="6a61b11e836f0eeccddb33643f7aa4cd" category="inline-link">Implantação do Intel AI para Enterprise RAG</block>
  <block id="ba489bb61012c1097c380a06f7b20cbe" category="paragraph">Instale o OPEA para Intel AI for Enterprise RAG no seu cluster Kubernetes.  Consulte o<block ref="d6f70ce0ce5c9ddf0b1e28a93f0968a7" category="inline-link-rx"></block> documentação para mais detalhes.  Não deixe de anotar as modificações necessárias no arquivo de configuração, descritas mais adiante neste artigo.  Você deve fazer essas modificações antes de executar o manual de instalação para que o aplicativo Intel AI for Enterprise RAG funcione corretamente com seu sistema de armazenamento ONTAP .</block>
  <block id="cd806c912d9a85a913016682326e17bc" category="section-title">Habilitar o uso do ONTAP S3</block>
  <block id="4a65f719a33b2a0cdefdd371bc5b4aa9" category="paragraph">Ao instalar o OPEA para Intel AI for Enterprise RAG, edite seu arquivo de configuração principal para habilitar o uso do ONTAP S3 como seu repositório de dados de origem.</block>
  <block id="3bbecd0884a5e013f45ca28fdee8daf4" category="paragraph">Para habilitar o uso do ONTAP S3, defina os seguintes valores em<block ref="ed9bdb883dd5d0bf37bd5d208a17fadc" prefix=" " category="inline-code"></block> seção.</block>
  <block id="799685b83814ceb35225cd15c9221159" category="paragraph">Observação: por padrão, o aplicativo Intel AI for Enterprise RAG ingere dados de todos os buckets existentes no seu SVM.  Se você tiver vários buckets em seu SVM, poderá modificá-los<block ref="50d6f108d2717f6e9be4eae460e94414" prefix=" " category="inline-code"></block> campo para que os dados sejam ingeridos apenas de determinados buckets.</block>
  <block id="533e38d744354d370be3e86bd8fe8b28" category="section-title">Configurar as configurações de sincronização agendada</block>
  <block id="ad99b73b01de134452a17a0dfa32cec2" category="paragraph">Ao instalar o aplicativo OPEA para Intel AI for Enterprise RAG, habilite<block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block> para que o aplicativo ingira automaticamente arquivos novos ou atualizados dos seus buckets do S3.</block>
  <block id="c64dcda39c59bb872461bbb0e651a561" category="paragraph">Quando<block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block> estiver habilitado, o aplicativo verificará automaticamente seus buckets S3 de origem em busca de arquivos novos ou atualizados.  Todos os arquivos novos ou atualizados encontrados como parte desse processo de sincronização são automaticamente ingeridos e adicionados à base de conhecimento do RAG.  O aplicativo verifica seus buckets de origem com base em um intervalo de tempo predefinido.  O intervalo de tempo padrão é 60 segundos, o que significa que o aplicativo verifica alterações a cada 60 segundos.  Talvez você queira alterar esse intervalo para atender às suas necessidades específicas.</block>
  <block id="6d6914305f62085b3a9f416c96b4d127" category="paragraph">Para habilitar<block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block> e defina o intervalo de sincronização, defina os seguintes valores em<block ref="84bfd070139b7efc56f8e85ce50bc0b4" prefix=" " category="inline-code"></block></block>
  <block id="b9edd7aa680f588a01b814c4969d387b" category="section-title">Alterar modos de acesso de volume</block>
  <block id="2fe889d552298c286373b708cafda8e7" category="paragraph">Em<block ref="cd37fd54d9ac25bbfe45a164824d6194" prefix=" " category="inline-code"></block> , para cada volume no<block ref="642542e40351edbd731ebad352b31317" prefix=" " category="inline-code"></block> lista, altere o<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block> para<block ref="caa8dc1f4bb28d2d11226494cd05a123" prefix=" " category="inline-code"></block> .</block>
  <block id="edad21c5950d7e773534103192f18dd8" category="section-title">(Opcional) Desabilitar verificação de certificado SSL</block>
  <block id="6aaadab147a2227d76985e7ef0fc2680" category="paragraph">Se você usou um certificado autoassinado ao habilitar o acesso S3 para seu SVM, deverá desabilitar a verificação do certificado SSL.  Se você usou um certificado assinado por uma CA publicamente confiável, pode pular esta etapa.</block>
  <block id="2bb2c1d3d614a1de0e2e1e97fe3ac3c1" category="paragraph">Para desabilitar a verificação do certificado SSL, defina os seguintes valores em<block ref="84bfd070139b7efc56f8e85ce50bc0b4" prefix=" " category="inline-code"></block></block>
  <block id="dd88285a7105f2f3e6756070ae0535e2" category="section-title">Acesse OPEA para Intel AI for Enterprise RAG UI</block>
  <block id="123b51539e81bc36af05f29733939680" category="inline-link">Documentação de implantação do Intel AI for Enterprise RAG</block>
  <block id="c1b501f6d4c8c6a8616b9ca35cd2fc45" category="paragraph">Acesse o OPEA para Intel AI for Enterprise RAG UI.  Consulte o<block ref="746fad554462625e79393992880c7bc6" category="inline-link-rx"></block> para mais detalhes.</block>
  <block id="922ca547bcfcab30994177a3c1d383ae" category="paragraph">Figura 8 – UI OPEA para Intel AI for Enterprise RAG.<block ref="4cedb9bc094b7a9f8925870620118f64" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71b202e61cbdf7d879691cc22fff5944" category="section-title">Ingerir dados para RAG</block>
  <block id="1e5926c65c9a0919b7d73b19b2df9d53" category="paragraph">Agora você pode ingerir arquivos para inclusão no aumento de consulta baseado em RAG.  Há várias opções para ingestão de arquivos.  Escolha a opção apropriada para suas necessidades.</block>
  <block id="36dc767aab6b2ad698f45815826a1a29" category="paragraph">Observação: depois que um arquivo é ingerido, o aplicativo OPEA para Intel AI for Enterprise RAG verifica automaticamente se há atualizações no arquivo e as ingere adequadamente.</block>
  <block id="39ba5d380c5ff87759539eee68e65d99" category="paragraph">*Opção 1: Carregar diretamente para o seu bucket S3 Para ingerir muitos arquivos de uma vez, recomendamos carregar os arquivos para o seu bucket S3 (o bucket que você criou anteriormente) usando o cliente S3 de sua escolha.  Os clientes S3 populares incluem o AWS CLI, o Amazon SDK para Python (Boto3), s3cmd, S3 Browser, Cyberduck e Commander One.  Se os arquivos forem de um tipo compatível, todos os arquivos que você enviar para seu bucket S3 serão ingeridos automaticamente pelo aplicativo OPEA for Intel AI for Enterprise RAG.</block>
  <block id="e8c9e1c06420b69e589d260def731d88" category="paragraph">Observação: no momento em que este artigo foi escrito, os seguintes tipos de arquivo eram suportados: PDF, HTML, TXT, DOC, DOCX, PPT, PPTX, MD, XML, JSON, JSONL, YAML, XLS, XLSX, CSV, TIFF, JPG, JPEG, PNG e SVG.</block>
  <block id="bc974fb6199b9073fbf1026bd2d236d2" category="paragraph">Você pode usar o OPEA para Intel AI for Enterprise RAG UI para confirmar se seus arquivos foram ingeridos corretamente.  Consulte a documentação da interface de usuário Intel AI for Enterprise RAG para obter detalhes.  Observe que pode levar algum tempo para o aplicativo ingerir um grande número de arquivos.</block>
  <block id="25ce0ebd12d3573d98440a5151efd06e" category="paragraph">*Opção 2: Carregar usando a interface do usuário. Se você precisar ingerir apenas um pequeno número de arquivos, poderá ingeri-los usando a interface do usuário do OPEA para Intel AI for Enterprise RAG.  Consulte a documentação da interface de usuário Intel AI for Enterprise RAG para obter detalhes.</block>
  <block id="aad57997fffb9169edca9049f6c408fc" category="paragraph">Figura 9 - Interface de usuário de ingestão de dados.<block ref="55969be455b6eb9c434a32c9edf9a19f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1aab14042462d545cbc81ccbd5144183" category="section-title">Executar consultas de bate-papo</block>
  <block id="37afbf2924fcb8ec313cd060eae9317c" category="paragraph">Agora você pode "conversar" com o aplicativo OPEA for Intel AI for Enterprise RAG usando a interface de bate-papo incluída.  Ao responder às suas perguntas, o aplicativo executa o RAG usando seus arquivos ingeridos.  Isso significa que o aplicativo busca automaticamente informações relevantes dentro dos seus arquivos ingeridos e incorpora essas informações ao responder às suas consultas.</block>
  <block id="2ed19e65997a81f69c25a47d5bf28407" category="paragraph">Como parte do nosso esforço de validação, conduzimos testes de desempenho em coordenação com a Intel.  Esse teste resultou nas orientações de dimensionamento descritas na tabela a seguir.</block>
  <block id="b0e166baec472090eb9b8fe69dd5736a" category="cell">Caracterizações</block>
  <block id="689202409e48743b914713f96d93947c" category="cell">Valor</block>
  <block id="a48c8e3a66454b67fa81ad9e940c8b27" category="cell">Tamanho do modelo</block>
  <block id="4f4ccdf1d741c3c95db91bbc2930fb82" category="cell">20 bilhões de parâmetros</block>
  <block id="9be9211aab4b7a1e7b93895b22cac265" category="cell">Lhama-8B, Lhama-13B, Mistral 7B, Qwen 14B, DeepSeek Distill 8B</block>
  <block id="5b176800a4fa5f818733bbc47bf50c58" category="cell">Tamanho da entrada</block>
  <block id="5da438d3d127ea08ac04b3ad27565f86" category="cell">~2 mil tokens</block>
  <block id="ec110f5087b1200011dcf2f34914001b" category="cell">~4 páginas</block>
  <block id="2e422b9da98e2d0a7b8c31aa22986312" category="cell">Tamanho da saída</block>
  <block id="0de7dbc3b2f780207078fda7fe5f5312" category="cell">Usuários simultâneos</block>
  <block id="2dda44ea1754f4e550f1a5cc97bd2f88" category="cell">"Usuários simultâneos" referem-se a solicitações rápidas que enviam consultas ao mesmo tempo.</block>
  <block id="e8d9bc5e8e6b28217a5661b56a0ce38d" category="paragraph">_Observação: as orientações de dimensionamento apresentadas acima são baseadas na validação de desempenho e nos resultados de testes coletados usando processadores Intel Xeon 6 com 96 núcleos.  Para clientes com tokens de E/S e requisitos de tamanho de modelo semelhantes, recomendamos usar servidores com processadores Xeon 6 com 96 ou 128 núcleos.</block>
  <block id="d83a33143fe76973b5528ae0d2b5750c" category="paragraph">Os sistemas RAG empresariais e LLMs são tecnologias que trabalham juntos para ajudar as organizações a fornecer respostas precisas e contextualizadas.  Essas respostas envolvem recuperação de informações com base em uma vasta coleção de dados empresariais privados e internos.  Ao usar RAG, APIs, embeddings de vetores e sistemas de armazenamento de alto desempenho para consultar repositórios de documentos que contêm dados da empresa, os dados são processados de forma mais rápida e segura.  O NetApp AIPod Mini combina a infraestrutura de dados inteligente da NetApp com recursos de gerenciamento de dados ONTAP e processadores Intel Xeon 6, Intel AI for Enterprise RAG e a pilha de software OPEA para ajudar a implantar aplicativos RAG de alto desempenho e colocar as organizações no caminho da liderança em IA.</block>
  <block id="37bea4d3bbce78210e52efa42aff98fc" category="section-title">Reconhecimento</block>
  <block id="9d17f4dbd111838ecf2ecb0306f6c255" category="paragraph">Este documento é trabalho de Sathish Thyagarajan e Michael Ogelsby, membros da equipe de engenharia de soluções da NetApp .  Os autores também gostariam de agradecer à equipe de produtos de IA empresarial da Intel — Ajay Mungara, Mikolaj Zyczynski, Igor Konopko, Ramakrishna Karamsetty, Michal Prostko, Shreejan Mistry e Ned Fiori — e outros membros da equipe da NetApp— Lawrence Bunka, Bobby Oommen e Jeff Liborio — por seu suporte e ajuda contínuos durante a validação desta solução.</block>
  <block id="638409a97591a74cbaf8ecaac7bc356a" category="section-title">Lista de materiais</block>
  <block id="faf3c2849bae24ab9045ae5add024400" category="paragraph">A seguir está a lista de materiais usada para a validação funcional desta solução e pode ser usada como referência.  Qualquer servidor ou componente de rede (ou mesmo uma rede existente com largura de banda preferencialmente de 100 GbE) que esteja alinhado com a seguinte configuração pode ser usado.</block>
  <block id="74953ad13674266e8135ca232d6d7d5d" category="paragraph">Para o servidor de aplicativos:</block>
  <block id="6737192650f0c3a81629128ea7774174" category="cell">*Número da peça*</block>
  <block id="eb6fa4e6fed41e388b4d654a174c1b82" category="cell">*Descrição do produto*</block>
  <block id="a3b91229cc5a5eb0d50908cc956824b3" category="cell">222HA-TN-OTO-37</block>
  <block id="2302a4ae44cddff506100b112f4645c6" category="cell">Hyper SuperServer SYS-222HA-TN /2U</block>
  <block id="e53619c1fe611a51eeeb8d148ba6e532" category="cell">BATER</block>
  <block id="673b9923dda6787459c6a0ae7f711593" category="cell">MEM-DR564MC-ER64(x16)64GB DDR5-6400 2RX4 (16Gb) ECC RDIMM</block>
  <block id="0be247e8eaad16189d4e7ce0829add7a" category="cell">HDS-M2N4-960G0-E1-TXD-NON-080(x2) SSD M.2 NVMe PCIe4 960GB 1DWPD TLC D, 80mm</block>
  <block id="c3ca791a9361b57a8fa217067084b891" category="cell">Fonte de alimentação redundante de saída única WS-1K63A-1R(x2)1U 692W/1600W.  Dissipação de calor de 2361 BTU/h com temperatura máxima de 59 °C (aprox.)</block>
  <block id="7d83e48371fe2b2bd396527bf08497f1" category="paragraph">Para o servidor de controle:</block>
  <block id="4bf51ddd79708218d2ca40addbf3f2fb" category="cell">511R-M-OTO-17</block>
  <block id="870f227b084b6f0c047a533d218e9874" category="cell">OTIMIZADO UP 1U X13SCH-SYS, CSE-813MF2TS-R0RCNBP, PWS-602A-1R</block>
  <block id="7c3e6ed807c306444b3bddd7fc90cb2a" category="cell">MEM-DR516MB-EU48(x2)16GB DDR5-4800 1Rx8 (16Gb) ECC UDIMM</block>
  <block id="c104b47ab1794697f8c929d251599740" category="paragraph">Para o switch de rede:</block>
  <block id="1bf595c07879a3e4909b5196570ee253" category="cell">DCS-7280CR3A</block>
  <block id="60e4b729f0a2b5471a6c6209bc49aac5" category="cell">Arista 7280R3A 28x100 GbE</block>
  <block id="40f46282e86b9c228e0cce6e2011f35c" category="paragraph">Armazenamento NetApp AFF :</block>
  <block id="39ff721f18a3edbb373a8c8f54cd3f14" category="cell">AFF-A20A-100-C</block>
  <block id="c133ed5a1928378c2f6a29bf6b6f1135" category="cell">Sistema AFF A20 HA, -C</block>
  <block id="52b142796a871ab98369e293ae4d91c2" category="cell">X800-42U-R6-C</block>
  <block id="c6b0cc56d77c17a08efb3742ab92e776" category="cell">Jumper Crd, na cabine, C13-C14, -C</block>
  <block id="128bdeded7a535e68b0f98e463111407" category="cell">X97602A-C</block>
  <block id="f14bf71f2d74fbf0d0560b5a355bbf63" category="cell">Fonte de alimentação, 1600 W, titânio, -C</block>
  <block id="2a0cfc5d71abb55759a510240510f87a" category="cell">X66211B-2-N-C</block>
  <block id="d50feb7d1470a9fb63d75f5a39b4b8bd" category="cell">Cabo, 100GbE, QSFP28-QSFP28, Cu, 2m, -C</block>
  <block id="9d4b1f9c3df948f2260e6332be9d5aed" category="cell">X66240A-05-N-C</block>
  <block id="7229ff7ba1f700db7ec3bd4b5221db26" category="cell">Cabo, 25GbE, SFP28-SFP28, Cu, 0,5m, -C</block>
  <block id="1ab2d2badc8592e1d029782bd25632a5" category="cell">X5532A-N-C</block>
  <block id="4688dd909d449010ca4b23347351a707" category="cell">Trilho, 4 postes, fino, furo quadrado/redondo, pequeno, ajuste, 24-32, -C</block>
  <block id="b24ac50247ba189d666fdae929cede64" category="cell">X4024A-2-A-C</block>
  <block id="25630a46b821a822994c9b1e0dd238d5" category="cell">Pacote de unidade 2X1,92 TB, NVMe4, SED, -C</block>
  <block id="326b6bb4ee61f9700e237d78e0a70b27" category="cell">X60130A-C</block>
  <block id="f2acaac754bf0c08463a09096b25ebd5" category="cell">Módulo IO, 2PT, 100GbE, -C</block>
  <block id="826f0d850b56b5bcd6026118ee4048b5" category="cell">X60132A-C</block>
  <block id="f567279f3d616d5bcfbd134b1e39b047" category="cell">Módulo IO, 4PT, 10/25GbE, -C</block>
  <block id="7090ee7c22ea0bf45e028538870d276f" category="cell">SW-ONTAPB-FLASH-A20-C</block>
  <block id="c2375e9a630d78f92c99f36859f2dc63" category="cell">SW, pacote base ONTAP , por TB, Flash, A20, -C</block>
  <block id="37693cfc748049e45d87b8c7d8b9aacd" category="cell">23</block>
  <block id="1006bcc3d9e9f1297760c57c62541267" category="paragraph"><block ref="1006bcc3d9e9f1297760c57c62541267" category="inline-link-rx"></block></block>
  <block id="9bf497d692d0e146d05a76e3a34ae95f" category="inline-link-macro">Projeto OPEA</block>
  <block id="feeb32cac2847bc01bfab8eb7dfbbbfe" category="paragraph"><block ref="feeb32cac2847bc01bfab8eb7dfbbbfe" category="inline-link-macro-rx"></block></block>
  <block id="a64127d2271b6c8ff07ae84c3a53c90c" category="inline-link">Manual de implantação do OPEA Enterprise RAG</block>
  <block id="3d766654d6f2d85f314e655c63e91d81" category="paragraph"><block ref="3d766654d6f2d85f314e655c63e91d81" category="inline-link-rx"></block></block>
  <block id="a5e99aa2ffae2218fdcf2038b1b3fd1b" category="doc">TR-4851: Data lake NetApp StorageGRID para cargas de trabalho de direção autônoma - Design de solução</block>
  <block id="981ed5a5ebc4fbc2a64f69a42d9ef36c" category="paragraph">David Arnette, NetApp</block>
  <block id="0e2b7ed1591c52ac15ea956ecb6a5701" category="paragraph">O TR-4851 demonstra o uso do armazenamento de objetos NetApp StorageGRID como um repositório de dados e sistema de gerenciamento para desenvolvimento de software de aprendizado de máquina (ML) e aprendizado profundo (DL).  Este artigo descreve o fluxo de dados e os requisitos no desenvolvimento de software para veículos autônomos e os recursos do StorageGRID que otimizam o ciclo de vida dos dados.  Esta solução se aplica a qualquer fluxo de trabalho de pipeline de dados de vários estágios típico em processos de desenvolvimento de ML e DL.</block>
  <block id="ba9a0dcacc73fb54c527ad33eceb30c1" category="paragraph"><block ref="ba9a0dcacc73fb54c527ad33eceb30c1" category="inline-link-macro-rx"></block></block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">Avisos legais</block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="paragraph">Avisos legais fornecem acesso a declarações de direitos autorais, marcas registradas, patentes e muito mais.</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">Direitos autorais</block>
  <block id="52009bb7ee17227f566cd26a02caee56" category="inline-link-macro"><block ref="52009bb7ee17227f566cd26a02caee56" category="inline-link-rx"></block></block>
  <block id="a1a9afcf552a769c282769271829889a" category="paragraph"><block ref="a1a9afcf552a769c282769271829889a" category="inline-link-macro-rx"></block></block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">Marcas Registradas</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NETAPP, o logotipo da NETAPP e as marcas listadas na página de Marcas Registradas da NetApp são marcas registradas da NetApp, Inc. Outros nomes de empresas e produtos podem ser marcas registradas de seus respectivos proprietários.</block>
  <block id="f99aa604031e5049799e73b5c3748a98" category="inline-link-macro"><block ref="f99aa604031e5049799e73b5c3748a98" category="inline-link-rx"></block></block>
  <block id="5d545fe5152641e2ebe654e336e520e5" category="paragraph"><block ref="5d545fe5152641e2ebe654e336e520e5" category="inline-link-macro-rx"></block></block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">Patentes</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">Uma lista atual de patentes de propriedade da NetApp pode ser encontrada em:</block>
  <block id="88e5eabd3917048b6927c42496b98f86" category="inline-link-macro"><block ref="88e5eabd3917048b6927c42496b98f86" category="inline-link-rx"></block></block>
  <block id="dd38f906b37d412de7d1c1dcf4cbf31c" category="paragraph"><block ref="dd38f906b37d412de7d1c1dcf4cbf31c" category="inline-link-macro-rx"></block></block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">Política de Privacidade</block>
  <block id="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-macro"><block ref="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-rx"></block></block>
  <block id="2352c4e1f4d0024ade0869e00e6243f4" category="paragraph"><block ref="2352c4e1f4d0024ade0869e00e6243f4" category="inline-link-macro-rx"></block></block>
  <block id="91bc87f1c8c087219cec868bb9eec3e7" category="summary">Para esta validação, realizamos inferência para um caso de uso de detecção de imagem usando um conjunto de imagens brutas.  Em seguida, realizamos a mesma tarefa de inferência no mesmo conjunto de imagens com ofuscação Protopia adicionada antes da inferência.  Repetimos a tarefa usando diferentes valores de ALPHA para o componente de ofuscação Protopia.</block>
  <block id="f63c4677c27e0489f346c0711720cc39" category="doc">Comparação de precisão de inferência</block>
  <block id="0c71eb4e1fba60fba81db988197da57d" category="paragraph">Para esta validação, realizamos inferência para um caso de uso de detecção de imagem usando um conjunto de imagens brutas.  Em seguida, realizamos a mesma tarefa de inferência no mesmo conjunto de imagens com ofuscação Protopia adicionada antes da inferência.  Repetimos a tarefa usando diferentes valores de ALPHA para o componente de ofuscação Protopia.  No contexto da ofuscação Protopia, o valor ALFA representa a quantidade de ofuscação aplicada, com um valor ALFA mais alto representando um nível mais alto de ofuscação.  Em seguida, comparamos a precisão da inferência entre essas diferentes execuções.</block>
  <block id="93d52a2c23957d4188c7b2ce8b2ae884" category="paragraph">As duas tabelas a seguir fornecem detalhes sobre nosso caso de uso e descrevem os resultados.</block>
  <block id="65a3419ae19e457df9db4c0e110b2538" category="paragraph">A Protopia trabalha diretamente com os clientes para determinar o valor ALPHA apropriado para um caso de uso específico.</block>
  <block id="e558777bd1568637c97294a33389e930" category="cell">FaceBoxes (PyTorch) -</block>
  <block id="20172a059ee71423ad0d94393e819e10" category="cell">Conjunto de dados FDDB</block>
  <block id="06a8fb4576a28a6488c929097c870fe1" category="cell">Ofuscação de Protopia</block>
  <block id="002101f8725e5c78d9f30d87f3fa4c87" category="cell">ALFA</block>
  <block id="d78f1fb7e69f7cddcf3e168f2663db20" category="cell">Precisão</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">Não</block>
  <block id="382b0f5185773fa0f67a8ed8056c7759" category="cell">N / D</block>
  <block id="646738dcd35eaf5c3f3c9bfdc6a90b78" category="cell">0,9337148153739079</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">Sim</block>
  <block id="b14399cbaac6da4b5b733b483106383f" category="cell">0,05</block>
  <block id="bcf8c22771ff8c7065180f5a6526d4a6" category="cell">0,9028766627325002</block>
  <block id="cb5ae17636e975f9bf71ddf5bc542075" category="cell">0,1</block>
  <block id="1336b1cb08d93aa0a453c53e27efa594" category="cell">0,9024301009661478</block>
  <block id="3d522deaf85577451c01974654b36ad3" category="cell">0,2</block>
  <block id="b1cb1b288bfae3850c74795f5691dc4e" category="cell">0,9081836283186224</block>
  <block id="54fbf38cf649866815e0fefc46a1f6c7" category="cell">0,4</block>
  <block id="b9e8c964d5c5d3e7c815896cd6235239" category="cell">0,9073066107482036</block>
  <block id="e95e1ca27d0e39aa03eb5a611ce4122f" category="cell">0,6</block>
  <block id="57489d9101ec373d9e2841292a5b3af9" category="cell">0,8847816568680239</block>
  <block id="57eeec0a6974ecb4e9fcf68fab052f7b" category="cell">0,8</block>
  <block id="8ab8d7756b82eb70d635bc66c1bc532b" category="cell">0,8841195749171925</block>
  <block id="a894124cc6d5c5c71afe060d5dde0762" category="cell">0,9</block>
  <block id="226cc0951c1f30973a4c71f0f567936a" category="cell">0,8455427675252052</block>
  <block id="248a7444f08189bb31ba143eabebe4e5" category="cell">0,95</block>
  <block id="cf285ec96f684d6597b7ffbbfcf16197" category="doc">Onde encontrar informações adicionais e agradecimentos</block>
  <block id="89f170193efdf8434f549c8e91adf860" category="list-text">Protopia AI — Inferência Confidencial</block>
  <block id="62faa8d62bfb6098877b809cce925de5" category="inline-link"><block ref="62faa8d62bfb6098877b809cce925de5" category="inline-link-rx"></block></block>
  <block id="45b79877f4c11139882c88df94d50fa6" category="paragraph"><block ref="45b79877f4c11139882c88df94d50fa6" category="inline-link-rx"></block></block>
  <block id="2c5e74d45708e2fae638e03f88353b75" category="list-text">Servidor de inferência NVIDIA Triton</block>
  <block id="2c54e28a12ce15452929a28550a30a96" category="inline-link"><block ref="2c54e28a12ce15452929a28550a30a96" category="inline-link-rx"></block></block>
  <block id="bc5345c4517d46bdf8a87f10d404839f" category="paragraph"><block ref="bc5345c4517d46bdf8a87f10d404839f" category="inline-link-rx"></block></block>
  <block id="fba4b133e329411c361e02e05efed0b9" category="list-text">Documentação do servidor de inferência NVIDIA Triton</block>
  <block id="cce40efbd4a717916ccbab694b676e9c" category="inline-link"><block ref="cce40efbd4a717916ccbab694b676e9c" category="inline-link-rx"></block></block>
  <block id="170ba65f4e4807f3643de39afb3f2e16" category="paragraph"><block ref="170ba65f4e4807f3643de39afb3f2e16" category="inline-link-rx"></block></block>
  <block id="ba1d5cc71378020998752955821460b2" category="list-text">FaceBoxes em PyTorch</block>
  <block id="ace8d80d2ede0fadf07325408b376b83" category="inline-link"><block ref="ace8d80d2ede0fadf07325408b376b83" category="inline-link-rx"></block></block>
  <block id="a688d324b63c4f882d06673058aa2f61" category="paragraph"><block ref="a688d324b63c4f882d06673058aa2f61" category="inline-link-rx"></block></block>
  <block id="121ef407a6a3c08ce9fa247e382d7637" category="list-text">Mark Cates, gerente de produtos principal, NetApp</block>
  <block id="fb345adb43ea24ffc891d20327bdca09" category="list-text">Sufian Ahmad, engenheiro técnico de marketing, NetApp</block>
  <block id="711ba3fec382e550526a6ab0f49bdf3a" category="list-text">Hadi Esmaeilzadeh, Diretor de Tecnologia e Professor, Protopia AI</block>
  <block id="cd24a85c5cf2d1a7af0bade6066be0aa" category="summary">Os dados existem em três estados: em repouso, em trânsito e em computação.  Uma parte importante de qualquer serviço de inferência de IA deve ser a proteção de dados contra ameaças durante todo o processo.  Proteger dados durante a inferência é essencial porque o processo pode expor informações privadas sobre clientes externos e a empresa que fornece o serviço de inferência.</block>
  <block id="cd9ef21e97d9c9e701bfc6d1a77634d5" category="paragraph">Os dados existem em três estados: em repouso, em trânsito e em computação.  Uma parte importante de qualquer serviço de inferência de IA deve ser a proteção de dados contra ameaças durante todo o processo.  Proteger dados durante a inferência é essencial porque o processo pode expor informações privadas sobre clientes externos e a empresa que fornece o serviço de inferência.  Protopia AI é uma solução de software não intrusiva para inferência confidencial de IA no mercado atual.  Com o Protopia, a IA é alimentada apenas com as informações transformadas nos registros de dados que são essenciais para executar a tarefa de IA/ML em questão e nada mais.  Essa transformação estocástica não é uma forma de mascaramento e se baseia na alteração matemática da representação dos dados usando ruído selecionado.</block>
  <block id="945691f1b395ce7af4d5e818b4e62b9b" category="paragraph">Os sistemas de armazenamento NetApp com recursos ONTAP oferecem o mesmo desempenho ou melhor que o armazenamento SSD local e, combinados com o NetApp DataOps Toolkit, oferecem os seguintes benefícios para cientistas de dados, engenheiros de dados, desenvolvedores de IA/ML e tomadores de decisões de TI empresariais ou empresariais:</block>
  <block id="2d1d64cb5768a8ce2a6d6bda322d2ecd" category="list-text">Proteção de dados de nível empresarial e governança de dados para recuperação de desastres, continuidade de negócios e requisitos regulatórios.</block>
  <block id="58b8e67477c25a96d3b430f4ee8d75cf" category="list-text">Invocação simplificada de operações de gerenciamento de dados; faça rapidamente cópias instantâneas dos espaços de trabalho dos cientistas de dados para backup e rastreabilidade do NetApp DataOps Toolkit em notebooks Jupyter.</block>
  <block id="57e858ddb0a3e1c340cfe4ba7d5c3a14" category="paragraph">A solução NetApp e Protopia fornece uma arquitetura flexível e escalável, ideal para implantações de inferência de IA de nível empresarial.  Ele permite a proteção de dados e fornece privacidade para informações confidenciais, onde os requisitos confidenciais de inferência de IA podem ser atendidos com práticas de IA responsáveis em implantações locais e em nuvem híbrida.</block>
  <block id="a41206687a4ac62c15fc883554a75883" category="summary">Esta seção descreve o ambiente de validação do design da solução.</block>
  <block id="0d013965bb31fe1cc0ba44ef3b846d09" category="paragraph">A tabela a seguir descreve o ambiente de validação do design da solução.</block>
  <block id="30136395f01879792198317c11831ea4" category="cell">Kubernetes</block>
  <block id="32f014d18e1f60596057834de2864322" category="cell">1.21.6</block>
  <block id="8b2b11d27dd7d347de30cae2db2ab86d" category="cell">Driver NetApp Trident CSI</block>
  <block id="8e232cd005846e0f66f39f19aa03103c" category="cell">22.01.0</block>
  <block id="297924c1d3fec9d97f9a1f3b49ee0709" category="cell">Kit de ferramentas NetApp DataOps para Kubernetes</block>
  <block id="70e2b24f7d348efe6b30b41469d5070c" category="cell">2.3.0</block>
  <block id="099d96b4d8f70fb73f1d4661f98c337a" category="cell">21.11-py3</block>
  <block id="6d01d0026564c98aa0d6274cd39c586a" category="summary">Este documento descreve uma solução de design validada em três cenários diferentes, com e sem ofuscação de imagem, relevantes para preservar a privacidade e implantar uma solução de IA responsável.</block>
  <block id="236e54165aafef697c2c82c667e05d36" category="doc">TR-4928: IA responsável e inferência confidencial - NetApp AI com Protopia Transformação de Imagem e Dados</block>
  <block id="0bbb7f0a0d464779fc0832c366f3a4e7" category="paragraph">Sathish Thyagarajan, Michael Oglesby, NetApp Byung Hoon Ahn, Jennifer Cwagenberg, Protopia</block>
  <block id="c110f3156d66710a207ebd7135164ec1" category="paragraph">As interpretações visuais se tornaram parte integrante da comunicação com o surgimento da captura e do processamento de imagens.  A inteligência artificial (IA) no processamento de imagens digitais traz novas oportunidades de negócios, como na área médica para identificação de câncer e outras doenças, em análises visuais geoespaciais para estudar riscos ambientais, em reconhecimento de padrões, em processamento de vídeo para combater o crime e assim por diante.  No entanto, essa oportunidade também traz responsabilidades extraordinárias.</block>
  <block id="0159205b6d54375adfabd56a2258fcb9" category="paragraph">Quanto mais decisões as organizações colocam nas mãos da IA, mais elas aceitam riscos relacionados à privacidade e segurança de dados e a questões legais, éticas e regulatórias.  A IA responsável possibilita uma prática que permite que empresas e organizações governamentais criem confiança e governança, o que é crucial para a IA em escala em grandes empresas.  Este documento descreve uma solução de inferência de IA validada pela NetApp em três cenários diferentes usando tecnologias de gerenciamento de dados da NetApp com o software de ofuscação de dados Protopia para privatizar dados confidenciais e reduzir riscos e preocupações éticas.</block>
  <block id="fade8b24490b0ba74a7ffa05d3f8631a" category="paragraph">Milhões de imagens são geradas todos os dias com vários dispositivos digitais, tanto por consumidores quanto por entidades empresariais.  A consequente explosão massiva de dados e carga de trabalho computacional faz com que as empresas recorram às plataformas de computação em nuvem para obter escala e eficiência.  Enquanto isso, preocupações com a privacidade das informações confidenciais contidas nos dados de imagem surgem com a transferência para uma nuvem pública.  A falta de garantias de segurança e privacidade se torna a principal barreira para a implantação de sistemas de IA de processamento de imagens.</block>
  <block id="e9ac7ec9dd27fe52477986ab1dccbcae" category="inline-link">direito ao apagamento</block>
  <block id="49dca35d3e0662046425327194fd8965" category="inline-link">Lei de Privacidade</block>
  <block id="f615b294f87bd53494e01691ab95c654" category="paragraph">Além disso, há o<block ref="ac9ac606204db63758cb1efd6e89e43e" category="inline-link-rx"></block> pelo GDPR, o direito de um indivíduo solicitar que uma organização apague todos os seus dados pessoais.  Há também o<block ref="fd57f794f9c27951b4a5b543db96bdb6" category="inline-link-rx"></block> , que estabelece um código de práticas justas de informação.  Imagens digitais, como fotografias, podem constituir dados pessoais de acordo com o GDPR, que rege como os dados devem ser coletados, processados e apagados.  Não fazer isso é uma falha em cumprir o GDPR, o que pode levar a multas pesadas por violação de conformidades, o que pode ser seriamente prejudicial às organizações.  Os princípios de privacidade estão entre a espinha dorsal da implementação de IA responsável que garante justiça nas previsões de modelos de aprendizado de máquina (ML) e aprendizado profundo (DL) e reduz os riscos associados à violação de privacidade ou conformidade regulatória.</block>
  <block id="d365f4ef3ed2b414236f81df850880a3" category="paragraph">Este documento descreve uma solução de design validada em três cenários diferentes, com e sem ofuscação de imagem, relevantes para preservar a privacidade e implantar uma solução de IA responsável:</block>
  <block id="bd12a6b0ed0be7808c1e30b1e360bee6" category="list-text">*Cenário 1.*  Inferência sob demanda no notebook Jupyter.</block>
  <block id="bf93b5af78256f2e49d2c0351133b08d" category="list-text">*Cenário 2.*  Inferência em lote no Kubernetes.</block>
  <block id="d5a10e810e1d293a064388e4980bde15" category="list-text">*Cenário 3.*  Servidor de inferência NVIDIA Triton.</block>
  <block id="870f1cf4b101c66b438e8dd024f24118" category="paragraph">Para esta solução, usamos o Face Detection Data Set and Benchmark (FDDB), um conjunto de dados de regiões faciais projetado para estudar o problema de detecção facial irrestrita, combinado com a estrutura de aprendizado de máquina PyTorch para implementação de FaceBoxes.  Este conjunto de dados contém as anotações de 5171 rostos em um conjunto de 2845 imagens de várias resoluções.  Além disso, este relatório técnico apresenta algumas das áreas de solução e casos de uso relevantes coletados de clientes e engenheiros de campo da NetApp em situações em que esta solução é aplicável.</block>
  <block id="e28a169eb64ee1d32c878a26595922f0" category="paragraph">Este relatório técnico destina-se aos seguintes públicos:</block>
  <block id="167e9693dfa764051f26b64ec22356a9" category="list-text">Líderes empresariais e arquitetos corporativos que desejam projetar e implementar IA responsável e abordar questões de proteção de dados e privacidade relacionadas ao processamento de imagens faciais em espaços públicos.</block>
  <block id="304e871b0b1ea55fe3e4f07ead7a7d42" category="list-text">Cientistas de dados, engenheiros de dados, pesquisadores de IA/aprendizado de máquina (ML) e desenvolvedores de sistemas de IA/ML que visam proteger e preservar a privacidade.</block>
  <block id="dcf26996b3ab9f385a95f72c1d0a0dce" category="list-text">Arquitetos corporativos que projetam soluções de ofuscação de dados para modelos e aplicativos de IA/ML que estão em conformidade com padrões regulatórios como GDPR, CCPA ou a Lei de Privacidade do Departamento de Defesa (DoD) e organizações governamentais.</block>
  <block id="bb6887ed7c7b07cbb7bd3ec71f951e6f" category="list-text">Cientistas de dados e engenheiros de IA buscam maneiras eficientes de implantar modelos de aprendizado profundo (DL) e inferência de IA/ML/DL que protejam informações confidenciais.</block>
  <block id="69adf8f52a6229e7062bda4b2b9679fb" category="paragraph">Esta solução foi projetada para lidar com cargas de trabalho de IA de inferência em lote e em tempo real em grandes conjuntos de dados usando o poder de processamento de GPUs junto com CPUs tradicionais.  Esta validação demonstra a inferência de preservação de privacidade para ML e o gerenciamento ideal de dados necessários para organizações que buscam implantações de IA responsáveis.  Esta solução fornece uma arquitetura adequada para uma plataforma Kubernetes de nó único ou múltiplo para computação de ponta e em nuvem interconectada com o NetApp ONTAP AI no núcleo local, o NetApp DataOps Toolkit e o software de ofuscação Protopia usando interfaces Jupyter Lab e CLI.  A figura a seguir mostra a visão geral da arquitetura lógica da malha de dados fornecida pela NetApp com o DataOps Toolkit e o Protopia.</block>
  <block id="28afcbd6e097b781313de9c75adccb13" category="paragraph"><block ref="28afcbd6e097b781313de9c75adccb13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7dfea85fd355e4966805c3504348aa8b" category="paragraph">O software de ofuscação Protopia é executado perfeitamente no NetApp DataOps Toolkit e transforma os dados antes de saírem do servidor de armazenamento.</block>
  <block id="46ded0be5f6c48090d38435b6dafa3e2" category="summary">Esta seção fornece uma visão geral dos três cenários validados nesta solução.</block>
  <block id="71446ef316489c70b5279867eb81a86b" category="doc">Plano de teste e validação</block>
  <block id="68cdc250e271cc43502e5f009d0ebec7" category="paragraph">Para o projeto desta solução, foram validados os três cenários a seguir:</block>
  <block id="83c38d8dc6bc37fe6bb9691e75d0f881" category="list-text">Uma tarefa de inferência, com e sem ofuscação do Protopia, dentro de um espaço de trabalho do JupyterLab que foi orquestrada usando o NetApp DataOps Toolkit para Kubernetes.</block>
  <block id="da4ec54ac3b4b67b77d52ccf0ebaefc0" category="list-text">Um trabalho de inferência em lote, com e sem ofuscação do Protopia, no Kubernetes com um volume de dados que foi orquestrado usando o NetApp DataOps Toolkit para Kubernetes.</block>
  <block id="5526e24c695504cfa8b2187b0a3da212" category="list-text">Uma tarefa de inferência usando uma instância do NVIDIA Triton Inference Server que foi orquestrada usando o NetApp DataOps Toolkit para Kubernetes.  Aplicamos a ofuscação Protopia à imagem antes de invocar a API de inferência Triton para simular o requisito comum de que todos os dados transmitidos pela rede devem ser ofuscados.  Este fluxo de trabalho é aplicável a casos de uso em que os dados são coletados dentro de uma zona confiável, mas devem ser passados para fora dessa zona confiável para inferência.  Sem a ofuscação do Protopia, não é possível implementar esse tipo de fluxo de trabalho sem que dados confidenciais saiam da zona confiável.</block>
  <block id="6bee97571af49e4c38ff85a4abbbe0e9" category="summary">Esta seção descreve as tarefas necessárias para concluir a validação.</block>
  <block id="ee68e5b99222bbc29a480fcb0d1d6ee2" category="section-title">Pré-requisitos</block>
  <block id="df06a8aa3d194f798e70c253c55d915c" category="paragraph">Para executar as tarefas descritas nesta seção, você deve ter acesso a um host Linux ou macOS com as seguintes ferramentas instaladas e configuradas:</block>
  <block id="c0ffe26d3756a5c964ff9bc591e1fc16" category="list-text">Kubectl (configurado para acesso a um cluster Kubernetes existente)</block>
  <block id="e436fe7c4ecfcca0f0327b41471955df" category="list-text">As instruções de instalação e configuração podem ser encontradas<block ref="f6d4f9e359e394de0cb3015a4518672c" category="inline-link-rx"></block> .</block>
  <block id="e3e34254666d96b8967227676b54e135" category="list-text">As instruções de instalação podem ser encontradas<block ref="9535953c30e005e9672e48b24a3ac733" category="inline-link-rx"></block> .</block>
  <block id="1a66086f406852b100e9d8f85d007b87" category="section-title">Cenário 1 – Inferência sob demanda no JupyterLab</block>
  <block id="28876e2d40a33fcbc3630d7408b14046" category="list-text">Crie um namespace do Kubernetes para cargas de trabalho de inferência de IA/ML.</block>
  <block id="1464ad61957a8ed3db5f67edbc20cc41" category="list-text">Use o NetApp DataOps Toolkit para provisionar um volume persistente para armazenar os dados nos quais você executará a inferência.</block>
  <block id="da33a6119aa0b49526bd284e9a865ed5" category="list-text">Use o NetApp DataOps Toolkit para criar um novo espaço de trabalho do JupyterLab.  Monte o volume persistente que foi criado na etapa anterior usando o<block ref="49477e975a03ac8fbc68aea44a67d49d" prefix=" " category="inline-code"></block> opção.  Aloque GPUs NVIDIA para o espaço de trabalho conforme necessário usando o<block ref="dfc4755b60ee7dfab3c1e88693efd099" prefix=" " category="inline-code"></block> opção.</block>
  <block id="810e88d69a6b7f454f24db3a25ba375a" category="paragraph">No exemplo a seguir, o volume persistente<block ref="682303bbf677ac9a205caf2d086b33d3" prefix=" " category="inline-code"></block> é montado no contêiner do espaço de trabalho JupyterLab em<block ref="a88bf20c35f897f8c2c3a03189e90c09" prefix=" " category="inline-code"></block> .  Ao usar imagens oficiais do contêiner do Projeto Jupyter,<block ref="3b8e9b793a1a95056575343e279719df" prefix=" " category="inline-code"></block> é apresentado como o diretório de nível superior dentro da interface web do JupyterLab.</block>
  <block id="ecca64929aad192e0cdba66d89af6fc2" category="list-text">Acesse o espaço de trabalho do JupyterLab usando o URL especificado na saída do<block ref="d9eb9b67c69b49a1b002e09de33d9ed9" prefix=" " category="inline-code"></block> comando.  O diretório de dados representa o volume persistente que foi montado no espaço de trabalho.</block>
  <block id="87209231def3204e4e4d9a18544294dd" category="paragraph"><block ref="87209231def3204e4e4d9a18544294dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5989087fa6f30a7b2ad79b3b28f4f68" category="list-text">Abra o<block ref="8d777f385d3dfec8815d20f7496026dc" prefix=" " category="inline-code"></block> diretório e carregue os arquivos nos quais a inferência será realizada.  Quando os arquivos são carregados no diretório de dados, eles são armazenados automaticamente no volume persistente que foi montado no espaço de trabalho.  Para carregar arquivos, clique no ícone Carregar arquivos, conforme mostrado na imagem a seguir.</block>
  <block id="e3b5f0c1efdf69526c759b1d33d05e5b" category="paragraph"><block ref="e3b5f0c1efdf69526c759b1d33d05e5b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6da42e23b9d4e193c2fb146b8189581" category="list-text">Retorne ao diretório de nível superior e crie um novo notebook.</block>
  <block id="8c8d84a9a1e17bebaa40920247f46e13" category="paragraph"><block ref="8c8d84a9a1e17bebaa40920247f46e13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d6d5c0ae1c38484d2d4fd513ff80f90" category="list-text">Adicione código de inferência ao notebook.  O exemplo a seguir mostra o código de inferência para um caso de uso de detecção de imagem.</block>
  <block id="cf7a1e02f4be1c22e175847fae951746" category="paragraph"><block ref="cf7a1e02f4be1c22e175847fae951746" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9fa1b8c326d7c59c16ba99f22361e9e4" category="paragraph"><block ref="9fa1b8c326d7c59c16ba99f22361e9e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="296d40736553e2033f5cf8817174bc7c" category="list-text">Adicione a ofuscação Protopia ao seu código de inferência.  A Protopia trabalha diretamente com os clientes para fornecer documentação específica para casos de uso e está fora do escopo deste relatório técnico.  O exemplo a seguir mostra o código de inferência para um caso de uso de detecção de imagem com ofuscação Protopia adicionada.</block>
  <block id="a782d09a204dcf45c8852abf7684c340" category="paragraph"><block ref="a782d09a204dcf45c8852abf7684c340" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b937401d5d173ae3750bccadcff9481e" category="paragraph"><block ref="b937401d5d173ae3750bccadcff9481e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d5709eb5c3d3d4a700397ee447f9818" category="section-title">Cenário 2 – Inferência em lote no Kubernetes</block>
  <block id="77b69d61f1889c8321dce66f3c3e2e1a" category="list-text">Preencha o novo volume persistente com os dados nos quais você executará a inferência.</block>
  <block id="8b6983cc7986c7b0553983d8ab669289" category="inline-link">Recursos do NetApp DataOps Toolkit S3 Data Mover</block>
  <block id="685f44c17611b1391b579c696f310b98" category="paragraph">Existem vários métodos para carregar dados em um PVC.  Se seus dados estiverem armazenados atualmente em uma plataforma de armazenamento de objetos compatível com S3, como NetApp StorageGRID ou Amazon S3, você poderá usar<block ref="5d1617256d53e0547b237f3cf3fda5b0" category="inline-link-rx"></block> .  Outro método simples é criar um espaço de trabalho do JupyterLab e, em seguida, carregar os arquivos por meio da interface da web do JupyterLab, conforme descrito nas Etapas 3 a 5 na seção "<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block> ."</block>
  <block id="a62147e18dbac7ad5eab17791c371ad4" category="list-text">Crie um trabalho do Kubernetes para sua tarefa de inferência em lote.  O exemplo a seguir mostra um trabalho de inferência em lote para um caso de uso de detecção de imagem.  Este trabalho realiza inferências em cada imagem em um conjunto de imagens e grava métricas de precisão de inferência no stdout.</block>
  <block id="a883fb9f7bda67c6fbcab6dfb8f091ce" category="list-text">Confirme se o trabalho de inferência foi concluído com sucesso.</block>
  <block id="590888c60942c47f5268c19f273109ee" category="list-text">Adicione a ofuscação do Protopia ao seu trabalho de inferência.  Você pode encontrar instruções específicas de casos de uso para adicionar ofuscação do Protopia diretamente do Protopia, o que está fora do escopo deste relatório técnico.  O exemplo a seguir mostra um trabalho de inferência em lote para um caso de uso de detecção de rosto com ofuscação Protopia adicionada usando um valor ALPHA de 0,8.  Este trabalho aplica a ofuscação do Protopia antes de realizar a inferência para cada imagem em um conjunto de imagens e, em seguida, grava as métricas de precisão da inferência no stdout.</block>
  <block id="babeb9cd0280f29f38c9a4c3029f7ba0" category="inline-link-macro">Comparação de precisão de inferência.</block>
  <block id="f4d99d417d0adde7f8d0f1a70caac126" category="paragraph">Repetimos esta etapa para os valores ALFA 0,05, 0,1, 0,2, 0,4, 0,6, 0,8, 0,9 e 0,95.  Você pode ver os resultados em<block ref="b3380bdc8f9311566c95bcb62c7aea42" category="inline-link-macro-rx"></block></block>
  <block id="76d6540fbdbbcd913fb6272a50d0e3f2" category="section-title">Cenário 3 – Servidor de Inferência NVIDIA Triton</block>
  <block id="c470d7124546c64e8539c39ced806428" category="list-text">Use o NetApp DataOps Toolkit para provisionar um volume persistente a ser usado como um repositório de modelo para o NVIDIA Triton Inference Server.</block>
  <block id="1ddcb92ade31c8fbd370001f9b29a7d9" category="inline-link">formatar</block>
  <block id="898dfcda591317ac60dd8d6af3aff189" category="list-text">Armazene seu modelo no novo volume persistente em um<block ref="2001a6caf72de652d98c6c64bc75a4e8" category="inline-link-rx"></block> que é reconhecido pelo NVIDIA Triton Inference Server.</block>
  <block id="23ed8d1b8cbc461ebdbedcdb67ee7718" category="paragraph">Existem vários métodos para carregar dados em um PVC.  Um método simples é criar um espaço de trabalho do JupyterLab e, em seguida, carregar os arquivos por meio da interface da web do JupyterLab, conforme descrito nas etapas 3 a 5 em "<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block> .  "</block>
  <block id="fc35606f82a544f9c79f09561d7a234d" category="list-text">Use o NetApp DataOps Toolkit para implantar uma nova instância do NVIDIA Triton Inference Server.</block>
  <block id="27a920b35a8f949700a98b22803c70fc" category="list-text">Use um SDK cliente Triton para executar uma tarefa de inferência.  O trecho de código Python a seguir usa o SDK do cliente Triton Python para executar uma tarefa de inferência para um caso de uso de detecção de rosto.  Este exemplo chama a API Triton e passa uma imagem para inferência.  O Triton Inference Server então recebe a solicitação, invoca o modelo e retorna a saída de inferência como parte dos resultados da API.</block>
  <block id="7b5e296090a5d063fdbd3ebb69fc6547" category="list-text">Adicione a ofuscação Protopia ao seu código de inferência.  Você pode encontrar instruções específicas de casos de uso para adicionar ofuscação do Protopia diretamente do Protopia; no entanto, esse processo está fora do escopo deste relatório técnico.  O exemplo a seguir mostra o mesmo código Python mostrado na etapa 5 anterior, mas com a ofuscação Protopia adicionada.</block>
  <block id="c3069165ee6fb9d5dde8d8472d8b4602" category="paragraph">Observe que a ofuscação do Protopia é aplicada à imagem antes de ela ser passada para a API do Triton.  Dessa forma, a imagem não ofuscada nunca sai da máquina local.  Somente a imagem ofuscada é passada pela rede.  Este fluxo de trabalho é aplicável a casos de uso em que os dados são coletados dentro de uma zona confiável, mas precisam ser passados para fora dessa zona confiável para inferência.  Sem a ofuscação do Protopia, não é possível implementar esse tipo de fluxo de trabalho sem que dados confidenciais saiam da zona confiável.</block>
  <block id="fb0e25ed6b061ae8d5a55a94457e445e" category="summary">Para essa validação, aplicamos a ofuscação Protopia a uma imagem de 1920 x 1080 pixels cinco vezes e medimos o tempo que a etapa de ofuscação levou para ser concluída a cada vez.</block>
  <block id="9c6852dd5556b48ff70dd2583a5d3aa0" category="doc">Velocidade de ofuscação</block>
  <block id="6977bb3543f8de6dcfa78f7970349ba1" category="paragraph">Usamos o PyTorch em execução em uma única GPU NVIDIA V100 para aplicar a ofuscação e limpamos o cache da GPU entre as execuções.  A etapa de ofuscação levou 5,47 ms, 5,27 ms, 4,54 ms, 5,24 ms e 4,84 ms, respectivamente, para ser concluída nas cinco execuções.  A velocidade média foi de 5,072 ms.</block>
  <block id="4c787c1632a0a940cb0b44706b1d24c6" category="summary">Esta seção fornece uma visão geral dos vários componentes técnicos necessários para concluir esta solução.</block>
  <block id="a6d48b22bcf266404bdb8c57102c14a4" category="section-title">Protopia</block>
  <block id="b2cbc1ff8afd6c872961a852572e1782" category="paragraph">A Protopia AI oferece uma solução discreta, somente de software, para inferência confidencial no mercado atual.  A solução Protopia oferece proteção incomparável para serviços de inferência, minimizando a exposição de informações confidenciais.  A IA só recebe as informações no registro de dados que são realmente essenciais para executar a tarefa em questão e nada mais.  A maioria das tarefas de inferência não usa todas as informações existentes em cada registro de dados.  Não importa se sua IA está consumindo imagens, voz, vídeo ou até mesmo dados tabulares estruturados, o Protopia fornece apenas o que o serviço de inferência precisa.  A tecnologia central patenteada usa ruído matematicamente selecionado para transformar estocasticamente os dados e distorcer as informações que não são necessárias para um determinado serviço de ML.  Esta solução não mascara os dados; em vez disso, ela altera a representação dos dados usando ruído aleatório selecionado.</block>
  <block id="46ce082967eab6fe2e33798614d50861" category="paragraph">A solução Protopia formula o problema de alterar a representação como um método de maximização de perturbação baseado em gradiente que ainda retém as informações pertinentes no espaço de recursos de entrada com relação à funcionalidade do modelo.  Esse processo de descoberta é executado como uma passagem de ajuste fino no final do treinamento do modelo de ML.  Depois que a passagem gera automaticamente um conjunto de distribuições de probabilidade, uma transformação de dados de baixa sobrecarga aplica amostras de ruído dessas distribuições aos dados, ofuscando-os antes de passá-los ao modelo para inferência.</block>
  <block id="af2063646dcea30a4bac90a1c51b14aa" category="section-title">NetApp ONTAP AI</block>
  <block id="4fb9892dc0183c3142a3629cecc3104a" category="paragraph">A arquitetura de referência NetApp ONTAP AI, alimentada por sistemas DGX A100 e sistemas de armazenamento conectado em nuvem NetApp , foi desenvolvida e verificada pela NetApp e pela NVIDIA.  Ele fornece às organizações de TI uma arquitetura que proporciona os seguintes benefícios:</block>
  <block id="9c6bd300c8cf3ca98c8548bbb27cc34a" category="list-text">Elimina complexidades de design</block>
  <block id="cee5abf75433f502c31530bc72eecd6a" category="list-text">Permite dimensionamento independente de computação e armazenamento</block>
  <block id="eccaf37681e446d183db0332d1e50552" category="list-text">Permite que os clientes comecem pequenos e escalem sem problemas</block>
  <block id="410a2fbd85ad3d74051034eac2b94889" category="list-text">Oferece uma variedade de opções de armazenamento para vários pontos de desempenho e custo</block>
  <block id="988d7b305f79b990bbacdaed46f4b2bf" category="paragraph">O ONTAP AI integra perfeitamente os sistemas DGX A100 e os sistemas de armazenamento NetApp AFF A800 com redes de última geração.  ONTAP AI simplifica as implantações de IA eliminando a complexidade do design e as suposições.  Os clientes podem começar pequeno e crescer sem interrupções, ao mesmo tempo em que gerenciam dados de forma inteligente, da borda ao núcleo, à nuvem e vice-versa.</block>
  <block id="57e22b018aa5130ece9890cd6b45e779" category="paragraph">A figura a seguir mostra diversas variações na família de soluções ONTAP AI com sistemas DGX A100.  O desempenho do sistema AFF A800 é verificado com até oito sistemas DGX A100.  Ao adicionar pares de controladores de armazenamento ao cluster ONTAP , a arquitetura pode ser dimensionada para vários racks para dar suporte a muitos sistemas DGX A100 e petabytes de capacidade de armazenamento com desempenho linear.  Essa abordagem oferece a flexibilidade de alterar as proporções de computação para armazenamento de forma independente com base no tamanho dos modelos de DL usados e nas métricas de desempenho necessárias.</block>
  <block id="a28d0dc585dd816bf7bcce4c5f5f6dd9" category="paragraph"><block ref="a28d0dc585dd816bf7bcce4c5f5f6dd9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ecc164061fb57b585c892f0faa6f4dcf" category="inline-link">NVA-1153: NetApp ONTAP AI com sistemas NVIDIA DGX A100 e switches Ethernet Mellanox Spectrum.</block>
  <block id="3046083f382853b50c004323f2cda8f9" category="paragraph">Para obter informações adicionais sobre o ONTAP AI, consulte<block ref="2c1616ab9baa55036487e7ef75b3821d" category="inline-link-rx"></block></block>
  <block id="862dcadd0f2887701abaa60bf59d5aa5" category="paragraph">ONTAP 9.11, a última geração de software de gerenciamento de armazenamento da NetApp, permite que as empresas modernizem a infraestrutura e façam a transição para um data center pronto para a nuvem.  Aproveitando os recursos de gerenciamento de dados líderes do setor, o ONTAP permite o gerenciamento e a proteção de dados com um único conjunto de ferramentas, independentemente de onde os dados residam.  Você também pode mover dados livremente para onde for necessário: na borda, no núcleo ou na nuvem.  O ONTAP 9.11 inclui vários recursos que simplificam o gerenciamento de dados, aceleram e protegem dados críticos e permitem recursos de infraestrutura de última geração em arquiteturas de nuvem híbrida.</block>
  <block id="94c4b42bd5bfaa12f328387b161a1686" category="paragraph">O NetApp DataOps Toolkit é uma biblioteca Python que simplifica para desenvolvedores, cientistas de dados, engenheiros de DevOps e engenheiros de dados a execução de diversas tarefas de gerenciamento de dados, como provisionamento quase instantâneo de um novo volume de dados ou espaço de trabalho do JupyterLab, clonagem quase instantânea de um volume de dados ou espaço de trabalho do JupyterLab e captura quase instantânea de snapshots de um volume de dados ou espaço de trabalho do JupyterLab para rastreabilidade ou definição de linha de base.  Esta biblioteca Python pode funcionar como um utilitário de linha de comando ou uma biblioteca de funções que você pode importar para qualquer programa Python ou notebook Jupyter.</block>
  <block id="2dcb054d023d8770b9ba0125434b8f20" category="paragraph">O NVIDIA Triton Inference Server é um software de servidor de inferência de código aberto que ajuda a padronizar a implantação e a execução de modelos para fornecer IA rápida e escalável em produção.  O Triton Inference Server simplifica a inferência de IA permitindo que equipes implantem, executem e dimensionem modelos de IA treinados de qualquer estrutura em qualquer infraestrutura baseada em GPU ou CPU.  O Triton Inference Server suporta todas as principais estruturas, como TensorFlow, NVIDIA TensorRT, PyTorch, MXNet, OpenVINO e assim por diante.  O Triton se integra ao Kubernetes para orquestração e dimensionamento que você pode usar em todas as principais plataformas de IA e Kubernetes de nuvem pública.  Ele também é integrado a muitas soluções de software MLOps.</block>
  <block id="6532191b754c006509ce4006a972990e" category="paragraph"><block ref="7b17fc2d2143dfdbd3bff6783f73e17c" category="inline-link-rx"></block>é uma estrutura de ML de código aberto.  É uma biblioteca de tensores otimizada para aprendizado profundo que usa GPUs e CPUs.  O pacote PyTorch contém estruturas de dados para tensores multidimensionais que fornecem muitos utilitários para serialização eficiente de tensores, entre outros utilitários úteis.  Ele também tem uma contraparte CUDA que permite que você execute seus cálculos de tensor em uma GPU NVIDIA com capacidade de computação.  Nesta validação, usamos a biblioteca OpenCV-Python (cv2) para validar nosso modelo, aproveitando os conceitos de visão computacional mais intuitivos do Python.</block>
  <block id="cdea8196113c492688981e0a035baa29" category="list-text">Desempenho e menor latência.  ONTAP oferece o maior rendimento possível com a menor latência possível.</block>
  <block id="fa126db4297464dd03b3ceef190df0d0" category="list-text">Proteção de dados.  O ONTAP fornece recursos integrados de proteção de dados com gerenciamento comum em todas as plataformas.</block>
  <block id="1f17e94c6f48114ff29ad3267277420c" category="list-text">Multilocação e autenticação multifator.  O ONTAP permite o compartilhamento de recursos de infraestrutura com os mais altos níveis de segurança.</block>
  <block id="b816bfff9511bcd88a9aa06fe0fd6389" category="list-text">Escalabilidade perfeita e operações não disruptivas.  O ONTAP oferece suporte à adição não disruptiva de capacidade aos controladores existentes e aos clusters escaláveis.  Os clientes podem atualizar para as tecnologias mais recentes, como NVMe e 32Gb FC, sem migrações de dados dispendiosas ou interrupções.</block>
  <block id="377c9a91b43c5423691b5ce75db91350" category="section-title">Controle NetApp Astra</block>
  <block id="35b46e301702b6fcb16192f9f4cf4533" category="inline-link">Serviço de Controle Astra</block>
  <block id="eb75cc706ac8cc6c0f4cb17f4fb073dd" category="paragraph">A família de produtos NetApp Astra oferece serviços de armazenamento e gerenciamento de dados com reconhecimento de aplicativos para aplicativos Kubernetes no local e na nuvem pública, com tecnologia de armazenamento e gerenciamento de dados da NetApp .  Ele permite que você faça backup de aplicativos Kubernetes facilmente, migre dados para um cluster diferente e crie instantaneamente clones de aplicativos funcionais.  Se você precisar gerenciar aplicativos Kubernetes em execução em uma nuvem pública, consulte a documentação para<block ref="6d442ad773e9d31651277931acd1583a" category="inline-link-rx"></block> .  O Astra Control Service é um serviço gerenciado pela NetApp que fornece gerenciamento de dados com reconhecimento de aplicativo de clusters Kubernetes no Google Kubernetes Engine (GKE) e no Azure Kubernetes Service (AKS).</block>
  <block id="545b3003eeeed3a05db492712188eaa8" category="paragraph">Astra<block ref="b792e70a7bbe82fe69049fd18abe3c18" category="inline-link-rx"></block> da NetApp é um orquestrador de armazenamento dinâmico de código aberto para Docker e Kubernetes que simplifica a criação, o gerenciamento e o consumo de armazenamento persistente.  O Trident, um aplicativo nativo do Kubernetes, é executado diretamente em um cluster do Kubernetes.  O Trident permite que os clientes implantem facilmente imagens de contêiner DL no armazenamento NetApp e fornece uma experiência de nível empresarial para implantações de contêineres de IA.  Os usuários do Kubernetes (desenvolvedores de ML, cientistas de dados e assim por diante) podem criar, gerenciar e automatizar a orquestração e a clonagem para aproveitar os recursos avançados de gerenciamento de dados fornecidos pela tecnologia NetApp .</block>
  <block id="45a189f17e7eec44ce720f6a979e501e" category="paragraph"><block ref="9f25cf06e22037e38bb7442b4d301b6c" category="inline-link-rx"></block>é um serviço da NetApp para sincronização de dados rápida e segura.  Se você precisa transferir arquivos entre compartilhamentos de arquivos NFS ou SMB locais, NetApp StorageGRID, NetApp ONTAP S3, Google Cloud NetApp Volumes, Azure NetApp Files, Amazon Simple Storage Service (Amazon S3), Amazon Elastic File System (Amazon EFS), Azure Blob, Google Cloud Storage ou IBM Cloud Object Storage, o BlueXP Copy and Sync move os arquivos para onde você precisa de forma rápida e segura.  Após seus dados serem transferidos, eles estarão totalmente disponíveis para uso tanto na origem quanto no destino.  O BlueXP Copy and Sync sincroniza continuamente os dados com base na sua programação predefinida, movendo apenas os deltas, para que o tempo e o dinheiro gastos na replicação de dados sejam minimizados.  O BlueXP Copy and Sync é uma ferramenta de software como serviço (SaaS) extremamente simples de configurar e usar.  As transferências de dados acionadas pelo BlueXP Copy and Sync são realizadas por corretores de dados.  Você pode implantar os corretores de dados BlueXP Copy and Sync na AWS, Azure, Google Cloud Platform ou no local.</block>
  <block id="b8bc3287c1345ab1a36c796d2de0aaa2" category="section-title">Classificação NetApp BlueXP</block>
  <block id="196f1872673d3381d912260929325605" category="paragraph">Impulsionado por poderosos algoritmos de IA,<block ref="860dd213c65646bc2292a7454f4cfbac" category="inline-link-rx"></block> fornece controles automatizados e governança de dados em todo o seu acervo de dados.  Você pode facilmente identificar economias de custos, identificar preocupações com conformidade e privacidade e encontrar oportunidades de otimização.  O painel de classificação BlueXP fornece insights para identificar dados duplicados para eliminar redundâncias, mapear dados pessoais, não pessoais e confidenciais e ativar alertas para dados confidenciais e anomalias.</block>
  <block id="c46aabfbeb0af662ede62f7325853fa2" category="summary">O processamento digital de imagens traz muitas vantagens, permitindo que muitas organizações aproveitem ao máximo os dados associados às representações visuais.  Esta solução da NetApp e Protopia fornece um design exclusivo de inferência de IA para proteger e privatizar dados de IA/ML em todo o ciclo de vida de ML/DL.  Ele permite que os clientes mantenham a propriedade de dados confidenciais, usem modelos de implantação de nuvem pública ou híbrida para escala e eficiência, aliviando preocupações relacionadas à privacidade, e implantem inferência de IA na borda.</block>
  <block id="55ece983a5251583397e3db1cd3926ec" category="section-title">Inteligência ambiental</block>
  <block id="d0f24bc92f5b7838f03e893b41066a90" category="paragraph">Há muitas maneiras pelas quais as indústrias podem aproveitar a análise geoespacial nas áreas de riscos ambientais.  Os governos e o departamento de obras públicas podem obter insights práticos sobre saúde pública e condições climáticas para melhor orientar o público durante uma pandemia ou um desastre natural, como incêndios florestais.  Por exemplo, você pode identificar um paciente com COVID-19 positivo em espaços públicos, como aeroportos ou hospitais, sem comprometer a privacidade do indivíduo afetado e alertar as autoridades competentes e o público nas proximidades sobre as medidas de segurança necessárias.</block>
  <block id="4f9352e4f65872238d755155cd23edec" category="section-title">Dispositivos vestíveis de ponta</block>
  <block id="315a1bbca88dbcbdc95471a0061c333f" category="paragraph">Nas forças armadas e nos campos de batalha, você pode usar a inferência de IA na ponta como dispositivos vestíveis para rastrear a saúde dos soldados, monitorar o comportamento dos motoristas e alertar as autoridades sobre a segurança e os riscos associados à aproximação de veículos militares, preservando e protegendo a privacidade dos soldados.  O futuro das forças armadas está se voltando para a alta tecnologia com a Internet das Coisas do Campo de Batalha (IoBT) e a Internet das Coisas Militares (IoMT) para equipamentos de combate vestíveis que ajudam os soldados a identificar inimigos e ter melhor desempenho em batalha usando computação de ponta rápida.  Proteger e preservar dados visuais coletados de dispositivos de ponta, como drones e equipamentos vestíveis, é crucial para manter hackers e inimigos afastados.</block>
  <block id="d6dded41a42f767150e641793fc0c929" category="section-title">Operações de evacuação de não combatentes</block>
  <block id="c5b381de9b2a4ee73bcc524aa380d725" category="paragraph">As operações de evacuação não combatentes (NEOs) são conduzidas pelo DoD para auxiliar na evacuação de cidadãos e cidadãos dos EUA, pessoal civil do DoD e pessoas designadas (nação anfitriã (HN) e cidadãos de terceiros países (TCNs)) cujas vidas estão em perigo para um refúgio seguro apropriado.  Os controles administrativos em vigor usam, em grande parte, processos manuais de triagem de evacuados.  No entanto, a precisão, a segurança e a velocidade da identificação de evacuados, do rastreamento de evacuados e da triagem de ameaças poderiam ser potencialmente melhoradas pelo uso de ferramentas de IA/ML altamente automatizadas combinadas com tecnologias de ofuscação de vídeo de IA/ML.</block>
  <block id="19c95c19bd7c939577775cd0ecce3df1" category="section-title">Pesquisa em saúde e biomédica</block>
  <block id="a047c61461aba5a84a0a221900c33984" category="paragraph">O processamento de imagens é utilizado para diagnosticar patologias para planejamento cirúrgico a partir de imagens 3D obtidas por tomografia computadorizada (TC) ou ressonância magnética (RM).  As regras de privacidade da HIPAA determinam como os dados devem ser coletados, processados e apagados pelas organizações para todas as informações pessoais e imagens digitais, como fotografias.  Para que os dados sejam qualificados como compartilháveis de acordo com os regulamentos HIPAA Safe Harbor, imagens fotográficas de rosto inteiro e quaisquer imagens comparáveis devem ser removidas.  Técnicas automatizadas, como algoritmos de desidentificação ou remoção de crânio, usadas para ocultar as características faciais de um indivíduo em imagens estruturais de TC/RM, tornaram-se parte essencial do processo de compartilhamento de dados para instituições de pesquisa biomédica.</block>
  <block id="2d930616ec617ae047b7b7eaefb0822c" category="section-title">Migração para a nuvem de análises de IA/ML</block>
  <block id="073395e7b5fc53b602884ac0aaf757fb" category="inline-link">proteção de dados</block>
  <block id="2c5c3872e94de8a36eac45213c5bf2e6" category="paragraph">Os clientes corporativos tradicionalmente treinam e implantam modelos de IA/ML no local.  Por razões de economia de escala e eficiência, esses clientes estão se expandindo para mover funções de IA/ML para implantações de nuvem pública, híbrida ou multi-nuvem.  No entanto, eles estão limitados pelos dados que podem ser expostos a outras infraestruturas.  As soluções NetApp abordam uma gama completa de ameaças à segurança cibernética necessárias para<block ref="9da3a9a08c9461b229d33f221e8caa37" category="inline-link-rx"></block> e avaliação de segurança e, quando combinados com a transformação de dados do Protopia, minimizam os riscos associados à migração de cargas de trabalho de IA/ML de processamento de imagens para a nuvem.</block>
  <block id="c9f2e6462caf995f1d336ab4bb33a7c2" category="inline-link-macro">TR-4886 Inferência de IA na Borda</block>
  <block id="ae1b6ac445119145d739025d55fe616f" category="inline-link">Inteligência versus privacidade</block>
  <block id="7c93429acdde399d280f2e20425ac745" category="paragraph">Para casos de uso adicionais para computação de ponta e inferência de IA em outros setores, consulte<block ref="c2ef3f1fa710d59c08d58b9025616182" category="inline-link-macro-rx"></block> e o blog NetApp AI,<block ref="bc130be57ffb0325128dc7274bbdbc64" category="inline-link-rx"></block> .</block>
  <block id="59a6ec9eb2075dc5ac847799c3c9b4e0" category="summary">MLOps multicloud híbridos com Domino Data Lab e NetApp - Onde encontrar informações adicionais</block>
  <block id="3887d417240a72ab69f6d0301efd3b2b" category="doc">Onde encontrar informações adicionais</block>
  <block id="44997fb529c7b7d20853c30af9ad918a" category="list-text">Laboratório de Dados Domino</block>
  <block id="1182c61de35b31af3e72f77e61442c77" category="inline-link-macro"><block ref="1182c61de35b31af3e72f77e61442c77" category="inline-link-rx"></block></block>
  <block id="bd0007c3dcc92207ee01f0427da0a4be" category="paragraph"><block ref="bd0007c3dcc92207ee01f0427da0a4be" category="inline-link-macro-rx"></block></block>
  <block id="d7574cd2803b94ddaa90cab193a19ba2" category="list-text">Domino Nexus</block>
  <block id="2703dd45bd40545fb60997c2d3afe208" category="inline-link-macro"><block ref="2703dd45bd40545fb60997c2d3afe208" category="inline-link-rx"></block></block>
  <block id="14a3e5a8d5046236b5959a8860c405eb" category="paragraph"><block ref="14a3e5a8d5046236b5959a8860c405eb" category="inline-link-macro-rx"></block></block>
  <block id="1273c8a63109161e6fd1f18d6998523f" category="list-text">NetApp BlueXP</block>
  <block id="43e196fd7d1a86adce26084a27e3d664" category="inline-link-macro"><block ref="43e196fd7d1a86adce26084a27e3d664" category="inline-link-rx"></block></block>
  <block id="2edabab990aa6b9914f978e6885781f2" category="paragraph"><block ref="2edabab990aa6b9914f978e6885781f2" category="inline-link-macro-rx"></block></block>
  <block id="5339d389f2f896062fb28b05454dc94a" category="list-text">Software de gerenciamento de dados NetApp ONTAP</block>
  <block id="5b8aea48f614361f60f00e194e1b0976" category="inline-link-macro"><block ref="5b8aea48f614361f60f00e194e1b0976" category="inline-link-rx"></block></block>
  <block id="59f3782142c74894e9aa57873085e394" category="paragraph"><block ref="59f3782142c74894e9aa57873085e394" category="inline-link-macro-rx"></block></block>
  <block id="13ed1686110be86a2aeef6d76d4ec65e" category="list-text">Soluções de IA da NetApp</block>
  <block id="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-macro"><block ref="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-rx"></block></block>
  <block id="501b3e03ab68e967ec7e74647ece575b" category="paragraph"><block ref="501b3e03ab68e967ec7e74647ece575b" category="inline-link-macro-rx"></block></block>
  <block id="5acaa2031a97473b7a185dc30ce9e62d" category="list-text">Josh Mineroff, Diretor de SA para Alianças Tecnológicas, Domino Data Lab</block>
  <block id="ed2311020217442776d108d1f99b7521" category="list-text">Nicholas Jablonski, CTO de campo, Domino Data Lab</block>
  <block id="5c38b0c6106b026873b5212202e5eb20" category="list-text">Prabu Arjunan, arquiteto de soluções, NetApp</block>
  <block id="958996b71437140af7dadceec3c0acf1" category="list-text">Brian Young, Diretor de Aliança Global, Parceiros de Aliança de Tecnologia, NetApp</block>
  <block id="182f685e8ff46f3bde7c8c63a6d3e8eb" category="summary">MLOps multicloud híbridos com Domino Data Lab e NetApp - Arquitetura</block>
  <block id="22a02f1b77fcd49462c4d58a6e2425fb" category="paragraph">Esta solução combina os recursos de agendamento de carga de trabalho multicloud híbrida do Domino Nexus com os serviços de dados da NetApp para criar uma plataforma MLOps de nuvem híbrida unificada.  Veja a tabela a seguir para mais detalhes.</block>
  <block id="0ba29c6a1afacf586b03a26162c72274" category="cell">Ambiente</block>
  <block id="1a01eb6a884a288b667e023501d09eea" category="cell">Plano de controle MLOps</block>
  <block id="51c0d15bebbbdb19d5e1bde9bf2bc1ba" category="inline-link-macro">Plataforma Domino Enterprise AI com Domino Nexus</block>
  <block id="a0133d74aa4167bee7ec6bb2830b32ab" category="cell"><block ref="a0133d74aa4167bee7ec6bb2830b32ab" category="inline-link-macro-rx"></block></block>
  <block id="4847e034bb0a55fcbc8a3380d6a3ab80" category="cell">AWS</block>
  <block id="dedb71b645ad83baa13a64e834ea32a3" category="cell">Ambientes de computação da plataforma MLOps</block>
  <block id="1f26213ee3d03d1bce28558ef8ff15ff" category="inline-link-macro">Planos de dados Domino Nexus</block>
  <block id="f2d3c460a5a76b316899ec775650d7ea" category="cell"><block ref="f2d3c460a5a76b316899ec775650d7ea" category="inline-link-macro-rx"></block></block>
  <block id="89f5a1a21bf30d5f2db943911b2d22f2" category="cell">AWS, data center local</block>
  <block id="1698863d644408b6fdc41803a6a1c234" category="cell">Plataforma de computação local</block>
  <block id="2c02a900da9ea696e0b13c405974ca0b" category="cell"><block ref="e08fa5b25dd32bed0a8727bee0e3fdd0" category="inline-link-macro-rx"></block>com<block ref="c8e9826c7461e34f8a6ee68d2d629f27" category="inline-link-macro-rx"></block></block>
  <block id="59f10558cba0587bc03fb56826f8cd4b" category="cell">Data center local</block>
  <block id="29e13ea538f81a8bf3cea3900519c8a1" category="cell">Plataforma de computação em nuvem</block>
  <block id="480c9b5f979d1ce95ea2a58b09826d1b" category="inline-link-macro">Serviço Amazon Elastic Kubernetes (EKS)</block>
  <block id="ff969739d0750911a50d47ea892fad80" category="cell"><block ref="4ecdb2c4c840fbc0e496687cc8bf58fe" category="inline-link-macro-rx"></block>com<block ref="c8e9826c7461e34f8a6ee68d2d629f27" category="inline-link-macro-rx"></block></block>
  <block id="cd3aefaae18f11e3ecc3de62739183f3" category="cell">Plataforma de dados local</block>
  <block id="e16a11bc6041db3c2b26ef054c8b8847" category="inline-link-macro">Dispositivo de armazenamento NetApp</block>
  <block id="b331d50869bea7c3b019d322cffc1f03" category="cell"><block ref="ea0807fcd7c8182254e93c3bfdf94abc" category="inline-link-macro-rx"></block>distribuído por<block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="0c9ae535d9e81d6e268c0ea087be535f" category="cell">Plataforma de dados em nuvem</block>
  <block id="35f7c29efc923e8a7920a0b331095d71" category="inline-link-macro">Amazon FSx ONTAP</block>
  <block id="2a9165a68b73a53b924deda7b9ec0251" category="cell"><block ref="2a9165a68b73a53b924deda7b9ec0251" category="inline-link-macro-rx"></block></block>
  <block id="b497a71f092b521e07c06ade7296c159" category="paragraph"><block ref="b497a71f092b521e07c06ade7296c159" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f92651ef1a171bf24e3a0279a4f656f" category="summary">MLOps multicloud híbridos com Domino Data Lab e NetApp - Acesse os mesmos dados em diferentes ambientes</block>
  <block id="2167fcd754f38c037a8a5fc219634638" category="doc">Acesse os mesmos dados em diferentes ambientes</block>
  <block id="2b2213cc89a71238bd2629046704d311" category="paragraph">Esta seção descreve as tarefas que precisam ser executadas para acessar os mesmos dados em diferentes ambientes de computação.  Na plataforma Domino MLOps, os ambientes de computação são chamados de "planos de dados".  Siga as tarefas descritas nesta seção se seus dados residirem em um volume NetApp em um plano de dados, mas você precisar acessá-los em outro plano de dados.  Esse tipo de cenário é frequentemente chamado de "explosão" ou, quando o ambiente de destino é a nuvem, "explosão de nuvem".  Esse recurso geralmente é necessário ao lidar com recursos de computação limitados ou sobrecarregados.  Por exemplo, se o seu cluster de computação local estiver lotado, talvez você queira agendar cargas de trabalho na nuvem, onde elas podem ser iniciadas imediatamente.</block>
  <block id="8e259831056b970e9e9ad97044e756ea" category="paragraph">Há duas opções recomendadas para acessar um volume NetApp que reside em um plano de dados diferente.  Essas opções são descritas nas subseções abaixo.  Escolha uma dessas opções dependendo de suas necessidades específicas.  Os benefícios e desvantagens das duas opções são descritos na tabela a seguir.</block>
  <block id="054b4f3ea543c990f6b125f41af6ebf7" category="cell">Opção</block>
  <block id="e654f7a86a4458b9cd662267e0f29b52" category="cell">Benefícios</block>
  <block id="0cfc0523189294ac086e11c8e286ba2d" category="cell">Desvantagens</block>
  <block id="a5a315a3bc09fc65d5b92a61203e604b" category="cell">Opção 1 - Cache</block>
  <block id="542d0200f163f8f3533463dd59fe0270" category="cell">- Fluxo de trabalho mais simples - Capacidade de armazenar em cache um subconjunto de dados com base nas necessidades - Capacidade de gravar dados de volta na fonte - Nenhuma cópia remota para gerenciar</block>
  <block id="7426e3bde1c62fb806a70f18c6134316" category="cell">- Aumento da latência no acesso inicial aos dados, pois o cache é hidratado.</block>
  <block id="aaa4d30d61e64cea712b7c05c68eb117" category="cell">Opção 2 - Espelho</block>
  <block id="cbefd7ef29f92291b21681c43ba469b7" category="cell">- Cópia completa do volume de origem - Sem aumento de latência devido à hidratação do cache (após a conclusão da operação de espelhamento)</block>
  <block id="03dab0d003c274e0f366cd0df3efb059" category="cell">- É necessário aguardar a conclusão da operação de espelho antes de acessar os dados - É necessário gerenciar uma cópia remota - Não há capacidade de gravar de volta na fonte</block>
  <block id="f794ea935b3f3b976964bf0990d05005" category="section-title">Opção 1 - Criar um cache de um volume que reside em um plano de dados diferente</block>
  <block id="79849c69657d54d5bfdd901f71375897" category="inline-link-macro">Tecnologia NetApp FlexCache</block>
  <block id="a816bf9775484a9a7049d55ece7f5396" category="paragraph">Com<block ref="bb0419306e9b544a3e597acbf1d444f1" category="inline-link-macro-rx"></block> , você pode criar um cache de um volume NetApp que reside em um plano de dados diferente.  Por exemplo, se você tiver um volume NetApp no seu plano de dados local e precisar acessar esse volume no seu plano de dados da AWS, poderá criar um cache do volume na AWS.  Esta seção descreve as tarefas que precisam ser executadas para criar um cache de um volume NetApp que reside em um plano de dados diferente.</block>
  <block id="d93488703b54616875bcacc4afd140a7" category="section-title">Criar volume FlexCache no ambiente de destino</block>
  <block id="5d03f3f921e1e11afbd6bc02646a4b6f" category="admonition">Se o ambiente de destino for seu data center local, você criará o volume FlexCache no seu sistema ONTAP local.  Se o ambiente de destino for AWS, você criará o volume FlexCache na sua instância Amazon FSx ONTAP .</block>
  <block id="a53f62411ee21cbe84822e3eba531ca4" category="paragraph">Primeiro, você deve criar um volume FlexCache no ambiente de destino.</block>
  <block id="671e0b00bec7311fe1a27ae3b1374868" category="inline-link-macro">Documentação de BlueXP volume caching</block>
  <block id="25d1d7fbc173abf20974acc2fd19014b" category="paragraph">Recomendamos usar o BlueXP para criar o volume FlexCache .  Para criar um volume FlexCache com BlueXP, siga as instruções descritas no<block ref="13882193b90946980fb2e14f0dc3f833" category="inline-link-macro-rx"></block> .</block>
  <block id="597fd5f01aeae294735b75c08203b6dd" category="paragraph">Se preferir não usar o BlueXP, você pode usar o ONTAP System Manager ou o ONTAP CLI para criar o volume FlexCache .  Para criar um volume FlexCache com o System Manager, consulte as instruções descritas no<block ref="01bbf1f7353a360c52874272bfd82e21" category="inline-link-macro-rx"></block> .  Para criar um volume FlexCache com o ONTAP CLI, consulte as instruções descritas no<block ref="91e4088944fb7c016c63d36e00422b16" category="inline-link-macro-rx"></block> .</block>
  <block id="e4de6f9df9cd48ef525131de3cb21481" category="inline-link-macro">API BlueXP</block>
  <block id="0ec641cfacd36c8e22a334135e2abdac" category="inline-link-macro">API REST ONTAP</block>
  <block id="ebf440be7bdce857e55ec25910ae837b" category="inline-link-macro">Coleção ONTAP Ansible</block>
  <block id="dd7a007ea7e610e168238b6d6ab542a1" category="paragraph">Se você deseja automatizar esse processo, você pode usar o<block ref="f07bcb7e875f8bb20680b339fb58364a" category="inline-link-macro-rx"></block> , o<block ref="0966e902a53f3a5becbd165bbdc18e79" category="inline-link-macro-rx"></block> , ou o<block ref="62c3d824298cc8f488bda82279b91e73" category="inline-link-macro-rx"></block> .</block>
  <block id="2f37e297d79532f437d3ab48727a61c0" category="admonition">O System Manager não está disponível no Amazon FSx ONTAP.</block>
  <block id="20f99b2a7f22945f3d769fa1def1e403" category="section-title">Expor o volume FlexCache ao Domino</block>
  <block id="c9743d6f9b7fcd7047ce3eb9d1f2a273" category="inline-link-macro">Seção 'Expor volumes NetApp existentes ao Domino'</block>
  <block id="82a25bd099304632e33529b36f2ac5de" category="paragraph">Em seguida, você deve expor o volume FlexCache para a plataforma Domino MLOps.  Para expor o volume FlexCache ao Domino, siga as instruções descritas na subseção 'Expor volumes NFS existentes que não foram provisionados pelo Trident' do<block ref="37f39ecc5e06a679f4975effd49fb9b8" category="inline-link-macro-rx"></block> desta solução.</block>
  <block id="1d25e828bd3386ce7ef8b97572c88781" category="paragraph">Agora, você poderá montar o volume FlexCache ao iniciar trabalhos e espaços de trabalho no plano de dados de destino, conforme mostrado nas capturas de tela a seguir.</block>
  <block id="edaa69742537cd645340e6ec55f0e7c2" category="section-title">Antes de criar o volume FlexCache</block>
  <block id="7708950a83e2f559b43ad1d7bc08a440" category="paragraph"><block ref="7708950a83e2f559b43ad1d7bc08a440" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7bf27913e6097a43d318c500146c1e1" category="section-title">Após expor o volume FlexCache ao Domino</block>
  <block id="acacf35ed5b32878a29f6d32e6a11ffe" category="paragraph"><block ref="acacf35ed5b32878a29f6d32e6a11ffe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9be78ccf5bdf4dc10f0e5d25b893eeb" category="section-title">Opção 2 - Replicar um volume que reside em um plano de dados diferente</block>
  <block id="0e6ab030c4eacec9efa80d3df6cd643b" category="inline-link-macro">Tecnologia de replicação de dados NetApp SnapMirror</block>
  <block id="124468d30e8b5047c5fe1b160b4fcbd2" category="paragraph">Com<block ref="ebe914c00393f99bd92af5cffa8376b0" category="inline-link-macro-rx"></block> , você pode criar uma cópia de um volume NetApp que reside em um plano de dados diferente.  Por exemplo, se você tiver um volume NetApp no seu plano de dados local e precisar acessar esse volume no seu plano de dados da AWS, poderá criar uma cópia do volume na AWS.  Esta seção descreve as tarefas que precisam ser executadas para criar uma cópia de um volume NetApp que reside em um plano de dados diferente.</block>
  <block id="050a227810327b3bcfd311be38b7d202" category="section-title">Criar relacionamento SnapMirror</block>
  <block id="fef6b7d4f88331bab85d2eb944d43e9b" category="paragraph">Primeiro, você deve criar um relacionamento SnapMirror entre seu volume de origem e um novo volume de destino no ambiente de destino.  Observe que o volume de destino será criado como parte do processo de criação do relacionamento SnapMirror .</block>
  <block id="62390de09bd56fbb6d4533a188f4f201" category="inline-link-macro">Documentação de BlueXP replication</block>
  <block id="6fbd84bba212db826d8a94b992bd6324" category="paragraph">Recomendamos usar o BlueXP para criar o relacionamento SnapMirror .  Para criar um relacionamento SnapMirror com BlueXP, siga as instruções descritas no<block ref="b08e4ece79f7d1aa7f110b298b659fae" category="inline-link-macro-rx"></block> .</block>
  <block id="052be79cbb457a1391bb0a6839e610d3" category="paragraph">Se preferir não usar o BlueXP, você pode usar o ONTAP System Manager ou o ONTAP CLI para criar o relacionamento SnapMirror .  Para criar um relacionamento SnapMirror com o System Manager, consulte as instruções descritas no<block ref="665d2354c4ea508e65993c5ec9dc3fa1" category="inline-link-macro-rx"></block> .  Para criar um relacionamento SnapMirror com o ONTAP CLI, consulte as instruções descritas no<block ref="bf03311f5c6980a3d817528b27741438" category="inline-link-macro-rx"></block> .</block>
  <block id="805b58c51fa6bf98d530bbc76f317e74" category="section-title">Quebrar relacionamento SnapMirror</block>
  <block id="9ee42869e01344256cee7824a61c3f00" category="paragraph">Em seguida, você deve quebrar o relacionamento SnapMirror para ativar o volume de destino para acesso aos dados.  Aguarde até que a replicação inicial seja concluída antes de executar esta etapa.</block>
  <block id="c16b6b1cdf70d97ab9f143b23f304ee5" category="admonition">Você pode determinar se a replicação foi concluída ou não verificando o estado do espelho no BlueXP, no ONTAP System Manager ou no ONTAP CLI.  Quando a replicação estiver concluída, o estado do espelho será "snapmirrored".</block>
  <block id="acab4369131a8c646dc85deedc5c4abb" category="paragraph">Recomendamos usar o BlueXP para quebrar o relacionamento com o SnapMirror .  Para interromper um relacionamento do SnapMirror com o BlueXP, siga as instruções descritas no<block ref="eb8fade3a2fe398b39f82043fade1a22" category="inline-link-macro-rx"></block> .</block>
  <block id="96009cd50e3918957734c7c1dbe9bbb1" category="paragraph">Se preferir não usar o BlueXP, você pode usar o ONTAP System Manager ou o ONTAP CLI para interromper o relacionamento do SnapMirror .  Para interromper um relacionamento do SnapMirror com o System Manager, consulte as instruções descritas no<block ref="2feb8ad9799acf2d659fb0cab9f5c802" category="inline-link-macro-rx"></block> .  Para interromper um relacionamento SnapMirror com o ONTAP CLI, consulte as instruções descritas no<block ref="a5d68b350f5308762130d0f350fbb93c" category="inline-link-macro-rx"></block> .</block>
  <block id="67a1a8de2d55c1b2a31ec40db952c0cf" category="section-title">Expor volume de destino ao Domino</block>
  <block id="0de56c363db9af31c3fe36cd53b5deaf" category="paragraph">Em seguida, você deve expor o volume de destino à plataforma Domino MLOps.  Para expor o volume de destino ao Domino, siga as instruções descritas na subseção 'Expor volumes NFS existentes que não foram provisionados pelo Trident' do<block ref="37f39ecc5e06a679f4975effd49fb9b8" category="inline-link-macro-rx"></block> desta solução.</block>
  <block id="aa4e6b2b0a9165bbe6adb64ff972dbb0" category="paragraph">Agora, você poderá montar o volume de destino ao iniciar trabalhos e espaços de trabalho no plano de dados de destino, conforme mostrado nas capturas de tela a seguir.</block>
  <block id="6c2d9f4c43e6e539a1b0bf3be24de513" category="section-title">Antes de criar o relacionamento SnapMirror</block>
  <block id="800f74671431bfc6b9efb2f7e294020f" category="section-title">Após expor o volume de destino ao Domino</block>
  <block id="a2207225ebdd3d675188d927e34ace5a" category="summary">O Domino Nexus é um painel único que permite executar cargas de trabalho de ciência de dados e aprendizado de máquina em qualquer cluster de computação — em qualquer nuvem, região ou localmente.</block>
  <block id="1882311bf64ae464a0b9653b463c8584" category="doc">MLOps multicloud híbridos com Domino Data Lab e NetApp</block>
  <block id="f0829d8f9d70b9de9de7beae86dc2129" category="paragraph">Mike Oglesby, NetApp</block>
  <block id="c716184d878cbe2fda94903e01c21291" category="paragraph">Organizações em todo o mundo estão atualmente adotando IA para transformar seus negócios e processos.  Por esse motivo, a infraestrutura de computação pronta para IA costuma ser escassa.  As empresas estão adotando arquiteturas MLOps multinuvem híbridas para aproveitar os ambientes de computação disponíveis em diferentes regiões, data centers e nuvens, equilibrando custo, disponibilidade e desempenho.</block>
  <block id="542493ebb9768d33d834c6edcade57dc" category="paragraph">O Domino Nexus, do Domino Data Lab, é um plano de controle MLOps unificado que permite executar cargas de trabalho de ciência de dados e aprendizado de máquina em qualquer cluster de computação — em qualquer nuvem, região ou localmente.  Ele unifica os silos de ciência de dados em toda a empresa, para que você tenha um só lugar para criar, implantar e monitorar modelos.  Da mesma forma, os recursos de gerenciamento de dados em nuvem híbrida da NetApp permitem que você leve seus dados para seus trabalhos e espaços de trabalho, não importa onde eles estejam sendo executados.  Ao combinar o Domino Nexus com o NetApp, você tem a flexibilidade de agendar cargas de trabalho em todos os ambientes sem precisar se preocupar com a disponibilidade de dados.  Em outras palavras, você tem a capacidade de enviar suas cargas de trabalho e seus dados para o ambiente de computação apropriado, o que lhe permite acelerar suas implantações de IA enquanto navega pelas regulamentações sobre privacidade e soberania de dados.</block>
  <block id="3eb3ace35104f92d82777b3219f769d7" category="paragraph">Esta solução demonstra a implantação de um plano de controle MLOps unificado incorporando um cluster Kubernetes local e um cluster Elastic Kubernetes Service (EKS) em execução na Amazon Web Services (AWS).</block>
  <block id="5be0395276ff3840daa0a0cb7643b68d" category="summary">MLOps multicloud híbridos com Domino Data Lab e NetApp - Configuração inicial</block>
  <block id="6641666d7bc2748bab0ac80cdec3a2a3" category="doc">Configuração inicial</block>
  <block id="ef81709626b455fffcd99d9f67085d18" category="paragraph">Esta seção descreve as tarefas de configuração inicial que precisam ser executadas para utilizar o Domino Nexus com serviços de dados NetApp em um ambiente híbrido que incorpora um data center local e a AWS.</block>
  <block id="87b13b0a04193ccc830f23d041d6f3ba" category="paragraph">Antes de executar as etapas descritas nesta seção, presumimos que você já tenha executado as seguintes tarefas:</block>
  <block id="677ae9330aedf715db07a33be39cbbeb" category="list-text">Você já implantou e configurou sua plataforma de armazenamento NetApp ONTAP local. Para mais informações, consulte o <block ref="077b296918e9131d07388450dbd7a243" category="inline-link-macro-rx"></block> .</block>
  <block id="8f117f8e1e04a7113b95048bd0077b28" category="inline-link-macro">Página do produto Amazon FSx ONTAP</block>
  <block id="837adf3f87eb8a7f5893e4b6a6f7cee5" category="list-text">Você já provisionou uma instância do Amazon FSx ONTAP na AWS. Para mais informações, consulte o <block ref="88e07f6417e37f8ff711e34864e5d89c" category="inline-link-macro-rx"></block> .</block>
  <block id="6bd1aa1204077ccb610d72dbc07f11b1" category="inline-link-macro">Guia de administração do Domino</block>
  <block id="83a12488d43dae9419d61f6f83fa014a" category="list-text">Você já provisionou um cluster Kubernetes em seu data center local. Para mais informações, consulte o <block ref="ae2d81862ffd2c0afcf7ba06af1fbd2e" category="inline-link-macro-rx"></block> .</block>
  <block id="6b59c41a4554c4e0f63a7da5ad17b347" category="list-text">Você já provisionou um cluster do Amazon EKS na AWS. Para mais informações, consulte o <block ref="ae2d81862ffd2c0afcf7ba06af1fbd2e" category="inline-link-macro-rx"></block> .</block>
  <block id="be3455a34c69a26df1a5f04a6245249b" category="inline-link-macro">Documentação do NetApp Trident</block>
  <block id="1ac8e4f74be6c2aad80e2d33e0bdef83" category="list-text">Você instalou o NetApp Trident no seu cluster Kubernetes local.  Além disso, você configurou esta instância do Trident para usar sua plataforma de armazenamento NetApp ONTAP local ao provisionar e gerenciar recursos de armazenamento. Para mais informações, consulte o <block ref="eaacbbbc0da023a88cdd2b5800b9ea3b" category="inline-link-macro-rx"></block> .</block>
  <block id="6c45529675023ab110b59c01a71b6038" category="list-text">Você instalou o NetApp Trident no seu cluster Amazon EKS.  Além disso, você configurou esta instância do Trident para usar sua instância do Amazon FSx ONTAP ao provisionar e gerenciar recursos de armazenamento. Para mais informações, consulte o <block ref="eaacbbbc0da023a88cdd2b5800b9ea3b" category="inline-link-macro-rx"></block> .</block>
  <block id="f8090d27d981a98d65c4401bdd84b3bf" category="inline-link-macro">Documentação da Amazon Virtual Private Network (VPN)</block>
  <block id="c09961db559c7c906d851ebf8ba40ac5" category="list-text">Você deve ter conectividade de rede bidirecional entre seu data center local e sua Nuvem Privada Virtual (VPC) na AWS.  Para mais detalhes sobre as várias opções para implementar isso, consulte o<block ref="f5c50c4f502917d968e827ba0a3b9d8e" category="inline-link-macro-rx"></block> .</block>
  <block id="077b7144cc60353e8c8fdc9663398f24" category="section-title">Instalar a plataforma Domino Enterprise AI na AWS</block>
  <block id="5e1251e5d0134550a0ea5f1f02c14c3a" category="paragraph">Para instalar a plataforma Domino Enterprise MLOps na AWS, siga as instruções descritas em<block ref="7ebd1f818144f08a887fe5d8dbad016a" category="inline-link-macro-rx"></block> .  Você deve implantar o Domino no mesmo cluster do Amazon EKS que você provisionou anteriormente.  Além disso, o NetApp Trident já deve estar instalado e configurado neste cluster EKS, e você deve especificar uma classe de armazenamento gerenciada pelo Trident como a classe de armazenamento compartilhado no seu arquivo de configuração de instalação domino.yml.</block>
  <block id="feee67bbfd0f30a09eeb08ca21cdf38d" category="inline-link-macro">Guia de referência de configuração de instalação do Domino</block>
  <block id="8facc83d9ba07b807b37a1cf4c7f8a74" category="admonition">Consulte o<block ref="ace9eaa491d11b57c3774d7e21b1cd72" category="inline-link-macro-rx"></block> para obter detalhes sobre como especificar uma classe de armazenamento compartilhado no seu arquivo de configuração de instalação domino.yml.</block>
  <block id="11f21d6309deb4cfcdc7f2cdb4fd0839" category="inline-link-macro">Relatório Técnico TR-4952</block>
  <block id="78dd0d0a7a9f103f53daa672d459adb9" category="admonition"><block ref="3de90155c2505cad82b61f16af3049bc" category="inline-link-macro-rx"></block>explica a implantação do Domino na AWS com o Amazon FSx ONTAP e pode ser uma referência útil para solucionar quaisquer problemas que surjam.</block>
  <block id="aa2a36e425ea068322a0e37b07481ba8" category="section-title">Habilitar Domino Nexus</block>
  <block id="1a942f929d8ad029b828b8e738a86a07" category="paragraph">Em seguida, você deve habilitar o Domino Nexus.  Consulte o<block ref="31b0fd9bf4991ddcfdb80d02c1415fe4" category="inline-link-macro-rx"></block> para mais detalhes.</block>
  <block id="fa64dcf7a96dbbcd90b8729d4d59ab2f" category="section-title">Implante um Domino Data Plane em seu data center local</block>
  <block id="4ad85753a09f6b6e21cf6089aa28f2b2" category="paragraph">Em seguida, você deve implantar um Domino Data Plane no seu data center local.  Você deve implantar esse plano de dados no cluster Kubernetes local que você provisionou anteriormente.  Além disso, o NetApp Trident já deve estar instalado e configurado neste cluster do Kubernetes.  Consulte o<block ref="d46974ff7fcd2c0e55b6b55f2aa698e1" category="inline-link-macro-rx"></block> para mais detalhes.</block>
  <block id="9fac4fc4e1be67e589c110f0c4647f2e" category="summary">MLOps multicloud híbridos com Domino Data Lab e NetApp - Visão geral da tecnologia</block>
  <block id="d8b778c81ae11eb5edbd4291a3cf8fff" category="doc">Visão geral da tecnologia</block>
  <block id="f0bbbdb43782a17fdb1b5541f4c2d25f" category="paragraph">Esta seção fornece uma visão geral da tecnologia para Hybrid Multicloud MLOps com Domino Data Lab e NetApp.</block>
  <block id="4e00c35efcd0578992f4821557db1c9e" category="paragraph">O Domino Data Lab capacita negócios baseados em modelos com sua plataforma líder de IA empresarial, na qual mais de 20% das empresas da Fortune 100 confiam.  O Domino acelera o desenvolvimento e a implantação do trabalho de ciência de dados ao mesmo tempo em que aumenta a colaboração e a governança.  Com a Domino, empresas no mundo todo podem desenvolver medicamentos melhores, cultivar plantações mais produtivas, construir carros melhores e muito mais.  Fundada em 2013, a Domino é apoiada pela Coatue Management, Great Hill Partners, Highland Capital, Sequoia Capital e outros investidores importantes.</block>
  <block id="582cc4e2654a5d265b3a9c8960a43e88" category="paragraph">A Domino permite que empresas e seus cientistas de dados criem, implantem e gerenciem IA em uma plataforma unificada e completa — de forma rápida, responsável e econômica.  As equipes podem acessar todos os dados, ferramentas, cálculos, modelos e projetos necessários em qualquer ambiente, para que possam colaborar, reutilizar trabalhos anteriores, rastrear modelos em produção para melhorar a precisão, padronizar com as melhores práticas e tornar a IA responsável e governada.</block>
  <block id="79aba99e2c2c50a4d5627b787bde8eae" category="list-text">*Aberto e flexível:* Acesse o mais amplo ecossistema de ferramentas e infraestrutura comerciais e de código aberto para obter as melhores inovações e sem dependência de fornecedores.</block>
  <block id="720b80ab9ad18c5e500ae8203bb712f2" category="list-text">*Sistema de Registro:* Centro central para operações e conhecimento de IA em toda a empresa, permitindo melhores práticas, colaboração multifuncional, inovação mais rápida e eficiência.</block>
  <block id="8d89627678490a8b88c851ea2fac357d" category="list-text">*Integrado:* fluxos de trabalho e automação integrados — desenvolvidos para processos, controles e governança empresarial — atendem às suas necessidades de conformidade e regulamentação.</block>
  <block id="9e390a9660aa9f11963ef8d4ebe9b58a" category="list-text">*Multinuvem híbrida:* execute cargas de trabalho de IA perto dos seus dados em qualquer lugar — no local, híbrida, em qualquer nuvem ou multinuvem — para menor custo, desempenho ideal e conformidade.</block>
  <block id="5bfd375703bc2df982ba9c5193150b90" category="paragraph"><block ref="5bfd375703bc2df982ba9c5193150b90" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80603873e677eebf28ec5645b40f7453" category="paragraph">O Domino Nexus é um painel único que permite executar cargas de trabalho de ciência de dados e aprendizado de máquina em qualquer cluster de computação — em qualquer nuvem, região ou localmente.  Ele unifica os silos de ciência de dados em toda a empresa, para que você tenha um só lugar para criar, implantar e monitorar modelos.</block>
  <block id="991a53642be15661dc9369ee1ae2085c" category="paragraph">O NetApp BlueXP unifica todos os serviços de armazenamento e dados da NetApp em uma única ferramenta que permite criar, proteger e governar seu patrimônio de dados multicloud híbrido.  Ele oferece uma experiência unificada para serviços de armazenamento e dados em ambientes locais e na nuvem, e permite simplicidade operacional por meio do poder do AIOps, com parâmetros de consumo flexíveis e proteção integrada necessários para o mundo atual liderado pela nuvem.</block>
  <block id="8814f8d780d4b85a940aa27445d68549" category="list-text">Conexão em nuvem.  ONTAP é o software de gerenciamento de armazenamento mais conectado à nuvem, com opções para armazenamento definido por software e instâncias nativas da nuvem em todas as nuvens públicas.</block>
  <block id="5dbf44a3195cc10e2873e76a30df05ac" category="section-title">Amazon FSx for NetApp ONTAP (FSx ONTAP)</block>
  <block id="bca10fd5d70f83556ba989ecf392df97" category="paragraph">O Amazon FSx ONTAP é um serviço AWS totalmente gerenciado e de primeira linha que fornece armazenamento de arquivos altamente confiável, escalável, de alto desempenho e rico em recursos, criado no popular sistema de arquivos ONTAP da NetApp. O FSx ONTAP combina os recursos familiares, o desempenho, as capacidades e as operações de API dos sistemas de arquivos NetApp com a agilidade, a escalabilidade e a simplicidade de um serviço AWS totalmente gerenciado.</block>
  <block id="193e0bb6f3a76822b629d0fae08bdb7e" category="paragraph">O Trident permite o consumo e o gerenciamento de recursos de armazenamento em todas as plataformas de armazenamento populares da NetApp , na nuvem pública ou no local, incluindo ONTAP (AFF, FAS, Select, Cloud, Amazon FSx ONTAP), software Element (NetApp HCI, SolidFire), serviço Azure NetApp Files e Google Cloud NetApp Volumes no Google Cloud.  O Trident é um orquestrador de armazenamento dinâmico compatível com Container Storage Interface (CSI) que se integra nativamente ao Kubernetes.</block>
  <block id="978ecccb92a71c90363dfd222ebdfe77" category="paragraph">O Kubernetes é uma plataforma de orquestração de contêineres distribuída e de código aberto que foi originalmente projetada pelo Google e agora é mantida pela Cloud Native Computing Foundation (CNCF).  O Kubernetes permite a automação de funções de implantação, gerenciamento e dimensionamento para aplicativos em contêineres e é a plataforma de orquestração de contêineres dominante em ambientes corporativos.</block>
  <block id="b2a7a79ed7fe83cbfb6fe2140e6fb60a" category="paragraph">O Amazon Elastic Kubernetes Service (Amazon EKS) é um serviço Kubernetes gerenciado na nuvem AWS.  O Amazon EKS gerencia automaticamente a disponibilidade e a escalabilidade dos nós do plano de controle do Kubernetes responsáveis por agendar contêineres, gerenciar a disponibilidade de aplicativos, armazenar dados de cluster e outras tarefas importantes.  Com o Amazon EKS, você pode aproveitar todo o desempenho, escala, confiabilidade e disponibilidade da infraestrutura da AWS, bem como integrações com serviços de rede e segurança da AWS.</block>
  <block id="7bdb77faa0d23db500f55d38c7812837" category="summary">MLOps multicloud híbridos com Domino Data Lab e NetApp - Exponha volumes NetApp existentes ao Domino</block>
  <block id="5f385895d8f69d19670414fea115c17e" category="doc">Expor volumes NetApp existentes ao Domino</block>
  <block id="012942ee2856a3a30e386d999ab4decd" category="paragraph">Esta seção descreve as tarefas que precisam ser executadas para expor volumes NFS NetApp ONTAP existentes à plataforma Domino MLOps.  Essas mesmas etapas se aplicam tanto no local quanto na AWS.</block>
  <block id="216745145dbb2663dd8ef64d1e7b70ce" category="section-title">Por que expor volumes do NetApp ONTAP ao Domino?</block>
  <block id="4f49bbf1791537d3f9cea32729bcf171" category="paragraph">O uso de volumes NetApp em conjunto com o Domino oferece os seguintes benefícios:</block>
  <block id="bdf339cbdff188396b615acb6642682f" category="list-text">Você pode executar cargas de trabalho em conjuntos de dados extremamente grandes aproveitando os recursos de dimensionamento do NetApp ONTAP.</block>
  <block id="ad859808af9509052afa68845ee13abf" category="list-text">Você pode executar cargas de trabalho em vários nós de computação sem precisar copiar seus dados para os nós individuais.</block>
  <block id="3019efb93cfae9d2074cee3ecba248ce" category="list-text">Você pode aproveitar os recursos de sincronização e movimentação de dados multicloud híbridos da NetApp para acessar seus dados em vários data centers e/ou nuvens.</block>
  <block id="72410fa7689169a336be6540fbab04cb" category="list-text">Você quer poder criar de forma rápida e fácil um cache dos seus dados em um data center ou nuvem diferente.</block>
  <block id="6d4734babb6928dd0a6f21c21a95be6a" category="section-title">Expor volumes NFS existentes que não foram provisionados pelo Trident</block>
  <block id="908d8e50ed4f87ffd16293ce7689ffa3" category="paragraph">Se o seu volume NetApp ONTAP NFS existente não foi provisionado pelo Trident, siga as etapas descritas nesta subseção.</block>
  <block id="b0604699a0737b4da7a79ed81a611605" category="section-title">Crie PV e PVC no Kubernetes</block>
  <block id="0b8e803956828c77b5f9c0745c726ca8" category="admonition">Para volumes locais, crie o PV e o PVC no seu cluster Kubernetes local.  Para volumes do Amazon FSx ONTAP , crie o PV e o PVC no Amazon EKS.</block>
  <block id="7ea686752cd0065765a1f236f52b6a86" category="inline-link-macro">Exemplo de NFS PV/PVC</block>
  <block id="21daa905ac0fe45b36e98c4b7c6cbfaf" category="paragraph">Primeiro, você deve criar um volume persistente (PV) e uma reivindicação de volume persistente (PVC) no seu cluster Kubernetes.  Para criar o PV e o PVC, use o<block ref="a25b642a6322d7659714e6bd71e7cd4f" category="inline-link-macro-rx"></block> do guia de administração do Domino e atualize os valores para refletir seu ambiente.  Certifique-se de especificar os valores corretos para o<block ref="89801e9e98979062e84647433a8ed3e9" prefix=" " category="inline-code"></block> ,<block ref="0a087fd97387c110f029a7a2550ff280" prefix=" " category="inline-code"></block> , e<block ref="34ae7d3a708b57f81af8fcfcd13c7a55" prefix=" " category="inline-code"></block> campos.  Além disso, recomendamos dar ao seu PV e PVC nomes exclusivos que representem a natureza dos dados armazenados no volume ONTAP NFS correspondente.  Por exemplo, se o volume contiver imagens de defeitos de fabricação, você pode nomear o PV,<block ref="7146834334002e1c2c8bbb00348a951c" prefix=" " category="inline-code"></block> , e o PVC,<block ref="2d04ce24c553ffe8e7f9b69269696618" prefix=" " category="inline-code"></block> .</block>
  <block id="3a0e23ff2bfd7dc5b55c1aeb14b0ce33" category="section-title">Registrar Volume de Dados Externos no Domino</block>
  <block id="cbde2df6a7c89370edc449dc5705d30c" category="inline-link-macro">instruções</block>
  <block id="6d38ad9604bf23123ad6f1505f8f64ce" category="paragraph">Em seguida, você deve registrar um volume de dados externo no Domino.  Para registrar um volume de dados externo, consulte o<block ref="1b56e73c8083d7259fd3343f2f8d6ce6" category="inline-link-macro-rx"></block> no guia de administração do Domino.  Ao registrar o volume, certifique-se de selecionar "NFS" no menu suspenso "Tipo de volume".  Depois de selecionar "NFS", você deverá ver seu PVC na lista "Volumes disponíveis".</block>
  <block id="f759d0a96176c0ce67a4269c5b45bc42" category="paragraph"><block ref="f759d0a96176c0ce67a4269c5b45bc42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f91c183558f2466e2e75a92424f7a3bf" category="section-title">Exponha volumes existentes que foram provisionados pelo Trident</block>
  <block id="733e83e8c2052942f7f0e96fcd19e8a4" category="paragraph">Se o seu volume existente foi provisionado pelo Trident, siga as etapas descritas nesta subseção.</block>
  <block id="57a045b809f3298056d203360becbd66" category="section-title">Editar PVC existente</block>
  <block id="aaf6f0a313e2fa37d3584aa97603489a" category="paragraph">Se o seu volume foi provisionado pelo Trident, você já tem uma reivindicação de volume persistente (PVC) correspondente ao seu volume.  Para expor este volume ao Domino, você deve editar o PVC e adicionar o seguinte rótulo à lista de rótulos no<block ref="9cc59534218c9b00f7eb481861d14401" prefix=" " category="inline-code"></block> campo:</block>
  <block id="d2790ed8ab25c08ee1efd69f0773cade" category="paragraph">Em seguida, você deve registrar um volume de dados externo no Domino.  Para registrar um volume de dados externo, consulte o<block ref="1b56e73c8083d7259fd3343f2f8d6ce6" category="inline-link-macro-rx"></block> no guia de administração do Domino.  Ao registrar o volume, certifique-se de selecionar "Genérico" no menu suspenso "Tipo de volume".  Depois de selecionar "Genérico", você deverá ver seu PVC na lista "Volumes disponíveis".</block>
  <block id="922b9696b39b06f6a4d313569231a446" category="summary">NVIDIA AI Enterprise com NetApp e VMware - Onde encontrar informações adicionais</block>
  <block id="913e298a14c5b49185ced898ccea22bd" category="list-text">NVIDIA AI Enterprise com VMware</block>
  <block id="c85cb3eda6d429393778efbed7420a50" category="list-text">Bobby Oommen, gerente sênior, NetApp</block>
  <block id="c4321e9f60724f09a097b4d8b79c6e7b" category="list-text">Ramesh Isaac, Administrador de Sistemas, NetApp</block>
  <block id="cf4995eac87d7ce5351e1043fe85683c" category="list-text">Roney Daniel, Engenheiro de Marketing Técnico, NetApp</block>
  <block id="d8299632c247aca8f771d7368ee36f9d" category="summary">NVIDIA AI Enterprise com NetApp e VMware - Arquitetura</block>
  <block id="37810ec69b6e321b4b377d835e7d84ac" category="paragraph">Esta solução se baseia em uma arquitetura comprovada e familiar com sistemas certificados pela NetApp, VMware e NVIDIA.  Veja a tabela a seguir para mais detalhes.</block>
  <block id="95a502ec0ddaf3352c2540e3e9f65a1b" category="cell">Software de IA e análise de dados</block>
  <block id="61da586210da33a8abab150a7d7d0972" category="inline-link-macro">NVIDIA AI Enterprise para VMware</block>
  <block id="7865e440c1b499e7942ca9b659d737d6" category="cell"><block ref="7865e440c1b499e7942ca9b659d737d6" category="inline-link-macro-rx"></block></block>
  <block id="102995a1cdd2c719d7d0aa4d888fa019" category="cell">Plataforma de Virtualização</block>
  <block id="8887a9a417a1629326acdb917d224337" category="inline-link-macro">VMware vSphere</block>
  <block id="4ce5f3794d6e351daaaaa4f211e419ee" category="cell"><block ref="4ce5f3794d6e351daaaaa4f211e419ee" category="inline-link-macro-rx"></block></block>
  <block id="8cf5fbd26a1d5d924600d38015860908" category="cell">Plataforma de computação</block>
  <block id="aee87e9fe5cc4cf9193cd27c74a0a6e7" category="inline-link-macro">Sistemas certificados pela NVIDIA</block>
  <block id="b3cdb2e0e953c1639ad63fe06b8c7a37" category="cell"><block ref="b3cdb2e0e953c1639ad63fe06b8c7a37" category="inline-link-macro-rx"></block></block>
  <block id="ddca712fc3b0dad3d85e423eb97d58ea" category="cell">Plataforma de Gerenciamento de Dados</block>
  <block id="1c317db419d669c4b6473c6d462e881e" category="cell"><block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="3e549e3b22de98c96646fb0586a93db3" category="paragraph"><block ref="3e549e3b22de98c96646fb0586a93db3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69e8c6aef5e50150d499e7fa39f846ed" category="summary">O NVIDIA AI Enterprise é um conjunto completo e nativo em nuvem de software de IA e análise de dados, otimizado para que todas as organizações possam ter sucesso com IA.</block>
  <block id="68cdb7bf3dabd26e338e1ba72b549c69" category="doc">NVIDIA AI Enterprise com NetApp e VMware</block>
  <block id="61cb0c1b4a32d4815eb2a785c0c84cb8" category="paragraph">Para arquitetos e administradores de TI, as ferramentas de IA podem ser complicadas e desconhecidas.  Além disso, muitas plataformas de IA não estão prontas para empresas.  O NVIDIA AI Enterprise, com tecnologia NetApp e VMware, foi criado para oferecer uma arquitetura de IA simplificada e de nível empresarial.</block>
  <block id="eb7e5009de0ce355dc9131d958a1541e" category="paragraph"><block ref="eb7e5009de0ce355dc9131d958a1541e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d6b1f830356956d1f4b73438f8604232" category="summary">NVIDIA AI Enterprise com NetApp e VMware - Utilize o software NVIDIA NGC - Configuração</block>
  <block id="ad2376beebecdcf7846ba973fa1a005b" category="doc">Configurar</block>
  <block id="7bb37c1d3fb64e908e6704f53b5fe4a8" category="paragraph">Esta seção descreve as tarefas de configuração inicial que precisam ser executadas para utilizar o software empresarial NVIDIA NGC em um ambiente NVIDIA AI Enterprise.</block>
  <block id="1eb5d19d2c5071a5a7a569f58f2c9613" category="paragraph">Antes de executar as etapas descritas nesta seção, presumimos que você já tenha implantado o software host NVIDIA AI Enterprise seguindo as instruções descritas na<block ref="b97b75086b5941ac63fab1eee89b4777" category="inline-link-macro-rx"></block> página.</block>
  <block id="c23799b3650257af14b8af5acb107354" category="section-title">Crie uma VM convidada do Ubuntu com vGPU</block>
  <block id="0271f6ade1f60c92c6548f0e5c440e4e" category="inline-link-macro">Guia de implantação empresarial do NVIDIA AI</block>
  <block id="4be8ecb3320915437222a84e9761bcec" category="paragraph">Primeiro, você deve criar uma VM convidada do Ubuntu 20.04 com vGPU.  Para criar uma VM convidada do Ubuntu 20.04 com vGPU, siga as instruções descritas no<block ref="2009ba36309e23fc0bb68cec4d4a3e0d" category="inline-link-macro-rx"></block> .</block>
  <block id="70c95294a49e1475adbde86d8eae754e" category="section-title">Baixe e instale o software convidado NVIDIA</block>
  <block id="6148d2809a69d7225df7c6dcc1b5f94f" category="inline-link-macro">Guia de início rápido do NVIDIA AI Enterprise</block>
  <block id="8f3d19df984dedd40b9998136343e036" category="paragraph">Em seguida, você deve instalar o software convidado NVIDIA necessário na VM convidada que você criou na etapa anterior.  Para baixar e instalar o software convidado NVIDIA necessário na VM convidada, siga as instruções descritas nas seções 5.1-5.4 do<block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block> .</block>
  <block id="15186686bd7e9c36683658388b6865b0" category="admonition">Ao executar as tarefas de verificação descritas na seção 5.4, talvez seja necessário usar uma tag de versão de imagem de contêiner CUDA diferente, pois a imagem de contêiner CUDA foi atualizada desde a redação do guia.  Em nossa validação, usamos 'nvidia/cuda:11.0.3-base-ubuntu20.04'.</block>
  <block id="f43e7f8a79b8984748fff81eeb0f8c5f" category="section-title">Baixar contêiner(es) do AI/Analytics Framework</block>
  <block id="939ac3b79a18fc027a13bea0aeebcd3c" category="paragraph">Em seguida, você deve baixar as imagens de contêiner da estrutura de IA ou análise necessárias do NVIDIA NGC para que elas fiquem disponíveis na sua VM convidada.  Para baixar contêineres de estrutura na VM convidada, siga as instruções descritas no<block ref="7ea494a5b1819fa63a0ad0f42cf94b43" category="inline-link-macro-rx"></block> .</block>
  <block id="5a8b2b886d790892b5beca474e789276" category="section-title">Instalar e configurar o NetApp DataOps Toolkit</block>
  <block id="a225239f36328db667324928281cd834" category="paragraph">Em seguida, você deve instalar o NetApp DataOps Toolkit para ambientes tradicionais na VM convidada.  O NetApp DataOps Toolkit pode ser usado para gerenciar volumes de dados escaláveis no seu sistema ONTAP diretamente do terminal na VM convidada.  Para instalar o NetApp DataOps Toolkit na VM convidada, execute as seguintes tarefas.</block>
  <block id="e0288a23fbe1bfdb5f5b06d39e315992" category="list-text">Instalar pip.</block>
  <block id="bb5f723fd408b79a93de1e726de66dd1" category="list-text">Saia do terminal da VM convidada e depois efetue login novamente.</block>
  <block id="c456f18c285a54b87c3bc96f0ee32ebb" category="list-text">Configure o NetApp DataOps Toolkit.  Para concluir esta etapa, você precisará de detalhes de acesso à API para seu sistema ONTAP .  Talvez seja necessário obtê-los com seu administrador de armazenamento.</block>
  <block id="defe5f6be79f86b85d956d3e53c7ac4d" category="section-title">Criar um modelo de VM convidada</block>
  <block id="d5d979be97f5a76cf2676ef5a9c7f071" category="paragraph">Por fim, você deve criar um modelo de VM com base na sua VM convidada.  Você poderá usar este modelo para criar rapidamente VMs convidadas para utilizar o software NVIDIA NGC.</block>
  <block id="fec1fe0b41ba3927cfb9ac7c0507a1f5" category="paragraph">Para criar um modelo de VM com base na sua VM convidada, faça login no VMware vSphere, clique com o botão direito do mouse no nome da VM convidada, escolha "Clonar", escolha "Clonar para modelo..." e siga o assistente.</block>
  <block id="ae46b5fec5e9fa6540317c6aff2886d0" category="paragraph"><block ref="ae46b5fec5e9fa6540317c6aff2886d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54d7050762b4d8c4af04f27ce33f1f9b" category="summary">NVIDIA AI Enterprise com NetApp e VMware - Configuração inicial</block>
  <block id="cb8b0bf52601ee3b7c48b31850f1a45a" category="paragraph">Esta seção descreve as tarefas de configuração inicial que precisam ser executadas para utilizar o NVIDIA AI Enterprise com NetApp e VMware.</block>
  <block id="5600e01753ba1c962c6d52ee6f0bdc72" category="inline-link-macro">Matriz de suporte a produtos empresariais NVIDIA AI</block>
  <block id="b46df8af05863c37f3cd1fd611e5d2d9" category="inline-link-macro">Documentação da solução NetApp e VMware</block>
  <block id="06a8848af5cbb48d04a6b9d27ea22cae" category="paragraph">Antes de executar as etapas descritas nesta seção, presumimos que você já tenha implantado o VMware vSphere e o NetApp ONTAP.  Consulte o<block ref="fca8480728eb091fdea60a7b3cdc16f7" category="inline-link-macro-rx"></block> para obter detalhes sobre as versões suportadas do vSphere.  Consulte o<block ref="dde322875ea0d7cfe426ecec0c0dad4c" category="inline-link-macro-rx"></block> para obter detalhes sobre a implantação do VMware vSphere com o NetApp ONTAP.</block>
  <block id="a067b320746c7952a2b152f5a3af42b4" category="section-title">Instalar o software host empresarial NVIDIA AI</block>
  <block id="ee9d732a57ce821e52e753e2b4bd4a84" category="paragraph">Para instalar o software host NVIDIA AI Enterprise, siga as instruções descritas nas seções 1 a 4 do<block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block> .</block>
  <block id="f0de4adaf6568678921cef0d0e69b81f" category="summary">NVIDIA AI Enterprise com NetApp e VMware - Visão geral da tecnologia</block>
  <block id="d54433e43cda21e1ff5ab715c73883de" category="paragraph">Esta seção fornece uma visão geral da tecnologia para NVIDIA AI Enterprise com NetApp e VMware.</block>
  <block id="0719941ec04c59670033b3b1f0e3c239" category="paragraph">O NVIDIA AI Enterprise é um conjunto completo e nativo em nuvem de software de IA e análise de dados que é otimizado, certificado e suportado pela NVIDIA para ser executado no VMware vSphere com sistemas certificados pela NVIDIA.  Este software facilita a implantação, o gerenciamento e o dimensionamento simples e rápidos de cargas de trabalho de IA no ambiente de nuvem híbrida moderno.</block>
  <block id="cbd4c44d2b7fc45943b834d2a03f2a63" category="paragraph">O NVIDIA NGC hospeda um catálogo de software otimizado para GPU para que profissionais de IA desenvolvam suas soluções de IA.  Ele também fornece acesso a vários serviços de IA, incluindo o NVIDIA Base Command para treinamento de modelos, o NVIDIA Fleet Command para implantar e monitorar modelos e o NGC Private Registry para acessar e gerenciar com segurança software proprietário de IA.  Além disso, os clientes do NVIDIA AI Enterprise podem solicitar suporte pelo portal NGC.</block>
  <block id="7ee50a783ac86f99c7b7db29b77e7a2a" category="paragraph">O VMware vSphere é a plataforma de virtualização da VMware, que transforma data centers em infraestruturas de computação agregadas que incluem recursos de CPU, armazenamento e rede. O vSphere gerencia essas infraestruturas como um ambiente operacional unificado e fornece aos administradores as ferramentas para gerenciar os data centers que participam desse ambiente.</block>
  <block id="a8b821c11b6c83cd7165137d4f68a45b" category="paragraph">Os dois principais componentes do vSphere são o ESXi e o vCenter Server.  O ESXi é a plataforma de virtualização onde os administradores criam e executam máquinas virtuais e dispositivos virtuais. O vCenter Server é o serviço por meio do qual os administradores gerenciam vários hosts conectados em uma rede e agrupam recursos de host.</block>
  <block id="7cc4f632835e2377fd90f38601a3e0eb" category="paragraph">O NetApp DataOps Toolkit é uma ferramenta baseada em Python que simplifica o gerenciamento de espaços de trabalho de desenvolvimento/treinamento e servidores de inferência apoiados por armazenamento NetApp de alto desempenho e escalonável.  Os principais recursos incluem:</block>
  <block id="23b97f551923a166ae2d3223b0ed84cc" category="list-text">Clone quase instantaneamente espaços de trabalho de alta capacidade do JupyterLab para permitir experimentação ou iteração rápida.</block>
  <block id="27c7d5bdafd6a9d64ad337b08e104c87" category="list-text">Salve quase instantaneamente snapshots de espaços de trabalho de alta capacidade do JupyterLab para backup e/ou rastreabilidade/linha de base.</block>
  <block id="86f28dd8fdffc90314bf94c94e1b3c1c" category="list-text">Provisione, clone e crie snapshots de volumes de dados de alta capacidade e alto desempenho quase instantaneamente.</block>
  <block id="e4f8ad54c095217d5da72f9ba2ad87d4" category="summary">NVIDIA AI Enterprise com NetApp e VMware - Utilize o software NVIDIA NGC - Exemplo de caso de uso - Treinamento TensorFlow</block>
  <block id="b26247c1865d93ea590ef10d1150c2ae" category="doc">Exemplo de caso de uso - Tarefa de treinamento do TensorFlow</block>
  <block id="ff35b7c65e31b6103dee61bd8d89ee4f" category="paragraph">Esta seção descreve as tarefas que precisam ser executadas para executar um trabalho de treinamento do TensorFlow em um ambiente NVIDIA AI Enterprise.</block>
  <block id="0733928d94b0eba77ac6cf7f3c950257" category="paragraph">Antes de executar as etapas descritas nesta seção, presumimos que você já criou um modelo de VM convidada seguindo as instruções descritas na<block ref="ad0d852572366b07cdb7f9f854b3aedf" category="inline-link-macro-rx"></block> página.</block>
  <block id="c8281ef65e7f967dfd74821eada0aed1" category="section-title">Criar VM convidada a partir do modelo</block>
  <block id="8f195db6a3d092a2d990de535475fb82" category="paragraph">Primeiro, você deve criar uma nova VM convidada a partir do modelo criado na seção anterior.  Para criar uma nova VM convidada a partir do seu modelo, faça login no VMware vSphere, clique com o botão direito do mouse no nome do modelo, escolha "Nova VM deste modelo..." e siga o assistente.</block>
  <block id="d31d5f91fee0f03911daa3d20a90e607" category="paragraph"><block ref="d31d5f91fee0f03911daa3d20a90e607" category="inline-image-macro-rx" type="image"></block></block>
  <block id="229fea3a8aa56b262dc3dbb996d81052" category="section-title">Criar e montar volume de dados</block>
  <block id="bbdc3bf8e16f6c828df2941c605e4ef3" category="paragraph">Em seguida, você deve criar um novo volume de dados para armazenar seu conjunto de dados de treinamento.  Você pode criar rapidamente um novo volume de dados usando o NetApp DataOps Toolkit.  O comando de exemplo a seguir mostra a criação de um volume chamado 'imagenet' com capacidade de 2 TB.</block>
  <block id="bed0c39c2a853526e026bbd1d13b0a29" category="paragraph">Antes de preencher seu volume de dados com dados, você deve montá-lo na VM convidada.  Você pode montar rapidamente um volume de dados usando o NetApp DataOps Toolkit.  O comando de exemplo a seguir mostra a montagem do volume que foi criado na etapa anterior.</block>
  <block id="3418ebfa9c3ff38c1bfcd27521d4e641" category="section-title">Preencher volume de dados</block>
  <block id="ec123d1ef57b0ab158b8c891c6b936da" category="paragraph">Depois que o novo volume for provisionado e montado, o conjunto de dados de treinamento poderá ser recuperado do local de origem e colocado no novo volume.  Isso normalmente envolverá extrair dados de um data lake S3 ou Hadoop e, às vezes, envolverá a ajuda de um engenheiro de dados.</block>
  <block id="d3e84e47f561be23742b30b8c3dd7d10" category="section-title">Executar tarefa de treinamento do TensorFlow</block>
  <block id="f6a0596efc5c96edbcbffd2d19e48f41" category="paragraph">Agora, você está pronto para executar seu trabalho de treinamento do TensorFlow.  Para executar seu trabalho de treinamento do TensorFlow, execute as seguintes tarefas.</block>
  <block id="83c4072e784e0048974a7fbaef9e7567" category="list-text">Puxe a imagem do contêiner NVIDIA NGC Enterprise TensorFlow.</block>
  <block id="26857c717c90aa9ca7c999304a47e6ad" category="list-text">Inicie uma instância do contêiner NVIDIA NGC Enterprise TensorFlow.  Use a opção '-v' para anexar seu volume de dados ao contêiner.</block>
  <block id="c8dc137f2972d72ed031b7e9000c2b58" category="list-text">Execute seu programa de treinamento do TensorFlow dentro do contêiner.  O comando de exemplo a seguir mostra a execução de um programa de treinamento ResNet-50 de exemplo que está incluído na imagem do contêiner.</block>
  <block id="9dd88053035e8518106da3a40ce3aa3b" category="summary">MLOps de código aberto com NetApp - Implantação do Apache Airflow</block>
  <block id="7d2a9e50f39ee00c2b180900e7bacc92" category="doc">Implantação do Apache Airflow</block>
  <block id="c2ae2e58baf01933984b63bbfd58c6c2" category="paragraph">Esta seção descreve as tarefas que você deve concluir para implantar o Airflow no seu cluster Kubernetes.</block>
  <block id="1874d60ac69d2a867825b1b7ab0f9297" category="admonition">É possível implantar o Airflow em outras plataformas além do Kubernetes.  A implantação do Airflow em plataformas diferentes do Kubernetes está fora do escopo desta solução.</block>
  <block id="e5595c75c723712666f834213ee6568f" category="paragraph">Antes de executar o exercício de implantação descrito nesta seção, presumimos que você já tenha executado as seguintes tarefas:</block>
  <block id="c7a7dda60a4edd19d3b5bad13d43d605" category="list-text">Você já tem um cluster Kubernetes funcional.</block>
  <block id="40ef3fb23e015d9b4b46a16fa50f10d3" category="inline-link-macro">Documentação do Trident</block>
  <block id="85dd9fb465515fcb64ad8d6b67591898" category="list-text">Você já instalou e configurou o NetApp Trident no seu cluster Kubernetes.  Para mais detalhes sobre o Trident, consulte o<block ref="6bc4e9e49caf522f01de7c1314cd2006" category="inline-link-macro-rx"></block> .</block>
  <block id="ead9806c164633fcb334dc844a3d588f" category="section-title">Instalar o Helm</block>
  <block id="7586dbf5f3ac1a66383f6c201a17a341" category="inline-link">instruções de instalação</block>
  <block id="f9093f3279eca680041e957a2a0505dd" category="paragraph">O Airflow é implantado usando o Helm, um gerenciador de pacotes popular para Kubernetes.  Antes de implantar o Airflow, você deve instalar o Helm no host de salto de implantação.  Para instalar o Helm no host de salto de implantação, siga as instruções<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> na documentação oficial do Helm.</block>
  <block id="72727333279dd1f9e8b63f969075bca8" category="section-title">Definir classe de armazenamento padrão do Kubernetes</block>
  <block id="124793fd2a85b1699a94b12bf4661758" category="inline-link-macro">Implantação do Kubeflow</block>
  <block id="53b8c224038ee8370989019811dd9379" category="paragraph">Antes de implantar o Airflow, você deve designar um StorageClass padrão dentro do seu cluster Kubernetes.  O processo de implantação do Airflow tenta provisionar novos volumes persistentes usando o StorageClass padrão.  Se nenhuma StorageClass for designada como StorageClass padrão, a implantação falhará.  Para designar uma StorageClass padrão em seu cluster, siga as instruções descritas no<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block> seção.  Se você já designou uma StorageClass padrão dentro do seu cluster, pode pular esta etapa.</block>
  <block id="c7feb8d7350bb5372c4dd0dfc1383865" category="section-title">Use o Helm para implantar o Airflow</block>
  <block id="a781e1f3dbd7b5f15c3257febe820528" category="paragraph">Para implantar o Airflow no seu cluster Kubernetes usando o Helm, execute as seguintes tarefas no host de salto de implantação:</block>
  <block id="014e85e7f3bbdad1ad6f193e82d21755" category="inline-link">instruções de implantação</block>
  <block id="fe1b26293aba127732d69bdc90866794" category="list-text">Implante o Airflow usando o Helm seguindo o<block ref="e4140084ec840191180d755827375d89" category="inline-link-rx"></block> para o gráfico oficial do Airflow no Artifact Hub.  Os comandos de exemplo a seguir mostram a implantação do Airflow usando o Helm.  Modifique, adicione e/ou remova valores no<block ref="b03054dec41b4d504351d411d8221d7f" prefix=" " category="inline-code"></block> arquivo conforme necessário, dependendo do seu ambiente e da configuração desejada.</block>
  <block id="fa7edbfc4d9facbb8db918116ff0ae46" category="list-text">Confirme se todos os pods Airflow estão funcionando.  Pode levar alguns minutos para que todos os pods sejam iniciados.</block>
  <block id="9bb040ffef8c89d0861be81732ca17de" category="list-text">Obtenha a URL do serviço web do Airflow seguindo as instruções impressas no console quando você implantou o Airflow usando o Helm na etapa 1.</block>
  <block id="0db6a8f601b49c6c3780b668eac398a8" category="list-text">Confirme se você consegue acessar o serviço web Airflow.</block>
  <block id="ae954beef496ebe087806e1ce5f985b1" category="paragraph"><block ref="ae954beef496ebe087806e1ce5f985b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1358ee6f6793d8ad5c774e77af0ef2f8" category="summary">MLOps de código aberto com NetApp - Use o NetApp DataOps Toolkit com Airflow</block>
  <block id="a6341ca5ab25e7d3076dec050c9e5a97" category="doc">Use o NetApp DataOps Toolkit com o Airflow</block>
  <block id="a408a973f45f990bcd545653e35109ff" category="paragraph">O<block ref="d2f8e20a78f43c00804244e7ccbfa516" category="inline-link-rx"></block> pode ser usado em conjunto com o Airflow.  Usar o NetApp DataOps Toolkit com o Airflow permite incorporar operações de gerenciamento de dados do NetApp , como criar snapshots e clones, em fluxos de trabalho automatizados orquestrados pelo Airflow.</block>
  <block id="dee957e8ec77b256b931e812220f0553" category="inline-link">Exemplos de fluxo de ar</block>
  <block id="b6cc356bf5062501529145b3a4643413" category="paragraph">Consulte o<block ref="7c367129528d87aa1adf73a57a51aa4d" category="inline-link-rx"></block> seção no repositório GitHub do NetApp DataOps Toolkit para obter detalhes sobre como usar o kit de ferramentas com o Airflow.</block>
  <block id="95cd1b9d487589b619592ac7a94f1001" category="summary">MLOps de código aberto com NetApp - Arquitetura</block>
  <block id="21d5dd37b5f077a36d22ba32af4054e6" category="paragraph">Esta solução não depende de hardware específico.  A solução é compatível com qualquer dispositivo de armazenamento físico, instância definida por software ou serviço de nuvem da NetApp suportado pelo NetApp Trident.  Exemplos incluem um sistema de armazenamento NetApp AFF , Amazon FSx ONTAP, Azure NetApp Files, Google Cloud NetApp Volumes ou uma instância NetApp Cloud Volumes ONTAP .  Além disso, a solução pode ser implementada em qualquer cluster do Kubernetes, desde que a versão do Kubernetes usada seja compatível com o NetApp Trident e os outros componentes da solução que estão sendo implementados.  Para obter uma lista de versões do Kubernetes suportadas pelo Trident, consulte<block ref="7e5b92b70f9fb8a6ea9680492953995f" category="inline-link-rx"></block> .  Consulte as tabelas a seguir para obter detalhes sobre os ambientes que foram usados para validar os vários componentes desta solução.</block>
  <block id="f9004e284a207cf92c8642965dc258f6" category="section-title">Ambiente de validação do Apache Airflow</block>
  <block id="68782f72ebeb2cac06f03226a6e941bb" category="cell">Componente de software</block>
  <block id="385904ba8ac27bcacafadf2113386df4" category="cell">Apache Airflow</block>
  <block id="78fd3ce4c7835c8336b8c4f52bbd8570" category="inline-link-macro">Gráfico do Apache Airflow Helm</block>
  <block id="923fc06abfe0b856f72313cb88706558" category="cell">2.0.1, implantado via<block ref="d1ea82e80be31e00d2b939c38f87e0a0" category="inline-link-macro-rx"></block> 8.0.8</block>
  <block id="836eb480bf66641d4fb44675e000d22b" category="cell">1,18</block>
  <block id="d029b605d0129cdb050642645b32b1db" category="cell">21,01</block>
  <block id="44ce1bc6a7380dccbb311f0fa6cd1972" category="section-title">Ambiente de validação JupyterHub</block>
  <block id="6a1bd94b05289cc97fd96ec055920439" category="cell">JupyterHub</block>
  <block id="263ec1d326c1f5a1bfd24b88cb972a38" category="inline-link-macro">Gráfico do JupyterHub Helm</block>
  <block id="6af30397902bd26914df2ae5955c4be8" category="cell">4.1.5, implantado via<block ref="26830a1e301761faef592d8e74481ce6" category="inline-link-macro-rx"></block> 3.3.7</block>
  <block id="c272116b61605b9462784a01f5899785" category="cell">1,29</block>
  <block id="4e9b156e7e2788c8cd4b0877fd922657" category="cell">24,02</block>
  <block id="aa3652d1dedca9375b76c8e59797d756" category="section-title">Ambiente de Validação MLflow</block>
  <block id="c8d3451e7307fb1b46769ec23ea7906a" category="cell">Fluxo de ML</block>
  <block id="04d257103d25b778df7089d6dbb0cb44" category="inline-link-macro">Gráfico Helm do MLflow</block>
  <block id="4814bad32946214124af37f70a7bee91" category="cell">2.14.1, implantado via<block ref="4baf34adb826df0481d498e42290114c" category="inline-link-macro-rx"></block> 1.4.12</block>
  <block id="6eeb675638e9c361028379b88415e2de" category="section-title">Ambiente de Validação Kubeflow</block>
  <block id="bb643a3a76aab569f9245a19f77d4b65" category="cell">Fluxo de cubo</block>
  <block id="e0d8584ae6ed8fd534954ae8ed8755a3" category="inline-link-macro">implantarKF</block>
  <block id="bb675cbb86ae4db4a1f3da16e57113cd" category="cell">1.7, implantado via<block ref="f0761e2008489c964db22d8d03da0a67" category="inline-link-macro-rx"></block> 0.1.1</block>
  <block id="32b2e96c4f6d14da1df5b25db372de8f" category="cell">1,26</block>
  <block id="217af7d1776d22530d98be04d104fd49" category="cell">23,07</block>
  <block id="db5eb84117d06047c97c9a0191b5fffe" category="section-title">Apoiar</block>
  <block id="b2e75bbfb9933bc21b7f875e8676641d" category="inline-link-macro">entre em contato com a NetApp</block>
  <block id="952c6ea6549ebf347f6aae3d6b029756" category="paragraph">A NetApp não oferece suporte empresarial para Apache Airflow, JupyterHub, MLflow, Kubeflow ou Kubernetes.  Se você estiver interessado em uma plataforma MLOps totalmente suportada,<block ref="15a32e54137b30751a17b6bf2b412f99" category="inline-link-macro-rx"></block> sobre soluções MLOps totalmente suportadas que a NetApp oferece em conjunto com parceiros.</block>
  <block id="6999319a5a39a9ca41436977f2cb8b8d" category="summary">MLOps de código aberto com NetApp - Visão geral da tecnologia</block>
  <block id="4c9ffff73cd2c66ec9f6be3cb2b21333" category="paragraph">Esta seção se concentra na visão geral da tecnologia para OpenSource MLOps com NetApp.</block>
  <block id="5cd2adc9e2a5254e4c1da803519f298b" category="section-title">Inteligência artificial</block>
  <block id="c2fabc0982aa161064ff2b73f50800d5" category="paragraph">IA é uma disciplina da ciência da computação na qual os computadores são treinados para imitar as funções cognitivas da mente humana.  Os desenvolvedores de IA treinam computadores para aprender e resolver problemas de uma maneira semelhante, ou até mesmo superior, aos humanos.  Aprendizado profundo e aprendizado de máquina são subcampos da IA.  As organizações estão adotando cada vez mais IA, ML e DL para dar suporte às suas necessidades comerciais críticas.  Alguns exemplos são os seguintes:</block>
  <block id="b3e764d3292b880c63140b20b9a90e6c" category="list-text">Analisar grandes quantidades de dados para descobrir insights de negócios até então desconhecidos</block>
  <block id="30512c04b26c269ec31ecd09f1f3a208" category="list-text">Interagindo diretamente com os clientes usando processamento de linguagem natural</block>
  <block id="4ee20869dbb821d3744d87176797401f" category="list-text">Automatizar vários processos e funções de negócios</block>
  <block id="5919922c658bd2a4f33f0cf546be3ea9" category="paragraph">As cargas de trabalho modernas de treinamento e inferência de IA exigem recursos de computação massivamente paralelos.  Portanto, as GPUs estão sendo cada vez mais usadas para executar operações de IA porque as capacidades de processamento paralelo das GPUs são muito superiores às das CPUs de uso geral.</block>
  <block id="5382aaf8b3d2fdeb6717f9805b0dd511" category="section-title">Recipientes</block>
  <block id="2154bae452b2343b649ee4b088b399f6" category="paragraph">Os contêineres são instâncias isoladas do espaço do usuário que são executadas sobre um kernel de sistema operacional de host compartilhado.  A adoção de contêineres está aumentando rapidamente.  Os contêineres oferecem muitos dos mesmos benefícios de sandbox de aplicativos que as máquinas virtuais (VMs) oferecem.  No entanto, como as camadas do hipervisor e do sistema operacional convidado das quais as VMs dependem foram eliminadas, os contêineres são muito mais leves.  A figura a seguir descreve uma visualização de máquinas virtuais versus contêineres.</block>
  <block id="91945d3c9ebb2261142b9c7fc516b559" category="inline-link">Site do Docker</block>
  <block id="d1920cb2aa1d83b6e74ea477546e30a3" category="paragraph">Os contêineres também permitem o empacotamento eficiente de dependências de aplicativos, tempos de execução e assim por diante, diretamente com um aplicativo.  O formato de embalagem de contêiner mais comumente usado é o contêiner Docker.  Um aplicativo que foi conteinerizado no formato de contêiner Docker pode ser executado em qualquer máquina que possa executar contêineres Docker.  Isso é verdadeiro mesmo que as dependências do aplicativo não estejam presentes na máquina, porque todas as dependências são empacotadas no próprio contêiner.  Para mais informações, visite o<block ref="f3aa778c455b7c9002cc51cdc41e7924" category="inline-link-rx"></block> .</block>
  <block id="0d64529eaeaf491f582b2ba0df6149c7" category="paragraph"><block ref="0d64529eaeaf491f582b2ba0df6149c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1304134d4f70b5d09af5fb5a8bda1de8" category="inline-link">Site do Kubernetes</block>
  <block id="f0ce8ef614fdf23fe30bc43ff89f53d3" category="paragraph">O Kubernetes é uma plataforma de orquestração de contêineres distribuída e de código aberto que foi originalmente projetada pelo Google e agora é mantida pela Cloud Native Computing Foundation (CNCF).  O Kubernetes permite a automação de funções de implantação, gerenciamento e dimensionamento para aplicativos em contêineres.  Nos últimos anos, o Kubernetes emergiu como a plataforma dominante de orquestração de contêineres.  Para mais informações, visite o<block ref="b99a36b6d7a8af9ad1172136115f0275" category="inline-link-rx"></block> .</block>
  <block id="759b696484e9a0ab24afe3237dd85e66" category="paragraph"><block ref="0d26e0900d0eeb1b6e1c8f5cfee8510e" category="inline-link-macro-rx"></block>permite o consumo e o gerenciamento de recursos de armazenamento em todas as plataformas de armazenamento populares da NetApp , na nuvem pública ou local, incluindo ONTAP (AFF, FAS, Select, Cloud, Amazon FSx ONTAP), serviço Azure NetApp Files e Google Cloud NetApp Volumes.  O Trident é um orquestrador de armazenamento dinâmico compatível com Container Storage Interface (CSI) que se integra nativamente ao Kubernetes.</block>
  <block id="db7f413e96e248375d3fabd005ca4fee" category="paragraph">O<block ref="c4bca757471e0afa8bcb4da8a5f5e802" category="inline-link-macro-rx"></block> é uma ferramenta baseada em Python que simplifica o gerenciamento de espaços de trabalho de desenvolvimento/treinamento e servidores de inferência apoiados por armazenamento NetApp de alto desempenho e escalável.  Os principais recursos incluem:</block>
  <block id="b96dbbd391395e38a8ba72ae75c21dc9" category="list-text">Provisione rapidamente novos espaços de trabalho de alta capacidade apoiados por armazenamento NetApp de alto desempenho e escalonável.</block>
  <block id="629509198041b5749e015afa6a9b2629" category="list-text">Clone quase instantaneamente espaços de trabalho de alta capacidade para permitir experimentação ou iteração rápida.</block>
  <block id="01f719401b5bc2f16f328b588b0bef97" category="list-text">Salve instantâneos de espaços de trabalho de alta capacidade para backup e/ou rastreabilidade/linha de base.</block>
  <block id="8b4d3b8f8e04f8cfef020d43ad93e87a" category="paragraph">O Apache Airflow é uma plataforma de gerenciamento de fluxo de trabalho de código aberto que permite a criação programática, o agendamento e o monitoramento de fluxos de trabalho empresariais complexos.  Ele é frequentemente usado para automatizar fluxos de trabalho de ETL e pipeline de dados, mas não se limita a esses tipos de fluxos de trabalho.  O projeto Airflow foi iniciado pelo Airbnb, mas desde então se tornou muito popular no setor e agora está sob os auspícios da Apache Software Foundation.  O Airflow é escrito em Python, os fluxos de trabalho do Airflow são criados por meio de scripts Python e o Airflow é projetado sob o princípio de "configuração como código".  Muitos usuários corporativos do Airflow agora executam o Airflow no Kubernetes.</block>
  <block id="8fb4a72500791f0bea82c5c9b4c33772" category="section-title">Grafos Acíclicos Dirigidos (GADs)</block>
  <block id="afd712bbacf94fbaf2852bd23c6b1a84" category="paragraph">No Airflow, os fluxos de trabalho são chamados de Gráficos Acíclicos Direcionados (DAGs).  Os DAGs são compostos de tarefas executadas em sequência, em paralelo ou uma combinação dos dois, dependendo da definição do DAG.  O agendador do Airflow executa tarefas individuais em uma matriz de trabalhadores, aderindo às dependências de nível de tarefa especificadas na definição do DAG.  Os DAGs são definidos e criados por meio de scripts Python.</block>
  <block id="802125395813e0bec35472d0403ab94e" category="section-title">Caderno Jupyter</block>
  <block id="a0b0430a41f582a12dac8f4d63ab450d" category="inline-link">Site do Jupyter</block>
  <block id="2ea401316bb56cd0dd460196fdb8bddc" category="paragraph">Os Jupyter Notebooks são documentos semelhantes a wiki que contêm código ativo e texto descritivo.  Os Jupyter Notebooks são amplamente utilizados na comunidade de IA e ML como um meio de documentar, armazenar e compartilhar projetos de IA e ML.  Para mais informações sobre Jupyter Notebooks, visite o<block ref="412a2c3f2a7af96a2a4f6a512ee2088e" category="inline-link-rx"></block> .</block>
  <block id="cc68740519bf7afc9dc5c17acc7db61e" category="section-title">Servidor de notebook Jupyter</block>
  <block id="1ceb0a3b747e9e685e69bf855aa91001" category="paragraph">Um Jupyter Notebook Server é um aplicativo web de código aberto que permite aos usuários criar Jupyter Notebooks.</block>
  <block id="d837769caeb4d9edfd53e4a5a4b94fce" category="inline-link">Site JupyterHub</block>
  <block id="aa77da24b3b7d00c6c4b22044c64a028" category="paragraph">O JupyterHub é um aplicativo multiusuário que permite que um usuário individual provisione e acesse seu próprio servidor Jupyter Notebook.  Para mais informações sobre o JupyterHub, visite o<block ref="8b235ac1daecf8d06ace248b8ac07b97" category="inline-link-rx"></block> .</block>
  <block id="891056fdef376263d6563716a06437cd" category="inline-link">Site MLflow</block>
  <block id="ea79d93ff06996ce8a177ec9a6f59b26" category="paragraph">MLflow é uma plataforma popular de gerenciamento de ciclo de vida de IA de código aberto.  Os principais recursos do MLflow incluem rastreamento de experimentos de IA/ML e um repositório de modelos de IA/ML.  Para mais informações sobre o MLflow, visite o<block ref="7d5e77d7cbcfeeed8850444afe1d66af" category="inline-link-rx"></block> .</block>
  <block id="173c35c4ef789d6956a0cd6fbd9a0cfc" category="inline-link">Site do Kubeflow</block>
  <block id="9a9c31b74376d75ed88c300dfd734acf" category="paragraph">Kubeflow é um kit de ferramentas de IA e ML de código aberto para Kubernetes que foi originalmente desenvolvido pelo Google.  O projeto Kubeflow torna as implantações de fluxos de trabalho de IA e ML no Kubernetes simples, portáteis e escaláveis.  O Kubeflow abstrai as complexidades do Kubernetes, permitindo que cientistas de dados se concentrem no que sabem fazer melhor: ciência de dados.  Veja a figura a seguir para uma visualização.  O Kubeflow é uma boa opção de código aberto para organizações que preferem uma plataforma MLOps completa.  Para mais informações, visite o<block ref="bbfd4ba68f44e2ff98f04ea32205485d" category="inline-link-rx"></block> .</block>
  <block id="e569c07c88fe6f8af1f63410c200abd1" category="section-title">Pipelines Kubeflow</block>
  <block id="7236436bac67d8eaadbf52811774b916" category="inline-link">documentação oficial do Kubeflow</block>
  <block id="f69bb06b79f60baced2f6faf97fc9e14" category="paragraph">Os pipelines do Kubeflow são um componente essencial do Kubeflow.  Os Kubeflow Pipelines são uma plataforma e um padrão para definir e implantar fluxos de trabalho de IA e ML portáteis e escaláveis. Para mais informações, consulte o<block ref="34d1e4686e190f53e3511c4faa8ac68b" category="inline-link-rx"></block> .</block>
  <block id="7724cfbda1ff4c3052c280f6b4af599c" category="section-title">Cadernos Kubeflow</block>
  <block id="352ec4b0886cdd10b69d3efaa4071648" category="paragraph">O Kubeflow simplifica o provisionamento e a implantação de Jupyter Notebook Servers no Kubernetes.  Para obter mais informações sobre Jupyter Notebooks no contexto do Kubeflow, consulte o<block ref="273f9b54e4f57ca19b4597f14d191196" category="inline-link-rx"></block> .</block>
  <block id="d8d51bb44e1cdcb1d7fde82b687339bd" category="section-title">Katib</block>
  <block id="8f5f81b63b950128a2104cb77339c846" category="paragraph">Katib é um projeto nativo do Kubernetes para aprendizado de máquina automatizado (AutoML).  O Katib oferece suporte ao ajuste de hiperparâmetros, parada antecipada e pesquisa de arquitetura neural (NAS).  Katib é um projeto agnóstico em relação a frameworks de aprendizado de máquina (ML).  Ele pode ajustar hiperparâmetros de aplicativos escritos em qualquer linguagem escolhida pelos usuários e oferece suporte nativo a muitas estruturas de ML, como TensorFlow, MXNet, PyTorch, XGBoost e outras.  O Katib oferece suporte a vários algoritmos AutoML, como otimização bayesiana, estimadores de árvore de Parzen, busca aleatória, estratégia de evolução de adaptação de matriz de covariância, hiperbanda, busca de arquitetura neural eficiente, busca de arquitetura diferenciável e muito mais.  Para obter mais informações sobre Jupyter Notebooks no contexto do Kubeflow, consulte o<block ref="5b959b0f3dbfc4557138b63a781b201c" category="inline-link-rx"></block> .</block>
  <block id="592d6ad3868437ff65a70353ab870f50" category="list-text">Escalabilidade perfeita e operações não disruptivas.  O ONTAP oferece suporte à adição não disruptiva de capacidade aos controladores existentes e aos clusters escaláveis.  Os clientes podem atualizar para as tecnologias mais recentes sem migrações de dados dispendiosas ou interrupções.</block>
  <block id="49a023178611b07475bac0823fc2dd53" category="section-title">Cópias de instantâneos da NetApp</block>
  <block id="42884680ea9780d61f4cce71fdc606b1" category="paragraph">Uma cópia do NetApp Snapshot é uma imagem somente leitura e pontual de um volume.  A imagem consome espaço de armazenamento mínimo e gera sobrecarga de desempenho insignificante porque ela registra apenas alterações em arquivos criados desde a última cópia do Snapshot, conforme ilustrado na figura a seguir.</block>
  <block id="13455e6dd452fcc850acd6696e670600" category="paragraph">As cópias de instantâneos devem sua eficiência à tecnologia de virtualização de armazenamento ONTAP , o Write Anywhere File Layout (WAFL).  Assim como um banco de dados, o WAFL usa metadados para apontar para blocos de dados reais no disco.  Mas, diferentemente de um banco de dados, o WAFL não substitui blocos existentes.  Ele grava dados atualizados em um novo bloco e altera os metadados.  É porque o ONTAP faz referência a metadados quando cria uma cópia do Snapshot, em vez de copiar blocos de dados, que as cópias do Snapshot são tão eficientes.  Isso elimina o tempo de busca que outros sistemas levam para localizar os blocos a serem copiados, bem como o custo de fazer a cópia em si.</block>
  <block id="921d0d1d37872e6233bf4da3688b03ef" category="paragraph">Você pode usar uma cópia de Snapshot para recuperar arquivos individuais ou LUNs ou para restaurar todo o conteúdo de um volume.  O ONTAP compara as informações do ponteiro na cópia do Snapshot com os dados no disco para reconstruir o objeto ausente ou danificado, sem tempo de inatividade ou custo significativo de desempenho.</block>
  <block id="fbfe7fb9706620c5ddb7b53cd9e06fa0" category="paragraph"><block ref="fbfe7fb9706620c5ddb7b53cd9e06fa0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76a33b697177fedefd70387e86214ebd" category="section-title">Tecnologia NetApp FlexClone</block>
  <block id="78e8cd917c99154d22a94ba80186ac33" category="paragraph">A tecnologia NetApp FlexClone faz referência a metadados de instantâneo para criar cópias graváveis e pontuais de um volume.  As cópias compartilham blocos de dados com seus pais, não consumindo nenhum armazenamento, exceto o necessário para metadados até que as alterações sejam gravadas na cópia, conforme ilustrado na figura a seguir.  Enquanto cópias tradicionais podem levar minutos ou até horas para serem criadas, o software FlexClone permite que você copie até os maiores conjuntos de dados quase instantaneamente.  Isso o torna ideal para situações em que você precisa de várias cópias de conjuntos de dados idênticos (um espaço de trabalho de desenvolvimento, por exemplo) ou cópias temporárias de um conjunto de dados (testar um aplicativo em um conjunto de dados de produção).</block>
  <block id="f28d7ba8bb28ad8ce873b4ec7ed61164" category="paragraph"><block ref="f28d7ba8bb28ad8ce873b4ec7ed61164" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f67824f4f94415299484432a092f76b1" category="section-title">Tecnologia de replicação de dados NetApp SnapMirror</block>
  <block id="553416a55e03cc49df61e631d17b8011" category="paragraph">O software NetApp SnapMirror é uma solução de replicação unificada, econômica e fácil de usar em toda a malha de dados.  Ele replica dados em alta velocidade via LAN ou WAN.  Ele oferece alta disponibilidade de dados e replicação rápida de dados para aplicativos de todos os tipos, incluindo aplicativos críticos de negócios em ambientes virtuais e tradicionais.  Quando você replica dados para um ou mais sistemas de armazenamento NetApp e atualiza continuamente os dados secundários, seus dados são mantidos atualizados e estão disponíveis sempre que você precisar deles.  Não são necessários servidores de replicação externos.  Veja a figura a seguir para ver um exemplo de uma arquitetura que aproveita a tecnologia SnapMirror .</block>
  <block id="5a12ba5d186c9ffcce65438f531e7c47" category="paragraph">O software SnapMirror aproveita a eficiência do armazenamento NetApp ONTAP enviando apenas blocos alterados pela rede.  O software SnapMirror também usa compactação de rede integrada para acelerar as transferências de dados e reduzir a utilização da largura de banda da rede em até 70%.  Com a tecnologia SnapMirror , você pode aproveitar um fluxo fino de dados de replicação para criar um único repositório que mantém tanto o espelho ativo quanto as cópias anteriores de um ponto no tempo, reduzindo o tráfego de rede em até 50%.</block>
  <block id="2ab1a10694bb0d67320839630a1c9ccb" category="paragraph"><block ref="c4152c5b1804294b9bc91a2fa3a92230" category="inline-link-macro-rx"></block>é um serviço da NetApp para sincronização de dados rápida e segura.  Se você precisa transferir arquivos entre compartilhamentos de arquivos NFS ou SMB locais, NetApp StorageGRID, NetApp ONTAP S3, Google Cloud NetApp Volumes, Azure NetApp Files, AWS S3, AWS EFS, Azure Blob, Google Cloud Storage ou IBM Cloud Object Storage, o BlueXP Copy and Sync move os arquivos para onde você precisa de forma rápida e segura.</block>
  <block id="7e333cc0e24ef7489559129fd944c91f" category="paragraph">Após seus dados serem transferidos, eles estarão totalmente disponíveis para uso tanto na origem quanto no destino.  O BlueXP Copy and Sync pode sincronizar dados sob demanda quando uma atualização é acionada ou sincronizar dados continuamente com base em uma programação predefinida.  De qualquer forma, o BlueXP Copy and Sync move apenas os deltas, minimizando o tempo e o dinheiro gastos na replicação de dados.</block>
  <block id="22716a1c6493f7fb09f4caf2084ad23c" category="paragraph">O BlueXP Copy and Sync é uma ferramenta de software como serviço (SaaS) extremamente simples de configurar e usar.  As transferências de dados acionadas pelo BlueXP Copy and Sync são realizadas por corretores de dados.  Os corretores de dados BlueXP Copy and Sync podem ser implantados na AWS, Azure, Google Cloud Platform ou no local.</block>
  <block id="204b9ffafe28e07fef53f08e2924e621" category="paragraph"><block ref="8eb894646a418e33ca3d088f11e4914c" category="inline-link-macro-rx"></block>é um software baseado em cliente para migrações de dados de qualquer para NetApp e de NetApp para NetApp e insights do sistema de arquivos.  O XCP foi projetado para escalar e atingir o desempenho máximo utilizando todos os recursos do sistema disponíveis para lidar com conjuntos de dados de alto volume e migrações de alto desempenho.  O XCP ajuda você a obter visibilidade completa do sistema de arquivos com a opção de gerar relatórios.</block>
  <block id="957e30f73566564bd8a99a6fac13e015" category="section-title">Volumes do NetApp ONTAP FlexGroup</block>
  <block id="22bd32dacc144ffc2601e6685260b4c3" category="paragraph">Um conjunto de dados de treinamento pode ser uma coleção de potencialmente bilhões de arquivos.  Os arquivos podem incluir texto, áudio, vídeo e outras formas de dados não estruturados que devem ser armazenados e processados para serem lidos em paralelo.  O sistema de armazenamento deve armazenar um grande número de arquivos pequenos e deve ler esses arquivos em paralelo para E/S sequencial e aleatória.</block>
  <block id="6d7d8c1311f5ac7d2ed289e012822f78" category="paragraph">Um volume FlexGroup é um único namespace que compreende vários volumes de membros constituintes, conforme mostrado na figura a seguir.  Do ponto de vista de um administrador de armazenamento, um volume FlexGroup é gerenciado e age como um FlexVol volume NetApp FlexVol.  Os arquivos em um volume FlexGroup são alocados para volumes de membros individuais e não são distribuídos entre volumes ou nós.  Eles permitem os seguintes recursos:</block>
  <block id="28f25e3d6de5d5fe801c8d194234f0a5" category="list-text">Os volumes FlexGroup fornecem vários petabytes de capacidade e baixa latência previsível para cargas de trabalho com muitos metadados.</block>
  <block id="82b42713e1be50bb140b7e85eecdd91f" category="list-text">Eles suportam até 400 bilhões de arquivos no mesmo namespace.</block>
  <block id="50af21bd57d5360eb9ffc8dbc4b9a5bd" category="list-text">Eles oferecem suporte a operações paralelizadas em cargas de trabalho NAS em CPUs, nós, agregados e volumes FlexVol constituintes.</block>
  <block id="b0d8567b3e8a1e892d0b59f7a3c27292" category="paragraph"><block ref="b0d8567b3e8a1e892d0b59f7a3c27292" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6459218853a974bb2b38718e6db79ed" category="summary">Esta solução pretende demonstrar diversas ferramentas e estruturas de código aberto que podem ser incorporadas a um fluxo de trabalho de MLOps.  Essas diferentes ferramentas e estruturas podem ser usadas juntas ou separadamente, dependendo dos requisitos e do caso de uso.</block>
  <block id="eb1b19572557d2f13528a30754e9997a" category="doc">MLOps de código aberto com NetApp</block>
  <block id="aa27e598d8d01ff612acd83b47a13b21" category="paragraph">Mike Oglesby, NetApp Sufian Ahmad, NetApp Rick Huang, NetApp Mohan Acharya, NetApp</block>
  <block id="36160a80da6291faa3ebc68ede194279" category="paragraph">Empresas e organizações de todos os tamanhos e de diversos setores estão recorrendo à inteligência artificial (IA) para resolver problemas do mundo real, fornecer produtos e serviços inovadores e obter vantagem em um mercado cada vez mais competitivo.  Muitas organizações estão recorrendo a ferramentas MLOps de código aberto para acompanhar o ritmo acelerado de inovação no setor.  Essas ferramentas de código aberto oferecem recursos avançados e de ponta, mas geralmente não levam em conta a disponibilidade e a segurança dos dados.  Infelizmente, isso significa que cientistas de dados altamente qualificados são forçados a gastar uma quantidade significativa de tempo esperando para obter acesso aos dados ou esperar que operações rudimentares relacionadas a dados sejam concluídas.  Ao combinar ferramentas populares de MLOps de código aberto com uma infraestrutura de dados inteligente da NetApp, as organizações podem acelerar seus pipelines de dados, o que, por sua vez, acelera suas iniciativas de IA.  Eles podem extrair valor de seus dados e, ao mesmo tempo, garantir que eles permaneçam protegidos e seguros.  Esta solução demonstra o emparelhamento de recursos de gerenciamento de dados da NetApp com diversas ferramentas e estruturas populares de código aberto para enfrentar esses desafios.</block>
  <block id="ad3ca69dbfa62630ace9a188e93d1f45" category="paragraph">A lista a seguir destaca alguns dos principais recursos habilitados por esta solução:</block>
  <block id="e6ffdd80d6efdfae1a367b394ef6afdf" category="list-text">Os usuários podem provisionar rapidamente novos volumes de dados de alta capacidade e espaços de trabalho de desenvolvimento apoiados pelo armazenamento NetApp de alto desempenho e escalonável.</block>
  <block id="24f5e64e89b475fca21e0a2d5536aa48" category="list-text">Os usuários podem clonar quase instantaneamente volumes de dados de alta capacidade e espaços de trabalho de desenvolvimento para permitir experimentação ou iteração rápida.</block>
  <block id="4657d40d11cf0257f60a599a2bc266b6" category="list-text">Os usuários podem salvar quase instantaneamente snapshots de volumes de dados de alta capacidade e espaços de trabalho de desenvolvimento para backup e/ou rastreabilidade/linha de base.</block>
  <block id="953c95173b5d3944693633d3b6ae7711" category="paragraph"><block ref="953c95173b5d3944693633d3b6ae7711" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3e3d207c7705b0f7dc0142df9cc2790a" category="inline-link-macro">Cadernos Jupyter</block>
  <block id="d1a5554bae0723fdaf349b8047aa0d08" category="paragraph">Um fluxo de trabalho MLOps típico incorpora espaços de trabalho de desenvolvimento, geralmente assumindo a forma de<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> ; rastreamento de experimentos; pipelines de treinamento automatizados; pipelines de dados; e inferência/implantação.  Esta solução destaca diversas ferramentas e estruturas diferentes que podem ser usadas de forma independente ou em conjunto para abordar os diferentes aspectos do fluxo de trabalho.  Também demonstramos o emparelhamento de recursos de gerenciamento de dados da NetApp com cada uma dessas ferramentas.  Esta solução tem como objetivo oferecer blocos de construção a partir dos quais uma organização pode construir um fluxo de trabalho MLOps personalizado, específico para seus casos de uso e requisitos.</block>
  <block id="0b34fcae55a765c46410fb4116433e75" category="paragraph">As seguintes ferramentas/estruturas são abordadas nesta solução:</block>
  <block id="074cd5ab3a3581efcb92b990cd4ed3b6" category="list-text"><block ref="074cd5ab3a3581efcb92b990cd4ed3b6" category="inline-link-macro-rx"></block></block>
  <block id="ac10ff0174545b18e3fd3b7ab41ebc08" category="list-text"><block ref="ac10ff0174545b18e3fd3b7ab41ebc08" category="inline-link-macro-rx"></block></block>
  <block id="4275daa2701a7c7ad4c1c5df1088ada8" category="list-text"><block ref="4275daa2701a7c7ad4c1c5df1088ada8" category="inline-link-macro-rx"></block></block>
  <block id="a0cf58c060e740cca7f48b1bb399e974" category="list-text"><block ref="a0cf58c060e740cca7f48b1bb399e974" category="inline-link-macro-rx"></block></block>
  <block id="9717b9722e82e47dc4445d7ffc90b79d" category="paragraph">A lista a seguir descreve padrões comuns para implantar essas ferramentas de forma independente ou em conjunto.</block>
  <block id="3f7626e711a1e660dae85d17fdc35882" category="list-text">Implantar JupyterHub, MLflow e Apache Airflow em conjunto - JupyterHub para<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> , MLflow para rastreamento de experimentos e Apache Airflow para treinamento automatizado e pipelines de dados.</block>
  <block id="1dceee44b0bde0ef7364704241dced5a" category="list-text">Implantar Kubeflow e Apache Airflow em conjunto - Kubeflow para<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> , rastreamento de experimentos, pipelines de treinamento automatizados e inferência; e Apache Airflow para pipelines de dados.</block>
  <block id="aa815dfaf0c405504952ea2a361a2a3e" category="list-text">Implemente o Kubeflow como uma solução de plataforma MLOps completa para<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> , rastreamento de experimentos, treinamento automatizado e pipelines de dados e inferência.</block>
  <block id="6ca687fb1fabca3bf671bc9bf39dbf27" category="summary">MLOps de código aberto com NetApp - Implantação do JupyterHub</block>
  <block id="09d2043b79460eb224957589f59ab494" category="doc">Implantação do JupyterHub</block>
  <block id="2ab6902fa61e1ea6912baf903a3b0bf1" category="paragraph">Esta seção descreve as tarefas que você deve concluir para implantar o JupyterHub no seu cluster Kubernetes.</block>
  <block id="26e29fcdb4d615c34b7fedb3a0564f8f" category="admonition">É possível implantar o JupyterHub em plataformas diferentes do Kubernetes.  A implantação do JupyterHub em plataformas diferentes do Kubernetes está fora do escopo desta solução.</block>
  <block id="99b37bb800ce4a91a3634a32f40b891b" category="list-text">Você já instalou e configurou o NetApp Trident no seu cluster Kubernetes.  Para mais detalhes sobre o Trident, consulte o<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block> .</block>
  <block id="2ac6b5f4951f689f17ae54334df0112f" category="paragraph">O JupyterHub é implantado usando o Helm, um gerenciador de pacotes popular para Kubernetes.  Antes de implantar o JupyterHub, você deve instalar o Helm no seu nó de controle do Kubernetes.  Para instalar o Helm, siga as instruções<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> na documentação oficial do Helm.</block>
  <block id="c0b1a9427c281e6178bd6cbeb95bc3a8" category="paragraph">Antes de implantar o JupyterHub, você deve designar um StorageClass padrão dentro do seu cluster Kubernetes.  Para designar uma StorageClass padrão em seu cluster, siga as instruções descritas no<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block> seção.  Se você já designou uma StorageClass padrão dentro do seu cluster, pode pular esta etapa.</block>
  <block id="771d8827304382e84db174fab916e726" category="section-title">Implantar o JupyterHub</block>
  <block id="cca32ccd336a1d99e57fe4b732c1db03" category="paragraph">Depois de concluir as etapas acima, você estará pronto para implantar o JupyterHub.  A implantação do JupyterHub requer as seguintes etapas:</block>
  <block id="02e6e3cd99fedc7e13d22d86bad5b831" category="section-title">Configurar a implantação do JupyterHub</block>
  <block id="ce95551547fa8ef240a593be5a20f5ee" category="paragraph">Antes da implantação, é uma boa prática otimizar a implantação do JupyterHub para seu respectivo ambiente.  Você pode criar um arquivo *config.yaml* e utilizá-lo durante a implantação usando o gráfico Helm.</block>
  <block id="53db901aeed4328fe567404ccb21206d" category="paragraph">Um exemplo de arquivo *config.yaml* pode ser encontrado em<block ref="8c152549701847c833121b3ad8e4af72" category="inline-link-rx"></block></block>
  <block id="d4acad87b1acbfd617a3b4988bfb1864" category="admonition">Neste arquivo config.yaml, você pode definir o parâmetro *(singleuser.storage.dynamic.storageClass)* para o NetApp Trident StorageClass.  Esta é a classe de armazenamento que será usada para provisionar os volumes para espaços de trabalho de usuários individuais.</block>
  <block id="fc1be4924094aec74f37b59bbd957af8" category="section-title">Adicionando volumes compartilhados</block>
  <block id="67e834a52ce0a7019fd9a1bec4bae36f" category="paragraph">Se quiser usar um volume compartilhado para todos os usuários do JupyterHub, você pode ajustar seu *config.yaml* adequadamente.  Por exemplo, se você tiver um PersistentVolumeClaim compartilhado chamado jupyterhub-shared-volume, você pode montá-lo como /home/shared em todos os pods de usuário como:</block>
  <block id="a66a54102aa462ebdfe0146ca96eaf33" category="admonition">Esta é uma etapa opcional, você pode ajustar esses parâmetros conforme suas necessidades.</block>
  <block id="67c7fe5cd005737db341f115281a5f71" category="section-title">Implantar o JupyterHub com o Helm Chart</block>
  <block id="54ad8b66fcd369a80298610d95ca37d9" category="paragraph">Informe ao Helm sobre o repositório de gráficos do JupyterHub Helm.</block>
  <block id="f98aad3b24c5bab5b4737b8fad3a723f" category="paragraph">Isso deve mostrar uma saída como esta:</block>
  <block id="4e29332ac1db944879502e11ab327960" category="paragraph">Agora instale o gráfico configurado pelo seu config.yaml executando este comando no diretório que contém seu config.yaml:</block>
  <block id="be118fb1d0e987a9d25c71312374ffdf" category="admonition">Neste exemplo:</block>
  <block id="750e13a1159e4f2b96ba2d8fadfb1aab" category="paragraph">&lt;helm-release-name&gt; é definido como my-jupyterhub, que será o nome da sua versão do JupyterHub.  &lt;k8s-namespace&gt; é definido como my-namespace, que é o namespace onde você deseja instalar o JupyterHub.  O sinalizador --create-namespace é usado para criar o namespace se ele ainda não existir.  O sinalizador --values especifica o arquivo config.yaml que contém as opções de configuração desejadas.</block>
  <block id="0873eec3dcb328f01cc596581047ae60" category="section-title">Verificar implantação</block>
  <block id="5b252fe874ba4bfb32f7c039993801ab" category="paragraph">Enquanto a etapa 2 estiver em execução, você poderá ver os pods sendo criados a partir do seguinte comando:</block>
  <block id="828e0f094cad198231ffd340f281e098" category="paragraph">Aguarde até que o hub e o pod proxy entrem no estado Em execução.</block>
  <block id="4f8f16ff2582a84eb01cbef90f467393" category="section-title">Acesse o JupyterHub</block>
  <block id="c7433009ea218afe4c1117491e4afccb" category="paragraph">Encontre o IP que podemos usar para acessar o JupyterHub.  Execute o seguinte comando até que o EXTERNAL-IP do serviço proxy-public esteja disponível, como na saída de exemplo.</block>
  <block id="7261a4593eb504b7857e5e4dd9a5459c" category="admonition">Usamos o serviço NodePort em nosso arquivo config.yaml, você pode ajustar para seu ambiente com base em sua configuração (por exemplo, LoadBalancer).</block>
  <block id="a5673ab624b33fdb767b6ec77b9901ca" category="paragraph">Para usar o JupyterHub, insira o IP externo do serviço proxy-público em um navegador.</block>
  <block id="9b5d03606d5f2609a4b9a6f1ac626a8d" category="summary">MLOps de código aberto com NetApp - Use o NetApp DataOps Toolkit com JupyterHub</block>
  <block id="8fc5f752dfcb57cd9232177f28b14765" category="doc">Use o NetApp DataOps Toolkit com o JupyterHub</block>
  <block id="0162e970f8577425266cb5c97d21c2a7" category="paragraph">O<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block> pode ser usado em conjunto com o JupyterHub.  O uso do NetApp DataOps Toolkit com o JupyterHub permite que os usuários finais criem instantâneos de volume para backup do espaço de trabalho e/ou rastreabilidade do conjunto de dados para o modelo diretamente de um Jupyter Notebook.</block>
  <block id="8f08aaf2916d1654fc96af766c150251" category="paragraph">Antes de poder usar o DataOps Toolkit com o JupyterHub, você deve conceder permissões apropriadas à conta de serviço do Kubernetes que o JupyterHub atribui aos pods individuais do Jupyter Notebook Server.  O JupyterHub usa a conta de serviço especificada pelo<block ref="b8c80a6db053e98d7341438c2eb0aea3" prefix=" " category="inline-code"></block> variável no seu arquivo de configuração do gráfico do JupyterHub Helm.</block>
  <block id="a815fb28e94390b627bc7915911578cf" category="section-title">Criar função de cluster para o DataOps Toolkit</block>
  <block id="333372e6f3961af5df82304243a2d5ba" category="paragraph">Primeiro, crie uma função de cluster chamada 'netapp-dataops' que tenha as permissões de API do Kubernetes necessárias para criar instantâneos de volume.</block>
  <block id="3805f69a30879fb016e5c3d0a85fab77" category="section-title">Atribuir função de cluster à conta de serviço do servidor de notebook</block>
  <block id="19506ab4aa03158eeea933145bd0471d" category="paragraph">Crie uma associação de função que atribua a função de cluster 'netapp-dataops-snapshots' à conta de serviço apropriada no namespace apropriado.  Por exemplo, se você instalou o JupyterHub no namespace 'jupyterhub' e especificou a conta de serviço 'padrão' por meio do<block ref="b8c80a6db053e98d7341438c2eb0aea3" prefix=" " category="inline-code"></block> variável, você atribuiria a função de cluster 'netapp-dataops-snapshots' à conta de serviço 'default' no namespace 'jupyterhub', conforme mostrado no exemplo a seguir.</block>
  <block id="fe7233ebd9f644239a2437c55d3419e1" category="section-title">Crie instantâneos de volume no Jupyter Notebook</block>
  <block id="02dd051970bea675e5def458342cd6e3" category="paragraph">Agora, os usuários do JupyterHub podem usar o NetApp DataOps Toolkit para criar snapshots de volume diretamente de um Jupyter Notebook, conforme mostrado no exemplo a seguir.</block>
  <block id="6bd0178572fd0f85ae777cd2c67d0907" category="paragraph"><block ref="6bd0178572fd0f85ae777cd2c67d0907" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ffc4debfa03808ebe14380555e9a891" category="summary">Ingerir dados com o NetApp SnapMirror</block>
  <block id="c9cfa55f76ce30116dc6c4a9d937fa9d" category="doc">Ingerir dados no JupyterHub com o NetApp SnapMirror</block>
  <block id="98aa5dbb610473a52540e5d0699bd079" category="paragraph">O NetApp SnapMirror é uma tecnologia de replicação que permite replicar dados entre sistemas de armazenamento NetApp .  O SnapMirror pode ser usado para ingerir dados de ambientes remotos no JupyterHub.</block>
  <block id="815eb616a6188ae082d3024fbb91e45e" category="section-title">Exemplo de fluxo de trabalho e demonstração</block>
  <block id="a3e50a098653f80e6a42662ee52e8b55" category="inline-link-macro">esta postagem do blog Tech ONTAP</block>
  <block id="5eae3f83c7f60bb551b097ccf3a4012b" category="paragraph">Consulte<block ref="585bdb2d9e21d8036a261701b86d814c" category="inline-link-macro-rx"></block> para um exemplo detalhado de fluxo de trabalho e demonstração do uso do NetApp SnapMirror para ingerir dados no JupyterHub.</block>
  <block id="ba47b65d29a2bcf968281d1e04ee29bb" category="summary">MLOps de código aberto com NetApp - Implantação Kubeflow</block>
  <block id="e560b8ed748180150ee1a196f2247fce" category="paragraph">Esta seção descreve as tarefas que você deve concluir para implantar o Kubeflow no seu cluster Kubernetes.</block>
  <block id="f3538dfada37d551dd71f26249dd82c6" category="list-text">Você já tem um cluster Kubernetes funcional e está executando uma versão do Kubernetes compatível com a versão do Kubeflow que pretende implantar.  Para obter uma lista de versões do Kubernetes com suporte, consulte as dependências da sua versão do Kubeflow no<block ref="b84967824090781ee960169bb3232fc6" category="inline-link-macro-rx"></block> .</block>
  <block id="84d21063d216560d873bc66cd38d62e8" category="paragraph">Antes de implantar o Kubeflow, recomendamos designar um StorageClass padrão no seu cluster Kubernetes.  O processo de implantação do Kubeflow pode tentar provisionar novos volumes persistentes usando o StorageClass padrão.  Se nenhuma StorageClass for designada como StorageClass padrão, a implantação poderá falhar.  Para designar um StorageClass padrão dentro do seu cluster, execute a seguinte tarefa no host de salto de implantação.  Se você já designou uma StorageClass padrão dentro do seu cluster, pode pular esta etapa.</block>
  <block id="d371ec612c125519e69855ad89d4445b" category="list-text">Designe uma das suas StorageClasses existentes como a StorageClass padrão.  Os comandos de exemplo a seguir mostram a designação de uma StorageClass denominada<block ref="19a55e78496416c8db6565a114cfd5f3" prefix=" " category="inline-code"></block> como StorageClass padrão.</block>
  <block id="f830a6eea70ae3a0e7af4606462ad281" category="admonition">O<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> O tipo Trident Backend tem um tamanho mínimo de PVC que é bastante grande.  Por padrão, o Kubeflow tenta provisionar PVCs com apenas alguns GBs de tamanho.  Portanto, você não deve designar uma StorageClass que utilize o<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> Tipo de backend como StorageClass padrão para fins de implantação do Kubeflow.</block>
  <block id="7724a5f9edc284eef2e4bc112adc1dd9" category="section-title">Opções de implantação do Kubeflow</block>
  <block id="e135506d2171533787a405262eeb67bc" category="paragraph">Há muitas opções diferentes para implantar o Kubeflow.  Consulte o<block ref="59d814781a574912b676e75f9fe0e882" category="inline-link-macro-rx"></block> para obter uma lista de opções de implantação e escolher a opção mais adequada às suas necessidades.</block>
  <block id="07379a7db414d96104f4d3ab35ee3d59" category="admonition">Para fins de validação, implantamos o Kubeflow 1.7 usando<block ref="f36b6222867dc75589b32398e1411061" category="inline-link-macro-rx"></block> 0.1.1.</block>
  <block id="0dbcc7b3c9a4c5ed6afff19c771a989d" category="summary">MLOps de código aberto com NetApp - Use o NetApp DataOps Toolkit com Kubeflow</block>
  <block id="3b70474868bce72e0d5d1fac42d1f643" category="doc">Use o NetApp DataOps Toolkit com o Kubeflow</block>
  <block id="6e4cd672cd8bd06c42a9e4ba697c61de" category="inline-link">Kit de ferramentas de ciência de dados da NetApp para Kubernetes</block>
  <block id="4065ea77b68b6d949a165c54fc532d2a" category="paragraph">O<block ref="6f920cea43eeb6dd3a1bfb8ce1f9946a" category="inline-link-rx"></block> pode ser usado em conjunto com o Kubeflow.  O uso do NetApp Data Science Toolkit com o Kubeflow oferece os seguintes benefícios:</block>
  <block id="0a19b387d7028ea674dc64f74ecb97ea" category="list-text">Cientistas de dados podem executar operações avançadas de gerenciamento de dados do NetApp , como criar snapshots e clones, diretamente de um Jupyter Notebook.</block>
  <block id="f4a972e1ae8aa85c6e67d7ad0ccc6dc4" category="list-text">Operações avançadas de gerenciamento de dados do NetApp , como criação de snapshots e clones, podem ser incorporadas em fluxos de trabalho automatizados usando a estrutura do Kubeflow Pipelines.</block>
  <block id="5e646a4ae4330cb948544333980f9f49" category="inline-link">Exemplos de Kubeflow</block>
  <block id="f1db0bc6ea6a4eee559e5d9946fd92ea" category="paragraph">Consulte o<block ref="a5886b5aa215f1fd67a69d09a2725b9d" category="inline-link-rx"></block> seção no repositório GitHub do NetApp Data Science Toolkit para obter detalhes sobre como usar o kit de ferramentas com o Kubeflow.</block>
  <block id="0e82e7615bc43e60306731cd1402df29" category="summary">MLOps de código aberto com NetApp - Provisione um espaço de trabalho do Jupyter Notebook para uso de cientistas de dados ou desenvolvedores</block>
  <block id="7fad49a67f130cbd7629be2d6c719aea" category="doc">Provisionar um espaço de trabalho do Jupyter Notebook para uso de cientistas de dados ou desenvolvedores</block>
  <block id="b09a995a770ac7d1022303afcc4effb0" category="paragraph">O Kubeflow é capaz de provisionar rapidamente novos servidores Jupyter Notebook para atuarem como espaços de trabalho de cientistas de dados.  Para obter mais informações sobre Jupyter Notebooks no contexto do Kubeflow, consulte o<block ref="05932219411c169f9e48f874e56f1ed3" category="inline-link-rx"></block> .</block>
  <block id="6b9617f7154782faea34239e9eb5ea4a" category="paragraph"><block ref="6b9617f7154782faea34239e9eb5ea4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e6dc629616db1f269870318e89e7522" category="summary">MLOps de código aberto com NetApp - Fluxo de trabalho de exemplo - Treinar um modelo de reconhecimento de imagem usando Kubeflow e o NetApp DataOps Toolkit</block>
  <block id="659e23f00660c05c4b7cf730eae0befe" category="doc">Exemplo de fluxo de trabalho - Treinar um modelo de reconhecimento de imagem usando o Kubeflow e o NetApp DataOps Toolkit</block>
  <block id="cc799f8653f5775220453347865834a9" category="paragraph">Esta seção descreve as etapas envolvidas no treinamento e na implantação de uma rede neural para reconhecimento de imagem usando o Kubeflow e o NetApp DataOps Toolkit.  O objetivo é servir como exemplo para mostrar um trabalho de treinamento que incorpora armazenamento NetApp .</block>
  <block id="b759ef76b26f922987fbf418c77766cb" category="paragraph">Crie um Dockerfile com as configurações necessárias para usar nas etapas de treinamento e teste dentro do pipeline do Kubeflow.  Aqui está um exemplo de um Dockerfile -</block>
  <block id="d1658ed5f5e35aee28cc518869591c5b" category="paragraph">Dependendo de suas necessidades, instale todas as bibliotecas e pacotes necessários para executar o programa.  Antes de treinar o modelo de Machine Learning, presume-se que você já tenha uma implantação funcional do Kubeflow.</block>
  <block id="1d7fb7fa777edda515304ad19af75036" category="section-title">Treine uma pequena NN em dados MNIST usando PyTorch e pipelines Kubeflow</block>
  <block id="a2d6c085b2bfbb3fc92caceedba6806e" category="paragraph">Usamos o exemplo de uma pequena Rede Neural treinada em dados MNIST.  O conjunto de dados MNIST consiste em imagens manuscritas de dígitos de 0 a 9.  As imagens têm 28x28 pixels de tamanho.  O conjunto de dados é dividido em 60.000 imagens de trens e 10.000 imagens de validação.  A rede neural usada neste experimento é uma rede feedforward de duas camadas.  O treinamento é executado usando o Kubeflow Pipelines. Consulte a documentação<block ref="bcb10ee1db2d847a3cadc06c872375ac" category="inline-link-rx"></block> para maiores informações.  Nosso pipeline do Kubeflow incorpora a imagem do Docker da seção Pré-requisitos.</block>
  <block id="edfa32db89306c0de4efde13667133a5" category="inline-image-macro">Visualização de execução do pipeline do Kubeflow</block>
  <block id="c0bdd0d6d088108de0d2d172bd2f25be" category="paragraph"><block ref="c0bdd0d6d088108de0d2d172bd2f25be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7d85cbff0f5dec5d5092004b5b8774e" category="section-title">Visualize resultados usando o Tensorboard</block>
  <block id="d3246eab9678602f9301a80184803dff" category="inline-link">Tensorboard</block>
  <block id="12e2a8be9c4e17ffc7dc66217d8530ff" category="paragraph">Depois que o modelo estiver treinado, podemos visualizar os resultados usando o Tensorboard.<block ref="a07862d9a0e51dec9c3587e87c541181" category="inline-link-rx"></block> está disponível como um recurso no Painel do Kubeflow.  Você pode criar um tensorboard personalizado para seu trabalho.  O exemplo abaixo mostra o gráfico da precisão do treinamento versus número de épocas e perda de treinamento versus número de épocas.</block>
  <block id="1618fe0e500d9ed850d5e614c6620fd8" category="inline-image-macro">Gráfico Tensorboard para perda e precisão de treinamento</block>
  <block id="cd45b495d2fd4d214ea7c430a9980d0a" category="paragraph"><block ref="cd45b495d2fd4d214ea7c430a9980d0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbdd778d6f4497497010df3f4ae35a67" category="section-title">Experimento com hiperparâmetros usando Katib</block>
  <block id="a47bff2eb2b867ca89a553eeb14da493" category="paragraph"><block ref="98b590f3a453d1e0809708b45d553c8f" category="inline-link-rx"></block>é uma ferramenta dentro do Kubeflow que pode ser usada para experimentar os hiperparâmetros do modelo.  Para criar um experimento, defina primeiro uma métrica/meta desejada.  Geralmente essa é a precisão do teste.  Depois que a métrica for definida, escolha os hiperparâmetros com os quais você gostaria de brincar (otimizador/taxa de aprendizado/número de camadas).  Katib faz uma varredura de hiperparâmetros com os valores definidos pelo usuário para encontrar a melhor combinação de parâmetros que satisfaçam a métrica desejada.  Você pode definir esses parâmetros em cada seção da interface do usuário.  Como alternativa, você pode definir um arquivo *YAML* com as especificações necessárias.  Abaixo está uma ilustração de um experimento Katib -</block>
  <block id="70e367edef0d0f2a63f6fff084365aa4" category="inline-image-macro">Painel de experimentos Katib com hiperparâmetros</block>
  <block id="12f61d15ca34416b644cbd8238634541" category="paragraph"><block ref="12f61d15ca34416b644cbd8238634541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd53955b02bf4a8bb0a318390df24ae6" category="inline-image-macro">Verificação de teste bem-sucedida</block>
  <block id="600782cca16442259d603526a7cd0b29" category="paragraph"><block ref="600782cca16442259d603526a7cd0b29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18d3e96caf95415deff9bb8b5bc25063" category="section-title">Use instantâneos do NetApp para salvar dados para rastreabilidade</block>
  <block id="0b6ef7f84e44ffbb76d4eef1ef587269" category="paragraph">Durante o treinamento do modelo, podemos querer salvar um instantâneo do conjunto de dados de treinamento para rastreabilidade.  Para fazer isso, podemos adicionar uma etapa de instantâneo ao pipeline, conforme mostrado abaixo.  Para criar o snapshot, podemos usar o<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block> .</block>
  <block id="9f205d5330ff4142363e15d261753156" category="inline-image-macro">Código para construir um pipeline de Snapshot no Kubeflow</block>
  <block id="18242bdffd149a4d04c88b7208997f55" category="paragraph"><block ref="18242bdffd149a4d04c88b7208997f55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe2b6f01ffb206a03c2e0fd0a802a4ca" category="inline-link">Exemplo do NetApp DataOps Toolkit para Kubeflow</block>
  <block id="7ba41dac79bc84ef4a806ce87fc4f97a" category="paragraph">Consulte o <block ref="f0b3c05b3c22509c21d3296c77ee92d9" category="inline-link-rx"></block> para maiores informações.</block>
  <block id="8ec1b3ffcff14d3a7476fee4a3e80bbd" category="summary">MLOps de código aberto com NetApp - Implantação do MLflow</block>
  <block id="1e24ddb7a6a8df2478eebd688cf1f1df" category="doc">Implantação do MLflow</block>
  <block id="eba75f7702c8d580f100f5c6e819419a" category="paragraph">Esta seção descreve as tarefas que você deve concluir para implantar o MLflow no seu cluster Kubernetes.</block>
  <block id="1988a9fc415911c1b6cb091f9672aa99" category="admonition">É possível implantar o MLflow em outras plataformas além do Kubernetes.  A implantação do MLflow em plataformas diferentes do Kubernetes está fora do escopo desta solução.</block>
  <block id="effe3b356a9db8beeafdbe3692a3df6b" category="paragraph">O MLflow é implantado usando o Helm, um gerenciador de pacotes popular para Kubernetes.  Antes de implantar o MLflow, você deve instalar o Helm no seu nó de controle do Kubernetes.  Para instalar o Helm, siga as instruções<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> na documentação oficial do Helm.</block>
  <block id="01fb0f36d01f7edcdcc66273b214f218" category="paragraph">Antes de implantar o MLflow, você deve designar uma StorageClass padrão dentro do seu cluster Kubernetes.  Para designar uma StorageClass padrão em seu cluster, siga as instruções descritas no<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block> seção.  Se você já designou uma StorageClass padrão dentro do seu cluster, pode pular esta etapa.</block>
  <block id="6369a4aa768b1882566ceb106febe885" category="section-title">Implantar MLflow</block>
  <block id="4996360f41c2160eefec53bc938631c4" category="paragraph">Depois que os pré-requisitos forem atendidos, você poderá começar a implantação do MLflow usando o gráfico do Helm.</block>
  <block id="9b40c49f5b19b6b30c8e46c9a322cfa9" category="section-title">Configurar a implantação do gráfico do MLflow Helm.</block>
  <block id="54662ab0339cacf58980938d0d2997f6" category="paragraph">Antes de implantar o MLflow usando o gráfico Helm, podemos configurar a implantação para usar a classe de armazenamento NetApp Trident e alterar outros parâmetros para atender às nossas necessidades usando um arquivo *config.yaml*.  Um exemplo do arquivo *config.yaml* pode ser encontrado em:<block ref="3fb631fe4b90fe5302819c1b11e0f768" category="inline-link-rx"></block></block>
  <block id="3ffd497fc5215b526be90b762ad3c730" category="admonition">Você pode definir o Trident storageClass no parâmetro *global.defaultStorageClass* no arquivo config.yaml (por exemplo, storageClass: "ontap-flexvol").</block>
  <block id="b0e9e89059c66feb24d2bae1faade5b4" category="section-title">Instalando o Helm Chart</block>
  <block id="e2de44bdf60d5282b2d1f5dce8ef9fb8" category="paragraph">O gráfico Helm pode ser instalado com o arquivo *config.yaml* personalizado para MLflow usando o seguinte comando:</block>
  <block id="b8fe21ea18633e2ba5c911e2b6c64135" category="admonition">O comando implanta o MLflow no cluster Kubernetes na configuração personalizada por meio do arquivo *config.yaml* fornecido.  O MLflow é implantado no namespace fornecido e um nome de versão aleatório é fornecido via kubernetes para a versão.</block>
  <block id="fe92b5543c9bb0daa69543a737a9937a" category="paragraph">Após a implantação do gráfico Helm, você pode verificar se o serviço está acessível usando:</block>
  <block id="5001194091e3ac05acb36e50188181cd" category="admonition">Substitua *jupyterhub* pelo namespace que você usou durante a implantação.</block>
  <block id="624995aae5a71a1b6b698d125dfa593f" category="paragraph">Você deverá ver os seguintes serviços:</block>
  <block id="0727c036d98dcf728bf3678abc379532" category="admonition">Editamos o arquivo config.yaml para usar o serviço NodePort para acessar o MLflow na porta 30002.</block>
  <block id="49ed0a1879305290bd3f5a83a6ebc4a2" category="section-title">Acesse o MLflow</block>
  <block id="4336069c7c6830c86e24b3590bc33968" category="paragraph">Depois que todos os serviços relacionados ao MLflow estiverem ativos e em execução, você poderá acessá-lo usando o endereço IP NodePort ou LoadBalancer fornecido (por exemplo<block ref="4470100f30fdceb8d4bf43ad086f55fe" prefix=" " category="inline-code"></block> )</block>
  <block id="4cdff711c1556a59f967422b42a85088" category="summary">MLOps de código aberto com NetApp - Rastreabilidade de conjunto de dados para modelo com NetApp e MLflow</block>
  <block id="96ea5f01f5435b957b4ccda05e9edc2a" category="doc">Rastreabilidade de conjunto de dados para modelo com NetApp e MLflow</block>
  <block id="49f4e58115751b6e777c0881bed17f7b" category="paragraph">O<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block> pode ser usado em conjunto com os recursos de rastreamento de experimentos do MLflow para implementar a rastreabilidade do conjunto de dados para o modelo ou do espaço de trabalho para o modelo.</block>
  <block id="a6086bfa36daf4e19b000df54ab1dd1e" category="paragraph">Para implementar a rastreabilidade de conjunto de dados para modelo ou de espaço de trabalho para modelo, basta criar um instantâneo do seu conjunto de dados ou volume de espaço de trabalho usando o DataOps Toolkit como parte da sua execução de treinamento, conforme mostrado no seguinte trecho de código de exemplo.  Este código salvará o nome do volume de dados e o nome do instantâneo como tags associadas à execução de treinamento específica que você está registrando no seu servidor de rastreamento de experimentos do MLflow.</block>
  <block id="f8e6fa4a88901fdc129b3ce376463f53" category="summary">MLOps de código aberto com NetApp - Execute uma carga de trabalho de IA distribuída síncrona</block>
  <block id="8725f0c1877790fea82aedbc23e26e70" category="doc">Executar uma carga de trabalho de IA distribuída síncrona</block>
  <block id="deb7f52575de614a91ae7472b76138ec" category="paragraph">Para executar um trabalho de IA e ML multinó síncrono no seu cluster Kubernetes, execute as seguintes tarefas no host de salto de implantação.  Esse processo permite que você aproveite os dados armazenados em um volume NetApp e use mais GPUs do que um único nó de trabalho pode fornecer.  Veja a figura a seguir para uma representação de um trabalho de IA distribuído síncrono.</block>
  <block id="c073d47c72ebccdc821d9e6419b3008c" category="admonition">Trabalhos distribuídos síncronos podem ajudar a aumentar o desempenho e a precisão do treinamento em comparação com trabalhos distribuídos assíncronos.  Uma discussão sobre os prós e contras de trabalhos síncronos versus trabalhos assíncronos está fora do escopo deste documento.</block>
  <block id="dd02d155f88fd3ea2f5dfd5720641a55" category="paragraph"><block ref="dd02d155f88fd3ea2f5dfd5720641a55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46300fa439cc237919f854816fc89fc2" category="inline-link-macro">Executar uma carga de trabalho de IA de nó único</block>
  <block id="252bb749f76608017bf1d4a822ebba6d" category="list-text">Os comandos de exemplo a seguir mostram a criação de um trabalhador que participa da execução distribuída síncrona do mesmo trabalho de benchmark do TensorFlow que foi executado em um único nó no exemplo da seção<block ref="055e86cc3668b8856dedbd3ee4c3f307" category="inline-link-macro-rx"></block> .  Neste exemplo específico, apenas um único trabalhador é implantado porque o trabalho é executado em dois nós de trabalho.</block>
  <block id="8f811f6151a10e9d15de57c2af8fcfed" category="inline-link">documentação oficial do Kubernetes</block>
  <block id="e3a5f2bdfc8576b6847bcbf0d53889d4" category="paragraph">Este exemplo de implantação de trabalhador solicita oito GPUs e, portanto, pode ser executado em um único nó de trabalhador de GPU que apresenta oito ou mais GPUs.  Se os nós de trabalho da sua GPU tiverem mais de oito GPUs, para maximizar o desempenho, você pode aumentar esse número para que fique igual ao número de GPUs que os nós de trabalho têm.  Para obter mais informações sobre implantações do Kubernetes, consulte o<block ref="29c4feb256f061356947baec0e1bfcb2" category="inline-link-rx"></block> .</block>
  <block id="4b59e69845bd812b9cddcb0b700f3680" category="paragraph">Uma implantação do Kubernetes é criada neste exemplo porque esse trabalhador em contêiner específico nunca seria concluído sozinho.  Portanto, não faz sentido implantá-lo usando a construção de tarefa do Kubernetes.  Se seu trabalhador foi projetado ou escrito para ser concluído sozinho, pode fazer sentido usar a construção de tarefa para implantá-lo.</block>
  <block id="57e84b8262eb9db582d9f861e85ed291" category="paragraph">O pod especificado neste exemplo de especificação de implantação recebe um<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> valor de<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> .  Esse valor significa que o pod usa a pilha de rede do nó de trabalho do host em vez da pilha de rede virtual que o Kubernetes normalmente cria para cada pod.  Esta anotação é usada neste caso porque a carga de trabalho específica depende do Open MPI, NCCL e Horovod para executar a carga de trabalho de maneira distribuída e síncrona.  Portanto, ele requer acesso à pilha de rede do host.  Uma discussão sobre Open MPI, NCCL e Horovod está fora do escopo deste documento.  Se isso é verdade ou não<block ref="02cbe2b15bc778c7658250053bbc5a5c" prefix=" " category="inline-code"></block> a anotação é necessária depende dos requisitos da carga de trabalho específica que você está executando.  Para mais informações sobre o<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> campo, veja o<block ref="f46b1bf9e67570ceac06230c1e502909" category="inline-link-rx"></block> .</block>
  <block id="b3f8c0432fa807543e6e24f429362a32" category="list-text">Confirme se a implantação do trabalhador que você criou na etapa 1 foi iniciada com sucesso.  Os comandos de exemplo a seguir confirmam que um único pod de trabalho foi criado para a implantação, conforme indicado na definição de implantação, e que esse pod está atualmente em execução em um dos nós de trabalho da GPU.</block>
  <block id="77fed810b2a592adcab667c30e5c0bdb" category="list-text">Crie um trabalho do Kubernetes para um mestre que inicia, participa e rastreia a execução do trabalho multinó síncrono.  Os comandos de exemplo a seguir criam um mestre que inicia, participa e rastreia a execução distribuída síncrona do mesmo trabalho de benchmark do TensorFlow que foi executado em um único nó no exemplo da seção<block ref="055e86cc3668b8856dedbd3ee4c3f307" category="inline-link-macro-rx"></block> .</block>
  <block id="4161928cbea20386310894ea85fd3711" category="paragraph">Este exemplo de tarefa mestre solicita oito GPUs e, portanto, pode ser executado em um único nó de trabalho de GPU que apresenta oito ou mais GPUs.  Se os nós de trabalho da sua GPU tiverem mais de oito GPUs, para maximizar o desempenho, você pode aumentar esse número para que fique igual ao número de GPUs que os nós de trabalho têm.</block>
  <block id="3e04ef9469e6953d66ae9c7536ed9b26" category="paragraph">O pod mestre especificado neste exemplo de definição de trabalho recebe um<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> valor de<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> , assim como o grupo de trabalhadores recebeu uma<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> valor de<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> na etapa 1.  Veja a etapa 1 para obter detalhes sobre por que esse valor é necessário.</block>
  <block id="8600ba20f40fb5668a1b2c02f92e220d" category="list-text">Confirme se o trabalho mestre que você criou na etapa 3 está sendo executado corretamente.  O comando de exemplo a seguir confirma que um único pod mestre foi criado para o trabalho, conforme indicado na definição do trabalho, e que esse pod está atualmente em execução em um dos nós de trabalho da GPU.  Você também deve ver que o pod de trabalho que você viu originalmente na etapa 1 ainda está em execução e que os pods mestre e de trabalho estão em execução em nós diferentes.</block>
  <block id="0f27ae3c630b411ce8f8dc123361f1b1" category="list-text">Confirme se o trabalho mestre que você criou na etapa 3 foi concluído com sucesso.  Os comandos de exemplo a seguir confirmam que o trabalho foi concluído com sucesso.</block>
  <block id="6fe5035373f479ed2a1c1d457e64ae9d" category="list-text">Exclua a implantação do trabalhador quando não precisar mais dela.  Os comandos de exemplo a seguir mostram a exclusão do objeto de implantação do trabalhador que foi criado na etapa 1.</block>
  <block id="e3861d1527373e7d8eeea1704f818a15" category="paragraph">Quando você exclui o objeto de implantação do trabalhador, o Kubernetes exclui automaticamente todos os pods de trabalhador associados.</block>
  <block id="7e4d2c0ae78fc38eeb38ffe12f736290" category="list-text">*Opcional:* Limpe os artefatos do trabalho mestre.  Os comandos de exemplo a seguir mostram a exclusão do objeto de trabalho mestre que foi criado na etapa 3.</block>
  <block id="d844794bfc5a0949dc2c38fecacf9ff1" category="paragraph">Quando você exclui o objeto de trabalho mestre, o Kubernetes exclui automaticamente todos os pods mestres associados.</block>
  <block id="3b1ef0ea9661ba5d2eeba15fab13cf00" category="summary">MLOps de código aberto com NetApp - Execute uma carga de trabalho de IA de nó único</block>
  <block id="9e339bbe1fec0fc2a91b7c2f8dd9d7f7" category="paragraph">Para executar uma tarefa de IA e ML de nó único no seu cluster Kubernetes, execute as seguintes tarefas no host de salto de implantação.  Com o Trident, você pode tornar um volume de dados, potencialmente contendo petabytes de dados, acessível de forma rápida e fácil a uma carga de trabalho do Kubernetes.  Para tornar esse volume de dados acessível de dentro de um pod do Kubernetes, basta especificar um PVC na definição do pod.</block>
  <block id="e3305581bc1f67d1989e08e42a43c113" category="admonition">Esta seção pressupõe que você já tenha conteinerizado (no formato de contêiner do Docker) a carga de trabalho específica de IA e ML que está tentando executar no seu cluster Kubernetes.</block>
  <block id="6bdbab1141be3c52dec1f29c4c5fdf52" category="inline-link">Site ImageNet</block>
  <block id="08eb6cc7203ec1b36805e4767d450467" category="list-text">Os comandos de exemplo a seguir mostram a criação de um trabalho do Kubernetes para uma carga de trabalho de benchmark do TensorFlow que usa o conjunto de dados ImageNet.  Para obter mais informações sobre o conjunto de dados ImageNet, consulte o<block ref="19a9693db577a40175aef26761f77fe7" category="inline-link-rx"></block> .</block>
  <block id="56920225f5c2d474925baad76ae3e7ce" category="paragraph">Este trabalho de exemplo solicita oito GPUs e, portanto, pode ser executado em um único nó de trabalho de GPU que apresenta oito ou mais GPUs.  Este trabalho de exemplo pode ser enviado em um cluster para o qual um nó de trabalho com oito ou mais GPUs não está presente ou está atualmente ocupado com outra carga de trabalho.  Se for esse o caso, o trabalho permanecerá em estado pendente até que o nó de trabalho fique disponível.</block>
  <block id="dd36f0d653a70e6e6c7e838454ee7e20" category="paragraph">Além disso, para maximizar a largura de banda de armazenamento, o volume que contém os dados de treinamento necessários é montado duas vezes dentro do pod criado por essa tarefa.  Outro volume também é montado no pod.  Este segundo volume será usado para armazenar resultados e métricas.  Esses volumes são referenciados na definição do trabalho usando os nomes dos PVCs.  Para obter mais informações sobre os trabalhos do Kubernetes, consulte o<block ref="0ceaf9ba0112a862c5fa5f8d38bee04b" category="inline-link-rx"></block> .</block>
  <block id="c1cf1b159caffa27246be2b5201cdd54" category="paragraph">Um<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> volume com um<block ref="075a3e36a0a52dcbc568c05788e8a713" prefix=" " category="inline-code"></block> valor de<block ref="4789f23283b3a61f858b641a1bef19a3" prefix=" " category="inline-code"></block> é montado em<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> no pod que este trabalho de exemplo cria.  O tamanho padrão do<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> O volume virtual criado automaticamente pelo tempo de execução do contêiner do Docker às vezes pode ser insuficiente para as necessidades do TensorFlow.  Montando um<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> volume como no exemplo a seguir fornece um suficientemente grande<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> volume virtual.  Para mais informações sobre<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> volumes, veja o<block ref="ad2ab91baa5517930a567ac7588e61fd" category="inline-link-rx"></block> .</block>
  <block id="ac5f33311bbfb696a5966510fc4a38b8" category="paragraph">O único contêiner especificado neste exemplo de definição de trabalho recebe um<block ref="616a0bdac22bb48049712f2f41741fd1" prefix=" " category="inline-code"></block> valor de<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> .  Este valor significa que o contêiner efetivamente tem acesso root no host.  Esta anotação é usada neste caso porque a carga de trabalho específica que está sendo executada requer acesso root.  Especificamente, uma operação de limpeza de cache executada pela carga de trabalho requer acesso root.  Se isso é verdade ou não<block ref="8be504a312b42bc24ff61c9c2c31990d" prefix=" " category="inline-code"></block> a anotação é necessária depende dos requisitos da carga de trabalho específica que você está executando.</block>
  <block id="8db728b0062c29a77e48bcd3be77be7f" category="list-text">Confirme se o trabalho que você criou na etapa 1 está sendo executado corretamente.  O comando de exemplo a seguir confirma que um único pod foi criado para o trabalho, conforme especificado na definição do trabalho, e que esse pod está atualmente em execução em um dos nós de trabalho da GPU.</block>
  <block id="7b2880ed5066d8fda6f6d5a4ec8f39ac" category="list-text">Confirme se o trabalho que você criou na etapa 1 foi concluído com sucesso.  Os comandos de exemplo a seguir confirmam que o trabalho foi concluído com sucesso.</block>
  <block id="bead823acab8a06d478eb02c7ff84d35" category="list-text">*Opcional:* Limpe artefatos de trabalho.  Os comandos de exemplo a seguir mostram a exclusão do objeto de trabalho que foi criado na etapa 1.</block>
  <block id="cb215cf0e9fb88bd1fc97b4ba53fd36f" category="paragraph">Quando você exclui o objeto de trabalho, o Kubernetes exclui automaticamente todos os pods associados.</block>
  <block id="91ab0152618ead1fcdc42eff8c2d0735" category="summary">MLOps de código aberto com NetApp - Exemplo de backends Trident para implantações NetApp AIPod</block>
  <block id="9137107e8d97a11b9174eb6766c2051f" category="doc">Exemplo de backends Trident para implantações NetApp AIPod</block>
  <block id="bf498d2b211c45a57e0eaa477b958b58" category="inline-link-macro">NetApp AIPod</block>
  <block id="8b57fa6d8107ac5ef8cc72bed591a355" category="paragraph">Antes de usar o Trident para provisionar dinamicamente recursos de armazenamento no seu cluster Kubernetes, você deve criar um ou mais Trident Backends.  Os exemplos a seguir representam diferentes tipos de backends que você pode querer criar se estiver implantando componentes desta solução em um<block ref="b2fcf1ac0e8df6bdaefce420e27d6368" category="inline-link-macro-rx"></block> .  Para obter mais informações sobre backends e, por exemplo, backends para outras plataformas/ambientes, consulte o<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block> .</block>
  <block id="5bce19d939aea54f55df565bb07b573b" category="list-text">A NetApp recomenda a criação de um Trident Backend habilitado para FlexGroup para seu AIPod.</block>
  <block id="987adc3703d1f7aeb77e70a3d25e35ca" category="paragraph">Os comandos de exemplo a seguir mostram a criação de um Trident Backend habilitado para FlexGroup para uma máquina virtual de armazenamento AIPod (SVM).  Este Backend usa o<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> driver de armazenamento.  O ONTAP suporta dois tipos principais de volume de dados: FlexVol e FlexGroup.  Os volumes FlexVol têm tamanho limitado (no momento em que este artigo foi escrito, o tamanho máximo depende da implantação específica).  Os volumes FlexGroup , por outro lado, podem ser dimensionados linearmente para até 20 PB e 400 bilhões de arquivos, fornecendo um único namespace que simplifica muito o gerenciamento de dados.  Portanto, os volumes FlexGroup são ideais para cargas de trabalho de IA e ML que dependem de grandes quantidades de dados.</block>
  <block id="ba9f56aafb45a750a8dffe5de6d2ed78" category="paragraph">Se você estiver trabalhando com uma pequena quantidade de dados e quiser usar volumes FlexVol em vez de volumes FlexGroup , você pode criar Trident Backends que usam o<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block> driver de armazenamento em vez do<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> driver de armazenamento.</block>
  <block id="112efecf6dc8105639ea7e0b2a19f0e1" category="list-text">A NetApp também recomenda a criação de um Trident Backend habilitado para FlexVol .  Você pode querer usar volumes FlexVol para hospedar aplicativos persistentes, armazenar resultados, saídas, informações de depuração e assim por diante.  Se quiser usar volumes FlexVol , você deve criar um ou mais Trident Backends habilitados para FlexVol .  Os comandos de exemplo a seguir mostram a criação de um único Trident Backend habilitado para FlexVol .</block>
  <block id="860fee506515550a9fba4086f9358bf0" category="summary">MLOps de código aberto com NetApp - Exemplo de operações Trident</block>
  <block id="3642f282b12269091ab196a3aabf0858" category="doc">Exemplo de Operações Trident</block>
  <block id="7f41e102595a65d30401b887b75060a4" category="paragraph">Esta seção inclui exemplos de várias operações que você pode querer executar com o Trident.</block>
  <block id="5a95bc44d2d93c77b65585a52a71d631" category="section-title">Importar um volume existente</block>
  <block id="37e60d34ab15afa59aac0989309fc77a" category="paragraph">Se houver volumes existentes no seu sistema/plataforma de armazenamento NetApp que você deseja montar em contêineres dentro do seu cluster Kubernetes, mas que não estão vinculados a PVCs no cluster, você deverá importar esses volumes.  Você pode usar a funcionalidade de importação de volumes do Trident para importar esses volumes.</block>
  <block id="8a87b71bee3405ddd29416b675ef7c61" category="paragraph">Os comandos de exemplo a seguir mostram a importação de um volume denominado<block ref="49f0544a1f0d45f5d68ad2e883eaec4a" prefix=" " category="inline-code"></block> .  Para mais informações sobre PVCs, consulte o<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block> .  Para obter mais informações sobre a funcionalidade de importação de volume, consulte o<block ref="7e5b92b70f9fb8a6ea9680492953995f" category="inline-link-rx"></block> .</block>
  <block id="313da63dfeb95842dd6a105fdcf40ebc" category="paragraph">Um<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block> valor de<block ref="c24ad3d99a666c95edd149419c958ee0" prefix=" " category="inline-code"></block> é especificado nos arquivos de especificação de PVC de exemplo.  Para mais informações sobre o<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block> campo, veja o<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block> .</block>
  <block id="533fff63e0b7486b2768ad15b5e2981c" category="section-title">Provisionar um novo volume</block>
  <block id="6b2d9cc0e6416b1fddc173d87e1ebad4" category="paragraph">Você pode usar o Trident para provisionar um novo volume no seu sistema de armazenamento ou plataforma NetApp .</block>
  <block id="4268e244b7de91b44bea226a48855c28" category="section-title">Provisionar um novo volume usando kubectl</block>
  <block id="d5c5993dfd543be5e01f6d98516d64cb" category="paragraph">Os comandos de exemplo a seguir mostram o provisionamento de um novo FlexVol volume usando kubectl.</block>
  <block id="78b7c8c28867630a421236d6f1ff9ba3" category="paragraph">Um<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block> valor de<block ref="caa8dc1f4bb28d2d11226494cd05a123" prefix=" " category="inline-code"></block> é especificado no seguinte arquivo de definição de PVC de exemplo.  Para mais informações sobre o<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block> campo, veja o<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block> .</block>
  <block id="3b12f01a10ad45fb526861fc286c7953" category="section-title">Provisionar um novo volume usando o NetApp DataOps Toolkit</block>
  <block id="55876228853abf632dec9346a4f372ec" category="inline-link-macro">documentação</block>
  <block id="b1e49394b547d60433afdf0d608bc52b" category="paragraph">Você também pode usar o NetApp DataOps Toolkit for Kubernetes para provisionar um novo volume no seu sistema de armazenamento ou plataforma NetApp .  O NetApp DataOps Toolkit para Kubernetes utiliza o Trident para provisionar volumes, mas simplifica o processo para o usuário.  Consulte o<block ref="37e4d77423419479f43c92e2fdd640ea" category="inline-link-macro-rx"></block> para mais detalhes.</block>
  <block id="fdc02d1c80a87a40b5361ca1abf33964" category="summary">MLOps de código aberto com NetApp - Exemplos de classes de armazenamento do Kubernetes para implantações de AIPod da NetApp</block>
  <block id="d25894e802e87270d1f6b560c3332055" category="doc">Exemplo de classes de armazenamento do Kubernetes para implantações do NetApp AIPod</block>
  <block id="98384d229f6fec246185f9bfa14fcb7a" category="paragraph">Antes de usar o Trident para provisionar dinamicamente recursos de armazenamento no seu cluster Kubernetes, você deve criar uma ou mais Kubernetes StorageClasses.  Os exemplos a seguir representam diferentes tipos de StorageClasses que você pode querer criar se estiver implantando componentes desta solução em um<block ref="b2fcf1ac0e8df6bdaefce420e27d6368" category="inline-link-macro-rx"></block> .  Para obter mais informações sobre StorageClasses e, por exemplo, StorageClasses para outras plataformas/ambientes, consulte o<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block> .</block>
  <block id="3f91a2c4d8ba66304e817a6c1c8d8086" category="inline-link-macro">NFS sobre RDMA</block>
  <block id="5f9e4626ef73df529e1be620feb3c403" category="list-text">A NetApp recomenda a criação de um StorageClass para o FlexGroup-enabled Trident Backend que você criou na seção<block ref="ba9f980165fbda795fa9abfedd793128" category="inline-link-macro-rx"></block> , passo 1.  Os comandos de exemplo a seguir mostram a criação de várias StorageClasses que correspondem ao Backend de exemplo que foi criado na seção<block ref="ba9f980165fbda795fa9abfedd793128" category="inline-link-macro-rx"></block> , passo 1 - aquele que utiliza<block ref="2f98f20aaeb2334cc6d03f1e60eea86f" category="inline-link-macro-rx"></block> e um que não.</block>
  <block id="d9348d075dc7b3c91cff99d56dfc327b" category="inline-link">Documentação do Kubernetes</block>
  <block id="063f66d6e76f1f9cc44a56824e67f49c" category="paragraph">Para que um volume persistente não seja excluído quando o PersistentVolumeClaim (PVC) correspondente for excluído, o exemplo a seguir usa um<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block> valor de<block ref="afece4245269582cb2f1009d4fb52047" prefix=" " category="inline-code"></block> .  Para mais informações sobre o<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block> campo, veja o oficial<block ref="2b8f9bbf9efeff879b3debc5484f0056" category="inline-link-rx"></block> .</block>
  <block id="b1c0c18c267e82c16a2fb0fd855fea96" category="paragraph">Observação: os StorageClasses de exemplo a seguir usam um tamanho máximo de transferência de 262144.  Para usar esse tamanho máximo de transferência, você deve configurar o tamanho máximo de transferência no seu sistema ONTAP adequadamente.  Consulte o<block ref="e88143f84eca8f5af17b24d59e272642" category="inline-link-macro-rx"></block> para mais detalhes.</block>
  <block id="611c47063b50d4e29ff14b57ac5d1a76" category="paragraph">Observação: para usar o NFS sobre RDMA, você deve configurar o NFS sobre RDMA no seu sistema ONTAP .  Consulte o<block ref="299f3386ca6234337ede91409b59779f" category="inline-link-macro-rx"></block> para mais detalhes.</block>
  <block id="8dffb2755e3c128c00970dd619da5b34" category="paragraph">Observação: no exemplo a seguir, um Backend específico é especificado no campo storagePool no arquivo de definição StorageClass.</block>
  <block id="cce8016ccbbe58eeb47eb8596b78018e" category="inline-link-macro">Exemplo de backends Trident para implantações de AIPod</block>
  <block id="6c9233cf2164bf9b74bbca02d5360c85" category="list-text">A NetApp também recomenda a criação de um StorageClass que corresponda ao FlexVol-enabled Trident Backend que você criou na seção<block ref="f93f354f4df9d1f116edb5ebdff3f7d5" category="inline-link-macro-rx"></block> , passo 2.  Os comandos de exemplo a seguir mostram a criação de uma única StorageClass para volumes FlexVol .</block>
  <block id="fc614170d6c05a82aef1df8658cdddbb" category="paragraph">Observação: no exemplo a seguir, um Backend específico não é especificado no campo storagePool no arquivo de definição StorageClass.  Quando você usa o Kubernetes para administrar volumes usando este StorageClass, o Trident tenta usar qualquer backend disponível que use o<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block> motorista.</block>
  <block id="3ad98aba8e7b278dbcb8d707671576f7" category="list-text">Clone quase instantaneamente espaços de trabalho de alta capacidade do JupyterLab para permitir experimentação ou iteração rápida.</block>
  <block id="85ca8d103a016e6e8898855c4ecfa6e2" category="list-text">Salve quase instantaneamente snapshots de espaços de trabalho de alta capacidade do JupyterLab para backup e/ou rastreabilidade/linha de base.</block>
  <block id="60a1b5ff80d3333df7174eb4d8d7f4e1" category="list-text">Provisione, clone e crie snapshots de volumes de dados de alta capacidade e alto desempenho quase instantaneamente.</block>
  <block id="c4bca757471e0afa8bcb4da8a5f5e802" category="paragraph"><block ref="c4bca757471e0afa8bcb4da8a5f5e802" category="inline-link-macro-rx"></block></block>
  <block id="e74b9287ad8cc207ad48fbfdff9cf078" category="summary">Conclusão - solução de banco de dados vetorial para netapp</block>
  <block id="b4eb3fd5fa52ba6b8d0eac43bac21d6f" category="paragraph">Esta seção conclui a solução de banco de dados vetorial para NetApp.</block>
  <block id="ec77b1d1c933a6b137ec223a695b5ace" category="paragraph">Concluindo, este documento fornece uma visão geral abrangente da implantação e do gerenciamento de bancos de dados vetoriais, como Milvus e pgvector, em soluções de armazenamento da NetApp .  Discutimos as diretrizes de infraestrutura para aproveitar o armazenamento de objetos NetApp ONTAP e StorageGRID e validamos o banco de dados Milvus no AWS FSx ONTAP por meio de armazenamento de arquivos e objetos.</block>
  <block id="9799eea6b7d21ae2ad3b8f14f6de8b57" category="paragraph">Exploramos a dualidade arquivo-objeto do NetApp, demonstrando sua utilidade não apenas para dados em bancos de dados vetoriais, mas também para outros aplicativos.  Também destacamos como o SnapCenter, produto de gerenciamento empresarial da NetApp, oferece funcionalidades de backup, restauração e clonagem para dados de bancos de dados vetoriais, garantindo a integridade e a disponibilidade dos dados.</block>
  <block id="31068d7cc739be3f40f71a1c2165b247" category="paragraph">O documento também analisa como a solução de nuvem híbrida da NetApp oferece replicação e proteção de dados em ambientes locais e na nuvem, proporcionando uma experiência de gerenciamento de dados segura e contínua.  Fornecemos insights sobre a validação de desempenho de bancos de dados vetoriais como Milvus e pgvecto no NetApp ONTAP, oferecendo informações valiosas sobre sua eficiência e escalabilidade.</block>
  <block id="48b5d59439c5cbfd986de5db0e4585aa" category="paragraph">Por fim, discutimos dois casos de uso de IA generativa: RAG com LLM e ChatAI interno da NetApp.  Esses exemplos práticos ressaltam as aplicações e os benefícios reais dos conceitos e práticas descritos neste documento.  No geral, este documento serve como um guia abrangente para qualquer pessoa que queira aproveitar as poderosas soluções de armazenamento da NetApp para gerenciar bancos de dados vetoriais.</block>
  <block id="95ab8b5192fec6278c61d897cbcc59b7" category="paragraph">O autor gostaria de agradecer sinceramente aos colaboradores abaixo, a outros que forneceram feedback e comentários para tornar este artigo valioso para os clientes e os setores da NetApp .</block>
  <block id="cf069f89f8b650e3f6d927f7417a21f1" category="list-text">Sathish Thyagarajan, engenheiro técnico de marketing, ONTAP AI &amp; Analytics, NetApp</block>
  <block id="74f47434914d29c7ec7d7d42593303b7" category="list-text">Mike Oglesby, engenheiro de marketing técnico, NetApp</block>
  <block id="633e7060d92a08658a3f5248a7c7cdf2" category="list-text">AJ Mahajan, Diretor Sênior, NetApp</block>
  <block id="4963f582fdf68104e20554eb28bcf2ca" category="list-text">Joe Scott, Gerente, Engenharia de Desempenho de Carga de Trabalho, NetApp</block>
  <block id="710fcc80e2c0809a7239d471028d8f70" category="list-text">Puneet Dhawan, Diretor Sênior, Gerenciamento de Produtos Fsx, NetApp</block>
  <block id="7b62519a4ae964c6b307925c68166ca7" category="list-text">Yuval Kalderon, gerente sênior de produtos, equipe de produtos FSx, NetApp</block>
  <block id="b97cdeb80b669ea57564c9bf0542d2ef" category="list-text">Documentação do Milvus -<block ref="35e085709f47cfca6bbc0746cd0ba49f" category="inline-link-rx"></block></block>
  <block id="f7356e8678620084b93884e3b7a23a9f" category="list-text">Documentação independente do Milvus -<block ref="a47fb3f2bfaa36fa0b44dc5f5ba452a4" category="inline-link-rx"></block></block>
  <block id="8b8bc5296c7be638754abb2f408d2099" category="list-text">Documentação do produto NetApp<block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="3852b719e664b2ae1596e622f21daba3" category="inline-link-macro">documentação do installclustr</block>
  <block id="9351f6d4d819e15d23724c78a36aea99" category="list-text">instaclustr -<block ref="39b68163c56ae9979050121a6264d765" category="inline-link-macro-rx"></block></block>
  <block id="3b3d7bce734c0832c20ba464b1f2d199" category="cell">Abril de 2024</block>
  <block id="123ffe6774f72f5d1c22607445987e46" category="summary">Preparar dados para solução de banco de dados vetorial para netapp</block>
  <block id="f7ab9b609aa315a4d224e6e33b2a10ee" category="doc">Apêndice B: prepare_data_netapp_new.py</block>
  <block id="8d5099e275cc435c14417dc8e6bd49aa" category="paragraph">Esta seção fornece um exemplo de script Python usado para preparar dados para o banco de dados vetorial.</block>
  <block id="fe51a53701c4e0dd7696bed40b6f70db" category="summary">vector-database-deployment-procedure - solução de banco de dados vetorial para netapp</block>
  <block id="19988795e8f88dfff005718f72472b6c" category="paragraph">Esta seção discute o procedimento de implantação da solução de banco de dados vetorial para NetApp.</block>
  <block id="fa0b3671f099fc4fc4fbe3ac8374d92c" category="section-title">Procedimento de implantação</block>
  <block id="b63c54c37cdb817c256ef1a7e50fc5fe" category="paragraph">Nesta seção de implantação, usamos o banco de dados vetorial milvus com o Kubernetes para a configuração do laboratório, conforme abaixo.</block>
  <block id="e275837fe1aa897ebc01eed7a7354278" category="paragraph"><block ref="e275837fe1aa897ebc01eed7a7354278" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b4b9b6998f8b3056b486430aa9c6fd" category="paragraph">O armazenamento netapp fornece armazenamento para o cluster para manter os dados dos clientes e os dados do cluster milvus.</block>
  <block id="46d201d3a5d870036bd7573752054979" category="section-title">Configuração de armazenamento NetApp – ONTAP</block>
  <block id="1fa9de5db47759d3e586f783f647d3e8" category="paragraph">Siga os passos abaixo para NFS (Network File System):</block>
  <block id="932d306add3eb18c39b41633590f1ad6" category="list-text">Crie um volume FlexGroup para NFSv4.  Em nossa configuração para esta validação, usamos 48 SSDs, 1 SSD dedicado para o volume raiz do controlador e 47 SSDs distribuídos para NFSv4]]. Verifique se a política de exportação NFS para o volume FlexGroup tem permissões de leitura/gravação para a rede de nós do Kubernetes (K8s).  Se essas permissões não estiverem em vigor, conceda permissões de leitura/gravação (rw) para a rede de nós K8s.</block>
  <block id="a53a2ae8c8ba1b0def8ad999e086f94c" category="list-text">Em todos os nós K8s, crie uma pasta e monte o volume FlexGroup nessa pasta por meio de uma Interface Lógica (LIF) em cada nó K8s.</block>
  <block id="b02cc86a747fc07392e2eceafa48816f" category="paragraph">Siga as etapas abaixo para NAS S3 (Network Attached Storage Simple Storage Service):</block>
  <block id="a1ec6ff754c8c8958a577b43995e9caf" category="list-text">Crie um volume FlexGroup para NFS.</block>
  <block id="c550fe4970f3cf4781625e620b4e30a9" category="list-text">Crie um bucket NAS definindo seu tipo como "nas" e fornecendo o caminho para o volume NFSv3.  Também é possível utilizar um bucket S3 para essa finalidade.</block>
  <block id="81f40424ce0b0dbbc91e2bc42bee8924" category="section-title">Configuração de armazenamento NetApp – StorageGRID</block>
  <block id="c8462ad4cf62a8bf6b594e7929097b68" category="list-text">Instale o software storageGRID.</block>
  <block id="aec1f80331e64507a359fd96a93d2dee" category="list-text">Crie um inquilino e um bucket.</block>
  <block id="6eea00d5693e3a2106cc3859939c6e8e" category="list-text">Crie um usuário com a permissão necessária.</block>
  <block id="5288dc14a18d189389b382eda1a7f83a" category="paragraph">Por favor, verifique mais detalhes em<block ref="c095f7864703639165de914bdacb9488" category="inline-link-rx"></block></block>
  <block id="1b4b1bbd037e26c942386744e0c37fb6" category="summary">docker-compose.xml - solução de banco de dados vetorial para netapp</block>
  <block id="05b4af2cc796ae07ae3efb49a12abe45" category="doc">Apêndice D: docker-compose.yml</block>
  <block id="4f50d45b7589f5ba7443aff7e641e0ce" category="paragraph">Esta seção inclui código YAML de exemplo para a solução de banco de dados vetorial para NetApp.</block>
  <block id="1746460223f3daa35634698cf8a11429" category="summary">Proteção de banco de dados vetorial usando snapcenter - solução de banco de dados vetorial para netapp</block>
  <block id="72043cdd90d91317b18d2fcdc935eea8" category="doc">Proteção de banco de dados vetorial usando SnapCenter</block>
  <block id="0cbe53988249acb8210e165c8f9d4ff1" category="paragraph">Esta seção descreve como fornecer proteção de dados para o banco de dados de vetores usando o NetApp SnapCenter.</block>
  <block id="62e16ceab82346a15bf6bb06f5076498" category="section-title">Proteção de banco de dados vetorial usando NetApp SnapCenter.</block>
  <block id="03e2211bf15aaf80440217e34090ab7a" category="paragraph">Por exemplo, na indústria de produção cinematográfica, os clientes geralmente possuem dados incorporados críticos, como arquivos de vídeo e áudio.  A perda desses dados, devido a problemas como falhas no disco rígido, pode ter um impacto significativo em suas operações, potencialmente colocando em risco empreendimentos multimilionários.  Encontramos casos em que conteúdo inestimável foi perdido, causando interrupções substanciais e perdas financeiras.  Garantir a segurança e a integridade desses dados essenciais é, portanto, de suma importância neste setor.  Nesta seção, nos aprofundamos em como o SnapCenter protege os dados do banco de dados vetorial e os dados Milvus que residem no ONTAP.  Para este exemplo, utilizamos um bucket NAS (milvusdbvol1) derivado de um volume NFS ONTAP (vol1) para dados do cliente e um volume NFS separado (vectordbpv) para dados de configuração do cluster Milvus. verifique o<block ref="d81f12ee1ce058489f6dd74377fd8f1e" category="inline-link-macro-rx"></block> para o fluxo de trabalho de backup do snapcenter</block>
  <block id="e159df91d2537b3f0b589d157dfbffd9" category="list-text">Configure o host que será usado para executar comandos do SnapCenter .</block>
  <block id="0d3b27c161709a06da0484a310f325e3" category="paragraph"><block ref="0d3b27c161709a06da0484a310f325e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00ebf5cec061915cd0462d73602dcad8" category="inline-link-macro">Loja de automação NetApp</block>
  <block id="e5dbb47baa2442a0c626c78cd3791dfb" category="list-text">Instale e configure o plugin de armazenamento.  No host adicionado, selecione "Mais opções".  Navegue e selecione o plugin de armazenamento baixado em<block ref="6d50396c8bd3accea0ce09d72830daea" category="inline-link-macro-rx"></block> .  Instale o plugin e salve a configuração.</block>
  <block id="4225308f0df24ace1516a7673df5f583" category="paragraph"><block ref="4225308f0df24ace1516a7673df5f583" category="inline-image-macro-rx" type="image"></block></block>
  <block id="56efc857e5b28976189acb94af8f4ac8" category="list-text">Configure o sistema de armazenamento e o volume: adicione o sistema de armazenamento em "Sistema de armazenamento" e selecione a SVM (Máquina Virtual de Armazenamento).  Neste exemplo, escolhemos "vs_nvidia".</block>
  <block id="6d0b2d59ec18c3814b7e5430ff27609f" category="paragraph"><block ref="6d0b2d59ec18c3814b7e5430ff27609f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e2dcb622158143845f18538a410575a" category="list-text">Estabeleça um recurso para o banco de dados vetorial, incorporando uma política de backup e um nome de instantâneo personalizado.</block>
  <block id="a8f4ce53516fd9e67b7eb9a099d49120" category="list-text">Habilite o backup de grupo de consistência com valores padrão e habilite o SnapCenter sem consistência do sistema de arquivos.</block>
  <block id="6230f7a2a3dc9bac46ff1cd677466af1" category="list-text">Na seção Storage Footprint, selecione os volumes associados aos dados do cliente do banco de dados vetorial e aos dados do cluster Milvus.  No nosso exemplo, são "vol1" e "vectordbpv".</block>
  <block id="61f90f32ea94cd1e612c6ce7a1713b45" category="list-text">Crie uma política para proteção de banco de dados de vetores e proteja os recursos do banco de dados de vetores usando a política.</block>
  <block id="de59432e970871e34ec01050d133ea25" category="paragraph"><block ref="de59432e970871e34ec01050d133ea25" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc8a652b9ab6e0d4b7d2a344da503ff6" category="list-text">Insira dados no bucket S3 NAS usando um script Python.  No nosso caso, modificamos o script de backup fornecido pelo Milvus, chamado 'prepare_data_netapp.py', e executamos o comando 'sync' para liberar os dados do sistema operacional.</block>
  <block id="3474edc9b3792a7404f86710df9ef875" category="list-text">Verifique os dados no bucket S3 NAS.  Em nosso exemplo, os arquivos com o registro de data e hora '2024-04-08 21:22' foram criados pelo script 'prepare_data_netapp.py'.</block>
  <block id="d47a679804c0cbffd0dc44fe5bb8fd17" category="list-text">Inicie um backup usando o snapshot do Consistency Group (CG) do recurso 'milvusdb'</block>
  <block id="fe4f644e0cbbb28bc2dc58c59ba4712f" category="paragraph"><block ref="fe4f644e0cbbb28bc2dc58c59ba4712f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="511f6b9ef02b86884feaa7670c95ad25" category="list-text">Para testar a funcionalidade de backup, adicionamos uma nova tabela após o processo de backup ou removemos alguns dados do NFS (bucket S3 NAS).</block>
  <block id="b32454a703c99d763bb542ccb4127d18" category="paragraph">Para este teste, imagine um cenário em que alguém criou uma coleção nova, desnecessária ou inadequada após o backup.  Nesse caso, precisaríamos reverter o banco de dados de vetores ao estado anterior à adição da nova coleção.  Por exemplo, novas coleções como 'hello_milvus_netapp_sc_testnew' e 'hello_milvus_netapp_sc_testnew2' foram inseridas.</block>
  <block id="90fecf651d0359e3ca580f04477241cd" category="list-text">Execute uma restauração completa do bucket S3 NAS a partir do snapshot anterior.</block>
  <block id="aad1d0bff0a7a377e2981515a3b2b613" category="paragraph"><block ref="aad1d0bff0a7a377e2981515a3b2b613" category="inline-image-macro-rx" type="image"></block></block>
  <block id="78a091f299be6eaf4277ba82c2e35823" category="list-text">Use um script Python para verificar os dados das coleções 'hello_milvus_netapp_sc_test' e 'hello_milvus_netapp_sc_test2'.</block>
  <block id="d680ce42e26a573726db92b9c2422bcc" category="list-text">Verifique se a coleção desnecessária ou inadequada não está mais presente no banco de dados.</block>
  <block id="9a792fb5937b90853e4c8d032e6cb887" category="paragraph">Concluindo, o uso do SnapCenter da NetApp para proteger dados de bancos de dados vetoriais e dados Milvus residentes no ONTAP oferece benefícios significativos aos clientes, especialmente em setores onde a integridade dos dados é primordial, como a produção de filmes.  A capacidade do SnapCenter de criar backups consistentes e executar restaurações completas de dados garante que dados críticos, como arquivos de vídeo e áudio incorporados, sejam protegidos contra perdas devido a falhas no disco rígido ou outros problemas.  Isso não apenas evita interrupções operacionais como também protege contra perdas financeiras substanciais.</block>
  <block id="2f51cfb1dd79ff854c52264b771ee6f7" category="paragraph">Nesta seção, demonstramos como o SnapCenter pode ser configurado para proteger dados residentes no ONTAP, incluindo a configuração de hosts, instalação e configuração de plug-ins de armazenamento e a criação de um recurso para o banco de dados de vetores com um nome de instantâneo personalizado.  Também mostramos como executar um backup usando o snapshot do Consistency Group e verificar os dados no bucket S3 NAS.</block>
  <block id="f3b4f7a7e2767144ed9c5f0d9d729580" category="paragraph">Além disso, simulamos um cenário em que uma coleção desnecessária ou inadequada foi criada após o backup.  Nesses casos, a capacidade do SnapCenter de executar uma restauração completa de um instantâneo anterior garante que o banco de dados de vetores possa ser revertido ao seu estado anterior à adição da nova coleção, mantendo assim a integridade do banco de dados.  Essa capacidade de restaurar dados para um ponto específico no tempo é inestimável para os clientes, fornecendo a eles a garantia de que seus dados não estão apenas seguros, mas também mantidos corretamente.  Assim, o produto SnapCenter da NetApp oferece aos clientes uma solução robusta e confiável para proteção e gerenciamento de dados.</block>
  <block id="8ceee6fd58c3c198cf913f99da69f893" category="summary">Recuperação de desastres usando NetApp SnapMirror - solução de banco de dados vetorial para netapp</block>
  <block id="e55b3630a4d66c6bf27e22779ce5d63e" category="doc">Recuperação de desastres usando NetApp SnapMirror</block>
  <block id="86e29a6d4e0a7a64c8112c7cec13c84f" category="paragraph">Esta seção discute DR (recuperação de desastres) com SnapMirror para a solução de banco de dados vetorial da NetApp.</block>
  <block id="b8bf217f690a13ed504fd70caf142a75" category="paragraph"><block ref="b8bf217f690a13ed504fd70caf142a75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b0f055a15ce6f9f633fb54c0d2436b6" category="paragraph">A recuperação de desastres é crucial para manter a integridade e a disponibilidade de um banco de dados vetorial, especialmente devido ao seu papel no gerenciamento de dados de alta dimensão e na execução de pesquisas complexas de similaridade.  Uma estratégia de recuperação de desastres bem planejada e implementada garante que os dados não sejam perdidos ou comprometidos em caso de incidentes imprevistos, como falhas de hardware, desastres naturais ou ataques cibernéticos.  Isso é particularmente significativo para aplicativos que dependem de bancos de dados vetoriais, onde a perda ou corrupção de dados pode levar a interrupções operacionais significativas e perdas financeiras.  Além disso, um plano robusto de recuperação de desastres também garante a continuidade dos negócios, minimizando o tempo de inatividade e permitindo a rápida restauração dos serviços.  Isso é obtido por meio do produto de replicação de dados SnapMirror da NetApp em diferentes localizações geográficas, backups regulares e mecanismos de failover.  Portanto, a recuperação de desastres não é apenas uma medida de proteção, mas um componente crítico do gerenciamento responsável e eficiente de bancos de dados de vetores.</block>
  <block id="c37567d5fe01335124697e36ce452df7" category="paragraph">O SnapMirror da NetApp fornece replicação de dados de um controlador de armazenamento NetApp ONTAP para outro, usado principalmente para recuperação de desastres (DR) e soluções híbridas.  No contexto de um banco de dados vetorial, esta ferramenta facilita a transição suave de dados entre ambientes locais e na nuvem.  Essa transição é alcançada sem a necessidade de conversões de dados ou refatoração de aplicativos, aumentando assim a eficiência e a flexibilidade do gerenciamento de dados em diversas plataformas.</block>
  <block id="b6c8a7338bea39b5f253444e1d873d4d" category="paragraph">A solução híbrida da NetApp em um cenário de banco de dados vetorial pode trazer mais vantagens:</block>
  <block id="bea498b35d669ee9af3e28b8fdb8e155" category="list-text">Escalabilidade: a solução de nuvem híbrida da NetApp oferece a capacidade de dimensionar seus recursos conforme suas necessidades.  Você pode utilizar recursos locais para cargas de trabalho regulares e previsíveis e recursos de nuvem, como o Amazon FSx ONTAP para NetApp ONTAP e o Google Cloud NetApp Volume (NetApp Volumes) para horários de pico ou cargas inesperadas.</block>
  <block id="c471a0669949fb6902a8ba657759604f" category="list-text">Eficiência de custos: o modelo de nuvem híbrida da NetApp permite que você otimize seus custos usando recursos locais para cargas de trabalho regulares e pagando pelos recursos de nuvem somente quando precisar deles.  Esse modelo de pagamento conforme o uso pode ser bastante econômico com uma oferta de serviço NetApp instaclustr.  Para provedores de serviços de nuvem locais e principais provedores, a instaclustr fornece suporte e consultoria.</block>
  <block id="6544e3cb40acee466e12bad4b51cee88" category="list-text">Flexibilidade: a nuvem híbrida da NetApp oferece a flexibilidade de escolher onde processar seus dados.  Por exemplo, você pode optar por executar operações vetoriais complexas no local, onde você tem hardware mais potente, e operações menos intensivas na nuvem.</block>
  <block id="2a11cdb9dd362247d7154c07bd516471" category="list-text">Continuidade dos negócios: em caso de desastre, ter seus dados em uma nuvem híbrida da NetApp pode garantir a continuidade dos negócios.  Você pode mudar rapidamente para a nuvem se seus recursos locais forem afetados.  Podemos aproveitar o NetApp SnapMirror para mover os dados do local para a nuvem e vice-versa.</block>
  <block id="3350f193c79eb670e977c23ae0a74f52" category="list-text">Inovação: as soluções de nuvem híbrida da NetApp também podem permitir inovação mais rápida, fornecendo acesso a serviços e tecnologias de nuvem de ponta.  As inovações da NetApp na nuvem, como o Amazon FSx ONTAP para NetApp ONTAP, o Azure NetApp Files e o Google Cloud NetApp Volumes, são produtos inovadores e NAS preferidos dos provedores de serviços de nuvem.</block>
  <block id="2adc0d5a06f39e5bd606c62ac1bdec94" category="summary">instaclustr com pgvector - solução de banco de dados vetorial para netapp</block>
  <block id="8505d7d1a5bb8f0709861077b6053aac" category="doc">Banco de dados vetorial com Instaclustr usando PostgreSQL: pgvector</block>
  <block id="45b4ccfe4060d903229f2ce1dcae0219" category="paragraph">Esta seção discute os detalhes específicos de como o produto instaclustr se integra com o PostgreSQL na funcionalidade pgvector na solução de banco de dados vetorial para NetApp.</block>
  <block id="126ac9f6149081eb0e97c2e939eaad52" category="inline-link-macro">blog</block>
  <block id="d2674849e623e64434efc8a6aa010be4" category="paragraph">Nesta seção, nos aprofundamos nos detalhes de como o produto instaclustr se integra com o PostgreSQL na funcionalidade do pgvector.  Temos um exemplo de "Como melhorar a precisão e o desempenho do seu LLM com PGVector e PostgreSQL: Introdução aos embeddings e ao papel do PGVector".  Por favor, verifique o<block ref="f7c4562444dacce2474e07621eb487a5" category="inline-link-macro-rx"></block> para obter mais informações.</block>
  <block id="755a3ba009d32e46dd37e73b1449ec79" category="summary">Introdução à solução de banco de dados vetorial para netapp</block>
  <block id="65fe25204f25a29d6784b93a3361bbd8" category="paragraph">Esta seção fornece uma introdução à solução de banco de dados vetorial para NetApp.</block>
  <block id="16091ccd671260c1a85526587bdd6247" category="paragraph">Os bancos de dados vetoriais abordam efetivamente os desafios projetados para lidar com as complexidades da pesquisa semântica em Grandes Modelos de Linguagem (LLMs) e Inteligência Artificial generativa (IA).  Diferentemente dos sistemas tradicionais de gerenciamento de dados, os bancos de dados vetoriais são capazes de processar e pesquisar vários tipos de dados, incluindo imagens, vídeos, texto, áudio e outras formas de dados não estruturados, usando o conteúdo dos dados em si, em vez de rótulos ou tags.</block>
  <block id="abd729dd7dfee14433df8341cdef1b8d" category="paragraph">As limitações dos Sistemas de Gerenciamento de Banco de Dados Relacionais (RDBMS) são bem documentadas, particularmente suas dificuldades com representações de dados de alta dimensão e dados não estruturados comuns em aplicativos de IA.  Os RDBMS geralmente exigem um processo demorado e sujeito a erros de nivelamento de dados em estruturas mais gerenciáveis, o que leva a atrasos e ineficiências nas pesquisas.  No entanto, os bancos de dados vetoriais são projetados para contornar esses problemas, oferecendo uma solução mais eficiente e precisa para gerenciar e pesquisar dados complexos e de alta dimensão, facilitando assim o avanço de aplicações de IA.</block>
  <block id="5059454011de9c1f28ed1489b3d5e352" category="paragraph">Este documento serve como um guia abrangente para clientes que estão usando ou planejam usar bancos de dados vetoriais, detalhando as práticas recomendadas para utilizar bancos de dados vetoriais em plataformas como NetApp ONTAP, NetApp StorageGRID, Amazon FSx ONTAP para NetApp ONTAP e SnapCenter.  O conteúdo fornecido aqui abrange uma variedade de tópicos:</block>
  <block id="a7e003a045fea49874b32ab9648eeff1" category="list-text">Diretrizes de infraestrutura para bancos de dados vetoriais, como Milvus, fornecidas pelo armazenamento NetApp por meio do NetApp ONTAP e do armazenamento de objetos StorageGRID .</block>
  <block id="dad32bf9f8412e678e687e1cf7bb9ca2" category="list-text">Validação do banco de dados Milvus no AWS FSx ONTAP por meio de armazenamento de arquivos e objetos.</block>
  <block id="68c4bdd7361d54de76b6a70ce9e66b6e" category="list-text">Investiga a dualidade arquivo-objeto do NetApp, demonstrando sua utilidade para dados em bancos de dados vetoriais, bem como outros aplicativos.</block>
  <block id="8aa4f3c0608b2b5d04870a90085180a0" category="list-text">Como o produto de gerenciamento de proteção de dados da NetApp, SnapCenter, oferece funcionalidades de backup e restauração para dados de bancos de dados vetoriais.</block>
  <block id="413963cd7c6051b3cbc48462a3167d68" category="list-text">Como a Nuvem Híbrida da NetApp oferece replicação e proteção de dados em ambientes locais e na nuvem.</block>
  <block id="73d0a81a7f19b02b2cf3e9084b655966" category="list-text">Fornece insights sobre a validação de desempenho de bancos de dados vetoriais como Milvus e pgvector no NetApp ONTAP.</block>
  <block id="de2054eca65b6e345160d8320bfa3d17" category="list-text">Dois casos de uso específicos: Retrieval Augmented Generation (RAG) com Large Language Models (LLM) e o ChatAI da equipe de TI da NetApp , oferecendo assim exemplos práticos dos conceitos e práticas descritos.</block>
  <block id="11eb7151c13e504e17cca8ecf079bd88" category="summary">banco de dados vetorial - solução de banco de dados vetorial para netapp</block>
  <block id="34e317d16a291e422cfed7563b8e4b74" category="doc">Banco de Dados Vetorial</block>
  <block id="bb6e7da57bf9b9f451aff5682584af81" category="paragraph">Esta seção aborda a definição e o uso de um banco de dados vetorial em soluções de IA da NetApp .</block>
  <block id="02cf9216cd9290a38db4e591b2d891a3" category="paragraph">Um banco de dados vetorial é um tipo especializado de banco de dados projetado para manipular, indexar e pesquisar dados não estruturados usando incorporações de modelos de aprendizado de máquina.  Em vez de organizar dados em um formato tabular tradicional, ele organiza os dados como vetores de alta dimensão, também conhecidos como incorporações de vetores.  Essa estrutura exclusiva permite que o banco de dados manipule dados complexos e multidimensionais de forma mais eficiente e precisa.</block>
  <block id="ee365553124acd5ca06a0026c4856306" category="paragraph">Um dos principais recursos de um banco de dados vetorial é o uso de IA generativa para realizar análises.  Isso inclui pesquisas de similaridade, onde o banco de dados identifica pontos de dados que são semelhantes a uma determinada entrada, e detecção de anomalias, onde ele pode identificar pontos de dados que se desviam significativamente da norma.</block>
  <block id="145e8c4c44e4cdc9ac189d0799494e03" category="paragraph">Além disso, bancos de dados vetoriais são adequados para lidar com dados temporais ou dados com registro de data e hora.  Esse tipo de dado fornece informações sobre "o que" aconteceu e quando aconteceu, em sequência e em relação a todos os outros eventos dentro de um determinado sistema de TI.  Essa capacidade de manipular e analisar dados temporais torna os bancos de dados vetoriais particularmente úteis para aplicações que exigem uma compreensão de eventos ao longo do tempo.</block>
  <block id="196ef3e0d720a0c9b617f7c8c553f64f" category="section-title">Vantagens do banco de dados vetorial para ML e IA:</block>
  <block id="2143262d5355c4a47b87575a67b2545b" category="list-text">Pesquisa de alta dimensão: bancos de dados vetoriais são excelentes no gerenciamento e na recuperação de dados de alta dimensão, que geralmente são gerados em aplicativos de IA e ML.</block>
  <block id="eaec9d6e0bc3d169492279c991b5c1e1" category="list-text">Escalabilidade: eles podem ser dimensionados com eficiência para lidar com grandes volumes de dados, dando suporte ao crescimento e à expansão de projetos de IA e ML.</block>
  <block id="1a581e9eb96703e6c387548283765d0f" category="list-text">Flexibilidade: Bancos de dados vetoriais oferecem um alto grau de flexibilidade, permitindo a acomodação de diversos tipos e estruturas de dados.</block>
  <block id="23f1f41790fda943f83f4fee180eb9c7" category="list-text">Desempenho: eles fornecem gerenciamento e recuperação de dados de alto desempenho, essenciais para a velocidade e eficiência das operações de IA e ML.</block>
  <block id="5ec5f2c444dccfe97885b44e9f81c73a" category="list-text">Indexação personalizável: os bancos de dados vetoriais oferecem opções de indexação personalizáveis, permitindo organização e recuperação otimizadas de dados com base em necessidades específicas.</block>
  <block id="431b6b79e58c421f73a7d7653f3a2641" category="section-title">Bancos de dados vetoriais e casos de uso.</block>
  <block id="03e65b2645d14a51684616a56e46e74b" category="paragraph">Esta seção fornece vários bancos de dados de vetores e detalhes de seus casos de uso.</block>
  <block id="4873dee9aab8428a3bad0247c8891122" category="section-title">Faiss e ScaNN</block>
  <block id="f8255a0712bd834e092674fb685b593d" category="paragraph">São bibliotecas que servem como ferramentas cruciais no âmbito da pesquisa vetorial.  Essas bibliotecas fornecem funcionalidades essenciais para gerenciar e pesquisar dados vetoriais, o que as torna recursos inestimáveis nessa área especializada de gerenciamento de dados.</block>
  <block id="45e23a169652aaf95ce80da844f3df0d" category="section-title">Elasticsearch</block>
  <block id="7bdddec875d1ea093ba8b35566b1775c" category="paragraph">É um mecanismo de busca e análise amplamente utilizado e recentemente incorporou recursos de busca vetorial.  Este novo recurso aprimora sua funcionalidade, permitindo que ele manipule e pesquise dados vetoriais de forma mais eficaz.</block>
  <block id="f6af38c920e468b8adbdd5793a09b4ca" category="section-title">Pinha</block>
  <block id="e50d3eac5e6bdb3d1ddd1f564ee13308" category="paragraph">É um banco de dados vetorial robusto com um conjunto exclusivo de recursos.  Ele suporta vetores densos e esparsos em sua funcionalidade de indexação, o que aumenta sua flexibilidade e adaptabilidade.  Um dos seus principais pontos fortes está na capacidade de combinar métodos de pesquisa tradicionais com pesquisa vetorial densa baseada em IA, criando uma abordagem de pesquisa híbrida que aproveita o melhor dos dois mundos.</block>
  <block id="8a6b6fbe69ba556a5fee7b289943c80b" category="paragraph">Basicamente baseado em nuvem, o Pinecone foi projetado para aplicativos de aprendizado de máquina e se integra bem a uma variedade de plataformas, incluindo GCP, AWS, Open AI, GPT-3, GPT-3.5, GPT-4, Catgut Plus, Elasticsearch, Haystack e muito mais.  É importante observar que o Pinecone é uma plataforma de código fechado e está disponível como uma oferta de Software como Serviço (SaaS).</block>
  <block id="b30cd65a7e403a5d3e792a3c02cfe9ef" category="paragraph">Dadas suas capacidades avançadas, o Pinecone é particularmente adequado para o setor de segurança cibernética, onde seus recursos de pesquisa de alta dimensão e pesquisa híbrida podem ser aproveitados efetivamente para detectar e responder a ameaças.</block>
  <block id="12f586b0171cf0f06960a27796d811d6" category="section-title">Croma</block>
  <block id="44fcc1838437cfd155de42d2d5133fd3" category="paragraph">É um banco de dados vetorial que tem uma Core-API com quatro funções principais, uma das quais inclui um armazenamento de vetores de documentos na memória.  Ele também utiliza a biblioteca Face Transformers para vetorizar documentos, aumentando sua funcionalidade e versatilidade.  O Chroma foi projetado para operar na nuvem e no local, oferecendo flexibilidade com base nas necessidades do usuário.  Particularmente, ele se destaca em aplicações relacionadas a áudio, o que o torna uma excelente escolha para mecanismos de busca baseados em áudio, sistemas de recomendação de música e outros casos de uso relacionados a áudio.</block>
  <block id="2a1e8d184d8101d9d99e3d491cd7be71" category="section-title">Weaviate</block>
  <block id="bd8b2ae24665811d42f62aa51b8f92c4" category="paragraph">É um banco de dados vetorial versátil que permite aos usuários vetorizar seu conteúdo usando seus módulos integrados ou módulos personalizados, proporcionando flexibilidade com base em necessidades específicas.  Ela oferece soluções totalmente gerenciadas e auto-hospedadas, atendendo a uma variedade de preferências de implantação.</block>
  <block id="5147cd0d10159454e367b25d270b0489" category="paragraph">Um dos principais recursos do Weaviate é sua capacidade de armazenar vetores e objetos, aprimorando suas capacidades de manipulação de dados.  É amplamente utilizado para uma variedade de aplicações, incluindo pesquisa semântica e classificação de dados em sistemas ERP.  No setor de comércio eletrônico, ele potencializa mecanismos de busca e recomendação.  O Weaviate também é usado para pesquisa de imagens, detecção de anomalias, harmonização automatizada de dados e análise de ameaças à segurança cibernética, demonstrando sua versatilidade em vários domínios.</block>
  <block id="e111446745a1825b862f8727ae63bce4" category="section-title">Redis</block>
  <block id="58cbcbf294faed43c2a7b44bb5dcafcc" category="paragraph">O Redis é um banco de dados vetorial de alto desempenho conhecido por seu rápido armazenamento na memória, oferecendo baixa latência para operações de leitura e gravação.  Isso o torna uma excelente escolha para sistemas de recomendação, mecanismos de busca e aplicativos de análise de dados que exigem acesso rápido aos dados.</block>
  <block id="4f9bdf8e8091be6f95cde54860bb88f7" category="paragraph">O Redis suporta várias estruturas de dados para vetores, incluindo listas, conjuntos e conjuntos classificados.  Ele também fornece operações vetoriais, como calcular distâncias entre vetores ou encontrar interseções e uniões.  Esses recursos são particularmente úteis para sistemas de pesquisa por similaridade, agrupamento e recomendação baseados em conteúdo.</block>
  <block id="2391a64216fab42522be1700985c5a9e" category="paragraph">Em termos de escalabilidade e disponibilidade, o Redis se destaca no tratamento de cargas de trabalho de alto rendimento e oferece replicação de dados.  Ele também se integra bem com outros tipos de dados, incluindo bancos de dados relacionais tradicionais (RDBMS).  O Redis inclui um recurso Publicar/Assinar (Pub/Sub) para atualizações em tempo real, o que é benéfico para gerenciar vetores em tempo real.  Além disso, o Redis é leve e simples de usar, o que o torna uma solução fácil de usar para gerenciar dados vetoriais.</block>
  <block id="4f3d528166032bacea5de8a509bb4d17" category="section-title">Milvus</block>
  <block id="e6aa3b4ef4ac18024fd88c49647d8277" category="paragraph">É um banco de dados vetorial versátil que oferece uma API como um armazenamento de documentos, muito parecido com o MongoDB.  Ele se destaca pelo suporte a uma ampla variedade de tipos de dados, o que o torna uma escolha popular nas áreas de ciência de dados e aprendizado de máquina.</block>
  <block id="4b4464f60a3dfd428d4c07edb8cac802" category="paragraph">Um dos recursos exclusivos do Milvus é sua capacidade de multivetorização, que permite aos usuários especificar em tempo de execução o tipo de vetor a ser usado para a pesquisa.  Além disso, ele utiliza o Knowwhere, uma biblioteca que fica em cima de outras bibliotecas como a Faiss, para gerenciar a comunicação entre consultas e algoritmos de busca vetorial.</block>
  <block id="bd3a3ade101e0f6fe46ad769dbf3cfa0" category="paragraph">O Milvus também oferece integração perfeita com fluxos de trabalho de aprendizado de máquina, graças à sua compatibilidade com PyTorch e TensorFlow.  Isso o torna uma excelente ferramenta para uma variedade de aplicações, incluindo comércio eletrônico, análise de imagens e vídeos, reconhecimento de objetos, pesquisa de similaridade de imagens e recuperação de imagens baseada em conteúdo.  No campo do processamento de linguagem natural, o Milvus é usado para agrupamento de documentos, pesquisa semântica e sistemas de perguntas e respostas.</block>
  <block id="df5acf267fd9d50988a9132e88ec089f" category="paragraph">Para esta solução, escolhemos o milvus para a validação da solução.  Para desempenho, usamos milvus e postgres(pgvecto.rs).</block>
  <block id="6b9a995b1c19c83b6360f58654598ab0" category="section-title">Por que escolhemos o milvus para esta solução?</block>
  <block id="ac80bf421cb6dec4ca81d75401709fce" category="list-text">Código aberto: Milvus é um banco de dados vetorial de código aberto, que incentiva o desenvolvimento e as melhorias conduzidas pela comunidade.</block>
  <block id="72e0b014c4927b1166a4c34028bf0a94" category="list-text">Integração de IA: aproveita a incorporação de pesquisa de similaridade e aplicativos de IA para aprimorar a funcionalidade do banco de dados vetorial.</block>
  <block id="1f3d7f832f4c276984a989e5a4760e7d" category="list-text">Manuseio de grande volume: o Milvus tem capacidade para armazenar, indexar e gerenciar mais de um bilhão de vetores de incorporação gerados por redes neurais profundas (DNN) e modelos de aprendizado de máquina (ML).</block>
  <block id="be23175f1d046ec7a81f41bbfbb7a710" category="list-text">Fácil de usar: é fácil de usar e a configuração leva menos de um minuto.  A Milvus também oferece SDKs para diferentes linguagens de programação.</block>
  <block id="2c86f12d4bdb64f5ff99e182033e6664" category="list-text">Velocidade: Oferece velocidades de recuperação extremamente rápidas, até 10 vezes mais rápidas que algumas alternativas.</block>
  <block id="23a12a1d1c53642355185e4cf7fd3d30" category="list-text">Escalabilidade e disponibilidade: o Milvus é altamente escalável, com opções de expansão vertical e horizontal conforme necessário.</block>
  <block id="eaa6e5cbb0e6c82b8217f591711c391a" category="list-text">Rico em recursos: suporta diferentes tipos de dados, filtragem de atributos, suporte a funções definidas pelo usuário (UDF), níveis de consistência configuráveis e tempo de viagem, o que o torna uma ferramenta versátil para várias aplicações.</block>
  <block id="cb1e9d4cfab2279dd63f9f75796dc14f" category="section-title">Visão geral da arquitetura Milvus</block>
  <block id="9c5b9910474e7d9e8c210fd3d649af4d" category="paragraph"><block ref="9c5b9910474e7d9e8c210fd3d649af4d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03bd3b894648d2e8a48d648b0fcedfac" category="paragraph">Esta seção fornece componentes e serviços de alto nível usados na arquitetura Milvus.  * Camada de acesso – É composta por um grupo de proxies sem estado e serve como camada frontal do sistema e ponto final para os usuários.  * Serviço de coordenação – ele atribui tarefas aos nós de trabalho e atua como o cérebro do sistema.  Ele tem três tipos de coordenadores: coordenada raiz, coordenada de dados e coordenada de consulta.  * Nós de trabalho: seguem as instruções do serviço do coordenador e executam comandos DML/DDL acionados pelo usuário. Possui três tipos de nós de trabalho: nó de consulta, nó de dados e nó de índice.  * Armazenamento: é responsável pela persistência dos dados.  Ele abrange meta armazenamento, log broker e armazenamento de objetos.  O armazenamento da NetApp , como ONTAP e StorageGRID, fornece armazenamento de objetos e armazenamento baseado em arquivos para a Milvus para dados de clientes e dados de banco de dados vetorial.</block>
  <block id="3ad011fbf1a887f55fe5db0f1c95891f" category="summary">milvus com Amazon FSx ONTAP para NetApp ONTAP - solução de banco de dados vetorial para netapp</block>
  <block id="dd69e86c3dc6fbad2a761367a22a0552" category="doc">Milvus com Amazon FSx ONTAP para NetApp ONTAP - dualidade de arquivo e objeto</block>
  <block id="8cec9207499fc7ae92bcaff5ffed4880" category="paragraph">Esta seção discute a configuração do cluster milvus com o Amazon FSx ONTAP para a solução de banco de dados vetorial para NetApp.</block>
  <block id="74126d145913f667c84fb0fae63d5f30" category="section-title">Milvus com Amazon FSx ONTAP para NetApp ONTAP – dualidade de arquivo e objeto</block>
  <block id="de1f3a826ad4a683281aa07d427c615a" category="paragraph">Nesta seção, veremos por que precisamos implantar um banco de dados vetorial na nuvem, bem como as etapas para implantar um banco de dados vetorial (milvus autônomo) no Amazon FSx ONTAP para NetApp ONTAP em contêineres do Docker.</block>
  <block id="c7d712a8f39fa8b7654218edbb110e3e" category="paragraph">A implantação de um banco de dados vetorial na nuvem oferece vários benefícios significativos, especialmente para aplicativos que exigem manipulação de dados de alta dimensão e execução de pesquisas de similaridade.  Primeiro, a implantação baseada em nuvem oferece escalabilidade, permitindo o fácil ajuste de recursos para corresponder aos crescentes volumes de dados e cargas de consulta.  Isso garante que o banco de dados possa lidar eficientemente com o aumento da demanda, mantendo alto desempenho.  Em segundo lugar, a implantação na nuvem oferece alta disponibilidade e recuperação de desastres, pois os dados podem ser replicados em diferentes localizações geográficas, minimizando o risco de perda de dados e garantindo serviço contínuo mesmo durante eventos inesperados.  Terceiro, ele oferece boa relação custo-benefício, pois você só paga pelos recursos que usa e pode aumentar ou diminuir conforme a demanda, evitando a necessidade de investimentos iniciais substanciais em hardware.  Por fim, a implantação de um banco de dados vetorial na nuvem pode melhorar a colaboração, pois os dados podem ser acessados e compartilhados de qualquer lugar, facilitando o trabalho em equipe e a tomada de decisões baseada em dados.  Verifique a arquitetura do milvus standalone com Amazon FSx ONTAP para NetApp ONTAP usado nesta validação.</block>
  <block id="f95a160e2c9ead1dd272587d85c4a8e3" category="paragraph"><block ref="f95a160e2c9ead1dd272587d85c4a8e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f1e75d11a34279b79d1140edc8f509e3" category="list-text">Crie uma instância do Amazon FSx ONTAP para NetApp ONTAP e anote os detalhes da VPC, dos grupos de segurança da VPC e da sub-rede.  Essas informações serão necessárias ao criar uma instância do EC2.  Você pode encontrar mais detalhes aqui -<block ref="600df3e2da0b9de1446fabf4802a063b" category="inline-link-rx"></block></block>
  <block id="d91af2df00186cd53f523a257cb2565a" category="list-text">Crie uma instância do EC2, garantindo que a VPC, os grupos de segurança e a sub-rede correspondam aos da instância do Amazon FSx ONTAP para NetApp ONTAP .</block>
  <block id="3f49259cc5a532eaad35643b8ddc6724" category="list-text">Instale o nfs-common usando o comando 'apt-get install nfs-common' e atualize as informações do pacote usando 'sudo apt-get update'.</block>
  <block id="7cd964c493dd7e6f0abd19075ad234a1" category="list-text">Crie uma pasta de montagem e monte o Amazon FSx ONTAP para NetApp ONTAP nela.</block>
  <block id="79f2982e5eb61f29ccc9204d1e575199" category="list-text">Instale o Docker e o Docker Compose usando 'apt-get install'.</block>
  <block id="8b2bc8a7f7a7f8a83a1a126f0f97c496" category="list-text">Configure um cluster Milvus com base no arquivo docker-compose.yaml, que pode ser baixado do site Milvus.</block>
  <block id="6667d03b2d7af61cacf9ce4779fbb601" category="list-text">Na seção 'volumes' do arquivo docker-compose.yml, mapeie o ponto de montagem do NetApp NFS para o caminho do contêiner Milvus correspondente, especificamente em etcd, minio e standalone. Verifique<block ref="cb2986bd8f2d29c4cca582736e0a680f" category="inline-link-macro-rx"></block> para detalhes sobre mudanças no yml</block>
  <block id="40722d15b9f6ad02c869cf6f587fd141" category="list-text">Verifique as pastas e arquivos montados.</block>
  <block id="b1c44a1b47e0ee05938bd8b62a636917" category="list-text">Execute 'docker-compose up -d' no diretório que contém o arquivo docker-compose.yml.</block>
  <block id="9a6325448af98c29154cb9ef7423c998" category="list-text">Verifique o status do contêiner Milvus.</block>
  <block id="e5666f40cd9052040de973832a6b5fb8" category="list-text">Para validar a funcionalidade de leitura e gravação do banco de dados vetorial e seus dados no Amazon FSx ONTAP para NetApp ONTAP, usamos o Python Milvus SDK e um programa de exemplo do PyMilvus.  Instale os pacotes necessários usando 'apt-get install python3-numpy python3-pip' e instale o PyMilvus usando 'pip3 install pymilvus'.</block>
  <block id="77b346f241703e75634a6437339f3874" category="list-text">Valide as operações de leitura e gravação de dados do Amazon FSx ONTAP para NetApp ONTAP no banco de dados vetorial.</block>
  <block id="edeedbd869dbb3831a9bfc7c26f04200" category="list-text">Verifique a operação de leitura usando o script verify_data_netapp.py.</block>
  <block id="bda2d30c9f3f0d40ab873d7c99e8c13b" category="list-text">Se o cliente quiser acessar (ler) dados NFS testados no banco de dados vetorial por meio do protocolo S3 para cargas de trabalho de IA, isso pode ser validado usando um programa Python simples.  Um exemplo disso poderia ser uma busca por similaridade de imagens de outro aplicativo, como mencionado na imagem que está no início desta seção.</block>
  <block id="8b97e19802900809af55c42c509e614a" category="paragraph">Esta seção demonstra efetivamente como os clientes podem implantar e operar uma configuração Milvus autônoma em contêineres Docker, utilizando o NetApp FSx ONTAP da Amazon para armazenamento de dados NetApp ONTAP .  Essa configuração permite que os clientes aproveitem o poder dos bancos de dados vetoriais para manipular dados de alta dimensão e executar consultas complexas, tudo dentro do ambiente escalável e eficiente dos contêineres do Docker.  Ao criar uma instância do Amazon FSx ONTAP para NetApp ONTAP e uma instância EC2 correspondente, os clientes podem garantir a utilização ideal de recursos e o gerenciamento de dados.  A validação bem-sucedida das operações de leitura e gravação de dados do FSx ONTAP no banco de dados vetorial fornece aos clientes a garantia de operações de dados confiáveis e consistentes.  Além disso, a capacidade de listar (ler) dados de cargas de trabalho de IA por meio do protocolo S3 oferece maior acessibilidade aos dados.  Portanto, esse processo abrangente fornece aos clientes uma solução robusta e eficiente para gerenciar suas operações de dados em larga escala, aproveitando os recursos do FSx ONTAP da Amazon para NetApp ONTAP.</block>
  <block id="80f3b490016fb09dd087c51b2a8b26f5" category="summary">Configuração do cluster milvus - solução de banco de dados vetorial para netapp</block>
  <block id="c0f2e2b603c0c8186341bf2945e1ad13" category="doc">Configuração do cluster Milvus com Kubernetes no local</block>
  <block id="4a6f6b145c2d627bc6b03f4b1e6dd96a" category="paragraph">Esta seção discute a configuração do cluster milvus para a solução de banco de dados vetorial para NetApp.</block>
  <block id="b5be4c6d053fbcf3d99fa7a27f14df10" category="section-title">Configuração do cluster Milvus com Kubernetes no local</block>
  <block id="ae5afd2c726fae66bdccf19c83604efb" category="paragraph">Os desafios do cliente para escalar de forma independente em armazenamento e computação, gerenciamento eficaz de infraestrutura e gerenciamento de dados, Kubernetes e bancos de dados vetoriais juntos formam uma solução poderosa e escalável para gerenciar grandes operações de dados.  O Kubernetes otimiza recursos e gerencia contêineres, enquanto bancos de dados vetoriais manipulam com eficiência dados de alta dimensão e pesquisas de similaridade.  Essa combinação permite o processamento rápido de consultas complexas em grandes conjuntos de dados e dimensiona perfeitamente com volumes crescentes de dados, tornando-a ideal para aplicativos de big data e cargas de trabalho de IA.</block>
  <block id="b74b373b546797287d3c21cceba52d3d" category="list-text">Nesta seção, detalhamos o processo de instalação de um cluster Milvus no Kubernetes, utilizando um controlador de armazenamento NetApp para dados do cluster e dados do cliente.</block>
  <block id="65c0326e8e372682bfaae45cec62723f" category="list-text">Para instalar um cluster Milvus, Volumes Persistentes (PVs) são necessários para armazenar dados de vários componentes do cluster Milvus.  Esses componentes incluem etcd (três instâncias), pulsar-bookie-journal (três instâncias), pulsar-bookie-ledgers (três instâncias) e pulsar-zookeeper-data (três instâncias).</block>
  <block id="c2e2fce3a995f59900d7afbbe58683f5" category="inline-link-macro">este link</block>
  <block id="d33fb2ef35d69747411b9e87c7d3d69f" category="admonition">No cluster Milvus, podemos usar o Pulsar ou o Kafka como mecanismo subjacente que dá suporte ao armazenamento confiável e à publicação/assinatura de fluxos de mensagens do cluster Milvus.  Para o Kafka com NFS, a NetApp fez melhorias no ONTAP 9.12.1 e versões posteriores, e essas melhorias, juntamente com o NFSv4.1 e as alterações do Linux incluídas no RHEL 8.7 ou 9.1 e versões superiores, resolvem o problema de "renomeação absurda" que pode ocorrer ao executar o Kafka sobre NFS. Se você estiver interessado em informações mais detalhadas sobre o tópico de execução do Kafka com a solução NetApp NFS, consulte -<block ref="19b6a7adb53ddda340943365a4b691d7" category="inline-link-macro-rx"></block> .</block>
  <block id="eea5737b25740da376e769b4f799f861" category="list-text">Criamos um único volume NFS do NetApp ONTAP e estabelecemos 12 volumes persistentes, cada um com 250 GB de armazenamento.  O tamanho do armazenamento pode variar dependendo do tamanho do cluster; por exemplo, temos outro cluster onde cada PV tem 50 GB.  Consulte abaixo um dos arquivos PV YAML para obter mais detalhes; tínhamos 12 arquivos desse tipo no total.  Em cada arquivo, o storageClassName é definido como 'padrão', e o armazenamento e o caminho são exclusivos para cada PV.</block>
  <block id="4bd70516b6325446dd3ab13888cff57f" category="list-text">Execute o comando 'kubectl apply' para cada arquivo PV YAML para criar os Volumes Persistentes e, em seguida, verifique sua criação usando 'kubectl get pv'</block>
  <block id="3468fc776a2c10c6b885c4b8f38fbb6f" category="list-text">Para armazenar dados do cliente, a Milvus oferece suporte a soluções de armazenamento de objetos como MinIO, Azure Blob e S3.  Neste guia, utilizamos o S3.  As etapas a seguir se aplicam ao ONTAP S3 e ao armazenamento de objetos StorageGRID .  Usamos o Helm para implantar o cluster Milvus.  Baixe o arquivo de configuração, values.yaml, do local de download do Milvus.  Consulte o apêndice para o arquivo values.yaml que usamos neste documento.</block>
  <block id="ac8152f5c769ca08c180374241d9797c" category="list-text">Certifique-se de que 'storageClass' esteja definido como 'padrão' em cada seção, incluindo aquelas para log, etcd, zookeeper e bookkeeper.</block>
  <block id="3c27656d225ef946516e7bec88519049" category="list-text">Na seção MinIO, desabilite o MinIO.</block>
  <block id="a9c572c8c594acac80d859b834139c09" category="list-text">Crie um bucket NAS a partir do armazenamento de objetos ONTAP ou StorageGRID e inclua-os em um S3 externo com as credenciais de armazenamento de objetos.</block>
  <block id="5c01f0212f13cb62a8e9c91143a9a0e8" category="list-text">Antes de criar o cluster Milvus, certifique-se de que o PersistentVolumeClaim (PVC) não tenha nenhum recurso preexistente.</block>
  <block id="8916cc7e0054297b71b9453a888657d1" category="list-text">Utilize o Helm e o arquivo de configuração values.yaml para instalar e iniciar o cluster Milvus.</block>
  <block id="774a1cf197a96a839f6b770e85cb2445" category="list-text">Verifique o status dos PersistentVolumeClaims (PVCs).</block>
  <block id="63b2b2b30427688208b8a24971cee62e" category="list-text">Verifique o status dos pods.</block>
  <block id="1d419f9c469484aa1d54fd468448977e" category="paragraph">Certifique-se de que o status dos pods seja 'em execução' e esteja funcionando conforme o esperado</block>
  <block id="890a387ef3d7768088115e7fea8a9ff6" category="list-text">Teste de gravação e leitura de dados no armazenamento de objetos Milvus e NetApp .</block>
  <block id="e5aef6bb28887bb265d168f37e539b38" category="list-text">Grave dados usando o programa Python "prepare_data_netapp_new.py".</block>
  <block id="db12c3e2840ba5032e784bab8e8fb917" category="list-text">Leia os dados usando o arquivo Python "verify_data_netapp.py".</block>
  <block id="25ab62108c16e9b732c38f62755ec991" category="paragraph">Com base na validação acima, a integração do Kubernetes com um banco de dados vetorial, conforme demonstrado por meio da implantação de um cluster Milvus no Kubernetes usando um controlador de armazenamento NetApp , oferece aos clientes uma solução robusta, escalável e eficiente para gerenciar operações de dados em larga escala.  Essa configuração oferece aos clientes a capacidade de manipular dados de alta dimensão e executar consultas complexas de forma rápida e eficiente, tornando-a uma solução ideal para aplicativos de big data e cargas de trabalho de IA.  O uso de Volumes Persistentes (PVs) para vários componentes de cluster, juntamente com a criação de um único volume NFS do NetApp ONTAP, garante a utilização ideal de recursos e o gerenciamento de dados.  O processo de verificação do status de PersistentVolumeClaims (PVCs) e pods, bem como o teste de leitura e gravação de dados, fornece aos clientes a garantia de operações de dados confiáveis e consistentes.  O uso do armazenamento de objetos ONTAP ou StorageGRID para dados do cliente melhora ainda mais a acessibilidade e a segurança dos dados.  No geral, essa configuração capacita os clientes com uma solução de gerenciamento de dados resiliente e de alto desempenho que pode ser facilmente dimensionada de acordo com suas crescentes necessidades de dados.</block>
  <block id="34d3fa32b415d892eb0e14786cafccea" category="summary">Visão geral da solução para solução de banco de dados vetorial para netapp</block>
  <block id="351df3cce379006f4ba6b903c32e39a0" category="paragraph">Esta seção fornece uma visão geral da solução de banco de dados vetorial da NetApp .</block>
  <block id="84c35d4e8bb8f8f09d3728632bcee7ce" category="paragraph">Esta solução mostra os benefícios e recursos diferenciados que a NetApp oferece para enfrentar os desafios enfrentados pelos clientes de bancos de dados vetoriais.  Ao aproveitar o NetApp ONTAP, o StorageGRID, as soluções de nuvem da NetApp e o SnapCenter, os clientes podem agregar valor significativo às suas operações comerciais.  Essas ferramentas não apenas resolvem problemas existentes, mas também aumentam a eficiência e a produtividade, contribuindo assim para o crescimento geral do negócio.</block>
  <block id="d383216ef38104a4ae0ac03e48c3f38c" category="section-title">Por que a NetApp?</block>
  <block id="c8850228b08f24ab3b77cf8228b9b2cf" category="list-text">As ofertas da NetApp, como ONTAP e StorageGRID, permitem a separação de armazenamento e computação, possibilitando a utilização ideal de recursos com base em requisitos específicos.  Essa flexibilidade permite que os clientes dimensionem seu armazenamento de forma independente usando soluções de armazenamento da NetApp .</block>
  <block id="40251a62505d04ab7d80bacded5fec97" category="list-text">O NetApp ONTAP fornece suporte nativo para NAS e armazenamento de objetos nos principais provedores de serviços de nuvem, como AWS, Azure e Google Cloud.  Essa ampla compatibilidade garante integração perfeita, permitindo mobilidade de dados do cliente, acessibilidade global, recuperação de desastres, escalabilidade dinâmica e alto desempenho.</block>
  <block id="6c1c83ac60affc59fcc3432ea130dd8f" category="list-text">Com os recursos robustos de gerenciamento de dados da NetApp, os clientes podem ficar tranquilos sabendo que seus dados estão bem protegidos contra potenciais riscos e ameaças.  A NetApp prioriza a segurança de dados, oferecendo tranquilidade aos clientes quanto à segurança e integridade de suas informações valiosas.</block>
  <block id="738158dc90e1d60ff7273e21bc2d2c4e" category="summary">Validação de desempenho de banco de dados vetorial - solução de banco de dados vetorial para netapp</block>
  <block id="39301670f58445b6e5aed7e2a2694632" category="doc">Validação de desempenho do banco de dados vetorial</block>
  <block id="334e1c5c0681bc3d3d6b9321ff851f44" category="paragraph">Esta seção destaca a validação de desempenho que foi realizada no banco de dados de vetores.</block>
  <block id="1eb24bd760e508043a3cfdfe91ba9489" category="section-title">Validação de desempenho</block>
  <block id="0dfe6e4dda5bda08f3b2f54fe5f51a3b" category="paragraph">A validação de desempenho desempenha um papel fundamental tanto em bancos de dados vetoriais quanto em sistemas de armazenamento, servindo como um fator essencial para garantir a operação ideal e a utilização eficiente de recursos.  Bancos de dados vetoriais, conhecidos por manipular dados de alta dimensão e executar pesquisas de similaridade, precisam manter altos níveis de desempenho para processar consultas complexas de forma rápida e precisa.  A validação de desempenho ajuda a identificar gargalos, ajustar configurações e garantir que o sistema possa lidar com as cargas esperadas sem degradação do serviço.  Da mesma forma, em sistemas de armazenamento, a validação de desempenho é essencial para garantir que os dados sejam armazenados e recuperados de forma eficiente, sem problemas de latência ou gargalos que possam afetar o desempenho geral do sistema.  Ele também auxilia na tomada de decisões informadas sobre atualizações ou mudanças necessárias na infraestrutura de armazenamento.  Portanto, a validação de desempenho é um aspecto crucial do gerenciamento de sistemas, contribuindo significativamente para manter a alta qualidade do serviço, a eficiência operacional e a confiabilidade geral do sistema.</block>
  <block id="9115de397cf08aaab47480ba37fbda9b" category="paragraph">Nesta seção, pretendemos nos aprofundar na validação de desempenho de bancos de dados vetoriais, como Milvus e pgvecto.rs, com foco em suas características de desempenho de armazenamento, como perfil de E/S e comportamento do controlador de armazenamento netapp em suporte a cargas de trabalho de RAG e inferência dentro do ciclo de vida do LLM.  Avaliaremos e identificaremos quaisquer diferenciais de desempenho quando esses bancos de dados forem combinados com a solução de armazenamento ONTAP .  Nossa análise será baseada em indicadores-chave de desempenho, como o número de consultas processadas por segundo (QPS).</block>
  <block id="259349a97b2ad2022418ffa271915c7f" category="paragraph">Confira abaixo a metodologia utilizada para o milvus e o progresso.</block>
  <block id="3805969a7e504e8baa224367a87cc5a8" category="cell">Milvus (autônomo e cluster)</block>
  <block id="1cfad7d7743394085072e5f7fcc3a203" category="cell">Postgres(pgvecto.rs) #</block>
  <block id="2af72f100c356273d46284f6fd1dfc08" category="cell">versão</block>
  <block id="c2ee74b62870d06b4b4ad6819b9bf142" category="cell">2.3.2</block>
  <block id="44b732a6709d52e07db0367d4938965c" category="cell">0.2.0</block>
  <block id="ac52cf637478f3656a1fdee5c02324fd" category="cell">Sistema de arquivos</block>
  <block id="6f27ca3ac8a02564ce2eef7e706e1e50" category="cell">XFS em LUNs iSCSI</block>
  <block id="30b5bb1d010e4fe15e0541fa9b96dbdc" category="cell">Gerador de carga de trabalho</block>
  <block id="73676a7da2a7cbd819e3a72dab6d2364" category="inline-link-macro">Banco VectorDB</block>
  <block id="b9350528e041c5ef962f5553183ca801" category="cell"><block ref="5a4d2a4510eb4d9895b68971f8744a05" category="inline-link-macro-rx"></block>– v0.0.5</block>
  <block id="f1cb45f64cdd7b55480ba6aeecd7b797" category="cell">Conjuntos de dados</block>
  <block id="0adc231fd0cbf3d7d8d5a0ff68eb2783" category="cell">Conjunto de dados LAION * 10 milhões de incorporações * 768 dimensões * tamanho do conjunto de dados de ~300 GB</block>
  <block id="3941cf702a750210280a88643fe83810" category="cell">AFF 800 * Versão – 9.14.1 * 4 x 100GbE – para milvus e 2x 100GbE para postgres * iscsi</block>
  <block id="39138e4aea637ddf9fc568de53bed3af" category="section-title">VectorDB-Bench com cluster autônomo Milvus</block>
  <block id="3a82e1f5d5f2195d71ba779a6ede894f" category="paragraph">Fizemos a seguinte validação de desempenho no cluster autônomo milvus com o vectorDB-Bench.  A conectividade de rede e servidor do cluster autônomo milvus está abaixo.</block>
  <block id="ef436c3d7bb0f3687e078dce4b9bdb28" category="paragraph"><block ref="ef436c3d7bb0f3687e078dce4b9bdb28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="663c78b1d11f60d7440f91f77e4f328a" category="paragraph">Nesta seção, compartilhamos nossas observações e resultados dos testes do banco de dados independente Milvus. .  Selecionamos DiskANN como o tipo de índice para esses testes. .  A ingestão, otimização e criação de índices para um conjunto de dados de aproximadamente 100 GB levou cerca de 5 horas.  Durante a maior parte desse período, o servidor Milvus, equipado com 20 núcleos (o que equivale a 40 vcpus quando o Hyper-Threading está habilitado), estava operando em sua capacidade máxima de CPU de 100%. Descobrimos que o DiskANN é particularmente importante para grandes conjuntos de dados que excedem o tamanho da memória do sistema. .  Na fase de consulta, observamos uma taxa de Consultas por Segundo (QPS) de 10,93 com um recall de 0,9987.  A latência do 99º percentil para consultas foi medida em 708,2 milissegundos.</block>
  <block id="624dbbdc3175c82e67aadff554ee1850" category="paragraph">Da perspectiva de armazenamento, o banco de dados emitiu cerca de 1.000 ops/s durante as fases de ingestão, otimização pós-inserção e criação de índice.  Na fase de consulta, foram necessárias 32.000 ops/seg.</block>
  <block id="2063cebb91be357ea64826c835821b9d" category="paragraph">A seção a seguir apresenta as métricas de desempenho de armazenamento.</block>
  <block id="5805c53ecb86f7c7ae7765287eda00d6" category="cell">Fase de carga de trabalho</block>
  <block id="216ab40cda5c7c00ff42a4efb1827d89" category="cell">Métrica</block>
  <block id="7f2bb2bf609fe39698d58a2d1d86863a" category="cell">Ingestão de dados e otimização pós-inserção</block>
  <block id="79073619fba8242703524f16870ff858" category="cell">IOPS</block>
  <block id="648a472fd7585d9d0c15b90f36365597" category="cell">&lt; 1.000</block>
  <block id="26ae7bdd1d6fb8c4886e6fde8d12601c" category="cell">Latência</block>
  <block id="822500fd5bb8ac11d944779a6703df98" category="cell">&lt; 400 usecs</block>
  <block id="68eaabb91b0d1c52be44217a24f27b91" category="cell">Carga de trabalho</block>
  <block id="59829f7cd61cf1113b8214b47aaeacd8" category="cell">Mistura de leitura/escrita, principalmente escrita</block>
  <block id="991ff9e60b05b3e05e67404474611720" category="cell">Tamanho de E/S</block>
  <block id="6b29aa131a7b968826c90e6801bacd23" category="cell">64 KB</block>
  <block id="66c1b4c7f3dc385b68a9fa903ccd016d" category="cell">Consulta</block>
  <block id="7d38c4599a45db6312f66bfac2fbba0d" category="cell">Pico em 32.000</block>
  <block id="866fc78d18122580af38eeff4375a3c0" category="cell">100% de leitura em cache</block>
  <block id="9632dc4ffd7ab759c4fc53341977d887" category="cell">Principalmente 8 KB</block>
  <block id="06b68ce1a31c0cdf5430d925dabff321" category="paragraph">O resultado do vectorDB-bench está abaixo.</block>
  <block id="2a8bd0e83a84e623eafaed41ef4a0b48" category="paragraph"><block ref="2a8bd0e83a84e623eafaed41ef4a0b48" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf13afd123e82c2f8504d046ac979ce6" category="paragraph">A partir da validação de desempenho da instância autônoma do Milvus, fica evidente que a configuração atual é insuficiente para suportar um conjunto de dados de 5 milhões de vetores com uma dimensionalidade de 1536. Determinamos que o armazenamento possui recursos adequados e não constitui um gargalo no sistema.</block>
  <block id="7a2e31e50716ca1d05ae61faa264e4d9" category="section-title">VectorDB-Bench com cluster milvus</block>
  <block id="1a3dd3962bc3776e2a670ea2dccbf4aa" category="paragraph">Nesta seção, discutimos a implantação de um cluster Milvus em um ambiente Kubernetes.  Esta configuração do Kubernetes foi construída sobre uma implantação do VMware vSphere, que hospedava os nós mestre e de trabalho do Kubernetes.</block>
  <block id="2f38e478e85318635a3c104d2f9689ea" category="paragraph">Os detalhes das implantações do VMware vSphere e do Kubernetes são apresentados nas seções a seguir.</block>
  <block id="6b38cbd988bc17810219001208570634" category="paragraph"><block ref="ef20c4495e84beca29aabf20791bc97a" category="inline-image-macro-rx" type="image"></block> <block ref="6f1c220e845ab7b8291a1a21a3646cac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09618a18978db1f9288bf0626e2e9d77" category="paragraph">Nesta seção, apresentamos nossas observações e resultados dos testes do banco de dados Milvus.  * O tipo de índice usado foi DiskANN.  * A tabela abaixo fornece uma comparação entre as implantações autônomas e em cluster ao trabalhar com 5 milhões de vetores em uma dimensionalidade de 1536.  Observamos que o tempo necessário para ingestão de dados e otimização pós-inserção foi menor na implantação do cluster.  A latência do 99º percentil para consultas foi reduzida em seis vezes na implantação do cluster em comparação à configuração autônoma.  * Embora a taxa de Consultas por Segundo (QPS) tenha sido maior na implantação do cluster, ela não estava no nível desejado.</block>
  <block id="fa7bae8c4e9fc0bec05867545cb65c08" category="paragraph"><block ref="fa7bae8c4e9fc0bec05867545cb65c08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec05b5e2e1b5d66f987712f952bfd377" category="paragraph">As imagens abaixo fornecem uma visão de várias métricas de armazenamento, incluindo latência do cluster de armazenamento e IOPS (operações de entrada/saída por segundo) total.</block>
  <block id="866b04fa947dc783f0a1ca67687a0b46" category="paragraph"><block ref="866b04fa947dc783f0a1ca67687a0b46" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f34ceedf45c53ac5bfc4732c7e9eb992" category="paragraph">A seção a seguir apresenta as principais métricas de desempenho de armazenamento.</block>
  <block id="40c9acf8f61419691d77b3dec178cdc9" category="cell">Pico em 147.000</block>
  <block id="971ae6b3c89c8ab12e0eed4e70f3ad7a" category="paragraph">Com base na validação de desempenho do Milvus autônomo e do cluster Milvus, apresentamos os detalhes do perfil de E/S de armazenamento.  * Observamos que o perfil de E/S permanece consistente em implantações autônomas e em cluster.  * A diferença observada no pico de IOPS pode ser atribuída ao maior número de clientes na implantação do cluster.</block>
  <block id="537edb0aa02f73a246f084214ff9a1e4" category="section-title">vectorDB-Bench com Postgres (pgvecto.rs)</block>
  <block id="62f6737d84249676fddeaa6678755d2a" category="paragraph">Realizamos as seguintes ações no PostgreSQL (pgvecto.rs) usando o VectorDB-Bench: Os detalhes sobre a conectividade de rede e servidor do PostgreSQL (especificamente, pgvecto.rs) são os seguintes:</block>
  <block id="467a4cd74d7adb713cf4f94b3dd642b7" category="paragraph"><block ref="467a4cd74d7adb713cf4f94b3dd642b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd9a767006e111bd203547a99e12e650" category="paragraph">Nesta seção, compartilhamos nossas observações e resultados dos testes do banco de dados PostgreSQL, especificamente usando pgvecto.rs.  * Selecionamos HNSW como o tipo de índice para esses testes porque, no momento do teste, o DiskANN não estava disponível para pgvecto.rs.  * Durante a fase de ingestão de dados, carregamos o conjunto de dados Cohere, que consiste em 10 milhões de vetores com uma dimensionalidade de 768.  Esse processo levou aproximadamente 4,5 horas.  * Na fase de consulta, observamos uma taxa de Consultas por Segundo (QPS) de 1.068 com um recall de 0,6344.  A latência do 99º percentil para consultas foi medida em 20 milissegundos.  Durante a maior parte do tempo de execução, a CPU do cliente estava operando a 100% da capacidade.</block>
  <block id="1f3e94e90c6dc70493177c947144e128" category="paragraph">As imagens abaixo fornecem uma visão de várias métricas de armazenamento, incluindo latência total do cluster de armazenamento (IOPS) (operações de entrada/saída por segundo).</block>
  <block id="887b48e40648d9beb4f86ffbf295813a" category="paragraph"><block ref="887b48e40648d9beb4f86ffbf295813a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59566b4d8c8fef1f2b244df87cbe1523" category="paragraph"><block ref="59566b4d8c8fef1f2b244df87cbe1523" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa49276609916c00fd739a7d0474f2e0" category="section-title">Comparação de desempenho entre milvus e postgres no banco de dados vetorial Bench</block>
  <block id="870f4bfca5a2e4c27797438cfbcdcafc" category="paragraph"><block ref="870f4bfca5a2e4c27797438cfbcdcafc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a6bb1cc3086d7d67df39b7f25c55f2f" category="paragraph">Com base em nossa validação de desempenho do Milvus e PostgreSQL usando VectorDBBench, observamos o seguinte:</block>
  <block id="edec147efc5d9e9f8c60dd4f8475a94a" category="list-text">Tipo de índice: HNSW</block>
  <block id="2d14d931ff962fab0d69fc6c540c032e" category="list-text">Conjunto de dados: Cohere com 10 milhões de vetores em 768 dimensões</block>
  <block id="0e18fa0193d93ed358d7fdb6a65a8bbc" category="paragraph">Descobrimos que pgvecto.rs atingiu uma taxa de Consultas por Segundo (QPS) de 1.068 com um recall de 0,6344, enquanto Milvus atingiu uma taxa de QPS de 106 com um recall de 0,9842.</block>
  <block id="6f8820eba6bfb1c4427de7e140948640" category="paragraph">Se alta precisão em suas consultas for uma prioridade, o Milvus supera o pgvecto.rs, pois recupera uma proporção maior de itens relevantes por consulta.  Entretanto, se o número de consultas por segundo for um fator mais crucial, pgvecto.rs supera Milvus.  É importante observar, porém, que a qualidade dos dados recuperados via pgvecto.rs é inferior, com cerca de 37% dos resultados da pesquisa sendo itens irrelevantes.</block>
  <block id="35a1dd67e98f2039e3b4dc79a35aaa3e" category="section-title">Observação baseada em nossas validações de desempenho:</block>
  <block id="e6b80e98176081ee739c8e730d3feb58" category="paragraph">Com base em nossas validações de desempenho, fizemos as seguintes observações:</block>
  <block id="9d57f733c58a90a624b060f00ad469bd" category="paragraph">No Milvus, o perfil de E/S se assemelha muito a uma carga de trabalho OLTP, como a vista com o Oracle SLOB.  O benchmark consiste em três fases: ingestão de dados, pós-otimização e consulta.  Os estágios iniciais são caracterizados principalmente por operações de gravação de 64 KB, enquanto a fase de consulta envolve predominantemente leituras de 8 KB.  Esperamos que o ONTAP lide com a carga de E/S do Milvus com eficiência.</block>
  <block id="e63d591f52bb0af8effc43c397a26a24" category="paragraph">O perfil de E/S do PostgreSQL não apresenta uma carga de trabalho de armazenamento desafiadora.  Dada a implementação na memória atualmente em andamento, não observamos nenhuma E/S de disco durante a fase de consulta.</block>
  <block id="dca2ae788fda893b11a6e115cfbd0c5d" category="paragraph">DiskANN surge como uma tecnologia crucial para diferenciação de armazenamento.  Ele permite o dimensionamento eficiente da pesquisa de banco de dados vetorial além do limite de memória do sistema.  No entanto, é improvável que seja possível estabelecer diferenciação de desempenho de armazenamento com índices de banco de dados vetoriais na memória, como HNSW.</block>
  <block id="dc94ef6a238640d927556506c546662f" category="paragraph">Também vale a pena notar que o armazenamento não desempenha um papel crítico durante a fase de consulta quando o tipo de índice é HSNW, que é a fase operacional mais importante para bancos de dados vetoriais que dão suporte a aplicativos RAG.  A implicação aqui é que o desempenho do armazenamento não afeta significativamente o desempenho geral desses aplicativos.</block>
  <block id="0a5775b4af8d3c53f18b8ccaf913945d" category="summary">Esta é uma página de resumo para uma solução de banco de dados vetorial com Netapp.</block>
  <block id="8df98bd508b3983f9578ff172fd33def" category="doc">Solução de banco de dados vetorial com NetApp</block>
  <block id="7dff0a79d9410666d77e5f2ac7d0344f" category="paragraph">Karthikeyan Nagalingam e Rodrigo Nascimento, NetApp</block>
  <block id="01fbfceb794af743cb563e2676923b70" category="paragraph">Este documento fornece uma exploração completa da implantação e do gerenciamento de bancos de dados vetoriais, como Milvus e pgvecto, uma extensão PostgreSQL de código aberto, usando as soluções de armazenamento da NetApp.  Ele detalha as diretrizes de infraestrutura para usar o armazenamento de objetos NetApp ONTAP e StorageGRID e valida a aplicação do banco de dados Milvus no AWS FSx ONTAP.  O documento elucida a dualidade arquivo-objeto do NetApp e sua utilidade para bancos de dados vetoriais e aplicativos que oferecem suporte a incorporações vetoriais.  Ele enfatiza os recursos do SnapCenter, produto de gerenciamento empresarial da NetApp, ao oferecer funcionalidades de backup e restauração para bancos de dados vetoriais, garantindo a integridade e a disponibilidade dos dados.  O documento se aprofunda ainda mais na solução de nuvem híbrida da NetApp, discutindo seu papel na replicação e proteção de dados em ambientes locais e na nuvem.  Ele inclui insights sobre a validação de desempenho de bancos de dados vetoriais no NetApp ONTAP e conclui com dois casos de uso prático em IA generativa: RAG com LLM e ChatAI interno da NetApp.  Este documento serve como um guia abrangente para aproveitar as soluções de armazenamento da NetApp para gerenciar bancos de dados vetoriais.</block>
  <block id="ad452e95198e544e4d893fc75ad47dd6" category="paragraph">A Arquitetura de Referência concentra-se no seguinte:</block>
  <block id="710d95da54f78f69676ae8cb435c6e6e" category="list-text"><block ref="710d95da54f78f69676ae8cb435c6e6e" category="inline-link-macro-rx"></block></block>
  <block id="ada57c9cda1b1c751a4e899e578d38e3" category="list-text"><block ref="ada57c9cda1b1c751a4e899e578d38e3" category="inline-link-macro-rx"></block></block>
  <block id="82f4ace5dffbf97de80ca1ea103fbe56" category="list-text"><block ref="82f4ace5dffbf97de80ca1ea103fbe56" category="inline-link-macro-rx"></block></block>
  <block id="55496e6b06de6e72c19b578ad4ce71d8" category="inline-link-macro">Requisito de Tecnologia</block>
  <block id="4abf02f5e3deeb5036c0eded610de05a" category="list-text"><block ref="4abf02f5e3deeb5036c0eded610de05a" category="inline-link-macro-rx"></block></block>
  <block id="19c63a75039d0a9cb4cec3458cfe0581" category="list-text"><block ref="19c63a75039d0a9cb4cec3458cfe0581" category="inline-link-macro-rx"></block></block>
  <block id="8c8f8b93bc06c57499a04ec1b06dae28" category="inline-link-macro">Visão geral da verificação da solução</block>
  <block id="ca47b69088a672a9b65069106989453e" category="list-text"><block ref="ca47b69088a672a9b65069106989453e" category="inline-link-macro-rx"></block></block>
  <block id="55d7ef09813b4d6fdcb2c5626efe487e" category="list-text"><block ref="55d7ef09813b4d6fdcb2c5626efe487e" category="inline-link-macro-rx"></block></block>
  <block id="0bf83d510fcfec34ea35ee03c83ce577" category="list-text">link:vector-database-milvus-with-Amazon-FSx ONTAP-for- NetApp- ONTAP.html[Milvus com Amazon FSx ONTAP para NetApp ONTAP – dualidade de arquivo e objeto]</block>
  <block id="d6b228867818081bf3ee3cecad050baf" category="list-text"><block ref="d6b228867818081bf3ee3cecad050baf" category="inline-link-macro-rx"></block></block>
  <block id="f7ba02d22d83dabd12f0465a68c210ea" category="list-text"><block ref="f7ba02d22d83dabd12f0465a68c210ea" category="inline-link-macro-rx"></block></block>
  <block id="9e30995c6d4864b29eb56e92d196baec" category="list-text"><block ref="9e30995c6d4864b29eb56e92d196baec" category="inline-link-macro-rx"></block></block>
  <block id="bd1287beca719fc00531ba3dd533f70c" category="list-text"><block ref="bd1287beca719fc00531ba3dd533f70c" category="inline-link-macro-rx"></block></block>
  <block id="a4349288a9fe8fecb32674ed8a0e5d15" category="inline-link-macro">Casos de uso de banco de dados vetorial</block>
  <block id="b8d3dfdbfce37d26c1f4f9d8acee71ca" category="list-text"><block ref="b8d3dfdbfce37d26c1f4f9d8acee71ca" category="inline-link-macro-rx"></block></block>
  <block id="da73b8a757c1735375b56d959d388619" category="list-text"><block ref="da73b8a757c1735375b56d959d388619" category="inline-link-macro-rx"></block></block>
  <block id="fec04177b34fde0762c2d0f1cb5bcf85" category="inline-link-macro">Apêndice A: values.yaml</block>
  <block id="4076746ca906dfd472a39281440bca63" category="list-text"><block ref="4076746ca906dfd472a39281440bca63" category="inline-link-macro-rx"></block></block>
  <block id="2c0fbb0e17a27b8dbff673fb6b03c50b" category="list-text"><block ref="2c0fbb0e17a27b8dbff673fb6b03c50b" category="inline-link-macro-rx"></block></block>
  <block id="016166f68a717d3a544b77970134fe92" category="inline-link-macro">Apêndice C: verify_data_netapp.py</block>
  <block id="1fa29d4bb8db316d27c057bc2ab73bcb" category="list-text"><block ref="1fa29d4bb8db316d27c057bc2ab73bcb" category="inline-link-macro-rx"></block></block>
  <block id="cb2986bd8f2d29c4cca582736e0a680f" category="list-text"><block ref="cb2986bd8f2d29c4cca582736e0a680f" category="inline-link-macro-rx"></block></block>
  <block id="f60546114707495cbcefb83f806b47e2" category="summary">Requisito de tecnologia - solução de banco de dados vetorial para netapp</block>
  <block id="73877510aa37e2bcf501625512e358c3" category="paragraph">Esta seção fornece uma visão geral dos requisitos para a solução de banco de dados vetorial NetApp .</block>
  <block id="1507fd593972e19976a48675eb11483a" category="paragraph">As configurações de hardware e software descritas abaixo foram utilizadas para a maioria das validações realizadas neste documento, com exceção do desempenho.  Essas configurações servem como um guia para ajudar você a configurar seu ambiente.  No entanto, observe que os componentes específicos podem variar dependendo dos requisitos individuais do cliente.</block>
  <block id="7e9534170bcf0d2cab4a69e22cdca79c" category="cell">* A800 * ONTAP 9.14.1 * 48 x 3,49 TB SSD-NVM * Dois volumes de grupo flexíveis: metadados e dados.  * O volume NFS de metadados tem 12 volumes persistentes com 250 GB.  * Os dados são um volume ONTAP NAS S3</block>
  <block id="bcb4d8bb0642dc62c114f2a0a31f5aa3" category="cell">6 x FUJITSU PRIMERGY RX2540 M4</block>
  <block id="891b7b85ad27bcf31f4d6b9d3e5f55eb" category="cell">* 64 CPUs * CPU Intel(R) Xeon(R) Gold 6142 a 2,60 GHz * 256 GM de memória física * 1 porta de rede 100GbE</block>
  <block id="4515188d6af40c03b16b310778b865c8" category="cell">* 1 x SG100, 3xSGF6024 * 3 x 24 x 7,68 TB</block>
  <block id="e7f07d17d04d9ac60dd3ebc382a1d58b" category="cell">Aglomerado de Milvus</block>
  <block id="5c9a77f3be5149b25ef3dd4a0d42f61e" category="cell">* GRÁFICO - milvus-4.1.11.  * Versão do APP – 2.3.4 * Pacotes dependentes como bookkeeper, zookeeper, pulsar, etcd, proxy, querynode, worker</block>
  <block id="b0654cc6796be715102b69214bddfb52" category="cell">* Cluster K8s de 5 nós * 1 nó mestre e 4 nós de trabalho * Versão – 1.7.2</block>
  <block id="5b8215321456694f36bc83a178e44856" category="cell">*3.10.12.</block>
  <block id="5a019cf3628ae4961c3ba86198ac5410" category="summary">caso de uso - solução de banco de dados vetorial para netapp</block>
  <block id="853fb1f37b200090af8f730400a34971" category="paragraph">Esta seção fornece uma visão geral dos casos de uso para a solução de banco de dados vetorial da NetApp .</block>
  <block id="61798ad0c56d51680f77d6b9f4694877" category="paragraph">Nesta seção, discutimos dois casos de uso, como Geração Aumentada de Recuperação com Grandes Modelos de Linguagem e chatbot de TI da NetApp .</block>
  <block id="2b376c37a6f0c2c21b8ba7b62ac86693" category="section-title">Geração Aumentada de Recuperação (RAG) com Grandes Modelos de Linguagem (LLMs)</block>
  <block id="6a482cb4a386f8c0b7889b5dc11a997a" category="paragraph">O NVIDIA Enterprise RAG LLM Operator é uma ferramenta útil para implementar o RAG na empresa.  Este operador pode ser usado para implantar um pipeline RAG completo.  O pipeline RAG pode ser personalizado para utilizar Milvus ou pgvecto como banco de dados vetorial para armazenar incorporações de base de conhecimento.  Consulte a documentação para obter detalhes.</block>
  <block id="4c1729beb205806fa130c0dbf0364b59" category="paragraph">Figura 1) Enterprise RAG com tecnologia NVIDIA NeMo Microservices e NetApp</block>
  <block id="b14745e6302744b3b3c226e1fdee230a" category="paragraph"><block ref="b14745e6302744b3b3c226e1fdee230a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da66e40722180b5a0466a9ff253976af" category="section-title">Caso de uso do chatbot de TI da NetApp</block>
  <block id="497416719429ff96f2462d991f6ea3f8" category="paragraph">O chatbot da NetApp serve como outro caso de uso em tempo real para o banco de dados vetorial.  Neste caso, o NetApp Private OpenAI Sandbox fornece uma plataforma eficaz, segura e eficiente para gerenciar consultas de usuários internos da NetApp.  Ao incorporar protocolos de segurança rigorosos, sistemas eficientes de gerenciamento de dados e recursos sofisticados de processamento de IA, ele garante respostas precisas e de alta qualidade aos usuários com base em suas funções e responsabilidades na organização por meio de autenticação SSO.  Esta arquitetura destaca o potencial de mesclar tecnologias avançadas para criar sistemas inteligentes focados no usuário.</block>
  <block id="8afdd8df71939b23b5b37041b4b0e243" category="paragraph"><block ref="8afdd8df71939b23b5b37041b4b0e243" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff2b3d5b17bdfc4a02990dd4115b7d4d" category="paragraph">O caso de uso pode ser dividido em quatro seções principais.</block>
  <block id="e21f69fe36aefc844dcebf8fb52262a3" category="section-title">Autenticação e verificação do usuário:</block>
  <block id="7457d61423f49fa817953d3c8e0c08cf" category="list-text">As consultas do usuário passam primeiro pelo processo de logon único (SSO) da NetApp para confirmar a identidade do usuário.</block>
  <block id="3dedad86d8ac55d8b2b034f0ff353ea5" category="list-text">Após a autenticação bem-sucedida, o sistema verifica a conexão VPN para garantir uma transmissão segura de dados.</block>
  <block id="34ef9101314d114f1bed9a4fc8c13666" category="section-title">Transmissão e processamento de dados:</block>
  <block id="e5aa3164f4a76a72d1d074c0285a4d54" category="list-text">Depois que a VPN é validada, os dados são enviados ao MariaDB por meio dos aplicativos web NetAIChat ou NetAICreate.  MariaDB é um sistema de banco de dados rápido e eficiente usado para gerenciar e armazenar dados do usuário.</block>
  <block id="d0d4d700ca2ba3e943833a184fce15db" category="list-text">O MariaDB então envia as informações para a instância do NetApp Azure, que conecta os dados do usuário à unidade de processamento de IA.</block>
  <block id="b1cbaf6e413b3b5a92538942710197de" category="section-title">Interação com OpenAI e filtragem de conteúdo:</block>
  <block id="e7a51c3da456741ac0fe5ae031a539a3" category="list-text">A instância do Azure envia as perguntas do usuário para um sistema de filtragem de conteúdo.  Este sistema limpa a consulta e a prepara para processamento.</block>
  <block id="8449bc1c7d0f0641656072f90d8d06db" category="list-text">A entrada limpa é então enviada ao modelo base do Azure OpenAI, que gera uma resposta com base na entrada.</block>
  <block id="ce4abebf9a6d91e3d12d3bd86ebd308f" category="section-title">Geração e moderação de respostas:</block>
  <block id="70ee91d51a5da426448f1ed59462804d" category="list-text">A resposta do modelo base é primeiro verificada para garantir que seja precisa e atenda aos padrões de conteúdo.</block>
  <block id="40d26f0ba80199b0eaf7b7e0525c7f34" category="list-text">Após passar na verificação, a resposta é enviada de volta ao usuário.  Esse processo garante que o usuário receba uma resposta clara, precisa e apropriada à sua consulta.</block>
  <block id="705451e750819c9ce68fb278a7b09839" category="summary">values-xml - solução de banco de dados vetorial para netapp</block>
  <block id="6e6c82b93338e2283cf42123803b79d4" category="doc">Apêndice A: Valores.yaml</block>
  <block id="42cb737e154e9abe53c3f800eae00d4e" category="paragraph">Esta seção fornece código YAML de exemplo para os valores usados na solução de banco de dados vetorial NetApp .</block>
  <block id="bdcc26240ab0215ba46efad29038278d" category="summary">Visão geral da verificação da solução - solução de banco de dados vetorial para netapp</block>
  <block id="a11dfa705c151f0af3e80cc954126655" category="paragraph">Realizamos uma validação abrangente da solução focada em cinco áreas principais, cujos detalhes estão descritos abaixo.  Cada seção aborda os desafios enfrentados pelos clientes, as soluções fornecidas pela NetApp e os benefícios subsequentes para o cliente.</block>
  <block id="748a76b95c3f380357377aefd2ed0474" category="list-text"><block ref="55d7ef09813b4d6fdcb2c5626efe487e" category="inline-link-macro-rx"></block>Os desafios do cliente são escalar de forma independente em armazenamento e computação, gerenciamento eficaz de infraestrutura e gerenciamento de dados.  Nesta seção, detalhamos o processo de instalação de um cluster Milvus no Kubernetes, utilizando um controlador de armazenamento NetApp para dados do cluster e dados do cliente.</block>
  <block id="e840bff7e1e9715df98e16fead8076cb" category="list-text">link:vector-database-milvus-with-Amazon-FSx ONTAP-for- NetApp- ONTAP.html[Milvus com Amazon FSx ONTAP para NetApp ONTAP – dualidade de arquivo e objeto] Nesta seção, por que precisamos implantar o banco de dados vetorial na nuvem, bem como as etapas para implantar o banco de dados vetorial (milvus autônomo) no Amazon FSx ONTAP para NetApp ONTAP em contêineres docker.</block>
  <block id="6cce3de9e8bf8cabbfe260cc36d61ac3" category="list-text"><block ref="d6b228867818081bf3ee3cecad050baf" category="inline-link-macro-rx"></block>Nesta seção, nos aprofundamos em como o SnapCenter protege os dados do banco de dados vetorial e os dados Milvus que residem no ONTAP.  Neste exemplo, utilizamos um bucket NAS (milvusdbvol1) derivado de um volume NFS ONTAP (vol1) para dados do cliente e um volume NFS separado (vectordbpv) para dados de configuração do cluster Milvus.</block>
  <block id="918f8a4912d6a98fb31ac7ba46e00ffc" category="list-text"><block ref="f7ba02d22d83dabd12f0465a68c210ea" category="inline-link-macro-rx"></block>Nesta seção, discutiremos a importância da recuperação de desastres (DR) para bancos de dados vetoriais e como o produto de recuperação de desastres Snapmirror da NetApp fornece uma solução de DR para bancos de dados vetoriais.</block>
  <block id="2f1a6b813251891cca144a8b91cde4f5" category="list-text"><block ref="9e30995c6d4864b29eb56e92d196baec" category="inline-link-macro-rx"></block>Nesta seção, pretendemos nos aprofundar na validação de desempenho de bancos de dados vetoriais, como Milvus e pgvecto.rs, com foco em suas características de desempenho de armazenamento, como perfil de E/S e comportamento do controlador de armazenamento netapp em suporte a cargas de trabalho de RAG e inferência dentro do ciclo de vida do LLM.  Avaliaremos e identificaremos quaisquer diferenciais de desempenho quando esses bancos de dados forem combinados com a solução de armazenamento ONTAP .  Nossa análise será baseada em indicadores-chave de desempenho, como o número de consultas processadas por segundo (QPS).</block>
  <block id="87c3db9ccf444604c258b88ee8489364" category="summary">verify_data_netapp.py - solução de banco de dados vetorial para netapp</block>
  <block id="599675cccffd45ab676aea932c3fdfbd" category="paragraph">Esta seção contém um script Python de exemplo que pode ser usado para validar o banco de dados vetorial na solução de banco de dados vetorial NetApp .</block>
  <block id="48e4e86482d1e72b17c82feb1e930352" category="doc">Assista a vídeos sobre soluções de IA com a NetApp</block>
  <block id="a9f5e6dcd1d44f9ba3dc3398020d2404" category="paragraph">Descubra como a NetApp capacita iniciativas de IA e aprendizado de máquina.  Essas playlists de vídeos selecionadas apresentam soluções de IA da NetApp e fluxos de trabalho de MLOps, destacando estratégias de implantação, automação e gerenciamento de dados para análises avançadas.</block>
  <block id="145706f4acca44c289ff5ca8cc5b2b86" category="paragraph-title">Soluções de IA da NetApp</block>
  <block id="b4bf3d1dd932a4fb0e32b91623652e42" category="inline-link-macro">Assista à playlist de soluções de IA da NetApp</block>
  <block id="d3e2da82e7d75fc2a126141e7169de49" category="paragraph">Playlist de vídeos abrangente cobrindo infraestrutura de IA, sistemas convergentes e implantações de IA empresarial.<block ref="af3f91668350fde9b89e361b330e6bf9" category="inline-link-macro-rx"></block></block>
  <block id="07aca6f404d3e6c525bac36328b0d27d" category="paragraph-title">Operações de Aprendizado de Máquina (MLOps)</block>
  <block id="aee569e95a8498ede74e68ae8306e6e5" category="inline-link-macro">Assista à playlist do MLOps</block>
  <block id="d41374c7672e6e4fdbfbd6504b672d3c" category="paragraph">Série de vídeos sobre fluxos de trabalho de MLOps, pipelines de dados e práticas operacionais recomendadas.<block ref="70aea7fc5134cd09b86d7ff27c954117" category="inline-link-macro-rx"></block></block>
  <block id="10b2aec15aae4d935355e27497e66c5f" category="summary">Série de vídeos e demonstrações discutindo os recursos de muitas das soluções da NetApp</block>
  <block id="6354d74cd74c1d9f49224ac4e6209bab" category="doc">Soluções NetApp : vídeos e demonstrações</block>
  <block id="60b5065968cf0f66d862a344124f6415" category="paragraph">Visão geral dos vídeos e demonstrações destacando recursos específicos de muitas das soluções da NetApp.</block>
  <block id="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="list-text"><block ref="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="inline-link-macro-rx"></block></block>
  <block id="895a85fc0a1a565ac547acc1bc9740f3" category="inline-link-macro">MLOps</block>
  <block id="90e97692c42b1eb0ec22c639049d78a1" category="list-text"><block ref="90e97692c42b1eb0ec22c639049d78a1" category="inline-link-macro-rx"></block></block>
  <block id="181a90cd4ce68792d6ce2049bb1ff6ec" category="summary">Registro de alterações recentes no material de apoio das soluções de inteligência artificial da NetApp .</block>
  <block id="232dfabf5b2a241a9f7473820c81bf15" category="doc">Novidades nas soluções de inteligência artificial da NetApp</block>
  <block id="be647982bfc8c0837c019b8fdbc711b3" category="paragraph">Aprenda o que há de novo em soluções de inteligência artificial.</block>
  <block id="bab52961b58c502c7991d35556c25367" category="section-title">18 de agosto de 2025</block>
  <block id="47e26e0d5bbeef43c544dd9ae72e66b0" category="inline-link-macro">Família de soluções NetApp</block>
  <block id="840125a006aee7dc0e8efd313e7b614e" category="paragraph">O site da NetApp Solutions agora é o<block ref="f083b096ae581e72c5ab727ef8bd5732" category="inline-link-macro-rx"></block> , que inclui os seguintes sites:</block>
  <block id="e87298059f60b0844dc971f315184cf5" category="list-text">Soluções de inteligência artificial da NetApp</block>
  <block id="9cae574c1dc1ca50a949c1e889637ba7" category="inline-link-macro">Soluções de contêiner NetApp</block>
  <block id="31d1ae0120af1d791e4320e17eb10687" category="list-text"><block ref="31d1ae0120af1d791e4320e17eb10687" category="inline-link-macro-rx"></block></block>
  <block id="3947417923606d3599bcba7a82f71f1b" category="inline-link-macro">Soluções de gerenciamento de dados da NetApp</block>
  <block id="56c054d4bb919790ebe189f7a7d11c3c" category="list-text"><block ref="56c054d4bb919790ebe189f7a7d11c3c" category="inline-link-macro-rx"></block></block>
  <block id="9bb3e58246c5654a6d8e08a7bddd60ec" category="inline-link-macro">Soluções de banco de dados NetApp</block>
  <block id="3e2420ab1ec1d6e02b32b017d3ba969a" category="list-text"><block ref="3e2420ab1ec1d6e02b32b017d3ba969a" category="inline-link-macro-rx"></block></block>
  <block id="a37049a2a78422ac5627c7987db5c337" category="inline-link-macro">Soluções de nuvem pública e híbrida da NetApp</block>
  <block id="144417321224efbf0afc2ae665a84a46" category="list-text"><block ref="144417321224efbf0afc2ae665a84a46" category="inline-link-macro-rx"></block></block>
  <block id="2729aba3baa90aaaed37b282e515f6e4" category="inline-link-macro">Soluções NetApp para SAP</block>
  <block id="5e056430559fb77ac659dbb71ecce256" category="list-text"><block ref="5e056430559fb77ac659dbb71ecce256" category="inline-link-macro-rx"></block></block>
  <block id="4ead908c2ca3b4c7156e0e703642415d" category="inline-link-macro">Soluções de virtualização da NetApp</block>
  <block id="3100186c9f62cec85ac05309c5d10217" category="list-text"><block ref="3100186c9f62cec85ac05309c5d10217" category="inline-link-macro-rx"></block></block>
  <block id="fac83ccf1756a0c9cb3b8982d7f17073" category="sidebar">A NetApp fornece soluções abrangentes de IA que combinam gerenciamento de dados de nível empresarial, arquiteturas de referência validadas e parcerias estratégicas para acelerar suas iniciativas de IA e dar suporte a resultados comerciais críticos.  Da implantação de infraestrutura à automação de MLOps, nossas soluções escalam perfeitamente em ambientes de borda, data center e nuvem híbrida.</block>
  <block id="be11c74c1dd7f307bb80183a90dc2067" category="sidebar">Começar</block>
  <block id="33871b6190a8d5adbe8b15282054766c" category="sidebar">O que há de novo</block>
  <block id="d6b9ea32b921a9f56de32062ba4b94f3" category="sidebar">Blogs</block>
  <block id="de42653a3a04e4aefa258105632011d4" category="sidebar">Vídeos e demonstrações</block>
  <block id="0356451dce8be030d34b4cddc51bd023" category="sidebar">Infraestrutura de IA e sistemas convergentes</block>
  <block id="9547dc55d95184a53ea1a8366b5aeced" category="sidebar">NetApp AIPod com sistemas NVIDIA DGX</block>
  <block id="1f403aa196fd2c94e882669641695d63" category="sidebar">NVIDIA DGX SuperPOD com série EF</block>
  <block id="ca2b44ea641055fab6c572a1ec645f40" category="sidebar">NetApp AIPod com Lenovo para NVIDIA OVX</block>
  <block id="71194b59e7e6e05cdd5e38686d46dd11" category="sidebar">Sistema de arquivos paralelos BeeGFS com E-Series</block>
  <block id="0490c28d4251b3da040883241b9a245b" category="sidebar">Casos de uso e aplicações de IA</block>
  <block id="03a2eeb037be2a65352a6ce833a5352d" category="sidebar">AIPod Mini para inferência RAG</block>
  <block id="2a5e8ee0f85321457b5b5051848b33df" category="sidebar">Inferência de IA na borda</block>
  <block id="1f5ef80ba6fe60fcd8fc9b93428724ca" category="sidebar">Soluções de banco de dados vetoriais</block>
  <block id="1c2e519ac88b24b944e313f1528b25ca" category="sidebar">Cargas de trabalho de direção autônoma</block>
  <block id="1f2d4372bbd3f4944eec91b65eb55b69" category="sidebar">Quantum StorNext com Série E</block>
  <block id="dd12d2c2197bdac0454f49eaf82efcb1" category="sidebar">MLOps e gerenciamento de dados</block>
  <block id="55200dead19623a5ed7fd47347cc531d" category="sidebar">MLOps de código aberto com NetApp</block>
  <block id="0fa95f40d436ae4b6b1a848a385c88f5" category="sidebar">MLOps multicloud híbridos com Domino Data Lab</block>
  <block id="ec441b7e7e90b2ae639b5c9784b469f9" category="sidebar">FSx ONTAP para MLOps</block>
  <block id="072e5110aacde0c4952afb7fa86bd5bf" category="sidebar">Soluções de IA para big data e nuvem híbrida</block>
  <block id="248d62097e51f823fbf1797b8d71b837" category="sidebar">Soluções de dados em nuvem híbrida</block>
  <block id="01ba1aebae20e7ddfe20f3ea9572b0a6" category="sidebar">Soluções Apache Spark</block>
  <block id="8f0ff6e8178c4e8f4ea0f489063d7586" category="sidebar">Confluent Kafka com armazenamento NetApp ONTAP</block>
  <block id="8e2406d586d4192dc66b85722da1c3b9" category="sidebar">NetApp StorageGRID com Splunk SmartStore</block>
  <block id="76a3eb07a798a5ace45b8500ba2aae19" category="sidebar">Lakehouse Dremio com armazenamento NetApp</block>
  <block id="e95b75f557af9310f3d9c6299286a533" category="sidebar">Solicitações de soluções e feedback</block>
  <block id="22d04ecae9fae88d0b8d4548a46a545b" category="sidebar">Solicitação de automação</block>
  <block id="776ab15fef436c9315c14738509d299e" category="sidebar">Proponha uma nova solução</block>
  <block id="cfdaac8ef24ac5b2612570c34da00954" category="sidebar">Fornecer feedback da solução</block>
  <block id="9e34d9d231e4cd17fbacda95fb51929b" category="sidebar">Simplifique seus fluxos de trabalho de IA/ML com as soluções abrangentes de MLOps e gerenciamento de dados da NetApp.  De plataformas de código aberto a ferramentas de nível empresarial, nossas soluções permitem o desenvolvimento, a implantação e o dimensionamento eficientes de modelos em ambientes de nuvem híbrida, ao mesmo tempo em que garantem a consistência e o desempenho dos dados.</block>
  <block id="e212a74da744d81b7be22fde8837f469" category="sidebar">Soluções de gerenciamento de dados e MLOps da NetApp</block>
  <block id="7c9c1738224214245dd19322f112f008" category="sidebar">Plataformas MLOps de código aberto</block>
  <block id="8225e12837234b91ab0ddcd265042318" category="sidebar">Configuração do NetApp Trident para AIPod</block>
  <block id="8b4f0b6bb6bc359f491be13c6d4217c4" category="sidebar">Implantação e integração do Apache Airflow</block>
  <block id="948fee9aa5251e39df94d1c32d0c25cf" category="sidebar">Implantação e operações de dados do JupyterHub</block>
  <block id="73cee63b0ef47212c43598d623b858e0" category="sidebar">Implantação e rastreabilidade do MLflow</block>
  <block id="938ff6f66cfc08077aee20a94cb3555a" category="sidebar">Fluxos de trabalho MLOps avançados</block>
  <block id="e037812c032cd0d9c22b13bc85e9e8b0" category="sidebar">Implantação e notebooks do Kubeflow</block>
  <block id="3ff4473b7f6cd29fd2f032383a101ad3" category="sidebar">Treine modelos de reconhecimento de imagem com Kubeflow</block>
  <block id="4d72e4ce52deedeed5378320bb10ba60" category="sidebar">Execução de carga de trabalho de IA de nó único</block>
  <block id="d4090ff0c5d6e77994fe88d878931a09" category="sidebar">Execução de carga de trabalho de IA distribuída</block>
  <block id="6d49da972d2b3e8021183d3dd882efc3" category="sidebar">Ingestão de dados com SnapMirror</block>
  <block id="13c4fd018be37b2e07ac1e3c7bf940da" category="sidebar">Soluções MLOps empresariais</block>
  <block id="bf57be3e9bf09ff89214bcab0ffcd37f" category="sidebar">MLOps híbridos com Domino Data Lab</block>
  <block id="5a938de20177e2b1dcb267d6d7b4f069" category="sidebar">Acesso a dados entre ambientes com o Domino</block>
  <block id="86c9440e933f2848898cd3a50e0d30c5" category="sidebar">Integração do software NVIDIA NGC</block>
  <block id="e9eb61f514f368f5d8d0cf3ccfded4f9" category="sidebar">Integração de Cloud MLOps e AWS</block>
  <block id="b9a33eec860aee8b042190248e9c0978" category="sidebar">Amazon FSx para ONTAP MLOps</block>
  <block id="19f22745fb509faf9a35f2999167b4b3" category="sidebar">Integrar FSx ONTAP como S3 privado no SageMaker</block>
  <block id="958182d4c4d2fbecef5e794dd36a2fcd" category="sidebar">FSx ONTAP para treinamento de modelo SageMaker</block>
  <block id="765bac8adf0ce0c27f43291f5f38e36e" category="sidebar">Crie um pipeline MLOps simplificado com FSx</block>
  <block id="cff078ffafce4368253406707fe938e2" category="sidebar">Bancos de dados vetoriais e aplicações de IA</block>
  <block id="8817647abcdf406ecb3f743ce1f4d0c3" category="sidebar">Solução de banco de dados vetorial com NetApp</block>
  <block id="eac46f1424b8a5f784861bfb337632d5" category="sidebar">Configuração de cluster Milvus com Kubernetes</block>
  <block id="e557c94c22c1c941bd40b8277f7f7753" category="sidebar">Proteção de banco de dados vetorial com SnapCenter</block>
  <block id="ba5dd0875f60bb8bfd1c4511266f65f1" category="sidebar">Validação de desempenho do banco de dados vetorial</block>
  <block id="8d80ba264d116b7cc3e458ba8697ce83" category="sidebar">Casos de uso de banco de dados vetorial</block>
  <block id="e90bb805ac6728252476dc4b6c9f33b8" category="sidebar">Ferramentas de gerenciamento e armazenamento de dados</block>
  <block id="8825002f133fae0b139e8325ac7730cf" category="sidebar">Data lake StorageGRID para direção autônoma</block>
  <block id="bf25ffbc01db3077dbf625f1f66b0b81" category="sidebar">Recuperação de desastres com SnapMirror</block>
  <block id="1e87a0e6a353196e3d5d6cd2e73a3e6e" category="sidebar">Implante uma infraestrutura de IA pronta para empresas com arquiteturas de referência validadas e sistemas convergentes da NetApp.  De soluções NetApp AIPod a plataformas de armazenamento de alto desempenho, nossos projetos oferecem o desempenho, a escalabilidade e a confiabilidade necessários para cargas de trabalho exigentes de IA/ML.</block>
  <block id="994ec7a86f72507f5352d2b180d45f33" category="sidebar">Infraestrutura de IA e sistemas convergentes da NetApp</block>
  <block id="1c869286ed71535693a9462972519af4" category="sidebar">Arquiteturas de referência NetApp AIPod</block>
  <block id="b4f767e2f090ec487aa796e06a450c3b" category="sidebar">Arquitetura AIPod</block>
  <block id="b6c79f2c0318b6d7625fb67322575ef8" category="sidebar">Detalhes de implantação do AIPod</block>
  <block id="8c660d55cc308e8a0142574e6cb06bb2" category="sidebar">Validação e orientação de dimensionamento do AIPod</block>
  <block id="f5a73cfaecb9184b2e8146ed455050a9" category="sidebar">Armazenamento de alto desempenho para cargas de trabalho de IA</block>
  <block id="dca52c3c8e9f73ebf5e2f52c01c943af" category="sidebar">NVIDIA DGX SuperPOD com armazenamento da série EF</block>
  <block id="0cdb4340f983739886aeeabf55ded9a0" category="sidebar">IBM Spectrum Scale com armazenamento da série E</block>
  <block id="103956252a2179a2f41c37f503662e57" category="sidebar">NetApp ONTAP com Lenovo ThinkSystem</block>
  <block id="e5a53cbbfd61be59509da2fb28b87bd6" category="sidebar">Explore implementações de IA do mundo real com soluções NetApp , desde sistemas RAG empresariais e inferência de ponta até práticas de IA responsáveis e estratégias de migração de dados.  Esses casos de uso demonstram como a NetApp permite que as organizações implantem aplicativos de IA em diversos ambientes, mantendo a segurança, o desempenho e a escalabilidade.</block>
  <block id="7438b9f1311e240ca42a988e9d13e00c" category="sidebar">Casos de uso e aplicativos de IA da NetApp</block>
  <block id="f5d80fd5b29670f59fa900f8c07fb329" category="sidebar">Explore implementações de IA do mundo real com soluções NetApp , desde sistemas RAG empresariais e inferência de ponta até práticas de IA responsáveis e estratégias de migração de dados.  Esses casos de uso demonstram como a NetApp habilita aplicativos de IA em diversos ambientes, mantendo a segurança, o desempenho e a escalabilidade.</block>
  <block id="0d6f02845b71bc324cd82a725369e788" category="sidebar">Aplicações e casos de uso de IA empresarial</block>
  <block id="a67b9cee4655d6177295261e4bcd604d" category="sidebar">NetApp AIPod Mini para RAG empresarial</block>
  <block id="f5d3d706e83df8136ffa361f6bf3de44" category="sidebar">IA generativa e valor da NetApp</block>
  <block id="e2c8fd379213f568475a9fd8d939677a" category="sidebar">Inferência de IA de ponta com NetApp e Lenovo</block>
  <block id="7625f6572992d4d6884af97bd58e8555" category="sidebar">Migração de análise de big data para IA</block>
  <block id="58f52c07cacafd13bf7c2b75bd52297b" category="sidebar">IA responsável</block>
  <block id="726a429bb7d3cf42471e4ef6d5064f39" category="sidebar">IA responsável com transformação de imagem Protopia</block>
  <block id="9aadc819040333a6a70c083f60934127" category="sidebar">Soluções de infraestrutura e armazenamento de IA</block>
  <block id="4ec66dae70419b5536af92b7e6af12eb" category="sidebar">Projete o Quantum StorNext com sistemas da série E</block>
  <block id="fdc9cddf0d9dda4d36a935baaa555437" category="sidebar">Implemente o Quantum StorNext com sistemas da série E</block>
  <block id="2107e3f2176d1159c57518d8100b979c" category="sidebar">Transforme sua infraestrutura de análise de dados com as soluções comprovadas da NetApp para cargas de trabalho de big data, incluindo Apache Spark, Hadoop, Kafka e arquiteturas modernas de data lake que escalam da borda para a nuvem.</block>
  <block id="a4c306bc134438ffdcde3dc25d141930" category="sidebar">Soluções modernas de análise de dados da NetApp</block>
  <block id="f6d439e305ff0317b08aeaad65bc202c" category="sidebar">As soluções modernas de análise de dados da NetApp são um conjunto de recursos estratégicos e tecnológicos que demonstram os recursos de armazenamento da NetApp no espaço da IA.</block>
  <block id="0c5c9c87a184244b0a7327aaef882e8e" category="sidebar">Soluções Apache Kafka</block>
  <block id="7d576967253ca2f566f9693183407367" category="sidebar">Cargas de trabalho do Apache Kafka com armazenamento NetApp NFS</block>
  <block id="b98ea9630b58bea0f022799ecefe4062" category="sidebar">Confluent Kafka com controladores de armazenamento NetApp ONTAP</block>
  <block id="7f8513139888dda0c0ecb82a93548af9" category="sidebar">Melhores práticas para Confluent Kafka</block>
  <block id="c9adcd46dfe28ab240bf984f9da39535" category="sidebar">Validação de desempenho do Kafka com AWS</block>
  <block id="c6dc54040e7551a25c7f14dd83a3ca37" category="sidebar">Soluções Apache Spark e Hadoop</block>
  <block id="75b5d408998484e1ea5a4ce3cc432cbe" category="sidebar">Soluções de armazenamento NetApp para Apache Spark</block>
  <block id="d2e5b5510723b29c7f85a6f53b0b30fe" category="sidebar">Implantar carga de trabalho do Apache Spark com armazenamento NetApp</block>
  <block id="d142861488d42c2de042afc4375049da" category="sidebar">Soluções de dados em nuvem híbrida da NetApp para Spark e Hadoop</block>
  <block id="15b1a623b46c0553eb7e0a02392de6f9" category="sidebar">Casos de uso e arquiteturas</block>
  <block id="7bbc21a3294c0070a8663140370d1f39" category="sidebar">Resultados dos testes do Apache Spark</block>
  <block id="8b809555e7e0cd658f51306db399d338" category="sidebar">Gerenciamento de dados em nuvem e IA</block>
  <block id="1d2114df6a9f8f5d7e8f597e9c70a6c1" category="sidebar">Gerenciamento de dados em nuvem com NetApp File-Object Duality e AWS SageMaker</block>
  <block id="4f25c5c9b33cc2f12b098bd8cc026222" category="sidebar">Análise de Big Data Dados para Inteligência Artificial</block>
  <block id="55cd26df7471de5ffbc83646a94fddbb" category="sidebar">Amazon FSx for NetApp ONTAP para MLOps</block>
  <block id="2a15fc3906339e08c458c8e62e447da3" category="sidebar">Solução de nuvem híbrida Apache Spark</block>
  <block id="e0afb7c0b35ca1c50d576d490c1f6f83" category="sidebar">Plataformas modernas de análise e data lake</block>
  <block id="2f8caf1cb27d10780daee2d12dfe6cf5" category="sidebar">Solução híbrida iceberg lakehouse de próxima geração da NetApp e Dremio</block>
  <block id="5e3dc34b61f6a21ffd6549ee40d4631b" category="sidebar">NetApp E-Series E5700 e Splunk Enterprise</block>
  <block id="8cd58c89ff3d51a256ecfe3fe8bab20f" category="sidebar">Recursos adicionais</block>
  <block id="7cc3c71ee2fdbff1fd2efbfcded89f90" category="sidebar">Diferentes soluções para diferentes estratégias analíticas</block>
  <block id="8598954d073301b356199d49f5c02a69" category="sidebar">Blog: Apache Spark participa do NetApp Data Analytics Playground</block>
  <block id="0795007b8521bf374f9ddd4eb68a4a2b" category="sidebar">Blog: Use XCP para migração de dados de um Data Lake e HPC para ONTAP NFS</block>
  <block id="c254d48fc85fff80674335af647fc2d3" category="sidebar">NetApp TV: Lista de reprodução de análise de Big Data</block>
  <block id="5baf6ec1129c513e42641878b72ed0d8" category="sidebar">Soluções de inteligência artificial</block>
  <block id="554cfab3938e21d9270bd6b75931f96f" category="sidebar">Vídeos</block>
  <block id="45552f1d8df5302f6b20a45bdca4873c" category="sidebar">Configuração do NetApp Trident</block>
  <block id="629606c7cd29d3a21eb21c6ac5139f33" category="sidebar">Backends Trident para implantações AIPod</block>
  <block id="6c7cb31582a28a42e762b2046a1ce896" category="sidebar">Kubernetes StorageClasses para implantações de AIPod</block>
  <block id="d9fd1af737bab40d222131485c9bb808" category="sidebar">Implantação do Apache Airflow</block>
  <block id="17f2e89c743299170fd62138fa80d495" category="sidebar">Implantação do JupyterHub</block>
  <block id="471efd78e003975a601bfbdaf70136d2" category="sidebar">Ingerir dados com o NetApp SnapMirror</block>
  <block id="7d6f6d1bc3093617ee4703c5e520774b" category="sidebar">Implantação do MLflow</block>
  <block id="7174f04026f1e5e87367c72c1c073824" category="sidebar">Rastreabilidade de conjunto de dados para modelo com NetApp e MLflow</block>
  <block id="a38d89f197f605418a88b686e0175fa2" category="sidebar">Implantação do Kubeflow</block>
  <block id="b540e10006be068e5e5fd93d05b7b12c" category="sidebar">Provisionar o espaço de trabalho do Jupyter Notebook</block>
  <block id="e8816281bfd02443de2002db66789462" category="sidebar">Treinar um modelo de reconhecimento de imagem - exemplo de fluxo de trabalho</block>
  <block id="4c71560715665aa3108585868c989cdc" category="sidebar">Exemplo de operações do Trident</block>
  <block id="1c6a3a6b23e40077c58b45d05d4d411f" category="sidebar">Exemplo de trabalhos de alto desempenho para implantações de AIPod</block>
  <block id="dcdebd18dbab6da6d511c220479f6460" category="sidebar">Execute uma carga de trabalho de IA de nó único</block>
  <block id="98053e2b2531af18e4f885fb8a731327" category="sidebar">Execute uma carga de trabalho de IA distribuída e síncrona</block>
  <block id="7406ea045ac944a9db15b50dba8cc04b" category="sidebar">MLOps híbridos com Domino Data Lab e NetApp</block>
  <block id="1231369e1218613623e1b520c27ce190" category="sidebar">Configuração inicial</block>
  <block id="e5726f3da1ad0304974cf103e75da470" category="sidebar">Expor volumes NetApp existentes ao Domino</block>
  <block id="f62030848d7cb177a11eb3916356bb29" category="sidebar">Acesse os mesmos dados em diferentes ambientes</block>
  <block id="0f68b904e33d9ac04605aecc958bcf52" category="sidebar">Informações adicionais</block>
  <block id="f4c44872f09acb0f4e8f90890004d4ab" category="sidebar">Use o software NVIDIA NGC</block>
  <block id="a12d6a26832d73816bca1235e9f4d8a1" category="sidebar">Exemplo de caso de uso - Treinamento TensorFlow</block>
  <block id="0975e7e38dac95fd7ce3d2e3966e26be" category="sidebar">Parte 1 - Integrar o Amazon FSx for NetApp ONTAP como um bucket S3 privado no AWS SageMaker</block>
  <block id="b675f3bab2742c1723ed556f8535349d" category="sidebar">Parte 2 - Aproveite o Amazon FSx for NetApp ONTAP como uma fonte de dados para treinamento de modelos no SageMaker</block>
  <block id="7609ccc24e4c12c32d0ad617fe91161e" category="sidebar">Parte 3 - Construir um pipeline MLOps simplificado</block>
  <block id="c79bd5ac7ebc0eae5588b9ad529a380f" category="sidebar">NetApp StorageGRID Data Lake para cargas de trabalho de direção autônoma</block>
  <block id="a20ee4ebc8e6614143815c881916cbba" category="sidebar">Solução de banco de dados vetorial com NetApp</block>
  <block id="e5df4bbe7b124f2fe5398d42696d57b3" category="sidebar">Banco de dados vetorial</block>
  <block id="9934c7eb2c2161e05fedd3b280e4eedc" category="sidebar">Requisito de tecnologia</block>
  <block id="951de808fb87ba9bc035ce3cf467b064" category="sidebar">Proteção de banco de dados vetorial usando SnapCenter</block>
  <block id="f0a132dd5ea90d189f80995d831f9b91" category="sidebar">Recuperação de desastres usando SnapMirror</block>
  <block id="e813a53d42d6bfe69e6907df9b0675d5" category="sidebar">Banco de dados vetorial com Instaclustr usando PostGreSQL: pgvector</block>
  <block id="7fad254d8199fbf6d695e96590444cff" category="sidebar">Apêndice B: prepare_data_netapp_new_py</block>
  <block id="4d4989117d6e4f26e57cc7135af8f508" category="sidebar">Apêndice D: docker_compose.yml</block>
  <block id="46aa0a2ad138d7cd72baea1b2f96553c" category="sidebar">Infraestruturas convergentes de IA</block>
  <block id="503011292be147bd4172e92de477a75e" category="sidebar">NVA-1173 NetApp AIPod com sistemas NVIDIA DGX</block>
  <block id="34df2039718349f1b8c838bff98ae8fa" category="sidebar">Componentes de hardware</block>
  <block id="7d19d593db0bb056876a9535cbced90a" category="sidebar">Componentes de software</block>
  <block id="aee745c6de04f3d08c0e628809cab1e7" category="sidebar">Detalhes de implantação de exemplo</block>
  <block id="56d2d7506e6dac3733b0a45a9eaf441d" category="sidebar">Orientação de validação e dimensionamento</block>
  <block id="db182982505626c6e79adca149851ca6" category="sidebar">Conclusão e informações adicionais</block>
  <block id="013e704990294f0b327123a61911f4cc" category="sidebar">NVIDIA DGX SuperPOD com NetApp Série EF</block>
  <block id="944c042dcc47f293062f941954082ceb" category="sidebar">BeeGFS no NetApp com armazenamento da série E</block>
  <block id="9af29e4b3d0045c948a7dd30b1c7f8ae" category="sidebar">Implementar o IBM Spectrum Scale com armazenamento E-Series</block>
  <block id="79bca636cb614580cfd2da67b668570e" category="sidebar">ONTAP e Lenovo ThinkSystem para IA</block>
  <block id="7e9b2db694c8b0a87a271e7085251d0e" category="sidebar">NetApp ONTAP e Lenovo ThinkSystem SR670 para IA</block>
  <block id="b669bc138f2f455218d4dce65e4693b4" category="sidebar">Casos de uso de IA</block>
  <block id="adb8741d27ea996906508affc4dfbc75" category="sidebar">NetApp AIPod Mini para inferência RAG</block>
  <block id="c94ba9961c97321b49a2f0af40a3c81b" category="sidebar">IA responsável e inferência confidencial - NetApp AI com transformação de imagem Protopia</block>
  <block id="549d044fec039c71abf82f76a0d7969c" category="sidebar">Movendo dados de um ambiente de Big Data para um ambiente de IA</block>
  <block id="18e04180e0442e18a559941bb8de310c" category="sidebar">Inferência de IA na Borda - NetApp com Lenovo ThinkSystem - Design de Solução</block>
  <block id="df901f2197cd86d62a25f2f43e523352" category="sidebar">Guia de design de sistemas Quantum StorNext com NetApp E-Series</block>
  <block id="e313734313e7ef573613df8b6edae0af" category="sidebar">Guia de implantação do Quantum StorNext com sistemas NetApp E-Series</block>
  <block id="78daadab78234c06769e4f331411d302" category="sidebar">Análise de dados moderna</block>
  <block id="a5428e6b4b42638886ab5870a883efb9" category="sidebar">Solução da NetApp para problema de renomeação absurdo na carga de trabalho do NFS para o Kafka</block>
  <block id="d7fd58c27a131209e8f320d109b293cc" category="sidebar">Visão geral de desempenho e validação no AWS - Cloud Volume ONTAP</block>
  <block id="076002e1839cd6d440e56b26850e1223" category="sidebar">Visão geral de desempenho e validação na AWS - FSx para NetApp ONTAP</block>
  <block id="0d7c7eeec9388fceaff3d06e03b45fe9" category="sidebar">Visão geral de desempenho e validação com AFF local</block>
  <block id="2835924be4bc657cfe3a5bd988b96845" category="sidebar">Validação de desempenho confluente</block>
  <block id="2ce0710320aace7b17c3af20eaac2918" category="sidebar">Resumo dos casos de uso</block>
  <block id="713522228cb3164cc6e71ff6d49c3b13" category="sidebar">GPFS para NFS - Etapas detalhadas</block>
  <block id="497da8ae75854ffd62dc59e332c15252" category="sidebar">Aglomerados confluentes auto-rebalanceados</block>
  <block id="c9f0818cde41901681a02b50763ec342" category="sidebar">Soluções de dados em nuvem híbrida da NetApp - Spark e Hadoop com base em casos de uso do cliente</block>
  <block id="924f605d39858bdb10692c8d8f810464" category="sidebar">Caso de uso 1 - Backup de dados do Hadoop</block>
  <block id="c028df954696d2e4011963e651237b7c" category="sidebar">Caso de uso 2 - Backup e recuperação de desastres da nuvem para o local</block>
  <block id="f1ab9c16fee4088d930b2a43e3d48f64" category="sidebar">Caso de uso 3 - Habilitando o DevTest em dados Hadoop existentes</block>
  <block id="4e7c79467b7b25f0415a3a4538d3e2f5" category="sidebar">Caso de uso 4 - Proteção de dados e conectividade multicloud</block>
  <block id="f38bc790ec57f948f20cbd270b996cc6" category="sidebar">Caso de uso 5 - Acelere as cargas de trabalho analíticas</block>
  <block id="2c1c3f6b0e9a17650f389f1aab405e8a" category="sidebar">Solução Iceberg Lakehouse Híbrida de Próxima Geração da NetApp e Dremio</block>
  <block id="1256c51dea275f8f002d62c89274c4dc" category="sidebar">Casos de uso do cliente</block>
  <block id="df6654a22cda1b94cf0f51d6ae94bb69" category="sidebar">Resumo da solução: Diferentes soluções para diferentes estratégias de análise</block>
  <block id="2b95dd053e967c99de1428e8953dd453" category="sidebar">Recursos do StorageGRID para Splunk SmartStore</block>
  <block id="42c2f45afefbd5150f5aa52986b2a3cc" category="sidebar">Hierarquização e economia de custos</block>
  <block id="039a70e0c8e34414c8b3f34333f95ca8" category="sidebar">Desempenho do SmartStore de Site Único</block>
  <block id="427d072a2c1690c6d9ece23bef05477b" category="sidebar">Carga de trabalho do Apache Spark com solução de armazenamento NetApp (guia de implantação)</block>
  <block id="74916818f2584b32e727fdc509b2f992" category="cell">P4X-GNR6980P-SRPL2-UCC</block>
  <block id="abaa679b5e80256d8e1d4fd65296a270" category="cell">Intel Xeon 6980P 2P 128C 2G 504M 500W SGX512</block>
  <block id="22f22b60e3e496fa07e67cfbf53cb70e" category="cell">RPL-E 6369P IP 8C/16T 3.3G 24MB 95W 1700 BO</block>
  <block id="fe1394c0024b947430d8383108eb2177" category="summary">NVIDIA DGX SuperPOD com NetApp AFF A90</block>
  <block id="bf8899c5267692573fb1304655fb765a" category="doc">Sistemas de armazenamento NetApp AFF A90 com NVIDIA DGX SuperPOD</block>
  <block id="7fa0ca2a0d7f53f3c8e59fc6c3e9ed2e" category="section-title">Implantação de NVA</block>
  <block id="8be806d9daf2bc32156e83bc0d005ec1" category="paragraph">Os sistemas de armazenamento NVIDIA DGX SuperPOD com NetApp AFF A90 combinam o desempenho de computação de classe mundial dos sistemas NVIDIA DGX com os sistemas de armazenamento conectados à nuvem da NetApp para permitir fluxos de trabalho orientados por dados para aprendizado de máquina (ML), inteligência artificial (IA) e computação técnica de alto desempenho (HPC).  Este documento descreve os detalhes de configuração e implantação para integrar sistemas de armazenamento AFF A90 na arquitetura DGX SuperPOD.</block>
  <block id="9b418007fd18dc2176e46adcd30db45f" category="inline-image-macro">Logotipo da Nvidia</block>
  <block id="c94ba3511d0db1d6babbf53090c19530" category="paragraph"><block ref="c94ba3511d0db1d6babbf53090c19530" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6091ca16495cdce90805252a1c12f4e6" category="section-title">Resumo do programa</block>
  <block id="c6f9b4ccfaf7da44e6c0c60854f0949d" category="paragraph">O NVIDIA DGX SuperPOD™ oferece uma solução de data center de IA pronta para uso para organizações, fornecendo computação de classe mundial, ferramentas de software, experiência e inovação contínua.  O DGX SuperPOD oferece tudo o que os clientes precisam para implantar cargas de trabalho de IA/ML e HPC com tempo mínimo de configuração e produtividade máxima.  A Figura 1 mostra os componentes de alto nível do DGX SuperPOD.</block>
  <block id="d144add61531a9bfe79e667824356b40" category="paragraph">Figura 1) NVIDIA DGX SuperPOD com sistemas de armazenamento NetApp AFF A90 .</block>
  <block id="bbd4822469057d9beafe8509a7ebee14" category="paragraph"><block ref="bbd4822469057d9beafe8509a7ebee14" category="inline-image-macro-rx" type="image"></block></block>
  <block id="283d31c0198ed7454a249b3e2b6eb174" category="paragraph">O DGX SuperPOD oferece os seguintes benefícios:</block>
  <block id="3ff8aa027f2fe1f296899270ebbb43fd" category="list-text">Desempenho comprovado para cargas de trabalho de IA/ML e HPC</block>
  <block id="ca127ea10cbbac4cda1fefa3e946e9ba" category="list-text">Pilha integrada de hardware e software, desde gerenciamento e monitoramento de infraestrutura até modelos e ferramentas de aprendizado profundo pré-criados.</block>
  <block id="a4cb23a9ac5d711552fe29021242bf26" category="list-text">Serviços dedicados, desde instalação e gerenciamento de infraestrutura até dimensionamento de cargas de trabalho e otimização de IA de produção.</block>
  <block id="96cffe8fd08355ee862ba83cb15407d9" category="paragraph">À medida que as organizações adotam iniciativas de inteligência artificial (IA) e aprendizado de máquina (ML), a demanda por soluções de infraestrutura robustas, escaláveis e eficientes nunca foi tão grande.  No centro dessas iniciativas está o desafio de gerenciar e treinar modelos de IA cada vez mais complexos, garantindo ao mesmo tempo a segurança dos dados, a acessibilidade e a otimização dos recursos. </block>
  <block id="61b865c697c4f21886d14a618df70f6d" category="paragraph">Esta solução oferece os seguintes benefícios principais:</block>
  <block id="aa88ccfa825dadd9cbb9acc84e508b2c" category="list-text">*Escalabilidade*</block>
  <block id="4738ea23a01f5635ce1c45dabb47da5c" category="list-text">*Gerenciamento e acesso a dados*</block>
  <block id="1e1fe2d30ed5bb9c5276dddb65f4ce65" category="list-text">*Segurança*</block>
  <block id="3c858853158f1a99c39a781718ec762c" category="inline-link">GUIA DE DESIGN DO NVA-1175</block>
  <block id="bc3456dcc61fc69ddf5057eb2521a503" category="inline-link">+++ Arquitetura de referência NVIDIA DGX SuperPOD +++</block>
  <block id="0db7341d4a6ac5f5ae439217ea22f2cf" category="paragraph">O NVIDIA DGX SuperPOD inclui os servidores, a rede e o armazenamento necessários para oferecer desempenho comprovado para cargas de trabalho de IA exigentes.  Os sistemas NVIDIA DGX™ H200 e B200 fornecem poder de computação de classe mundial, e os switches de rede NVIDIA Quantum InfiniBand e Spectrum™ Ethernet oferecem latência ultrabaixa e desempenho de rede líder do setor.  Com a adição dos recursos líderes do setor de gerenciamento de dados e desempenho do armazenamento NetApp ONTAP , os clientes podem entregar iniciativas de IA/ML mais rapidamente e com menos migração de dados e sobrecarga administrativa.  Para obter mais informações sobre os componentes específicos desta solução, consulte o<block ref="a5c1176c129a896b2b922e5580efc58f" category="inline-link-rx"></block> e<block ref="1910ffa640b224c818fe3ba99c94129a" category="inline-link-rx"></block> documentação.</block>
  <block id="c18232c17d0f8ffeae2d726834c91f89" category="paragraph">O NVIDIA DGX SuperPOD foi projetado para atender aos requisitos de desempenho e escala das cargas de trabalho mais exigentes.</block>
  <block id="36ff5f6df178e197d3123e478db8410b" category="list-text">Aprendizado de máquina em grande escala usando ferramentas analíticas tradicionais.</block>
  <block id="2d12f254287ce40df1f66968734498ba" category="list-text">Treinamento de modelos de inteligência artificial para modelos de grande linguagem, visão computacional/classificação de imagens, detecção de fraudes e inúmeros outros casos de uso.</block>
  <block id="d8f31668d0cecb0b54a6d01e2f76c6cf" category="list-text">Computação de alto desempenho, como análise sísmica, dinâmica de fluidos computacional e visualização em larga escala.</block>
  <block id="f0414b39a05dd4079562350e267bf1b3" category="inline-link">+++ Arquitetura de referência NVIDIA DGX SuperPOD +++</block>
  <block id="5f5d88c3d3b4a5616e3937b4fe349866" category="paragraph">O DGX SuperPOD é baseado no conceito de uma Unidade Escalável (SU) que inclui todos os componentes necessários para fornecer a conectividade e o desempenho necessários e eliminar quaisquer gargalos na infraestrutura.  Os clientes podem começar com uma ou várias SUs e adicionar SUs adicionais conforme necessário para atender às suas necessidades.  Para mais informações, consulte o<block ref="b3bda9bcc3402290297547b224b66efa" category="inline-link-rx"></block> .  Este documento descreve os componentes de armazenamento e a configuração de uma única SU.</block>
  <block id="353fc344c9bee691edbf50c13067653c" category="paragraph">A Tabela 1 lista os componentes de hardware necessários para implementar os componentes de armazenamento para 1SU.  Consulte o Apêndice A para peças e quantidades específicas para Unidades Escaláveis de 1 a 4.</block>
  <block id="6cef63cf1d59b401d88755cbea01a416" category="paragraph">Tabela 1) Requisitos de hardware.</block>
  <block id="46f0306a597ab13c222e7d6551ce9f96" category="cell">Sistema de armazenamento NetApp AFF A90</block>
  <block id="c28cb49992003622546cc5f9509cfcff" category="cell">Switch de interconexão de cluster de armazenamento NetApp</block>
  <block id="9097f0013a59ba655e2c83bd26ae1ce7" category="cell">NVIDIA 800 GB -&gt; 4 cabos divisores de 200 Gb</block>
  <block id="aec453803363ab0e5ca6f6df8d465def" category="inline-link">+++Notas de lançamento do DGX SuperPOD+++</block>
  <block id="b6ffed0f516d3b52a4910321a2a889ba" category="paragraph">A Tabela 2 lista os componentes mínimos de software e versões necessárias para integrar o sistema de armazenamento AFF A90 com o DGX SuperPOD.  O DGX SuperPOD também envolve outros componentes de software que não estão listados aqui.  Por favor, consulte o<block ref="2523a697ed64d9038adf903273ea5150" category="inline-link-rx"></block> para obter detalhes completos.</block>
  <block id="c50cf4cacfaa91c82ab6a24e939cbaca" category="paragraph">Tabela 2) Requisitos de software.</block>
  <block id="518f98e82df6bde3bef11b7aa885a289" category="cell">9.16.1 ou superior</block>
  <block id="df6c5bc905afa2504396faf036b87927" category="cell">Gerenciador NVIDIA BaseCommand</block>
  <block id="6fe49606da6092b118e02ef2d0ef0d6c" category="cell">10.24.11 ou superior</block>
  <block id="a62649c559be1634e22dd7df0b58ad32" category="cell">Sistema operacional NVIDIA DGX</block>
  <block id="ba2b41c4ccfe23325bd590218a62fa8a" category="cell">6.3.1 ou superior</block>
  <block id="be49cc02b8372e6202cf52fbe8204ead" category="cell">Driver NVIDIA OFED</block>
  <block id="cf439b0da4b623c11f90db3c956758b1" category="cell">MLNX_OFED_LINUX-23.10.3.2.0 LTS ou superior</block>
  <block id="c220bcc9beaaaf29d1905f9819577f0b" category="cell">NVIDIA Cumulus OS</block>
  <block id="f7bfb037c565dcf0f80631851ee87307" category="cell">5,10 ou superior</block>
  <block id="ea1eee49815915fc6500c0bfc1fcef31" category="paragraph">A integração do armazenamento NetApp ONTAP com o DGX SuperPOD envolve as seguintes tarefas:</block>
  <block id="dc8a828d28f4f811808cdb82b54453ec" category="list-text">Configuração de rede para sistemas de armazenamento NetApp AFF A90 com RoCE</block>
  <block id="37c6bfb67043d31447903c4665d6ed11" category="list-text">Instalação e configuração do sistema de armazenamento</block>
  <block id="4cafd7b33984b4cb34f95fe4314e4a49" category="list-text">Configuração do cliente DGX com o NVIDIA Base Command™ Manager</block>
  <block id="b8088d3f2b3972d6f986cf0a37543617" category="section-title">Preparação do local e instalação básica</block>
  <block id="bf0615788eed920e4e9f1a96749cfb34" category="inline-link">+++ Documentação de instalação de hardware do AFF A90 +++</block>
  <block id="e1006e935ca66a5f59a3fd40689fff46" category="paragraph">A preparação do local e a instalação básica do cluster de armazenamento AFF A90 serão realizadas pela NetApp Professional Services para todas as implantações do DGX SuperPOD como parte do serviço de implantação padrão.  O NetApp PS confirmará se as condições do local são apropriadas para a instalação e instalará o hardware nos racks designados.  Eles também conectarão as conexões de rede OOB e concluirão a configuração básica do cluster usando informações de rede fornecidas pelo cliente.  Apêndice A – Lista de materiais e elevações de rack inclui elevações de rack padrão para referência.  Para obter mais informações sobre a instalação do A90, consulte o<block ref="7ddd605a062e7b77012eccf1c4bcffd7" category="inline-link-rx"></block> .</block>
  <block id="321c92980ad0e1d922d02a2f704ca782" category="paragraph">Após a conclusão da implantação padrão, o NetApp PS concluirá a configuração avançada da solução de armazenamento usando os procedimentos abaixo, incluindo a integração com o Base Command Manager para conectividade e ajuste do cliente.</block>
  <block id="00720789d4f50564af280240dfe0c1a0" category="section-title">Cabeamento do sistema de armazenamento para a estrutura de armazenamento DGX SuperPOD</block>
  <block id="93f38c7fefe0798b27b29ac2727c9aff" category="paragraph">O sistema de armazenamento AFF A90 é conectado aos switches leaf de estrutura de armazenamento usando quatro portas Ethernet de 200 Gb por controlador, com duas conexões para cada switch.  As portas de switch de 800 Gb nos switches NVIDIA Spectrum SN5600 são divididas em 4 portas de 200 Gb usando as configurações apropriadas de DAC ou divisor óptico listadas no Apêndice A. As portas individuais de cada porta de switch são distribuídas pelo controlador de armazenamento para eliminar pontos únicos de falha.  A Figura 2 abaixo mostra o cabeamento para as conexões da estrutura de armazenamento:</block>
  <block id="428c881d379aed620164886a529bf2ac" category="paragraph">Figura 2) Cabeamento de rede de armazenamento.</block>
  <block id="e97080670de5db4003a6abdd37d81eb5" category="paragraph"><block ref="e97080670de5db4003a6abdd37d81eb5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb83bbea93dbe46008125af94bc508be" category="section-title">Cabeamento do sistema de armazenamento para a rede em banda DGX SuperPOD</block>
  <block id="3c4e3bd6ddc8a3cd692e2866674ec982" category="paragraph">O NetApp ONTAP inclui recursos de multilocação líderes do setor que permitem que ele opere como um sistema de armazenamento de alto desempenho na arquitetura DGX SuperPOD e também ofereça suporte a diretórios pessoais, compartilhamentos de arquivos em grupo e artefatos de cluster do Base Command Manager.  Para uso na rede em banda, cada controlador AFF A90 é conectado aos switches de rede em banda com uma conexão Ethernet de 200 Gb por controlador, e as portas são configuradas em uma configuração LACP MLAG.  A Figura 3 abaixo mostra o cabeamento do sistema de armazenamento para as redes in-band e OOB.</block>
  <block id="651c2d0bd757128b4d9ed91fc5026a3d" category="paragraph">Figura 3) Cabeamento de rede dentro da banda e OOB.</block>
  <block id="92bf4c084f930281026def79beae3794" category="paragraph"><block ref="92bf4c084f930281026def79beae3794" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76edc3dadc8deca645fd525182eaad33" category="section-title">Configurar o ONTAP para DGX SuperPOD</block>
  <block id="41905234b7d34b88a1559733c741d5aa" category="inline-link">+++ Documentação ONTAP +++</block>
  <block id="d4b2d66f490475665ea833d8f89c2cfd" category="paragraph">Esta solução utiliza várias Máquinas Virtuais de Armazenamento (SVM) para hospedar volumes para acesso de armazenamento de alto desempenho, bem como diretórios pessoais de usuários e outros artefatos de cluster em uma SVM de gerenciamento.  Cada SVM é configurado com interfaces de rede nas redes de armazenamento ou em banda e volumes FlexGroup para armazenamento de dados.  Para garantir o desempenho do Data SVM, uma política de QoS de armazenamento é implementada.  Para obter mais informações sobre FlexGroups, máquinas virtuais de armazenamento e recursos de QoS ONTAP , consulte o<block ref="619babf0e51393513dd3986ae0aee969" category="inline-link-rx"></block> .</block>
  <block id="fec48034cdf04f518f58b4f727f55543" category="section-title">Configurar armazenamento base</block>
  <block id="7e4b30d10f60fcb3bdf4c3382d601615" category="section-title">Configurar um único agregado em cada controlador</block>
  <block id="3c6858e020c27b4eb574d124f73c04d3" category="paragraph">Repita as etapas acima para cada nó no cluster.</block>
  <block id="241ba9d616774bbadf9c9f28ee386505" category="section-title">Configurar ifgrps em cada controlador para rede em banda</block>
  <block id="610c7975125c56dc62b000999926f4d8" category="section-title">Configurar portas físicas para RoCE</block>
  <block id="ff00a412cfca01b43041104775ac8460" category="paragraph">Habilitar o NFS sobre RDMA requer configuração para garantir que o tráfego de rede seja marcado adequadamente no cliente e no servidor e, então, seja manipulado adequadamente pela rede usando RDMA sobre Ethernet Convergente (RoCE).  Isso inclui configurar o Controle de Fluxo de Prioridade (PFC) e configurar a fila CoS do PFC a ser usada.  O NetApp ONTAP também configura automaticamente o código DSCP 26 para alinhar com a configuração de QoS da rede quando os comandos abaixo são executados.</block>
  <block id="e9dc479a2f60169b39fb74cc86d13a43" category="section-title">Criar SVM de gerenciamento</block>
  <block id="ce25292d4b04b878f74951ed7b5fb173" category="section-title">Criar e configurar o Management SVM</block>
  <block id="c110d2ffde8993db523c41f0c524e68e" category="section-title">Configurar o serviço NFS no SVM de gerenciamento</block>
  <block id="5441effcbbef51defcc1340e745e28ad" category="section-title">Crie sub-redes IP para interfaces de rede em banda</block>
  <block id="919d6feabfd1e5f5f04bedfd487f50c8" category="paragraph">*Observação:* as informações de sub-rede IP devem ser fornecidas pelo cliente no momento da implantação para integração nas redes existentes do cliente.</block>
  <block id="2bc9e41900e064c3368d9eca2dba546c" category="section-title">Crie interfaces de rede em cada nó para SVM em banda</block>
  <block id="44db41cf8b74978388680587aa8b7d55" category="section-title">Criar volumes FlexGroup para o Management SVM</block>
  <block id="20d5f1ad8803160edb381217d776701e" category="section-title">Criar política de exportação para o Management SVM</block>
  <block id="1624c693fdd8f06e52c87d0b2b576a19" category="section-title">Criar SVM de dados</block>
  <block id="9ff068915b90e059d15444fe8dc13aaa" category="section-title">Criar e configurar o Data SVM</block>
  <block id="cb7d25e4139e72b33ef687ed8a0ae945" category="section-title">Configurar o serviço NFS no Data SVM com RDMA habilitado</block>
  <block id="ca1f913932acc2aad423357d56f86ea7" category="section-title">Criar sub-redes IP para interfaces de rede Data SVM</block>
  <block id="3c2060cdeb230d3f42a725b2a9ca7e23" category="section-title">Crie interfaces de rede em cada nó para Data SVM</block>
  <block id="ca648b8fb4bf1f54cbf7a626468eada3" category="section-title">Configurar interfaces de rede Data SVM para RDMA</block>
  <block id="afb51d28a404c42df2a054df2c6da14b" category="section-title">Criar política de exportação em dados SVM</block>
  <block id="d9a6b253dd081b231d9d1a14cec7a227" category="section-title">Crie rotas estáticas no SVM de dados</block>
  <block id="4f3e59209435398e52c0df85d0034275" category="section-title">Criar volume FlexGroup com GDD para Data SVM</block>
  <block id="08ec3810f1dcb452442911f8d8173b1a" category="paragraph">A Distribuição Granular de Dados (GDD) permite que grandes arquivos de dados sejam distribuídos entre vários volumes e controladores constituintes do FlexGroup para permitir desempenho máximo para cargas de trabalho de arquivo único.  A NetApp recomenda habilitar o GDD em volumes de dados para todas as implantações do DGX SuperPOD.</block>
  <block id="7eb2bd842a06eb48d9bbfe4f644731d9" category="section-title">Desabilitar eficiência de armazenamento para volume de dados primário</block>
  <block id="8a0cdebf4e36c1af6ac542485413a77b" category="paragraph">eficiência de volume desligada -vserver spod_data -volume spod_data</block>
  <block id="46e5a2d41b69706b3dcd5e89c34e7c5e" category="section-title">Crie uma política mínima de QoS para SVM de dados</block>
  <block id="065d35d3d9a4319f54773a754b2c0e6c" category="section-title">Aplicar política de QoS para SVM de dados</block>
  <block id="2cc5056a61a5f1643bf387d49d197728" category="section-title">Configuração do servidor DGX com NVIDIA Base Command Manager</block>
  <block id="e546e9d0da56999b5973de8a7ad71572" category="paragraph">Para preparar os clientes DGX para usar o sistema de armazenamento AFF A90 , conclua as seguintes tarefas.  Este processo pressupõe que as interfaces de rede e rotas estáticas para a estrutura de armazenamento já foram configuradas nos nós do sistema DGX.  As seguintes tarefas serão concluídas pela NetApp Professional Services como parte do processo de configuração avançada.</block>
  <block id="f9a9381a56f728d139ee191de307ef5f" category="section-title">Configurar a imagem do servidor DGX com os parâmetros de kernel necessários e outras configurações</block>
  <block id="256b6f56d994f129832d2b7567bb951f" category="paragraph">O NetApp ONTAP usa protocolos NFS padrão do setor e não exige a instalação de nenhum software adicional nos sistemas DGX.  Para fornecer desempenho ideal dos sistemas clientes, são necessárias várias modificações na imagem do sistema DGX.  Ambas as etapas a seguir são executadas após entrar no modo chroot da imagem do BCM usando o comando abaixo:</block>
  <block id="45fb2f19f77fc1d9d4dfdd092f805b42" category="section-title">Configurar as configurações de memória virtual do sistema em /etc/sysctl.conf</block>
  <block id="13b4c0be439ee4875352c0ff2a039c13" category="paragraph">A configuração padrão do sistema Linux fornece configurações de memória virtual que podem não necessariamente proporcionar um desempenho ideal.  No caso de sistemas DGX B200 com 2 TB de RAM, as configurações padrão permitem 40 GB de espaço de buffer, o que cria padrões de E/S inconsistentes e permite que o cliente sobrecarregue o sistema de armazenamento ao esvaziar o buffer.  As configurações abaixo limitam o espaço do buffer do cliente a 5 GB e forçam a liberação com mais frequência para criar um fluxo de E/S consistente que não sobrecarregue o sistema de armazenamento.</block>
  <block id="c35419f49457a55135a16f4a73d4fb6b" category="paragraph">Após entrar no modo chroot da imagem, edite o arquivo /etc/sysctl.s/90-cm-sysctl.conf e adicione as seguintes linhas:</block>
  <block id="4caebde52be0001b1e59098dd149b653" category="paragraph">Salve e feche o arquivo /etc/sysctl.conf.</block>
  <block id="d05565dbb5b9175c4df06e8d9d029a18" category="section-title">Configure outras configurações do sistema com um script que é executado após a reinicialização</block>
  <block id="4e1ff13d493c47a47dde7cb5a24aceeb" category="paragraph">Algumas configurações exigem que o sistema operacional esteja totalmente online para serem executadas e não são persistentes após uma reinicialização.  Para executar essas configurações em um ambiente do Base Command Manager, crie um arquivo /root/ntap_dgx_config.sh e insira as seguintes linhas:</block>
  <block id="191be9d79602632b279bc3126e49847d" category="paragraph">*Salve e feche o arquivo.  Altere as permissões do arquivo para que ele seja executável:*</block>
  <block id="13036c88d00af2d37c1d8e1ae332f79e" category="paragraph">Crie uma tarefa cron que será executada pelo root na inicialização editando a seguinte linha:</block>
  <block id="a4d911dee959cadc8c53c92d6361fc05" category="paragraph">Veja o arquivo crontab de exemplo abaixo:</block>
  <block id="e813523727c040149e1ecad0358d60b8" category="paragraph">Saia do modo chroot da imagem BCM digitando exit ou Ctrl-D.</block>
  <block id="70f4c658a41ea1900dd94027c0ffa103" category="section-title">Configurar a categoria DGX do BaseCommand Manager para pontos de montagem do cliente</block>
  <block id="9df3dcf41d131b1d0097435f6b290ba4" category="paragraph">Para configurar a montagem dos clientes DGX no sistema de armazenamento AFF A90 , a categoria de cliente BCM usada pelos sistemas DGX deve ser modificada para incluir as informações e opções relevantes.  As etapas abaixo descrevem como configurar o ponto de montagem do NFS.</block>
  <block id="dcde3a7bf8f0a03f480df9078bfa9297" category="paragraph">O NVIDIA DGX SuperPOD com sistemas de armazenamento NetApp * AFF A90 * representa um avanço significativo em soluções de infraestrutura de IA.  Ao abordar os principais desafios em torno de segurança, gerenciamento de dados, utilização de recursos e escalabilidade, ele permite que as organizações acelerem suas iniciativas de IA, mantendo a eficiência operacional, a proteção de dados e a colaboração.  A abordagem integrada da solução elimina gargalos comuns em pipelines de desenvolvimento de IA, permitindo que cientistas e engenheiros de dados se concentrem na inovação em vez do gerenciamento de infraestrutura.</block>
  <block id="77b69988a6b247bd3829a8e03ff332a6" category="inline-link">Guia de design de sistemas de armazenamento NVA-1175 NVIDIA DGX SuperPOD com NetApp AFF A90</block>
  <block id="78200c657113173ee4bd06de792e86af" category="list-text"><block ref="78200c657113173ee4bd06de792e86af" category="inline-link-rx"></block></block>
  <block id="4b70410b9d727a1fc1d60d4483d86325" category="inline-link">Arquitetura de referência NVIDIA DGX B200 SuperPOD</block>
  <block id="54dbc563049b479cfef99d1d872020e4" category="list-text"><block ref="54dbc563049b479cfef99d1d872020e4" category="inline-link-rx"></block></block>
  <block id="d5023dae85155f754c6bfd520cbdc150" category="inline-link">+++ Arquitetura de referência NVIDIA DGX H200 SuperPOD+++</block>
  <block id="5d4678ba7793147c6b3109fcdbe3294f" category="list-text"><block ref="5d4678ba7793147c6b3109fcdbe3294f" category="inline-link-rx"></block></block>
  <block id="0018465bd63e2711758aea9e68126f6d" category="inline-link">+++ Software NVIDIA BaseCommand+++</block>
  <block id="dd2a70a6cd8d74ddbed24590bf9efd37" category="list-text"><block ref="dd2a70a6cd8d74ddbed24590bf9efd37" category="inline-link-rx"></block></block>
  <block id="a2433670a2f11bda41782875f82e4c0e" category="inline-link">+++ Switches Ethernet NVIDIA Spectrum SN5600+++</block>
  <block id="197d7b18bb595fa0c4339f599bb57c70" category="list-text"><block ref="197d7b18bb595fa0c4339f599bb57c70" category="inline-link-rx"></block></block>
  <block id="61345f1959bf0e90ce956f7fe87b97e6" category="inline-link">+++ Notas de lançamento do NVIDIA DGX SuperPOD +++</block>
  <block id="a42d326cc55152a32997b9b244e9e4ea" category="list-text"><block ref="a42d326cc55152a32997b9b244e9e4ea" category="inline-link-rx"></block></block>
  <block id="18b5a5e73e5f66fb20d8f46f70d0c0ba" category="inline-link">+++ Instalação do NetApp AFF A90 +++</block>
  <block id="cc99b2a6b638db71f55772efa9ae5a44" category="list-text"><block ref="cc99b2a6b638db71f55772efa9ae5a44" category="inline-link-rx"></block></block>
  <block id="326b3ec244c0b719f75faee5d63eda19" category="inline-link">+++ Documentação de soluções de IA da NetApp +++</block>
  <block id="2a6b527a76b4dd02f63188fa855840f7" category="list-text"><block ref="2a6b527a76b4dd02f63188fa855840f7" category="inline-link-rx"></block></block>
  <block id="7d3cb5a08ca45610a4bc66221efd1e06" category="inline-link">+++ Software NetApp ONTAP +++</block>
  <block id="7de45c9a3f46892f98b68ddb83483727" category="list-text"><block ref="7de45c9a3f46892f98b68ddb83483727" category="inline-link-rx"></block></block>
  <block id="b20609bf792bc04f91d5af3f95c34249" category="inline-link">+++ Instalação e manutenção de sistemas de armazenamento AFF da NetApp +++</block>
  <block id="f4f8a0ca5a3908b7ff3dc9977384172c" category="list-text"><block ref="f4f8a0ca5a3908b7ff3dc9977384172c" category="inline-link-rx"></block></block>
  <block id="784cd7f14efdcfe6b12e47d3ac14c2ea" category="list-text"><block ref="784cd7f14efdcfe6b12e47d3ac14c2ea" category="inline-link-rx"></block></block>
  <block id="2af6b6d1a0f9284afbd220786019c104" category="inline-link">+++O que é pNFS+++</block>
  <block id="40b22abaae26a9e924653fdf64192dd5" category="list-text"><block ref="0b4edeca10dea88e1e3ff87f6aece04a" category="inline-link-rx"></block>(documento antigo com ótimas informações sobre pNFS)</block>
  <block id="8b609f2b56884902c05d97d442f1d533" category="section-title">Apêndice A: Lista de materiais e elevações de rack</block>
  <block id="97ac09ecf630c90bdc4eae789d1cb26e" category="paragraph">A Tabela 3 mostra o número da peça e as quantidades dos componentes NetApp necessários para implantar o armazenamento para uma, duas, três e quatro unidades escaláveis.</block>
  <block id="a399f4735d9b76eb2c734ce8b23a4051" category="paragraph">Tabela 3) BOM da NetApp para 1, 2, 3 e 4 SU.</block>
  <block id="12671d03ae10ac5096ddbf709e44e260" category="cell">Papel #</block>
  <block id="7d74f3b92b19da5e606d737d339a9679" category="cell">Item</block>
  <block id="4b35db9f95e91ac3ce4b119c8d590dc3" category="cell">Quantidade para 1SU</block>
  <block id="10ae8487d40b09fd13a32fd5b761dff2" category="cell">Quantidade para 2SU</block>
  <block id="4f4a383868a5c8f1aff4d21e301cf77d" category="cell">Quantidade para 3SU</block>
  <block id="7e3f2097d4da066bf518435f0d22d629" category="cell">Quantidade para 4SU</block>
  <block id="a9eadd771f7974cbfb4a0f82da15155e" category="cell">AFF-A90A-100-C</block>
  <block id="a5b8692ce33078554d4df65b88479996" category="cell">Sistema de armazenamento AFF A90</block>
  <block id="c9f0f895fb98ab9159f51fd0297e236d" category="cell">8</block>
  <block id="109799441719d48125200028617a078c" category="cell">X4025A-2-A-C</block>
  <block id="ae1ffcee034fa197d7e6a3d49392ad1b" category="cell">Pacote de unidade de 2x7,6 TB</block>
  <block id="0a09c8844ba8f0936c20bd791130d6b6" category="cell">144</block>
  <block id="58a2fc6ed39fd083f55d4182bf88826d" category="cell">192</block>
  <block id="01fc28c75297fac48aca3e18491846a8" category="cell">X50131A-C</block>
  <block id="ef52c5c3e61828c1957bb235e48b9aaf" category="cell">Módulo IO, 2PT, 100/200/400GbE</block>
  <block id="76dc611d6ebaafc66cc0879c71b5db5c" category="cell">128</block>
  <block id="da07ac8264b7cdb99a4eb96ab4d91111" category="cell">X50130A-C</block>
  <block id="02104e3c4b3f8d428381d1c68b10320d" category="cell">Módulo IO, 2PT, 100GbE</block>
  <block id="90d67d58a9628ba253eee43c6dbc9559" category="cell">X-02659-00</block>
  <block id="eaba4c24f91259319d86e2dc6a375c2c" category="cell">Kit, 4 postes, furo quadrado ou redondo, trilho de 24" a 32"</block>
  <block id="a08f2932fed05b33c4945eca514134dc" category="cell">X1558A-R6</block>
  <block id="3229af69927999e5df543d1f9fb22eb5" category="cell">Cabo de alimentação, embutido no gabinete, 48 pol., + C13-C14, 10 A/250 V</block>
  <block id="98f13708210194c475687be6106a3b84" category="cell">20</block>
  <block id="d645920e395fedad7bbbed0eca3fe2e0" category="cell">40</block>
  <block id="f033ab37c30201f73f142449d037028d" category="cell">80</block>
  <block id="e6aa165cded1f8e32159470ff027af2f" category="cell">X190200-CS</block>
  <block id="7e011d9eef19544d7078d2a70563144a" category="cell">Interruptor de cluster, N9336C 36Pt PTSX10/25/40/100G</block>
  <block id="76dedba1bf45af402ab07ddd57ff749e" category="cell">X66211A-2</block>
  <block id="2a1aeb324c9e886af32f12ad5049c6f7" category="cell">Cabo, 100GbE, QSFP28-QSFP28, Cu, 2m</block>
  <block id="e2fd227baa44b6632aa7c2fef9002b8a" category="cell">X66211A-05</block>
  <block id="0dff9249f8d94512b43527f1f5b044c9" category="cell">Cabo, 100GbE, QSFP28-QSFP28, Cu, 0,5m</block>
  <block id="6e421f2c1b8bf174d208a91d7f5dc0ae" category="cell">X6561-R6</block>
  <block id="95c7e45248e11b15430ec3c5d1d3dcc1" category="cell">Cabo, Ethernet, CAT6, RJ45, 5m</block>
  <block id="e369853df766fa44e1ed0ff613f563bd" category="cell">34</block>
  <block id="3295c76acbf4caaed33c36b1b5fc2cb1" category="cell">66</block>
  <block id="2a108c75662ccb5a38e6db46a016aa40" category="paragraph">A Tabela 4 mostra o número da peça e a quantidade de cabos NVIDIA necessários para conectar os sistemas de armazenamento AFF A90 aos switches SN5600 nas redes de armazenamento de alto desempenho e em banda.</block>
  <block id="c71399ea2a367ce779897d49ca77b4a0" category="paragraph">Tabela 4) Cabos NVIDIA necessários para conectar sistemas de armazenamento AFF A90 aos switches SN5600 em redes de armazenamento de alto desempenho e em banda.</block>
  <block id="5557f1218ab08d91639048aab26f1de0" category="cell">MCP7Y40-N003</block>
  <block id="2b11e18cd1f4ae786c28a6a1bce455ed" category="cell">DAC 3m 26ga 2x400G para 4x200G OSFP para 4xQSFP112</block>
  <block id="19ca14e7ea6328a42e0eb13d585e4c22" category="cell">36</block>
  <block id="1d00e7dce692e8dc3f6877f035e3a616" category="cell">OU</block>
  <block id="84686a1d557f4fefd53eaff2d691796d" category="cell">MMS4X00-NS</block>
  <block id="e67c53a2100e086542158b7496d248a7" category="cell">Transceptor multimodo OSFP 2x400G 2xSR4 de porta dupla MPO-12/APC duplo</block>
  <block id="bbf6b7b52739d4479aae0bd6508ac746" category="cell">MFP7E20-N0XX</block>
  <block id="718b622b69fc995a4d3738ecaf2953b0" category="cell">Divisores de Fibra Multimodo 400G-&gt; 2x200G XX = 03, 05, 07, 10, 15, 20, 30, 40, 50) metros</block>
  <block id="7b55b9077a4e94ce71aba3fbb4b1ebcd" category="cell">MMA1Z00-NS400</block>
  <block id="1d1c4e0c3b72af208b18fbbfbf63c17b" category="cell">Transceptor QSFP112 multimodo SR4 de porta única 400G MPO-12/APC</block>
  <block id="098103233c14421a2092214651f99ac3" category="section-title">Elevações de rack</block>
  <block id="64441b5a3bcfb8a874107dfe4766feb6" category="paragraph">As Figuras 4-6 mostram exemplos de elevações de rack para 1-4 SU.</block>
  <block id="c22e6da1b1ce3c83fb3004d53e804737" category="paragraph">Figura 4) Elevações de rack para 1 SU e 2 SU.</block>
  <block id="7ef24ed03ec40ae9ef02f5c904953418" category="paragraph"><block ref="7ef24ed03ec40ae9ef02f5c904953418" category="inline-image-macro-rx" type="image"></block></block>
  <block id="64769808ba101c666bcd29615cc1e9d3" category="paragraph">Figura 5) Elevações de rack para 3 SU.</block>
  <block id="02a5df2de00e7145cadd3753d42d3dc1" category="paragraph"><block ref="02a5df2de00e7145cadd3753d42d3dc1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d8d7011e8983f361d68e382e119c1819" category="paragraph">Figura 6) Elevações de rack para 4 SU.</block>
  <block id="381008e8bad1425034ca5fa30cd57133" category="paragraph"><block ref="381008e8bad1425034ca5fa30cd57133" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9376ca935750f1ee987d9b2ce256bfbf" category="paragraph">O NVIDIA DGX SuperPOD™ com sistemas de armazenamento NetApp AFF® A90 combina o desempenho de computação de classe mundial dos sistemas NVIDIA DGX com os sistemas de armazenamento conectados à nuvem da NetApp para permitir fluxos de trabalho orientados por dados para aprendizado de máquina (ML), inteligência artificial (IA) e computação técnica de alto desempenho (HPC).  Este documento descreve a arquitetura de alto nível da solução DGX SuperPOD usando sistemas de armazenamento NetApp AFF A90 com uma estrutura de armazenamento Ethernet.</block>
  <block id="180ea794b48cd487087e5b1dd21023f0" category="paragraph">Com o desempenho de computação comprovado do NVIDIA DGX SuperPOD combinado com os recursos de segurança de dados, governança de dados e multilocação líderes do setor da NetApp, os clientes podem implantar a infraestrutura mais eficiente e ágil para cargas de trabalho de última geração.  Este documento descreve a arquitetura de alto nível e os principais recursos que ajudam os clientes a entregar tempo de colocação no mercado mais rápido e retorno sobre o investimento para iniciativas de IA/ML.</block>
  <block id="98e7b017fa4951d28f1516c0bee63969" category="section-title">Resumo do programa</block>
  <block id="0e7a454160d4f81e5b82fe865851c0b5" category="paragraph">O NVIDIA DGX SuperPOD oferece uma solução de data center de IA pronta para uso para organizações, fornecendo computação de classe mundial, ferramentas de software, experiência e inovação contínua.  O DGX SuperPOD oferece tudo o que os clientes precisam para implantar cargas de trabalho de IA/ML e HPC com tempo mínimo de configuração e produtividade máxima.  A Figura 1 mostra os componentes de alto nível do DGX SuperPOD.</block>
  <block id="0df8fda8ee1a402c3eb7dc7582d3a710" category="paragraph"><block ref="0df8fda8ee1a402c3eb7dc7582d3a710" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d91208793b9a449dbecfd553707c79d6" category="list-text">Pilha integrada de hardware e software, desde gerenciamento e monitoramento de infraestrutura até modelos e ferramentas de aprendizado profundo pré-criados.</block>
  <block id="84245e1cf723377c5a2991885cd57409" category="list-text">Serviços dedicados, desde instalação e gerenciamento de infraestrutura até dimensionamento de cargas de trabalho e otimização de IA de produção</block>
  <block id="5d8430a9387a385c7ee9a8b83ff28b12" category="paragraph">À medida que as organizações adotam iniciativas de inteligência artificial (IA) e aprendizado de máquina (ML), a demanda por soluções de infraestrutura robustas, escaláveis e eficientes nunca foi tão grande.  No centro dessas iniciativas está o desafio de gerenciar e treinar modelos de IA cada vez mais complexos, garantindo ao mesmo tempo a segurança dos dados, a acessibilidade e a otimização dos recursos.  A evolução da IA de agente e os requisitos sofisticados de treinamento de modelos criaram demandas sem precedentes na infraestrutura computacional e de armazenamento.  As organizações agora precisam lidar com grandes conjuntos de dados, dar suporte a diversas cargas de trabalho de treinamento simultâneas e manter ambientes de computação de alto desempenho, garantindo ao mesmo tempo a proteção de dados e a conformidade regulatória.  Soluções de infraestrutura tradicionais muitas vezes têm dificuldade para atender a essas demandas, o que leva a ineficiências operacionais e atraso no tempo de retorno do investimento para projetos de IA.  Esta solução oferece os seguintes benefícios principais:</block>
  <block id="1844a1480427b3b276783fd66fc58226" category="list-text">*Escalabilidade.*  Os sistemas de armazenamento NVIDIA DGX SuperPOD com NetApp AFF A90 oferecem escalabilidade incomparável por meio de sua arquitetura modular e recursos de expansão flexíveis.  As organizações podem dimensionar perfeitamente sua infraestrutura de IA adicionando nós de computação DGX e sistemas de armazenamento AFF A90 sem interromper as cargas de trabalho existentes ou exigir reconfigurações complexas.</block>
  <block id="02a63d3f709e7b79dac689e7724d8821" category="list-text">*Gerenciamento e acesso a dados.*  Os sistemas de armazenamento NVIDIA DGX SuperPOD com NetApp AFF A90 são baseados no NetApp ONTAP , que se destaca no gerenciamento de dados por meio de seu conjunto abrangente de recursos de nível empresarial.  Usando os recursos de snapshot e FlexClone do ONTAP, as equipes podem criar instantaneamente cópias com eficiência de espaço de conjuntos de dados e bancos de dados vetoriais para desenvolvimento e testes paralelos.  As tecnologias de replicação FlexCache e Snapmirror permitem pipelines de dados simplificados, com economia de espaço e automatizados a partir de fontes de dados em toda a empresa, e o acesso multiprotocolo aos dados usando NAS e protocolos de objeto permite novos fluxos de trabalho otimizados para tarefas de ingestão e engenharia de dados.</block>
  <block id="3b5ce4caaf6acea212e6608eb826a52c" category="list-text">*Segurança.*  Os sistemas de armazenamento NetApp AFF A90 oferecem segurança de nível empresarial por meio de várias camadas de proteção.  No nível de infraestrutura, a solução implementa mecanismos robustos de controle de acesso, incluindo controle de acesso baseado em função (RBAC), autenticação multifator e recursos detalhados de registro de auditoria.  A estrutura abrangente de criptografia da plataforma protege dados em repouso e em trânsito, utilizando protocolos e algoritmos padrão do setor para proteger a propriedade intelectual e manter a conformidade com os requisitos regulatórios.  Ferramentas integradas de monitoramento de segurança fornecem visibilidade em tempo real de potenciais ameaças à segurança, enquanto mecanismos de resposta automatizados ajudam a mitigar riscos antes que eles possam impactar as operações.</block>
  <block id="d2374eb265fd2592ef7b4b817140ba67" category="paragraph">Esta solução é destinada a organizações com cargas de trabalho de HPC e IA/ML que exigem integração mais profunda com amplos conjuntos de dados e ferramentas e processos tradicionais de infraestrutura de TI.</block>
  <block id="549c608b9fe93192110cc2552d28da22" category="paragraph">O público-alvo da solução inclui os seguintes grupos:</block>
  <block id="f79b8cf1009178e9a2fd45c1f4ae4ef7" category="list-text">Tomadores de decisões de TI e de linha de negócios que planejam a infraestrutura mais eficiente para entregar iniciativas de IA/ML com o menor tempo de lançamento no mercado e ROI.</block>
  <block id="c328ed7f0a74043c4e73f7ea491b4eb7" category="list-text">Cientistas e engenheiros de dados interessados em maximizar a eficiência de partes críticas do fluxo de trabalho de IA/ML focadas em dados.</block>
  <block id="fa7b81174ad3677e1ed9da1ea8185c4d" category="list-text">Arquitetos e engenheiros de TI que precisam fornecer uma infraestrutura confiável e segura que permita fluxos de trabalho de dados automatizados e conformidade com os padrões existentes de governança de dados e processos.</block>
  <block id="dad37ea926873ef3d5ee869827ddc40c" category="paragraph">O NVIDIA DGX SuperPOD inclui os servidores, a rede e o armazenamento necessários para oferecer desempenho comprovado para cargas de trabalho de IA exigentes.  Os sistemas NVIDIA DGX™ H200 e NVIDIA DGX B200 fornecem poder de computação de classe mundial, e os switches de rede NVIDIA Quantum e Spectrum™ InfiniBand oferecem latência ultrabaixa e desempenho de rede líder do setor.  Com a adição dos recursos líderes do setor de gerenciamento de dados e desempenho do armazenamento NetApp ONTAP , os clientes podem entregar iniciativas de IA/ML mais rapidamente e com menos migração de dados e sobrecarga administrativa.  As seções a seguir descrevem os componentes de armazenamento do DGX SuperPOD com sistemas de armazenamento AFF A90 .</block>
  <block id="4caba5452d50c27473615492a421d0b7" category="section-title">Sistemas de armazenamento NetApp AFF A90 com NetApp ONTAP</block>
  <block id="5b01f10375ddf0fa7a318292fb1ab544" category="paragraph">O NetApp AFF A90, equipado com o software de gerenciamento de dados NetApp ONTAP, oferece proteção de dados integrada, recursos anti-ransomware e alto desempenho, capacidade de escalabilidade e resiliência necessários para dar suporte às cargas de trabalho empresariais mais críticas. Ele elimina interrupções em operações de missão crítica, minimiza o ajuste de desempenho e protege seus dados contra ataques de ransomware.  Os sistemas NetApp AFF A90 fornecem-</block>
  <block id="5f443413f7f04549bcfdd089e04a0c3a" category="list-text">*Desempenho.* O AFF A90 gerencia facilmente cargas de trabalho de última geração, como aprendizado profundo, IA e análises de alta velocidade, bem como bancos de dados empresariais tradicionais, como Oracle, SAP HANA, Microsoft SQL Server e aplicativos virtualizados. Com NFS sobre RDMA, pNFS e entroncamento de sessão, os clientes podem atingir o alto nível de desempenho de rede necessário para aplicativos de última geração usando infraestrutura de rede de data center existente e protocolos padrão do setor sem software proprietário.  A Distribuição Granular de Dados permite que arquivos individuais sejam distribuídos entre todos os nós do cluster de armazenamento e, quando combinada com o pNFS, oferece acesso paralelo de alto desempenho a conjuntos de dados contidos em um único arquivo grande.</block>
  <block id="ae299319707718bf9587df62a89ca873" category="list-text">*Inteligência.*  Acelere a transformação digital com um ecossistema pronto para IA construído com inteligência orientada por dados, infraestrutura preparada para o futuro e integrações profundas com a NVIDIA e o ecossistema MLOps.  Usando os recursos de snapshot e FlexClone do ONTAP, as equipes podem criar instantaneamente cópias de conjuntos de dados com otimização de espaço para desenvolvimento e testes paralelos.  As tecnologias de replicação FlexCache e Snapmirror permitem pipelines de dados simplificados, com eficiência de espaço e automatizados a partir de fontes de dados em toda a empresa.  E o acesso multiprotocolo aos dados usando NAS e protocolos de objeto permite novos fluxos de trabalho otimizados para tarefas de ingestão e engenharia de dados.  Os pontos de verificação de dados e treinamento podem ser hierarquizados para armazenamento de menor custo para evitar o preenchimento do armazenamento primário.  Os clientes podem gerenciar, proteger e mobilizar dados facilmente, com o menor custo, em uma nuvem híbrida com um único sistema operacional de armazenamento e o pacote de serviços de dados mais completo do setor.</block>
  <block id="3a6d4fa926afe309c404561a18033103" category="list-text">*Segurança.*  O NVIDIA DGX SuperPOD com NetApp ONTAP Storage oferece segurança de nível empresarial por meio de várias camadas de proteção.  No nível de infraestrutura, a solução implementa mecanismos robustos de controle de acesso, incluindo controle de acesso baseado em função (RBAC), autenticação multifator e recursos detalhados de registro de auditoria.  A estrutura abrangente de criptografia da plataforma protege dados em repouso e em trânsito, utilizando protocolos e algoritmos padrão do setor para proteger a propriedade intelectual e manter a conformidade com os requisitos regulatórios.  Ferramentas integradas de monitoramento de segurança fornecem visibilidade em tempo real de potenciais ameaças à segurança, enquanto mecanismos de resposta automatizados ajudam a mitigar riscos antes que eles possam impactar as operações.  O NetApp ONTAP é o único armazenamento empresarial reforçado validado para armazenar dados ultrassecretos.</block>
  <block id="5a79514564c762f34f82d2f86ba269f6" category="list-text">*Multilocação*.  O NetApp ONTAP oferece a mais ampla gama de recursos para permitir o uso seguro de recursos de armazenamento por vários locatários.  As máquinas virtuais de armazenamento fornecem delegação administrativa baseada em locatário com controles RBAC. Controles abrangentes de QoS garantem o desempenho para cargas de trabalho críticas, ao mesmo tempo em que permitem a utilização máxima, e recursos de segurança, como chaves gerenciadas por locatário para criptografia em nível de volume, garantem a segurança dos dados em mídia de armazenamento compartilhada.</block>
  <block id="234fe3186330a0015f240eaa46026f52" category="inline-link">+++ Documento técnico do ONTAP RASS +++</block>
  <block id="aa2c50d70660a4e07e28a4a1e62cbbeb" category="list-text">*Confiabilidade.*  A NetApp elimina interrupções em operações de missão crítica por meio de recursos avançados de confiabilidade, disponibilidade, capacidade de manutenção e capacidade de gerenciamento (RASM), proporcionando o maior tempo de atividade disponível.  Para mais informações, consulte o<block ref="06c9743ea9b1147ff9ba8b6afddf02b3" category="inline-link-rx"></block> .  Além disso, a saúde do sistema pode ser otimizada com análises preditivas baseadas em IA fornecidas pelo Active IQ e pelo Data Infrastructure Insights.</block>
  <block id="dbefda683c705de53408671cbbab4e34" category="section-title">Sistemas NVIDIA DGX B200</block>
  <block id="c2e6165182afeb3c2d3013f3389087b6" category="inline-link">+++NVIDIA+++</block>
  <block id="2ed6f2103f37f8b4eec016533f493515" category="inline-link">+++NVLink(™)+++</block>
  <block id="1697b07c98d5b223a74b615c776f0b65" category="inline-link">+++ NVIDIA Blackwell+++</block>
  <block id="5e923560ec7f11fe71232bd344d8d81a" category="inline-link">+++arquitetura+++</block>
  <block id="f7be9a2901218b858c97cd4113fbc2aa" category="paragraph">NVIDIA DGX™ B200 é uma plataforma de IA unificada para pipelines de desenvolvimento para implantação para empresas de qualquer tamanho e em qualquer estágio de sua jornada de IA.  Equipado com oito GPUs NVIDIA Blackwell interconectadas com processadores de quinta geração<block ref="8d33a92989a52a298d52379f9acef95c" category="inline-link-rx"></block><block ref="66ff52a072f2c292b9f50112a8543358" category="inline-link-rx"></block> O DGX B200 oferece desempenho de ponta, oferecendo 3 vezes mais desempenho de treinamento e 15 vezes mais desempenho de inferência do que as gerações anteriores.  Aproveitando o<block ref="113af14b044c5bd4dc15be4b6100b100" category="inline-link-rx"></block><block ref="adaec91c8092748fe326913de2b3a1f0" category="inline-link-rx"></block> O DGX B200 pode lidar com diversas cargas de trabalho, incluindo grandes modelos de linguagem, sistemas de recomendação e chatbots, tornando-o ideal para empresas que buscam acelerar sua transformação de IA.</block>
  <block id="f94ad1ea1a52dd514a5e42a7eec71e94" category="section-title">Switches Ethernet NVIDIA Spectrum SN5600</block>
  <block id="a1bd19971bc35fdd30c6a0b2eee21865" category="paragraph">O switch SN5600 smart-leaf, spine e super-spine oferece 64 portas de 800GbE em um formato denso de 2U.  O SN5600 permite designs de folha/espinha padrão com switches de topo de rack (ToR) e topologias de fim de linha (EoR).  O SN5600 oferece conectividade diversificada em combinações de 1 a 800 GbE e ostenta uma taxa de transferência total líder do setor de 51,2 Tb/s.</block>
  <block id="ffe61852985d936bb555e1c150a3feca" category="section-title">Software NVIDIA Base Command</block>
  <block id="040380b5657454a9d0ce1064c83dd667" category="paragraph">O NVIDIA Base Command™ impulsiona a plataforma NVIDIA DGX, permitindo que as organizações aproveitem o melhor da inovação de IA da NVIDIA .  Com ele, cada organização pode explorar todo o potencial de sua infraestrutura DGX com uma plataforma comprovada que inclui gerenciamento de fluxo de trabalho de IA, gerenciamento de cluster de nível empresarial, bibliotecas que aceleram a computação, o armazenamento e a infraestrutura de rede, e software de sistema otimizado para executar cargas de trabalho de IA.  A Figura 2 mostra a pilha de software do NVIDIA Base Command.</block>
  <block id="9620c8c92a535942ede6a202c5bf5b0d" category="paragraph">Figura 2) Software NVIDIA Base Command.</block>
  <block id="2e15a851530c5d474531243cfd838752" category="paragraph"><block ref="2e15a851530c5d474531243cfd838752" category="inline-image-macro-rx" type="image"></block></block>
  <block id="651beb53a2e8224545ff56fc0d0efd02" category="paragraph">O NVIDIA Base Command Manager oferece implantação rápida e gerenciamento de ponta a ponta para clusters heterogêneos de IA e computação de alto desempenho (HPC) na borda, no data center e em ambientes de nuvem múltipla e híbrida.  Ele automatiza o provisionamento e a administração de clusters que variam em tamanho de alguns nós a centenas de milhares, oferece suporte a sistemas acelerados por GPU NVIDIA e outros, e permite a orquestração com o Kubernetes.  A integração dos sistemas de armazenamento NetApp AFF A90 com o DGX SuperPOD requer configuração mínima do Base Command Manager para ajuste do sistema e parâmetros de montagem para desempenho ideal, mas nenhum software adicional é necessário para fornecer acesso multicaminho altamente disponível entre os sistemas DGX e o sistema de armazenamento AFF A90 .</block>
  <block id="24f67e93854c90d735466339a375c002" category="paragraph">O NVIDIA DGX SuperPOD foi projetado para atender aos requisitos de desempenho das cargas de trabalho mais exigentes em maior escala.</block>
  <block id="cfc814162b41538ad397b897a24c4937" category="list-text">Treinamento de modelos de inteligência artificial para modelos de grande linguagem, visão computacional/classificação de imagens, detecção de fraudes e inúmeros outros casos de uso.</block>
  <block id="607aa89216cc994d4e20cfce8695d306" category="list-text">Computação de alto desempenho, como análise sísmica, dinâmica de fluidos computacional e visualização em larga escala.</block>
  <block id="9f6302143996033ebb94d536b860acc3" category="section-title">Arquitetura da Solução</block>
  <block id="d0eadc16af6d6df8893f37be51ed2bc6" category="paragraph">O DGX SuperPOD é baseado no conceito de uma Unidade Escalável (SU) que inclui 32 sistemas DGX B200 e todos os outros componentes necessários para fornecer a conectividade necessária e eliminar quaisquer gargalos de desempenho na infraestrutura.  Os clientes podem começar com uma ou várias SUs e adicionar SUs adicionais conforme necessário para atender às suas necessidades.  Este documento descreve a configuração de armazenamento para uma única SU, e a Tabela 1 mostra os componentes necessários para configurações maiores.</block>
  <block id="2a4a6621abe5b6f39b1534ead593f20a" category="inline-link">+++ Arquitetura de referência NVIDIA DGX SuperPOD +++</block>
  <block id="60696b15e8be9fd24231177ac611836f" category="paragraph">A arquitetura de referência do DGX SuperPOD inclui várias redes, e o sistema de armazenamento AFF A90 está conectado a várias delas.  Para obter mais informações sobre a rede DGX SuperPOD, consulte o<block ref="562b92094dd1a3e9b7e68b6a6fb7de81" category="inline-link-rx"></block> .</block>
  <block id="fdd68d018aab06584c6bc4e8351fa72b" category="paragraph">Para esta solução, a estrutura de armazenamento de alto desempenho é uma rede Ethernet baseada no switch NVIDIA Spectrum SN5600 com 64 portas de 800 Gb em uma configuração Spine/Leaf.  A rede em banda fornece acesso do usuário para outras funções, como diretórios pessoais e compartilhamentos gerais de arquivos, e também é baseada em switches SN5600, enquanto a rede fora de banda (OOB) é para acesso do administrador do sistema no nível do dispositivo usando switches SN2201.</block>
  <block id="3a812cac2db0a2d9638c3b252cc24b8e" category="paragraph">A estrutura de armazenamento é uma arquitetura leaf-spine onde os sistemas DGX se conectam a um par de switches leaf e o sistema de armazenamento se conecta a outro par de switches leaf.  Várias portas de 800 Gb são usadas para conectar cada switch leaf a um par de switches spine, criando vários caminhos de alta largura de banda pela rede para desempenho agregado e redundância.  Para conectividade com o sistema de armazenamento AFF A90 , cada porta de 800 Gb é dividida em quatro portas de 200 Gb usando cabos de cobre ou ópticos apropriados.  Para dar suporte aos clientes que montam o sistema de armazenamento com NFS sobre RDMA, a estrutura de armazenamento é configurada para RDMA sobre Ethernet convergente (RoCE), o que garante a entrega de pacotes sem perdas na rede.  A Figura 3 mostra a topologia de rede de armazenamento desta solução.</block>
  <block id="6a53d316acbe58b01a749e96481412aa" category="paragraph">Figura 3) Topologia de estrutura de armazenamento.</block>
  <block id="00031e516cb8c09c104ebdb164264d7f" category="paragraph"><block ref="00031e516cb8c09c104ebdb164264d7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="316d243b972562ec3f8d06fcd980b1d6" category="paragraph">O sistema de armazenamento NetApp AFF A90 é um chassi 4RU contendo 2 controladores que operam como parceiros de alta disponibilidade (par HA) um para o outro, com até 48 discos de estado sólido (SSD) de formato de 2,5 polegadas.  Cada controlador é conectado aos dois switches leaf de armazenamento SN5600 usando quatro conexões Ethernet de 200 Gb, e há duas interfaces IP lógicas em cada porta física.  O cluster de armazenamento oferece suporte ao NFS v4.1 com NFS Paralelo (pNFS), que permite que os clientes estabeleçam conexões diretamente com cada controlador no cluster.  Além disso, o entroncamento de sessão combina o desempenho de várias interfaces físicas em uma única sessão, permitindo que até mesmo cargas de trabalho de thread único acessem mais largura de banda de rede do que é possível com a vinculação Ethernet tradicional. A combinação de todos esses recursos com RDMA permite que o sistema de armazenamento AFF A90 ofereça baixa latência e alto rendimento que pode ser dimensionado linearmente para cargas de trabalho que utilizam o NVIDIA GPUDirect Storage™.</block>
  <block id="2ecf799238706280879a7218f5c9384f" category="paragraph">Para conectividade com a rede em banda, os controladores AFF A90 têm interfaces Ethernet adicionais de 200 Gb configuradas em um grupo de interface LACP, fornecendo serviços gerais NFS v3 e v4, bem como acesso S3 a sistemas de arquivos compartilhados, se desejado.  Todos os controladores e switches do cluster de armazenamento são conectados à rede OOB para acesso administrativo remoto.</block>
  <block id="242354762ac710a9d168daccad8ea40d" category="paragraph">Para permitir alto desempenho e escalabilidade, os controladores de armazenamento formam um cluster de armazenamento que permite que todo o desempenho e capacidade dos nós do cluster sejam combinados em um único namespace chamado FlexGroup , com dados distribuídos entre os discos de cada nó do cluster.  Com o novo recurso de Distribuição de Dados Granulares lançado no ONTAP 9.16.1, arquivos individuais são separados e distribuídos pelo FlexGroup para permitir os mais altos níveis de desempenho para cargas de trabalho de arquivo único.  A Figura 4 abaixo mostra como o pNFS e o entroncamento de sessão NFS funcionam em conjunto com FlexGroups e GDD para permitir acesso paralelo a arquivos grandes, aproveitando todas as interfaces de rede e discos no sistema de armazenamento.</block>
  <block id="c3c4a8bbb2b351b3bf984cb2d6864b94" category="paragraph">Figura 4) pNFS, entroncamento de sessão, FlexGroups e GDD.</block>
  <block id="4f30b88a042ae485248ebaa1099b4a91" category="paragraph"><block ref="4f30b88a042ae485248ebaa1099b4a91" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ac50512926081a099344a18f27b3818" category="paragraph">Esta solução utiliza várias Máquinas Virtuais de Armazenamento (SVM) para hospedar volumes para acesso de armazenamento de alto desempenho, bem como diretórios pessoais de usuários e outros artefatos de cluster em uma SVM de gerenciamento.  Cada SVM é configurado com interfaces de rede e volumes FlexGroup e a política de QoS é implementada para garantir o desempenho do SVM de dados.  Para obter mais informações sobre FlexGroups, máquinas virtuais de armazenamento e recursos de QoS ONTAP , consulte o<block ref="619babf0e51393513dd3986ae0aee969" category="inline-link-rx"></block> .</block>
  <block id="2a57ec7828afba5c513d03e967cb3884" category="section-title">Requisitos de hardware da solução</block>
  <block id="b761a63ce0a1bd27710c7207a50b8577" category="paragraph">A Tabela 1 lista os componentes de hardware de armazenamento necessários para implementar uma, duas, quatro ou oito unidades escaláveis.  Para requisitos detalhados de hardware para servidores e redes, consulte o<block ref="b8ab7d3cc54802757d9a49bb252840ab" category="inline-link-rx"></block> .</block>
  <block id="a7504f8a3068ecf26f816d83dfcae5a8" category="cell">Tamanho SU</block>
  <block id="eb94f28ae18769ccde6259223dde0683" category="cell">Sistemas AFF A90</block>
  <block id="258b220fa2ed31020ab102479476e757" category="cell">Switches de interconexão de cluster de armazenamento</block>
  <block id="9254819941449b706e4282e2f2e6a7b9" category="cell">Capacidade utilizável (típica com SSD de 3,8 TB)</block>
  <block id="eb17bb52c3b173b3911725d1c9a194f0" category="cell">Capacidade máxima utilizável (com SSD NVMe de 15,3 TB)</block>
  <block id="c9d196f41b3911fefebc23e6efbc32f4" category="cell">RU (típico)</block>
  <block id="1fec42eb0945f00ee2125c78858d7366" category="cell">Potência (típica)</block>
  <block id="f04a7a4ef42eb207cec5a3d7fcc9d3fa" category="cell">555 TB</block>
  <block id="104bf07415681a49e985f5dd5895d4d6" category="cell">13.75PB</block>
  <block id="4f10ff6d954a760dbf5b59fb54597722" category="cell">7.300 watts</block>
  <block id="830daef3058bf009b39d03050f58f3f4" category="cell">27.5PB</block>
  <block id="62aa76bddc36c76968deb0ae09c8063f" category="cell">14.600 watts</block>
  <block id="76a4dd9b098f9a8877b8b79d0c80c5d3" category="cell">2PB</block>
  <block id="3b07c527868f20c47db7e08e0e02ced5" category="cell">55PB</block>
  <block id="f4680500c767e37e35c38315af80e9f9" category="cell">29.200 watts</block>
  <block id="e79a79f20fe06b0beb657745cf11949a" category="cell">4PB</block>
  <block id="1609fc8f39b0baac216cbb19fb420ef2" category="cell">110PB</block>
  <block id="ec8956637a99787bd197eacd77acce5e" category="cell">102</block>
  <block id="bc6012118a1ec87da87af67c6b3a0f74" category="cell">58.400 watts</block>
  <block id="0f37a7e60b292d864a5ac969ec04cc27" category="paragraph">*OBSERVAÇÃO:* A NetApp recomenda um mínimo de 24 unidades por par AFF A90 HA para desempenho máximo.  Unidades internas adicionais, unidades de maior capacidade e prateleiras de unidades de expansão externas permitem uma capacidade agregada muito maior sem impacto no desempenho do sistema.</block>
  <block id="d3469c07f7acce56e0d039ec0b164141" category="paragraph">A Tabela 2 lista os componentes de software e versões necessários para integrar o sistema de armazenamento AFF A90 com o DGX SuperPOD.  O DGX SuperPOD também envolve outros componentes de software que não estão listados aqui.  Por favor, consulte o<block ref="2523a697ed64d9038adf903273ea5150" category="inline-link-rx"></block> para obter detalhes completos.</block>
  <block id="0bd0e673df4c14cae45a11fac30c530b" category="cell">9.16.1</block>
  <block id="dbc8a3aaafc47a649eed1dcc0bc5155e" category="cell">10.24.11</block>
  <block id="c6d4f54ff5f7e221a70cdd46daa396b3" category="cell">6.3.1</block>
  <block id="09e619b353cb3d3ca08701e294bb9047" category="cell">MLNX_OFED_LINUX-23.10.3.2.0 LTS</block>
  <block id="51eed8fde1839744a1b920b0dacb0a0a" category="cell">5,10</block>
  <block id="f11a60eea5a7abfd75bb28890eaef1ec" category="paragraph">Esta solução de armazenamento foi validada em vários estágios pela NetApp e pela NVIDIA para garantir que o desempenho e a escalabilidade atendam aos requisitos do NVIDIA DGX SuperPOD.  A configuração foi validada usando uma combinação de cargas de trabalho sintéticas e cargas de trabalho de ML/DL do mundo real para verificar o desempenho máximo e a interoperabilidade do aplicativo.  A Tabela 3 abaixo fornece exemplos de cargas de trabalho típicas e seus requisitos de dados que são comumente vistos em implantações do DGX SuperPOD.</block>
  <block id="e203df30cd7f31417aee170026e44f70" category="paragraph">Tabela 3) Exemplos de carga de trabalho do SuperPOD.</block>
  <block id="a0db49ba470c1c9ae2128c3470339153" category="cell">Nível</block>
  <block id="0ba48588b95eb9052082d27db3380801" category="cell">Descrição do Trabalho</block>
  <block id="c8ceada943dc5d58578660bf60d0762a" category="cell">Tamanho do conjunto de dados</block>
  <block id="eb6d8ae6f20283755b339c0dc273988b" category="cell">Padrão</block>
  <block id="c7f0dd1953999823199f993b956164f6" category="cell">Vários trabalhos simultâneos de treinamento de LLM ou ajuste fino e pontos de verificação periódicos, onde os requisitos de computação dominam significativamente os requisitos de E/S de dados.</block>
  <block id="f2db8117278a7bff3e0e0bff0571726d" category="cell">A maioria dos conjuntos de dados pode caber no cache de memória dos sistemas de computação locais durante o treinamento.  Os conjuntos de dados são de modalidade única e os modelos têm milhões de parâmetros.</block>
  <block id="53123044b4b65d0ad1b7ed0cfa4c3480" category="cell">Aprimorado</block>
  <block id="c9e72abf53e870d36e47df81d7f139bf" category="cell">Vários trabalhos de treinamento multimodal simultâneos e pontos de verificação periódicos, onde o desempenho de E/S de dados é um fator importante para o tempo de treinamento de ponta a ponta.</block>
  <block id="981d20fc47284a9be8695e715a3d1d47" category="cell">Os conjuntos de dados são grandes demais para caber no cache de memória dos sistemas de computação locais, exigindo mais E/S durante o treinamento, o que não é suficiente para evitar a necessidade de E/S frequentes.  Os conjuntos de dados têm múltiplas modalidades e os modelos têm bilhões (ou mais) de parâmetros.</block>
  <block id="255eebee8e38299d9f7282ffa8b76db3" category="paragraph">A Tabela 4 mostra diretrizes de desempenho para as cargas de trabalho de exemplo acima.  Esses valores representam a taxa de transferência de armazenamento que pode ser gerada por essas cargas de trabalho em condições ideais.</block>
  <block id="fe54d8f94c652ba49e4aba03f3107a9c" category="paragraph">Tabela 4) Diretrizes de desempenho do DGX SuperPOD.</block>
  <block id="f5bab93f6f25cd702dcbcb4aad615260" category="cell">Característica de desempenho</block>
  <block id="94f3edd272dbb778616c50e083536c63" category="cell">Padrão (GBps)</block>
  <block id="abaf1dc2e3d5bf424c74cd4566b0f1a3" category="cell">Aprimorado (GBps)</block>
  <block id="c5b9e837f1006565fbb01cd3b64d3df7" category="cell">Leitura do sistema de agregação SU único</block>
  <block id="3def184ad8f4755ff269862ea77393dd" category="cell">125</block>
  <block id="8eb042782ea4dd597d037482af02c144" category="cell">Gravação de sistema de agregação SU única</block>
  <block id="44f683a84163b3523afe57c2e008bc8c" category="cell">62</block>
  <block id="f53ce0357707bf3db713c9d71337529d" category="cell">4 leitura do sistema agregado SU</block>
  <block id="b73ce398c39f506af761d2277d853a92" category="cell">160</block>
  <block id="cee631121c2ec9232f3a2f028ad5c89b" category="cell">500</block>
  <block id="bc96df788d872dc23329bae80cc02619" category="cell">4 Sistema de agregação SU escreve</block>
  <block id="6c9882bbac1c7093bd25041881277658" category="cell">250</block>
  <block id="ef6f2913d5f1e19a1aa781a5d72d6caa" category="inline-link">Guia de implantação de sistemas de armazenamento NVA-1175 NVIDIA DGX SuperPOD com NetApp AFF A90</block>
  <block id="6f8af77cdc63a21a3e7b99a2511ed006" category="list-text"><block ref="6f8af77cdc63a21a3e7b99a2511ed006" category="inline-link-rx"></block></block>
  <block id="4498f6091821057a5b12bbe00bad6fb7" category="inline-link">Arquitetura de referência NVIDIA DGX B200 SuperPOD</block>
  <block id="e0ef89706b7f0268557664ed42040243" category="list-text"><block ref="e0ef89706b7f0268557664ed42040243" category="inline-link-rx"></block></block>
  <block id="076218ee0774bfaae3fcf92a3241a9fe" category="inline-link">Arquitetura de referência NVIDIA DGX H200 SuperPOD</block>
  <block id="b02d06e7da163e15a51f5a0277a72641" category="list-text"><block ref="b02d06e7da163e15a51f5a0277a72641" category="inline-link-rx"></block></block>
  <block id="e9cc843bc2157ef28fd2c0657e05a6f0" category="inline-link">Software NVIDIA BaseCommand</block>
  <block id="5b147f17197401088429ad2165ca94db" category="list-text"><block ref="5b147f17197401088429ad2165ca94db" category="inline-link-rx"></block></block>
  <block id="f6f89e67f0d14eefc85ee96a3de66d60" category="list-text"><block ref="f6f89e67f0d14eefc85ee96a3de66d60" category="inline-link-rx"></block></block>
  <block id="8365b73ca224de7f689b1708ed448af9" category="inline-link">+++ Documentação de soluções de IA da NetApp +++</block>
  <block id="aed2dde7ddb9cf045a1de05c19aa6fe6" category="list-text"><block ref="aed2dde7ddb9cf045a1de05c19aa6fe6" category="inline-link-rx"></block></block>
  <block id="4245faba305e62f6fdc30b1ce8bf8ac3" category="inline-link">+++ Instalação e manutenção de sistemas de armazenamento AFF da NetApp +++</block>
  <block id="bf45808f34c6dcc540de81441ed8372a" category="list-text"><block ref="bf45808f34c6dcc540de81441ed8372a" category="inline-link-rx"></block></block>
  <block id="51af5c28c5aeade3eeee8efe1cf0c265" category="list-text"><block ref="0b4edeca10dea88e1e3ff87f6aece04a" category="inline-link-rx"></block>(documento antigo com ótimas informações sobre pNFS)</block>
  <block id="e84f1067b5e0c62707fee9cec31ec6e6" category="sidebar">Sistemas de armazenamento NetApp AFF A90 com NVIDIA DGX SuperPOD - Design</block>
  <block id="ebe830dbdb267fd10b3f4000455f19f2" category="sidebar">Sistemas de armazenamento NetApp AFF A90 com NVIDIA DGX SuperPOD - Implantar</block>
</blocks>