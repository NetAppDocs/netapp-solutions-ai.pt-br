---
sidebar: sidebar 
permalink: data-analytics/hdcs-sh-use-case-backup.html 
keywords: use case 2, Hadoop repository, dr, disaster recovery 
summary: Neste cenário, o cliente tem um grande repositório Hadoop local e deseja fazer backup dele para fins de recuperação de desastres.  No entanto, a solução de backup atual do cliente é cara e sofre com uma longa janela de backup de mais de 24 horas. 
---
= Caso de uso 1: Fazendo backup de dados do Hadoop
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
Neste cenário, o cliente tem um grande repositório Hadoop local e deseja fazer backup dele para fins de recuperação de desastres.  No entanto, a solução de backup atual do cliente é cara e sofre com uma longa janela de backup de mais de 24 horas.



== Requisitos e desafios

Os principais requisitos e desafios para este caso de uso incluem:

* Compatibilidade com versões anteriores do software:
+
** A solução de backup alternativa proposta deve ser compatível com as versões atuais do software em execução usadas no cluster Hadoop de produção.


* Para cumprir os SLAs comprometidos, a solução alternativa proposta deve atingir RPOs e RTOs muito baixos.
* O backup criado pela solução de backup da NetApp pode ser usado no cluster Hadoop criado localmente no data center, bem como no cluster Hadoop em execução no local de recuperação de desastres no site remoto.
* A solução proposta deve ser econômica.
* A solução proposta deve reduzir o efeito no desempenho dos trabalhos analíticos em execução e em produção durante os períodos de backup.




== Solução de backup existente do cliente

A figura abaixo mostra a solução original de backup nativa do Hadoop.

image:hdcs-sh-005.png["Figura mostrando diálogo de entrada/saída ou representando conteúdo escrito"]

Os dados de produção são protegidos em fita por meio do cluster de backup intermediário:

* Os dados do HDFS1 são copiados para o HDFS2 executando o `hadoop distcp -update <hdfs1> <hdfs2>` comando.
* O cluster de backup atua como um gateway NFS e os dados são copiados manualmente para a fita por meio do Linux `cp` comando por meio da biblioteca de fitas.


Os benefícios da solução de backup nativa original do Hadoop incluem:

* A solução é baseada em comandos nativos do Hadoop, o que evita que o usuário tenha que aprender novos procedimentos.
* A solução aproveita arquitetura e hardware padrão do setor.


As desvantagens da solução de backup nativa original do Hadoop incluem:

* O longo tempo de janela de backup excede 24 horas, o que torna os dados de produção vulneráveis.
* Degradação significativa do desempenho do cluster durante os períodos de backup.
* Copiar para fita é um processo manual.
* A solução de backup é cara em termos de hardware necessário e horas humanas necessárias para processos manuais.




== Soluções de backup

Com base nesses desafios e requisitos, e levando em consideração o sistema de backup existente, três possíveis soluções de backup foram sugeridas.  As subseções a seguir descrevem cada uma dessas três soluções de backup diferentes, rotuladas de solução A a solução C.



=== Solução A

Na Solução A, o cluster de backup do Hadoop envia os backups secundários para os sistemas de armazenamento NetApp NFS, eliminando a necessidade de fita, conforme mostrado na figura abaixo.

image:hdcs-sh-006.png["Figura mostrando diálogo de entrada/saída ou representando conteúdo escrito"]

As tarefas detalhadas para a solução A incluem:

* O cluster de produção do Hadoop tem os dados analíticos do cliente no HDFS que exigem proteção.
* O cluster Hadoop de backup com HDFS atua como um local intermediário para os dados.  Apenas um conjunto de discos (JBOD) fornece o armazenamento para HDFS nos clusters Hadoop de produção e de backup.
* Proteja os dados de produção do Hadoop do cluster de produção HDFS para o cluster de backup HDFS executando o `Hadoop distcp –update –diff <hdfs1> <hdfs2>` comando.



NOTE: O snapshot do Hadoop é usado para proteger os dados da produção para o cluster de backup do Hadoop.

* O controlador de armazenamento NetApp ONTAP fornece um volume exportado NFS, que é provisionado para o cluster Hadoop de backup.
* Ao executar o `Hadoop distcp` comando aproveitando o MapReduce e vários mapeadores, os dados analíticos são protegidos do cluster Hadoop de backup para o NFS.
+
Depois que os dados são armazenados no NFS no sistema de armazenamento NetApp , as tecnologias NetApp Snapshot, SnapRestore e FlexClone são usadas para fazer backup, restaurar e duplicar os dados do Hadoop, conforme necessário.




NOTE: Os dados do Hadoop podem ser protegidos na nuvem, bem como em locais de recuperação de desastres, usando a tecnologia SnapMirror .

Os benefícios da solução A incluem:

* Os dados de produção do Hadoop são protegidos do cluster de backup.
* Os dados do HDFS são protegidos pelo NFS, permitindo proteção em locais de nuvem e recuperação de desastres.
* Melhora o desempenho transferindo as operações de backup para o cluster de backup.
* Elimina operações manuais de fita
* Permite funções de gerenciamento empresarial por meio de ferramentas NetApp .
* Requer mudanças mínimas no ambiente existente.
* É uma solução econômica.


A desvantagem dessa solução é que ela requer um cluster de backup e mapeadores adicionais para melhorar o desempenho.

O cliente implantou recentemente a solução A devido à sua simplicidade, custo e desempenho geral.

Nesta solução, discos SAN do ONTAP podem ser usados em vez de JBOD.  Esta opção transfere a carga de armazenamento do cluster de backup para o ONTAP; no entanto, a desvantagem é que são necessários switches de malha SAN.



=== Solução B

A solução B adiciona um volume NFS ao cluster de produção do Hadoop, o que elimina a necessidade do cluster de backup do Hadoop, conforme mostrado na figura abaixo.

image:hdcs-sh-007.png["Figura mostrando diálogo de entrada/saída ou representando conteúdo escrito"]

As tarefas detalhadas para a solução B incluem:

* O controlador de armazenamento NetApp ONTAP provisiona a exportação NFS para o cluster de produção do Hadoop.
+
O nativo do Hadoop `hadoop distcp` O comando protege os dados do Hadoop do cluster de produção HDFS para NFS.

* Depois que os dados são armazenados no NFS no sistema de armazenamento NetApp , as tecnologias Snapshot, SnapRestore e FlexClone são usadas para fazer backup, restaurar e duplicar os dados do Hadoop, conforme necessário.


Os benefícios da solução B incluem:

* O cluster de produção é ligeiramente modificado para a solução de backup, o que simplifica a implementação e reduz o custo adicional de infraestrutura.
* Não é necessário um cluster de backup para a operação de backup.
* Os dados de produção do HDFS são protegidos na conversão para dados NFS.
* A solução permite funções de gerenciamento empresarial por meio de ferramentas NetApp .


A desvantagem dessa solução é que ela é implementada no cluster de produção, o que pode adicionar tarefas adicionais de administrador no cluster de produção.



=== Solução C

Na solução C, os volumes NetApp SAN são provisionados diretamente no cluster de produção do Hadoop para armazenamento HDFS, conforme mostrado na figura abaixo.

image:hdcs-sh-008.png["Figura mostrando diálogo de entrada/saída ou representando conteúdo escrito"]

As etapas detalhadas para a solução C incluem:

* O armazenamento NetApp ONTAP SAN é provisionado no cluster Hadoop de produção para armazenamento de dados HDFS.
* As tecnologias NetApp Snapshot e SnapMirror são usadas para fazer backup dos dados HDFS do cluster de produção do Hadoop.
* Não há efeito de desempenho na produção do cluster Hadoop/Spark durante o processo de backup da cópia do Snapshot porque o backup está na camada de armazenamento.



NOTE: A tecnologia Snapshot fornece backups concluídos em segundos, independentemente do tamanho dos dados.

Os benefícios da solução C incluem:

* É possível criar backups com economia de espaço usando a tecnologia Snapshot.
* Permite funções de gerenciamento empresarial por meio de ferramentas NetApp .

