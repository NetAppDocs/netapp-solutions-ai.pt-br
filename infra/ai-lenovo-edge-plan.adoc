---
sidebar: sidebar 
permalink: infra/ai-lenovo-edge-plan.html 
keywords: test, plan, mlperf, inference, benchmarks 
summary: Este documento segue o código e as regras do MLPerf Inference v0.7, do MLPerf Inference v1.1.  Executamos benchmarks projetados para inferência na borda, conforme definido nas tabelas apresentadas nesta seção. 
---
= Plano de teste
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
Este documento segue o MLPerf Inference v0.7 https://github.com/mlperf/inference_results_v0.7/tree/master/closed/Lenovo["código"^] , Inferência MLPerf v1.1 https://github.com/mlcommons/inference_results_v1.1/tree/main/closed/Lenovo["código"^] , e https://github.com/mlcommons/inference_policies/blob/master/inference_rules.adoc["regras"^] .  Executamos benchmarks MLPerf projetados para inferência na borda, conforme definido na tabela a seguir.

|===
| Área | Tarefa | Modelo | Conjunto de dados | Tamanho QSL | Qualidade | Restrição de latência multistream 


| Visão | Classificação de imagens | Resnet50v1.5 | ImageNet (224x224) | 1024 | 99% do FP32 | 50 ms 


| Visão | Detecção de objetos (grandes) | SSD- ResNet34 | COCO (1200x1200) | 64 | 99% do FP32 | 66 ms 


| Visão | Detecção de objetos (pequenos) | SSD- MobileNetsv1 | COCO (300x300) | 256 | 99% do FP32 | 50 ms 


| Visão | Segmentação de imagens médicas | 3D UNET | BraTS 2019 (224x224x160) | 16 | 99% e 99,9% do FP32 | n / D 


| Discurso | Conversão de fala em texto | RNNT | Librispeech dev-clean | 2513 | 99% do FP32 | n / D 


| Linguagem | Processamento de linguagem | BERTO | Esquadrão v1.1 | 10833 | 99% do FP32 | n / D 
|===
A tabela a seguir apresenta cenários de benchmark do Edge.

|===
| Área | Tarefa | Cenários 


| Visão | Classificação de imagens | Transmissão única, offline, multitransmissão 


| Visão | Detecção de objetos (grandes) | Transmissão única, offline, multitransmissão 


| Visão | Detecção de objetos (pequenos) | Transmissão única, offline, multitransmissão 


| Visão | Segmentação de imagens médicas | Transmissão única, offline 


| Discurso | Conversão de fala em texto | Transmissão única, offline 


| Linguagem | Processamento de linguagem | Transmissão única, offline 
|===
Realizamos esses benchmarks usando a arquitetura de armazenamento em rede desenvolvida nesta validação e comparamos os resultados com aqueles de execuções locais nos servidores de borda enviados anteriormente ao MLPerf.  A comparação serve para determinar quanto impacto o armazenamento compartilhado tem no desempenho da inferência.
